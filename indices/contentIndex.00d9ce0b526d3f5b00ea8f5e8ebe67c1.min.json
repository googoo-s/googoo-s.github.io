{"/":{"title":"_index","content":"\n\nHello !😀😘😆😂😁\n\n\n\n\n\n\n# Obsidian\n\n* [[Obsidian/dataview]]\n\n- [[Obsidian/excalidraw]]\n\n- [[Obsidian/Front Matter]]\n\n- [[Obsidian/obsidian overview]]\n\n- [[Obsidian/Obsidian-plugin]]\n\n- [[Obsidian/publish]]\n\n- [[Obsidian/template]]\n\n\n# Lua\n\n- [[lua/lua基础]]\n\n- [[lua/Lua高级]]\n\n","lastmodified":"2023-08-02T03:10:42.044088141Z","tags":[]},"/%E5%88%86%E5%B8%83%E5%BC%8F%E9%AB%98%E5%B9%B6%E5%8F%91%E9%AB%98%E6%80%A7%E8%83%BD%E9%AB%98%E5%8F%AF%E7%94%A8/%E6%97%A5%E5%BF%97/%E6%9C%8D%E5%8A%A1%E6%B2%BB%E7%90%86%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%8B%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86":{"title":"服务治理：分布式下如何进行日志管理？","content":"![](statistic/Pasted%20image%2020230802010117.png)","lastmodified":"2023-08-02T03:10:42.496093621Z","tags":[]},"/%E5%88%86%E5%B8%83%E5%BC%8F%E9%AB%98%E5%B9%B6%E5%8F%91%E9%AB%98%E6%80%A7%E8%83%BD%E9%AB%98%E5%8F%AF%E7%94%A8/%E7%9B%91%E6%8E%A7/%E6%9C%8D%E5%8A%A1%E6%B2%BB%E7%90%86%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E5%A6%82%E4%BD%95%E5%81%9A":{"title":"服务治理：监控系统如何做？","content":"![](statistic/Pasted%20image%2020230802010009.png)","lastmodified":"2023-08-02T03:10:42.496093621Z","tags":[]},"/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/git/git":{"title":"git","content":"\n## 版本控制\n\n### 什么是版本控制\n\n版本控制是一种记录一个或若干文件内容变化，以便将来查阅特定版本修订情况的系统。除了项目源代码，你可以对任何类型的文件进行版本控制。\n\n### 为什么要版本控制\n\n有了它你就可以将某个文件回溯到之前的状态，甚至将整个项目都回退到过去某个时间点的状态，你可以比较文件的变化细节，查出最后是谁修改了哪个地方，从而找出导致怪异问题出现的原因，又是谁在何时报告了某个功能缺陷等等。\n\n### 本地版本控制系统\n\n许多人习惯用复制整个项目目录的方式来保存不同的版本，或许还会改名加上备份时间以示区别。这么做唯一的好处就是简单，但是特别容易犯错。有时候会混淆所在的工作目录，一不小心会写错文件或者覆盖意想外的文件。\n\n为了解决这个问题，人们很久以前就开发了许多种本地版本控制系统，大多都是采用某种简单的数据库来记录文件的历次更新差异。\n\n![本地版本控制系统](statistic/本地版本控制系统.png)\n\n### 集中化的版本控制系统\n\n接下来人们又遇到一个问题，如何让在不同系统上的开发者协同工作？ 于是，集中化的版本控制系统（Centralized Version Control Systems，简称 CVCS）应运而生。\n\n集中化的版本控制系统都有一个单一的集中管理的服务器，保存所有文件的修订版本，而协同工作的人们都通过客户端连到这台服务器，取出最新的文件或者提交更新。\n\n![集中化的版本控制系统](statistic/集中化的版本控制系统.png)\n\n这么做虽然解决了本地版本控制系统无法让在不同系统上的开发者协同工作的诟病，但也还是存在下面的问题：\n\n- **单点故障：** 中央服务器宕机，则其他人无法使用；如果中心数据库磁盘损坏又没有进行备份，你将丢失所有数据。本地版本控制系统也存在类似问题，只要整个项目的历史记录被保存在单一位置，就有丢失所有历史更新记录的风险。\n- **必须联网才能工作：** 受网络状况、带宽影响。\n\n### 分布式版本控制系统\n\n于是分布式版本控制系统（Distributed Version Control System，简称 DVCS）面世了。 Git 就是一个典型的分布式版本控制系统。\n\n这类系统，客户端并不只提取最新版本的文件快照，而是把代码仓库完整地镜像下来。这么一来，任何一处协同工作用的服务器发生故障，事后都可以用任何一个镜像出来的本地仓库恢复。因为每一次的克隆操作，实际上都是一次对代码仓库的完整备份。\n\n![分布式版本控制系统](statistic/分布式版本控制系统.png)\n\n分布式版本控制系统可以不用联网就可以工作，因为每个人的电脑上都是完整的版本库，当你修改了某个文件后，你只需要将自己的修改推送给别人就可以了。但是，在实际使用分布式版本控制系统的时候，很少会直接进行推送修改，而是使用一台充当“中央服务器”的东西。这个服务器的作用仅仅是用来方便“交换”大家的修改，没有它大家也一样干活，只是交换修改不方便而已。\n\n分布式版本控制系统的优势不单是不必联网这么简单，后面我们还会看到 Git 极其强大的分支管理等功能。\n\n## 认识 Git\n\n### Git 简史\n\nLinux 内核项目组当时使用分布式版本控制系统 BitKeeper 来管理和维护代码。但是，后来开发 BitKeeper 的商业公司同 Linux 内核开源社区的合作关系结束，他们收回了 Linux 内核社区免费使用 BitKeeper 的权力。 Linux 开源社区（特别是 Linux 的缔造者 Linus Torvalds）基于使用 BitKeeper 时的经验教训，开发出自己的版本系统，而且对新的版本控制系统做了很多改进。\n\n### Git 与其他版本管理系统的主要区别\n\nGit 在保存和对待各种信息的时候与其它版本控制系统有很大差异，尽管操作起来的命令形式非常相近，理解这些差异将有助于防止你使用中的困惑。\n\n下面我们主要说一个关于 Git 与其他版本管理系统的主要差别：**对待数据的方式**。\n\n**Git 采用的是直接记录快照的方式，而非差异比较。我后面会详细介绍这两种方式的差别。**\n\n大部分版本控制系统（CVS、Subversion、Perforce、Bazaar 等等）都是以文件变更列表的方式存储信息，这类系统**将它们保存的信息看作是一组基本文件和每个文件随时间逐步累积的差异。**\n\n具体原理如下图所示，理解起来其实很简单，每当我们提交更新一个文件之后，系统都会记录这个文件做了哪些更新，以增量符号 Δ(Delta)表示。\n\n![](statistic/2019-3deltas.png)\n\n**我们怎样才能得到一个文件的最终版本呢？**\n\n很简单，高中数学的基本知识，我们只需要将这些原文件和这些增加进行相加就行了。\n\n**这种方式有什么问题呢？**\n\n比如我们的增量特别特别多的话，如果我们要得到最终的文件是不是会耗费时间和性能。\n\nGit 不按照以上方式对待或保存数据。反之，Git 更像是把数据看作是对小型文件系统的一组快照。每次你提交更新，或在 Git 中保存项目状态时，它主要对当时的全部文件制作一个快照并保存这个快照的索引。为了高效，如果文件没有修改，Git 不再重新存储该文件，而是只保留一个链接指向之前存储的文件。 Git 对待数据更像是一个 **快照流**。\n\n![](statistic/2019-3snapshots.png)\n\n### Git 的三种状态\n\nGit 有三种状态，你的文件可能处于其中之一：\n\n1. **已提交（committed）**：数据已经安全的保存在本地数据库中。\n2. **已修改（modified）**：已修改表示修改了文件，但还没保存到数据库中。\n3. **已暂存（staged）**：表示对一个已修改文件的当前版本做了标记，使之包含在下次提交的快照中。\n\n由此引入 Git 项目的三个工作区域的概念：**Git 仓库 (. Git directory)**、**工作目录 (Working Directory)** 以及 **暂存区域 (Staging Area)** 。\n\n![](statistic/2019-3areas.png)\n\n**基本的 Git 工作流程如下：**\n\n1. 在工作目录中修改文件。\n2. 暂存文件，将文件的快照放入暂存区域。\n3. 提交更新，找到暂存区域的文件，将快照永久性存储到 Git 仓库目录。\n\n## Git 使用快速入门\n\n### 获取 Git 仓库\n\n有两种取得 Git 项目仓库的方法。\n\n1. 在现有目录中初始化仓库: 进入项目目录运行 `git init` 命令, 该命令将创建一个名为 `.git` 的子目录。\n2. 从一个服务器克隆一个现有的 Git 仓库: `git clone [url]` 自定义本地仓库的名字: `git clone [url] directoryname`\n\n### 记录每次更新到仓库\n\n1. **检测当前文件状态** : `git status`\n2. **提出更改（把它们添加到暂存区**）：`git add filename` (针对特定文件)、`git add *` (所有文件)、`git add *.txt`（支持通配符，所有 .txt 文件）\n3. **忽略文件**：`.gitignore` 文件\n4. **提交更新:** `git commit -m \"代码提交信息\"` （每次准备提交前，先用 `git status` 看下，是不是都已暂存起来了，然后再运行提交命令 `git commit`）\n5. **跳过使用暂存区域更新的方式** : `git commit -a -m \"代码提交信息\"`。 `git commit` 加上 `-a` 选项，Git 就会自动把所有已经跟踪过的文件暂存起来一并提交，从而跳过 `git add` 步骤。\n6. **移除文件**：`git rm filename` （从暂存区域移除，然后提交。）\n7. **对文件重命名**：`git mv README.md README` (这个命令相当于 `mv README.md README`、`git rm README.md`、`git add README` 这三条命令的集合)\n\n### 一个好的 Git 提交消息\n\n一个好的 Git 提交消息如下：\n\n```\n标题行：用这一行来描述和解释你的这次提交\n\n主体部分可以是很少的几行，来加入更多的细节来解释提交，最好是能给出一些相关的背景或者解释这个提交能修复和解决什么问题。\n\n主体部分当然也可以有几段，但是一定要注意换行和句子不要太长。因为这样在使用 \"git log\" 的时候会有缩进比较好看。\n```\n\n提交的标题行描述应该尽量的清晰和尽量的一句话概括。这样就方便相关的 Git 日志查看工具显示和其他人的阅读。\n\n### 推送改动到远程仓库\n\n- 如果你还没有克隆现有仓库，并欲将你的仓库连接到某个远程服务器，你可以使用如下命令添加：`git remote add origin \u003cserver\u003e` ,比如我们要让本地的一个仓库和 GitHub 上创建的一个仓库关联可以这样 `git remote add origin https://github.com/Snailclimb/test.git`\n- 将这些改动提交到远端仓库：`git push origin master` (可以把 _master_ 换成你想要推送的任何分支)\n\n  如此你就能够将你的改动推送到所添加的服务器上去了。\n\n### 远程仓库的移除与重命名\n\n- 将 test 重命名为 test 1：`git remote rename test test 1`\n- 移除远程仓库 test 1:`git remote rm test 1`\n\n### 查看提交历史\n\n在提交了若干更新，又或者克隆了某个项目之后，你也许想回顾下提交历史。完成这个任务最简单而又有效的工具是 `git log` 命令。`git log` 会按提交时间列出所有的更新，最近的更新排在最上面。\n\n**可以添加一些参数来查看自己希望看到的内容：**\n\n只看某个人的提交记录：\n\n```shell\nGit log --author=bob\n```\n\n### 撤销操作\n\n有时候我们提交完了才发现漏掉了几个文件没有添加，或者提交信息写错了。此时，可以运行带有 `--amend` 选项的提交命令尝试重新提交：\n\n```shell\nGit commit --amend\n```\n\n取消暂存的文件\n\n```shell\nGit reset filename\n```\n\n撤消对文件的修改:\n\n```shell\nGit checkout -- filename\n```\n\n假如你想丢弃你在本地的所有改动与提交，可以到服务器上获取最新的版本历史，并将你本地主分支指向它：\n\n```shell\nGit fetch origin\nGit reset --hard origin/master\n```\n\n### 分支\n\n分支是用来将特性开发绝缘开来的。在你创建仓库的时候，_master_ 是“默认”的分支。在其他分支上进行开发，完成后再将它们合并到主分支上。\n\n我们通常在开发新功能、修复一个紧急 bug 等等时候会选择创建分支。单分支开发好还是多分支开发好，还是要看具体场景来说。\n\n创建一个名字叫做 test 的分支\n\n```shell\nGit branch test\n```\n\n切换当前分支到 test（当你切换分支的时候，Git 会重置你的工作目录，使其看起来像回到了你在那个分支上最后一次提交的样子。 Git 会自动添加、删除、修改文件以确保此时你的工作目录和这个分支最后一次提交时的样子一模一样）\n\n```shell\nGit checkout test\n```\n\n![](statistic/2019-3%E5%88%87%E6%8D%A2%E5%88%86%E6%94%AF.png)\n\n你也可以直接这样创建分支并切换过去 (上面两条命令的合写)\n\n```shell\nGit checkout -b feature_x\n```\n\n切换到主分支\n\n```shell\nGit checkout master\n```\n\n合并分支 (可能会有冲突)\n\n```shell\n Git merge test\n```\n\n把新建的分支删掉\n\n```shell\nGit branch -d feature_x\n```\n\n将分支推送到远端仓库（推送成功后其他人可见）：\n\n```shell\nGit push origin\n```\n\n\n---\nTitle: Github 实用小技巧总结\nCategory: 开发工具\nTag:\n  - Git\n---\n\n我使用 Github 已经有 6 年多了，今天毫无保留地把自己觉得比较有用的 Github 小技巧送给关注 JavaGuide 的各位小伙伴。\n\n## 一键生成 Github 简历 \u0026 Github 年报\n\n通过 [https://resume.github.io/](https://resume.github.io/) 这个网站你可以一键生成一个在线的 Github 简历。\n\n当时我参加的校招的时候，个人信息那里就放了一个在线的 Github 简历。我觉得这样会让面试官感觉你是一个内行，会提高一些印象分。\n\n但是，如果你的 Github 没有什么项目的话还是不要放在简历里面了。生成后的效果如下图所示。\n\n![Github简历](statistic/Github简历.png)\n\n通过 \u003chttps://www.githubtrends.io/wrapped\u003e 这个网站，你可以生成一份 Github 个人年报，这个年报会列举出你在这一年的项目贡献情况、最常使用的编程语言、详细的贡献信息。\n\n![](statistic/image-20211226144607457.png)\n\n## 个性化 Github 首页\n\nGithub 目前支持在个人主页自定义展示一些内容。展示效果如下图所示。\n\n![个性化首页展示效果](statistic/个性化首页展示效果.png)\n\n想要做到这样非常简单，你只需要创建一个和你的 Github 账户同名的仓库，然后自定义 `README.md` 的内容即可。\n\n展示在你主页的自定义内容就是 `README.md` 的内容（_不会 Markdown 语法的小伙伴自行面壁 5 分钟_）。\n\n![创建一个和你的Github账户同名的仓库](statistic/创建一个和你的Github账户同名的仓库.png)\n\n这个也是可以玩出花来的！比如说：通过 [github-readme-stats](https://hellogithub.com/periodical/statistics/click/?target=https://github.com/anuraghazra/github-readme-stats) 这个开源项目，你可以 README 中展示动态生成的 GitHub 统计信息。展示效果如下图所示。\n\n![通过github-readme-stats动态生成GitHub统计信息 ](statistic/通过github-readme-stats动态生成GitHub统计信息_.png)\n\n关于个性化首页这个就不多提了，感兴趣的小伙伴自行研究一下。\n\n## 自定义项目徽章\n\n你在 Github 上看到的项目徽章都是通过 [https://shields.io/](https://shields.io/) 这个网站生成的。我的 JavaGuide 这个项目的徽章如下图所示。\n\n![项目徽章](statistic/项目徽章.png)\n\n并且，你不光可以生成静态徽章，shield. Io 还可以动态读取你项目的状态并生成对应的徽章。\n\n![自定义项目徽章](statistic/自定义项目徽章.png)\n\n生成的描述项目状态的徽章效果如下图所示。\n\n![描述项目状态的徽章](statistic/描述项目状态的徽章.png)\n\n## 自动为项目添加贡献情况图标\n\n通过 repobeats 这个工具可以为 Github 项目添加如下图所示的项目贡献基本情况图表，挺不错的 👍\n\n![](statistic/repobeats.png)\n\n地址：\u003chttps://repobeats.axiom.co/\u003e 。\n\n## Github 表情\n\n![Github表情](statistic/Github表情.png)\n\n如果你想要在 Github 使用表情的话，可以在这里找找：[www.webfx.com/tools/emoji-cheat-sheet/](https://www.webfx.com/tools/emoji-cheat-sheet/)。\n\n![在线Github表情](statistic/在线Github表情.png)\n\n## 高效阅读 Github 项目的源代码\n\nGithub 前段时间推出的 Codespaces 可以提供类似 VS Code 的在线 IDE，不过目前还没有完全开发使用。\n\n简单介绍几种我最常用的阅读 Github 项目源代码的方式。\n\n### Chrome 插件 Octotree\n\n这个已经老生常谈了，是我最喜欢的一种方式。使用了 Octotree 之后网页侧边栏会按照树形结构展示项目，为我们带来 IDE 般的阅读源代码的感受。\n\n![Chrome插件Octotree](statistic/Chrome插件Octotree.png)\n\n### Chrome 插件 SourceGraph\n\n我不想将项目 clone 到本地的时候一般就会使用这种方式来阅读项目源代码。SourceGraph 不仅可以让我们在 Github 优雅的查看代码，它还支持一些骚操作，比如：类之间的跳转、代码搜索等功能。\n\n当你下载了这个插件之后，你的项目主页会多出一个小图标如下图所示。点击这个小图标即可在线阅读项目源代码。\n\n![](statistic/image-20201107145749659.png)\n\n使用 SourceGraph 阅读代码的就像下面这样，同样是树形结构展示代码，但是我个人感觉没有 Octotree 的手感舒服。不过，SourceGraph 内置了很多插件，而且还支持类之间的跳转！\n\n![](statistic/image-20201107150307314.png)\n\n### 克隆项目到本地\n\n先把项目克隆到本地，然后使用自己喜欢的 IDE 来阅读。可以说是最酸爽的方式了！\n\n如果你想要深入了解某个项目的话，首选这种方式。一个 `git clone` 就完事了。\n\n## 扩展 Github 的功能\n\n**Enhanced GitHub** 可以让你的 Github 更好用。这个 Chrome 插件可以可视化你的 Github 仓库大小，每个文件的大小并且可以让你快速下载单个文件。\n\n![](statistic/image-20201107160817672.png)\n\n## 自动为 Markdown 文件生成目录\n\n如果你想为 Github 上的 Markdown 文件生成目录的话，通过 VS Code 的 **Markdown Preview Enhanced** 这个插件就可以了。\n\n生成的目录效果如下图所示。你直接点击目录中的链接即可跳转到文章对应的位置，可以优化阅读体验。\n\n![](\u003chttps://oss.javaguide.cn/2020-11/iShot2020-11-07%2016.14.14%20(1).png\u003e)\n\n不过，目前 Github 已经自动为 Markdown 文件生成了目录，只是需要通过点击的方式才能显示出来。\n\n![](statistic/image-20211227093215005.png)\n\n## 善用 Github Explore\n\n其实，Github 自带的 Explore 是一个非常强大且好用的功能。不过，据我观察，国内很多 Github 用户都不知道这个到底是干啥的。\n\n简单来说，Github Explore 可以为你带来下面这些服务：\n\n1. 可以根据你的个人兴趣为你推荐项目；\n2. Githunb Topics 按照类别/话题将一些项目进行了分类汇总。比如 [Data visualization](https://github.com/topics/data-visualization) 汇总了数据可视化相关的一些开源项目，[Awesome Lists](https://github.com/topics/awesome) 汇总了 Awesome 系列的仓库；\n3. 通过 Github Trending 我们可以看到最近比较热门的一些开源项目，我们可以按照语言类型以及时间维度对项目进行筛选；\n4. Github Collections 类似一个收藏夹集合。比如 [Teaching materials for computational social science](https://github.com/collections/teaching-computational-social-science) 这个收藏夹就汇总了计算机课程相关的开源资源，[Learn to Code](https://github.com/collections/learn-to-code) 这个收藏夹就汇总了对你学习编程有帮助的一些仓库；\n5. ......\n\n![](statistic/github-explore.png)\n\n## GitHub Actions 很强大\n\n你可以简单地将 GitHub Actions 理解为 Github 自带的 CI/CD ，通过 GitHub Actions 你可以直接在 GitHub 构建、测试和部署代码，你还可以对代码进行审查、管理 API、分析项目依赖项。总之，GitHub Actions 可以自动化地帮你完成很多事情。\n\n关于 GitHub Actions 的详细介绍，推荐看一下阮一峰老师写的 [GitHub Actions 入门教程](https://www.ruanyifeng.com/blog/2019/09/getting-started-with-github-actions.html) 。\n\nGitHub Actions 有一个官方市场，上面有非常多别人提交的 Actions ，你可以直接拿来使用。\n\n![](statistic/image-20211227100147433.png)\n\n## 后记\n\n这一篇文章，我毫无保留地把自己这些年总结的 Github 小技巧分享了出来，真心希望对大家有帮助，真心希望大家一定要利用好 Github 这个专属程序员的宝藏。\n\n另外，这篇文章中，我并没有提到 Github 搜索技巧。在我看来，Github 搜索技巧不必要记网上那些文章说的各种命令啥的，真没啥卵用。你会发现你用的最多的还是关键字搜索以及 Github 自带的筛选功能。\n\n\n\n## 学习资料推荐\n\n**在线演示学习工具：**\n\n「补充，来自 [issue729](https://github.com/Snailclimb/JavaGuide/issues/729) 」Learn Git Branching \u003chttps://oschina.gitee.io/learn-git-branching/\u003e 。该网站可以方便的演示基本的 git 操作，讲解得明明白白。每一个基本命令的作用和结果。\n\n**推荐阅读：**\n\n- [Git 入门图文教程(1.5W 字 40 图)](https://www.cnblogs.com/anding/p/16987769.html)：超用心的一篇文章，内容全面且附带详细的图解，强烈推荐！\n- [Git - 简明指南](https://rogerdudler.github.io/git-guide/index.zh.html)：涵盖 Git 常见操作，非常清晰。\n- [图解 Git](https://marklodato.github.io/visual-git-guide/index-zh-cn.html)：图解 Git 中的最常用命令。如果你稍微理解 git 的工作原理，这篇文章能够让你理解的更透彻。\n- [猴子都能懂得 Git 入门](https://backlog.com/git-tutorial/cn/intro/intro1_1.html)：有趣的讲解。\n- [Pro Git book](https://git-scm.com/book/zh/v2)：国外的一本 Git 书籍，被翻译成多国语言，质量很高。","lastmodified":"2023-08-02T03:10:42.496093621Z","tags":[]},"/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RocketMQ/RocketMQ%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93":{"title":"RocketMQ常见问题总结","content":"## 消息队列扫盲\n\n消息队列顾名思义就是存放消息的队列，队列我就不解释了，别告诉我你连队列都不知道是啥吧？\n\n所以问题并不是消息队列是什么，而是 **消息队列为什么会出现？消息队列能用来干什么？用它来干这些事会带来什么好处？消息队列会带来副作用吗？**\n\n### [#](#消息队列为什么会出现) 消息队列为什么会出现？\n\n消息队列算是作为后端程序员的一个必备技能吧，因为**分布式应用必定涉及到各个系统之间的通信问题**，这个时候消息队列也应运而生了。可以说分布式的产生是消息队列的基础，而分布式怕是一个很古老的概念了吧，所以消息队列也是一个很古老的中间件了。\n\n### [#](#消息队列能用来干什么) 消息队列能用来干什么？\n\n#### [#](#异步) 异步\n\n你可能会反驳我，应用之间的通信又不是只能由消息队列解决，好好的通信为什么中间非要插一个消息队列呢？我不能直接进行通信吗？\n\n很好 👍，你又提出了一个概念，**同步通信**。就比如现在业界使用比较多的 `Dubbo` 就是一个适用于各个系统之间同步通信的 `RPC` 框架。\n\n我来举个 🌰 吧，比如我们有一个购票系统，需求是用户在购买完之后能接收到购买完成的短信。\n\n![](statistic/16ef37fee7e09230.jpg)\n\n我们省略中间的网络通信时间消耗，假如购票系统处理需要 150ms ，短信系统处理需要 200ms ，那么整个处理流程的时间消耗就是 150ms + 200ms = 350ms。\n\n当然，乍看没什么问题。可是仔细一想你就感觉有点问题，我用户购票在购票系统的时候其实就已经完成了购买，而我现在通过同步调用非要让整个请求拉长时间，而短信系统这玩意又不是很有必要，它仅仅是一个辅助功能增强用户体验感而已。我现在整个调用流程就有点 **头重脚轻** 的感觉了，购票是一个不太耗时的流程，而我现在因为同步调用，非要等待发送短信这个比较耗时的操作才返回结果。那我如果再加一个发送邮件呢？\n\n![](statistic/16ef380429cf373e.jpg)\n\n这样整个系统的调用链又变长了，整个时间就变成了 550ms。\n\n当我们在学生时代需要在食堂排队的时候，我们和食堂大妈就是一个同步的模型。\n\n我们需要告诉食堂大妈：“姐姐，给我加个鸡腿，再加个酸辣土豆丝，帮我浇点汁上去，多打点饭哦 😋😋😋” 咦~~~ 为了多吃点，真恶心。\n\n然后大妈帮我们打饭配菜，我们看着大妈那颤抖的手和掉落的土豆丝不禁咽了咽口水。\n\n最终我们从大妈手中接过饭菜然后去寻找座位了...\n\n回想一下，我们在给大妈发送需要的信息之后我们是 **同步等待大妈给我配好饭菜** 的，上面我们只是加了鸡腿和土豆丝，万一我再加一个番茄牛腩，韭菜鸡蛋，这样是不是大妈打饭配菜的流程就会变长，我们等待的时间也会相应的变长。\n\n![](statistic/006APoFYly1fvd9cwjlfrj30as0b03ym.jpg)\n\n那后来，我们工作赚钱了有钱去饭店吃饭了，我们告诉服务员来一碗牛肉面加个荷包蛋 **(传达一个消息)** ，然后我们就可以在饭桌上安心的玩手机了 **(干自己其他事情)** ，等到我们的牛肉面上了我们就可以吃了。这其中我们也就传达了一个消息，然后我们又转过头干其他事情了。这其中虽然做面的时间没有变短，但是我们只需要传达一个消息就可以干其他事情了，这是一个 **异步** 的概念。\n\n所以，为了解决这一个问题，聪明的程序员在中间也加了个类似于服务员的中间件——消息队列。这个时候我们就可以把模型给改造了。\n\n![](statistic/16ef38124f55eaea.jpg)\n\n这样，我们在将消息存入消息队列之后我们就可以直接返回了(我们告诉服务员我们要吃什么然后玩手机)，所以整个耗时只是 150ms + 10ms = 160ms。\n\n\u003e 但是你需要注意的是，整个流程的时长是没变的，就像你仅仅告诉服务员要吃什么是不会影响到做面的速度的。\n\n#### [#](#解耦) 解耦\n\n回到最初同步调用的过程，我们写个伪代码简单概括一下。\n\n![](statistic/16ef381a505d3e1f.jpg.png)\n\n那么第二步，我们又添加了一个发送邮件，我们就得重新去修改代码，如果我们又加一个需求：用户购买完还需要给他加积分，这个时候我们是不是又得改代码？\n\n![](statistic/16ef381c4e1b1ac7.jpg.png)\n\n如果你觉得还行，那么我这个时候不要发邮件这个服务了呢，我是不是又得改代码，又得重启应用？\n\n![](statistic/16ef381f273a66bd.jpg)\n\n这样改来改去是不是很麻烦，那么 **此时我们就用一个消息队列在中间进行解耦** 。你需要注意的是，我们后面的发送短信、发送邮件、添加积分等一些操作都依赖于上面的 `result` ，这东西抽象出来就是购票的处理结果呀，比如订单号，用户账号等等，也就是说我们后面的一系列服务都是需要同样的消息来进行处理。既然这样，我们是不是可以通过 **“广播消息”** 来实现。\n\n我上面所讲的“广播”并不是真正的广播，而是接下来的系统作为消费者去 **订阅** 特定的主题。比如我们这里的主题就可以叫做 `订票` ，我们购买系统作为一个生产者去生产这条消息放入消息队列，然后消费者订阅了这个主题，会从消息队列中拉取消息并消费。就比如我们刚刚画的那张图，你会发现，在生产者这边我们只需要关注 **生产消息到指定主题中** ，而 **消费者只需要关注从指定主题中拉取消息** 就行了。\n\n![](statistic/16ef382674b66892.jpg)\n\n\u003e 如果没有消息队列，每当一个新的业务接入，我们都要在主系统调用新接口、或者当我们取消某些业务，我们也得在主系统删除某些接口调用。有了消息队列，我们只需要关心消息是否送达了队列，至于谁希望订阅，接下来收到消息如何处理，是下游的事情，无疑极大地减少了开发和联调的工作量。\n\n#### [#](#削峰) 削峰\n\n我们再次回到一开始我们使用同步调用系统的情况，并且思考一下，如果此时有大量用户请求购票整个系统会变成什么样？\n\n![](statistic/16ef382a9756bb1c.jpg)\n\n如果，此时有一万的请求进入购票系统，我们知道运行我们主业务的服务器配置一般会比较好，所以这里我们假设购票系统能承受这一万的用户请求，那么也就意味着我们同时也会出现一万调用发短信服务的请求。而对于短信系统来说并不是我们的主要业务，所以我们配备的硬件资源并不会太高，那么你觉得现在这个短信系统能承受这一万的峰值么，且不说能不能承受，系统会不会 **直接崩溃** 了？\n\n短信业务又不是我们的主业务，我们能不能 **折中处理** 呢？如果我们把购买完成的信息发送到消息队列中，而短信系统 **尽自己所能地去消息队列中取消息和消费消息** ，即使处理速度慢一点也无所谓，只要我们的系统没有崩溃就行了。\n\n留得江山在，还怕没柴烧？你敢说每次发送验证码的时候是一发你就收到了的么？\n\n#### [#](#消息队列能带来什么好处) 消息队列能带来什么好处？\n\n其实上面我已经说了。**异步、解耦、削峰。** 哪怕你上面的都没看懂也千万要记住这六个字，因为他不仅是消息队列的精华，更是编程和架构的精华。\n\n#### [#](#消息队列会带来副作用吗) 消息队列会带来副作用吗？\n\n没有哪一门技术是“银弹”，消息队列也有它的副作用。\n\n比如，本来好好的两个系统之间的调用，我中间加了个消息队列，如果消息队列挂了怎么办呢？是不是 **降低了系统的可用性** ？\n\n那这样是不是要保证 HA(高可用)？是不是要搞集群？那么我 **整个系统的复杂度是不是上升了** ？\n\n抛开上面的问题不讲，万一我发送方发送失败了，然后执行重试，这样就可能产生重复的消息。\n\n或者我消费端处理失败了，请求重发，这样也会产生重复的消息。\n\n对于一些微服务来说，消费重复消息会带来更大的麻烦，比如增加积分，这个时候我加了多次是不是对其他用户不公平？\n\n那么，又 **如何解决重复消费消息的问题** 呢？\n\n如果我们此时的消息需要保证严格的顺序性怎么办呢？比如生产者生产了一系列的有序消息(对一个 id 为 1 的记录进行删除增加修改)，但是我们知道在发布订阅模型中，对于主题是无顺序的，那么这个时候就会导致对于消费者消费消息的时候没有按照生产者的发送顺序消费，比如这个时候我们消费的顺序为修改删除增加，如果该记录涉及到金额的话是不是会出大事情？\n\n那么，又 **如何解决消息的顺序消费问题** 呢？\n\n就拿我们上面所讲的分布式系统来说，用户购票完成之后是不是需要增加账户积分？在同一个系统中我们一般会使用事务来进行解决，如果用 `Spring` 的话我们在上面伪代码中加入 `@Transactional` 注解就好了。但是在不同系统中如何保证事务呢？总不能这个系统我扣钱成功了你那积分系统积分没加吧？或者说我这扣钱明明失败了，你那积分系统给我加了积分。\n\n那么，又如何 **解决分布式事务问题** 呢？\n\n我们刚刚说了，消息队列可以进行削峰操作，那如果我的消费者如果消费很慢或者生产者生产消息很快，这样是不是会将消息堆积在消息队列中？\n\n那么，又如何 **解决消息堆积的问题** 呢？\n\n可用性降低，复杂度上升，又带来一系列的重复消费，顺序消费，分布式事务，消息堆积的问题，这消息队列还怎么用啊 😵？\n\n![](statistic/16ef382d709abc9d.png.jpg)\n\n别急，办法总是有的。\n\n## [#](#rocketmq-是什么) RocketMQ 是什么？\n\n![](statistic/16ef383014430799.jpg)\n\n哇，你个混蛋！上面给我抛出那么多问题，你现在又讲 `RocketMQ` ，还让不让人活了？！🤬\n\n别急别急，话说你现在清楚 `MQ` 的构造吗，我还没讲呢，我们先搞明白 `MQ` 的内部构造，再来看看如何解决上面的一系列问题吧，不过你最好带着问题去阅读和了解喔。\n\n`RocketMQ` 是一个 **队列模型** 的消息中间件，具有**高性能、高可靠、高实时、分布式** 的特点。它是一个采用 `Java` 语言开发的分布式的消息系统，由阿里巴巴团队开发，在 2016 年底贡献给 `Apache`，成为了 `Apache` 的一个顶级项目。 在阿里内部，`RocketMQ` 很好地服务了集团大大小小上千个应用，在每年的双十一当天，更有不可思议的万亿级消息通过 `RocketMQ` 流转。\n\n废话不多说，想要了解 `RocketMQ` 历史的同学可以自己去搜寻资料。听完上面的介绍，你只要知道 `RocketMQ` 很快、很牛、而且经历过双十一的实践就行了！\n\n## [#](#队列模型和主题模型是什么) 队列模型和主题模型是什么？\n\n在谈 `RocketMQ` 的技术架构之前，我们先来了解一下两个名词概念——**队列模型** 和 **主题模型** 。\n\n首先我问一个问题，消息队列为什么要叫消息队列？\n\n你可能觉得很弱智，这玩意不就是存放消息的队列嘛？不叫消息队列叫什么？\n\n的确，早期的消息中间件是通过 **队列** 这一模型来实现的，可能是历史原因，我们都习惯把消息中间件成为消息队列。\n\n但是，如今例如 `RocketMQ`、`Kafka` 这些优秀的消息中间件不仅仅是通过一个 **队列** 来实现消息存储的。\n\n### [#](#队列模型) 队列模型\n\n就像我们理解队列一样，消息中间件的队列模型就真的只是一个队列。。。我画一张图给大家理解。\n\n![](statistic/16ef3834ae653469.jpg)\n\n在一开始我跟你提到了一个 **“广播”** 的概念，也就是说如果我们此时我们需要将一个消息发送给多个消费者(比如此时我需要将信息发送给短信系统和邮件系统)，这个时候单个队列即不能满足需求了。\n\n当然你可以让 `Producer` 生产消息放入多个队列中，然后每个队列去对应每一个消费者。问题是可以解决，创建多个队列并且复制多份消息是会很影响资源和性能的。而且，这样子就会导致生产者需要知道具体消费者个数然后去复制对应数量的消息队列，这就违背我们消息中间件的 **解耦** 这一原则。\n\n### [#](#主题模型) 主题模型\n\n那么有没有好的方法去解决这一个问题呢？有，那就是 **主题模型** 或者可以称为 **发布订阅模型** 。\n\n\u003e 感兴趣的同学可以去了解一下设计模式里面的观察者模式并且手动实现一下，我相信你会有所收获的。\n\n在主题模型中，消息的生产者称为 **发布者(Publisher)** ，消息的消费者称为 **订阅者(Subscriber)** ，存放消息的容器称为 **主题(Topic)** 。\n\n其中，发布者将消息发送到指定主题中，订阅者需要 **提前订阅主题** 才能接受特定主题的消息。\n\n![](statistic/16ef3837887d9a54sds.jpg)\n\n### [#](#rocketmq-中的消息模型) RocketMQ 中的消息模型\n\n`RocketMQ` 中的消息模型就是按照 **主题模型** 所实现的。你可能会好奇这个 **主题** 到底是怎么实现的呢？你上面也没有讲到呀！\n\n其实对于主题模型的实现来说每个消息中间件的底层设计都是不一样的，就比如 `Kafka` 中的 **分区** ，`RocketMQ` 中的 **队列** ，`RabbitMQ` 中的 `Exchange` 。我们可以理解为 **主题模型/发布订阅模型** 就是一个标准，那些中间件只不过照着这个标准去实现而已。\n\n所以，`RocketMQ` 中的 **主题模型** 到底是如何实现的呢？首先我画一张图，大家尝试着去理解一下。\n\n![](statistic/16ef383d3e8c9788.jpg)\n\n我们可以看到在整个图中有 `Producer Group`、`Topic`、`Consumer Group` 三个角色，我来分别介绍一下他们。\n\n- `Producer Group` 生产者组：代表某一类的生产者，比如我们有多个秒杀系统作为生产者，这多个合在一起就是一个 `Producer Group` 生产者组，它们一般生产相同的消息。\n- `Consumer Group` 消费者组：代表某一类的消费者，比如我们有多个短信系统作为消费者，这多个合在一起就是一个 `Consumer Group` 消费者组，它们一般消费相同的消息。\n- `Topic` 主题：代表一类消息，比如订单消息，物流消息等等。\n\n你可以看到图中生产者组中的生产者会向主题发送消息，而 **主题中存在多个队列**，生产者每次生产消息之后是指定主题中的某个队列发送消息的。\n\n每个主题中都有多个队列(分布在不同的 `Broker`中，如果是集群的话，`Broker`又分布在不同的服务器中)，集群消费模式下，一个消费者集群多台机器共同消费一个 `topic` 的多个队列，**一个队列只会被一个消费者消费**。如果某个消费者挂掉，分组内其它消费者会接替挂掉的消费者继续消费。就像上图中 `Consumer1` 和 `Consumer2` 分别对应着两个队列，而 `Consumer3` 是没有队列对应的，所以一般来讲要控制 **消费者组中的消费者个数和主题中队列个数相同** 。\n\n当然也可以消费者个数小于队列个数，只不过不太建议。如下图。\n\n![](statistic/16ef3850c808d707.jpg)\n\n**每个消费组在每个队列上维护一个消费位置** ，为什么呢？\n\n因为我们刚刚画的仅仅是一个消费者组，我们知道在发布订阅模式中一般会涉及到多个消费者组，而每个消费者组在每个队列中的消费位置都是不同的。如果此时有多个消费者组，那么消息被一个消费者组消费完之后是不会删除的(因为其它消费者组也需要呀)，它仅仅是为每个消费者组维护一个 **消费位移(offset)** ，每次消费者组消费完会返回一个成功的响应，然后队列再把维护的消费位移加一，这样就不会出现刚刚消费过的消息再一次被消费了。\n\n![](statistic/16ef3857fefaa079.jpg)\n\n可能你还有一个问题，**为什么一个主题中需要维护多个队列** ？\n\n答案是 **提高并发能力** 。的确，每个主题中只存在一个队列也是可行的。你想一下，如果每个主题中只存在一个队列，这个队列中也维护着每个消费者组的消费位置，这样也可以做到 **发布订阅模式** 。如下图。\n\n![](statistic/16ef38600cdb6d4b.jpg)\n\n但是，这样我生产者是不是只能向一个队列发送消息？又因为需要维护消费位置所以一个队列只能对应一个消费者组中的消费者，这样是不是其他的 `Consumer` 就没有用武之地了？从这两个角度来讲，并发度一下子就小了很多。\n\n所以总结来说，`RocketMQ` 通过**使用在一个 `Topic` 中配置多个队列并且每个队列维护每个消费者组的消费位置** 实现了 **主题模式/发布订阅模式** 。\n\n## [#](#rocketmq-的架构图) RocketMQ 的架构图\n\n讲完了消息模型，我们理解起 `RocketMQ` 的技术架构起来就容易多了。\n\n`RocketMQ` 技术架构中有四大角色 `NameServer`、`Broker`、`Producer`、`Consumer` 。我来向大家分别解释一下这四个角色是干啥的。\n\n- `Broker`：主要负责消息的存储、投递和查询以及服务高可用保证。说白了就是消息队列服务器嘛，生产者生产消息到 `Broker` ，消费者从 `Broker` 拉取消息并消费。\n    \n    这里，我还得普及一下关于 `Broker`、`Topic` 和 队列的关系。上面我讲解了 `Topic` 和队列的关系——一个 `Topic` 中存在多个队列，那么这个 `Topic` 和队列存放在哪呢？\n    \n    **一个 `Topic` 分布在多个 `Broker`上，一个 `Broker` 可以配置多个 `Topic` ，它们是多对多的关系**。\n    \n    如果某个 `Topic` 消息量很大，应该给它多配置几个队列(上文中提到了提高并发能力)，并且 **尽量多分布在不同 `Broker` 上，以减轻某个 `Broker` 的压力** 。\n    \n    `Topic` 消息量都比较均匀的情况下，如果某个 `broker` 上的队列越多，则该 `broker` 压力越大。\n    \n    ![](statistic/16ef38687488a5a4.jpg)\n    \n    \u003e 所以说我们需要配置多个 Broker。\n    \n- `NameServer`：不知道你们有没有接触过 `ZooKeeper` 和 `Spring Cloud` 中的 `Eureka` ，它其实也是一个 **注册中心** ，主要提供两个功能：**Broker 管理** 和 **路由信息管理** 。说白了就是 `Broker` 会将自己的信息注册到 `NameServer` 中，此时 `NameServer` 就存放了很多 `Broker` 的信息(Broker 的路由表)，消费者和生产者就从 `NameServer` 中获取路由表然后照着路由表的信息和对应的 `Broker` 进行通信(生产者和消费者定期会向 `NameServer` 去查询相关的 `Broker` 的信息)。\n    \n- `Producer`：消息发布的角色，支持分布式集群方式部署。说白了就是生产者。\n    \n- `Consumer`：消息消费的角色，支持分布式集群方式部署。支持以 push 推，pull 拉两种模式对消息进行消费。同时也支持集群方式和广播方式的消费，它提供实时消息订阅机制。说白了就是消费者。\n    \n\n听完了上面的解释你可能会觉得，这玩意好简单。不就是这样的么？\n\n![](statistic/16ef386c6d1e8bdb.jpg)\n\n嗯？你可能会发现一个问题，这老家伙 `NameServer` 干啥用的，这不多余吗？直接 `Producer`、`Consumer` 和 `Broker` 直接进行生产消息，消费消息不就好了么？\n\n但是，我们上文提到过 `Broker` 是需要保证高可用的，如果整个系统仅仅靠着一个 `Broker` 来维持的话，那么这个 `Broker` 的压力会不会很大？所以我们需要使用多个 `Broker` 来保证 **负载均衡** 。\n\n如果说，我们的消费者和生产者直接和多个 `Broker` 相连，那么当 `Broker` 修改的时候必定会牵连着每个生产者和消费者，这样就会产生耦合问题，而 `NameServer` 注册中心就是用来解决这个问题的。\n\n\u003e 如果还不是很理解的话，可以去看我介绍 `Spring Cloud` 的那篇文章，其中介绍了 `Eureka` 注册中心。\n\n当然，`RocketMQ` 中的技术架构肯定不止前面那么简单，因为上面图中的四个角色都是需要做集群的。我给出一张官网的架构图，大家尝试理解一下。\n\n![](statistic/16ef386fa3be1e53.jpg)\n\n其实和我们最开始画的那张乞丐版的架构图也没什么区别，主要是一些细节上的差别。听我细细道来 🤨。\n\n第一、我们的 `Broker` **做了集群并且还进行了主从部署** ，由于消息分布在各个 `Broker` 上，一旦某个 `Broker` 宕机，则该`Broker` 上的消息读写都会受到影响。所以 `Rocketmq` 提供了 `master/slave` 的结构， `salve` 定时从 `master` 同步数据(同步刷盘或者异步刷盘)，如果 `master` 宕机，**则 `slave` 提供消费服务，但是不能写入消息** (后面我还会提到哦)。\n\n第二、为了保证 `HA` ，我们的 `NameServer` 也做了集群部署，但是请注意它是 **去中心化** 的。也就意味着它没有主节点，你可以很明显地看出 `NameServer` 的所有节点是没有进行 `Info Replicate` 的，在 `RocketMQ` 中是通过 **单个 Broker 和所有 NameServer 保持长连接** ，并且在每隔 30 秒 `Broker` 会向所有 `Nameserver` 发送心跳，心跳包含了自身的 `Topic` 配置信息，这个步骤就对应这上面的 `Routing Info` 。\n\n第三、在生产者需要向 `Broker` 发送消息的时候，**需要先从 `NameServer` 获取关于 `Broker` 的路由信息**，然后通过 **轮询** 的方法去向每个队列中生产数据以达到 **负载均衡** 的效果。\n\n第四、消费者通过 `NameServer` 获取所有 `Broker` 的路由信息后，向 `Broker` 发送 `Pull` 请求来获取消息数据。`Consumer` 可以以两种模式启动—— **广播（Broadcast）和集群（Cluster）**。广播模式下，一条消息会发送给 **同一个消费组中的所有消费者** ，集群模式下消息只会发送给一个消费者。\n\n## [#](#如何解决顺序消费和重复消费) 如何解决顺序消费和重复消费？\n\n其实，这些东西都是我在介绍消息队列带来的一些副作用的时候提到的，也就是说，这些问题不仅仅挂钩于 `RocketMQ` ，而是应该每个消息中间件都需要去解决的。\n\n在上面我介绍 `RocketMQ` 的技术架构的时候我已经向你展示了 **它是如何保证高可用的** ，这里不涉及运维方面的搭建，如果你感兴趣可以自己去官网上照着例子搭建属于你自己的 `RocketMQ` 集群。\n\n\u003e 其实 `Kafka` 的架构基本和 `RocketMQ` 类似，只是它注册中心使用了 `Zookeeper`、它的 **分区** 就相当于 `RocketMQ` 中的 **队列** 。还有一些小细节不同会在后面提到。\n\n### [#](#顺序消费) 顺序消费\n\n在上面的技术架构介绍中，我们已经知道了 **`RocketMQ` 在主题上是无序的、它只有在队列层面才是保证有序** 的。\n\n这又扯到两个概念——**普通顺序** 和 **严格顺序** 。\n\n所谓普通顺序是指 消费者通过 **同一个消费队列收到的消息是有顺序的** ，不同消息队列收到的消息则可能是无顺序的。普通顺序消息在 `Broker` **重启情况下不会保证消息顺序性** (短暂时间) 。\n\n所谓严格顺序是指 消费者收到的 **所有消息** 均是有顺序的。严格顺序消息 **即使在异常情况下也会保证消息的顺序性** 。\n\n但是，严格顺序看起来虽好，实现它可会付出巨大的代价。如果你使用严格顺序模式，`Broker` 集群中只要有一台机器不可用，则整个集群都不可用。你还用啥？现在主要场景也就在 `binlog` 同步。\n\n一般而言，我们的 `MQ` 都是能容忍短暂的乱序，所以推荐使用普通顺序模式。\n\n那么，我们现在使用了 **普通顺序模式** ，我们从上面学习知道了在 `Producer` 生产消息的时候会进行轮询(取决你的负载均衡策略)来向同一主题的不同消息队列发送消息。那么如果此时我有几个消息分别是同一个订单的创建、支付、发货，在轮询的策略下这 **三个消息会被发送到不同队列** ，因为在不同的队列此时就无法使用 `RocketMQ` 带来的队列有序特性来保证消息有序性了。\n\n![](statistic/16ef3874585e096e.jpg)\n\n那么，怎么解决呢？\n\n其实很简单，我们需要处理的仅仅是将同一语义下的消息放入同一个队列(比如这里是同一个订单)，那我们就可以使用 **Hash 取模法** 来保证同一个订单在同一个队列中就行了。\n\n### [#](#重复消费) 重复消费\n\nemmm，就两个字—— **幂等** 。在编程中一个_幂等_ 操作的特点是其任意多次执行所产生的影响均与一次执行的影响相同。比如说，这个时候我们有一个订单的处理积分的系统，每当来一个消息的时候它就负责为创建这个订单的用户的积分加上相应的数值。可是有一次，消息队列发送给订单系统 FrancisQ 的订单信息，其要求是给 FrancisQ 的积分加上 500。但是积分系统在收到 FrancisQ 的订单信息处理完成之后返回给消息队列处理成功的信息的时候出现了网络波动(当然还有很多种情况，比如 Broker 意外重启等等)，这条回应没有发送成功。\n\n那么，消息队列没收到积分系统的回应会不会尝试重发这个消息？问题就来了，我再发这个消息，万一它又给 FrancisQ 的账户加上 500 积分怎么办呢？\n\n所以我们需要给我们的消费者实现 **幂等** ，也就是对同一个消息的处理结果，执行多少次都不变。\n\n那么如何给业务实现幂等呢？这个还是需要结合具体的业务的。你可以使用 **写入 `Redis`** 来保证，因为 `Redis` 的 `key` 和 `value` 就是天然支持幂等的。当然还有使用 **数据库插入法** ，基于数据库的唯一键来保证重复数据不会被插入多条。\n\n不过最主要的还是需要 **根据特定场景使用特定的解决方案** ，你要知道你的消息消费是否是完全不可重复消费还是可以忍受重复消费的，然后再选择强校验和弱校验的方式。毕竟在 CS 领域还是很少有技术银弹的说法。\n\n而在整个互联网领域，幂等不仅仅适用于消息队列的重复消费问题，这些实现幂等的方法，也同样适用于，**在其他场景中来解决重复请求或者重复调用的问题** 。比如将 HTTP 服务设计成幂等的，**解决前端或者 APP 重复提交表单数据的问题** ，也可以将一个微服务设计成幂等的，解决 `RPC` 框架自动重试导致的 **重复调用问题** 。\n\n## [#](#rocketmq-如何实现分布式事务) RocketMQ 如何实现分布式事务？\n\n如何解释分布式事务呢？事务大家都知道吧？**要么都执行要么都不执行** 。在同一个系统中我们可以轻松地实现事务，但是在分布式架构中，我们有很多服务是部署在不同系统之间的，而不同服务之间又需要进行调用。比如此时我下订单然后增加积分，如果保证不了分布式事务的话，就会出现 A 系统下了订单，但是 B 系统增加积分失败或者 A 系统没有下订单，B 系统却增加了积分。前者对用户不友好，后者对运营商不利，这是我们都不愿意见到的。\n\n那么，如何去解决这个问题呢？\n\n如今比较常见的分布式事务实现有 2PC、TCC 和事务消息(half 半消息机制)。每一种实现都有其特定的使用场景，但是也有各自的问题，**都不是完美的解决方案**。\n\n在 `RocketMQ` 中使用的是 **事务消息加上事务反查机制** 来解决分布式事务问题的。我画了张图，大家可以对照着图进行理解。\n\n![](statistic/16ef38798d7a987f.png.jpg)\n\n在第一步发送的 half 消息 ，它的意思是 **在事务提交之前，对于消费者来说，这个消息是不可见的** 。\n\n\u003e 那么，如何做到写入消息但是对用户不可见呢？RocketMQ 事务消息的做法是：如果消息是 half 消息，将备份原消息的主题与消息消费队列，然后 **改变主题** 为 RMQ_SYS_TRANS_HALF_TOPIC。由于消费组未订阅该主题，故消费端无法消费 half 类型的消息，**然后 RocketMQ 会开启一个定时任务，从 Topic 为 RMQ_SYS_TRANS_HALF_TOPIC 中拉取消息进行消费**，根据生产者组获取一个服务提供者发送回查事务状态请求，根据事务状态来决定是提交或回滚消息。\n\n你可以试想一下，如果没有从第 5 步开始的 **事务反查机制** ，如果出现网路波动第 4 步没有发送成功，这样就会产生 MQ 不知道是不是需要给消费者消费的问题，他就像一个无头苍蝇一样。在 `RocketMQ` 中就是使用的上述的事务反查来解决的，而在 `Kafka` 中通常是直接抛出一个异常让用户来自行解决。\n\n你还需要注意的是，在 `MQ Server` 指向系统 B 的操作已经和系统 A 不相关了，也就是说在消息队列中的分布式事务是——**本地事务和存储消息到消息队列才是同一个事务**。这样也就产生了事务的**最终一致性**，因为整个过程是异步的，**每个系统只要保证它自己那一部分的事务就行了**。\n\n## [#](#如何解决消息堆积问题) 如何解决消息堆积问题？\n\n在上面我们提到了消息队列一个很重要的功能——**削峰** 。那么如果这个峰值太大了导致消息堆积在队列中怎么办呢？\n\n其实这个问题可以将它广义化，因为产生消息堆积的根源其实就只有两个——生产者生产太快或者消费者消费太慢。\n\n我们可以从多个角度去思考解决这个问题，当流量到峰值的时候是因为生产者生产太快，我们可以使用一些 **限流降级** 的方法，当然你也可以增加多个消费者实例去水平扩展增加消费能力来匹配生产的激增。如果消费者消费过慢的话，我们可以先检查 **是否是消费者出现了大量的消费错误** ，或者打印一下日志查看是否是哪一个线程卡死，出现了锁资源不释放等等的问题。\n\n\u003e 当然，最快速解决消息堆积问题的方法还是增加消费者实例，不过 **同时你还需要增加每个主题的队列数量** 。\n\u003e \n\u003e 别忘了在 `RocketMQ` 中，**一个队列只会被一个消费者消费** ，如果你仅仅是增加消费者实例就会出现我一开始给你画架构图的那种情况。\n\n![](statistic/16ef387d939ab66d.jpg)\n\n## [#](#什么事回溯消费) 什么事回溯消费？\n\n回溯消费是指 `Consumer` 已经消费成功的消息，由于业务上需求需要重新消费，在`RocketMQ` 中， `Broker` 在向`Consumer` 投递成功消息后，**消息仍然需要保留** 。并且重新消费一般是按照时间维度，例如由于 `Consumer` 系统故障，恢复后需要重新消费 1 小时前的数据，那么 `Broker` 要提供一种机制，可以按照时间维度来回退消费进度。`RocketMQ` 支持按照时间回溯消费，时间维度精确到毫秒。\n\n这是官方文档的解释，我直接照搬过来就当科普了 😁😁😁。\n\n## [#](#rocketmq-的刷盘机制) RocketMQ 的刷盘机制\n\n上面我讲了那么多的 `RocketMQ` 的架构和设计原理，你有没有好奇\n\n在 `Topic` 中的 **队列是以什么样的形式存在的？**\n\n**队列中的消息又是如何进行存储持久化的呢？**\n\n我在上文中提到的 **同步刷盘** 和 **异步刷盘** 又是什么呢？它们会给持久化带来什么样的影响呢？\n\n下面我将给你们一一解释。\n\n### [#](#同步刷盘和异步刷盘) 同步刷盘和异步刷盘\n\n![](statistic/16ef387fba311cda.jpg)\n\n如上图所示，在同步刷盘中需要等待一个刷盘成功的 `ACK` ，同步刷盘对 `MQ` 消息可靠性来说是一种不错的保障，但是 **性能上会有较大影响** ，一般地适用于金融等特定业务场景。\n\n而异步刷盘往往是开启一个线程去异步地执行刷盘操作。消息刷盘采用后台异步线程提交的方式进行， **降低了读写延迟** ，提高了 `MQ` 的性能和吞吐量，一般适用于如发验证码等对于消息保证要求不太高的业务场景。\n\n一般地，**异步刷盘只有在 `Broker` 意外宕机的时候会丢失部分数据**，你可以设置 `Broker` 的参数 `FlushDiskType` 来调整你的刷盘策略(ASYNC_FLUSH 或者 SYNC_FLUSH)。\n\n### [#](#同步复制和异步复制) 同步复制和异步复制\n\n上面的同步刷盘和异步刷盘是在单个结点层面的，而同步复制和异步复制主要是指的 `Borker` 主从模式下，主节点返回消息给客户端的时候是否需要同步从节点。\n\n- 同步复制：也叫 “同步双写”，也就是说，**只有消息同步双写到主从节点上时才返回写入成功** 。\n- 异步复制：**消息写入主节点之后就直接返回写入成功** 。\n\n然而，很多事情是没有完美的方案的，就比如我们进行消息写入的节点越多就更能保证消息的可靠性，但是随之的性能也会下降，所以需要程序员根据特定业务场景去选择适应的主从复制方案。\n\n那么，**异步复制会不会也像异步刷盘那样影响消息的可靠性呢？**\n\n答案是不会的，因为两者就是不同的概念，对于消息可靠性是通过不同的刷盘策略保证的，而像异步同步复制策略仅仅是影响到了 **可用性** 。为什么呢？其主要原因**是 `RocketMQ` 是不支持自动主从切换的，当主节点挂掉之后，生产者就不能再给这个主节点生产消息了**。\n\n比如这个时候采用异步复制的方式，在主节点还未发送完需要同步的消息的时候主节点挂掉了，这个时候从节点就少了一部分消息。但是此时生产者无法再给主节点生产消息了，**消费者可以自动切换到从节点进行消费**(仅仅是消费)，所以在主节点挂掉的时间只会产生主从结点短暂的消息不一致的情况，降低了可用性，而当主节点重启之后，从节点那部分未来得及复制的消息还会继续复制。\n\n在单主从架构中，如果一个主节点挂掉了，那么也就意味着整个系统不能再生产了。那么这个可用性的问题能否解决呢？**一个主从不行那就多个主从的呗**，别忘了在我们最初的架构图中，每个 `Topic` 是分布在不同 `Broker` 中的。\n\n![](statistic/16ef38687488a5a4.jpg)\n\n但是这种复制方式同样也会带来一个问题，那就是无法保证 **严格顺序** 。在上文中我们提到了如何保证的消息顺序性是通过将一个语义的消息发送在同一个队列中，使用 `Topic` 下的队列来保证顺序性的。如果此时我们主节点 A 负责的是订单 A 的一系列语义消息，然后它挂了，这样其他节点是无法代替主节点 A 的，如果我们任意节点都可以存入任何消息，那就没有顺序性可言了。\n\n而在 `RocketMQ` 中采用了 `Dledger` 解决这个问题。他要求在写入消息的时候，要求**至少消息复制到半数以上的节点之后**，才给客⼾端返回写⼊成功，并且它是⽀持通过选举来动态切换主节点的。这里我就不展开说明了，读者可以自己去了解。\n\n\u003e 也不是说 `Dledger` 是个完美的方案，至少在 `Dledger` 选举过程中是无法提供服务的，而且他必须要使用三个节点或以上，如果多数节点同时挂掉他也是无法保证可用性的，而且要求消息复制半数以上节点的效率和直接异步复制还是有一定的差距的。\n\n### [#](#存储机制) 存储机制\n\n还记得上面我们一开始的三个问题吗？到这里第三个问题已经解决了。\n\n但是，在 `Topic` 中的 **队列是以什么样的形式存在的？队列中的消息又是如何进行存储持久化的呢？** 还未解决，其实这里涉及到了 `RocketMQ` 是如何设计它的存储结构了。我首先想大家介绍 `RocketMQ` 消息存储架构中的三大角色——`CommitLog`、`ConsumeQueue` 和 `IndexFile` 。\n\n- `CommitLog`：**消息主体以及元数据的存储主体**，存储 `Producer` 端写入的消息主体内容,消息内容不是定长的。单个文件大小默认 1G ，文件名长度为 20 位，左边补零，剩余为起始偏移量，比如 00000000000000000000 代表了第一个文件，起始偏移量为 0，文件大小为 1G=1073741824；当第一个文件写满了，第二个文件为 00000000001073741824，起始偏移量为 1073741824，以此类推。消息主要是**顺序写入日志文件**，当文件满了，写入下一个文件。\n- `ConsumeQueue`：消息消费队列，**引入的目的主要是提高消息消费的性能**(我们再前面也讲了)，由于`RocketMQ` 是基于主题 `Topic` 的订阅模式，消息消费是针对主题进行的，如果要遍历 `commitlog` 文件中根据 `Topic` 检索消息是非常低效的。`Consumer` 即可根据 `ConsumeQueue` 来查找待消费的消息。其中，`ConsumeQueue`（逻辑消费队列）**作为消费消息的索引**，保存了指定 `Topic` 下的队列消息在 `CommitLog` 中的**起始物理偏移量 `offset` **，消息大小 `size` 和消息 `Tag` 的 `HashCode` 值。**`consumequeue` 文件可以看成是基于 `topic` 的 `commitlog` 索引文件**，故 `consumequeue` 文件夹的组织方式如下：topic/queue/file 三层组织结构，具体存储路径为：$HOME/store/consumequeue/{topic}/{queueId}/{fileName}。同样 `consumequeue` 文件采取定长设计，每一个条目共 20 个字节，分别为 8 字节的 `commitlog` 物理偏移量、4 字节的消息长度、8 字节 tag `hashcode`，单个文件由 30W 个条目组成，可以像数组一样随机访问每一个条目，每个 `ConsumeQueue`文件大小约 5.72M；\n- `IndexFile`：`IndexFile`（索引文件）提供了一种可以通过 key 或时间区间来查询消息的方法。这里只做科普不做详细介绍。\n\n总结来说，整个消息存储的结构，最主要的就是 `CommitLoq` 和 `ConsumeQueue` 。而 `ConsumeQueue` 你可以大概理解为 `Topic` 中的队列。\n\n![](statistic/16ef3884c02acc72.png.jpg)\n\n`RocketMQ` 采用的是 **混合型的存储结构** ，即为 `Broker` 单个实例下所有的队列共用一个日志数据文件来存储消息。有意思的是在同样高并发的 `Kafka` 中会为每个 `Topic` 分配一个存储文件。这就有点类似于我们有一大堆书需要装上书架，`RockeMQ` 是不分书的种类直接成批的塞上去的，而 `Kafka` 是将书本放入指定的分类区域的。\n\n而 `RocketMQ` 为什么要这么做呢？原因是 **提高数据的写入效率** ，不分 `Topic` 意味着我们有更大的几率获取 **成批** 的消息进行数据写入，但也会带来一个麻烦就是读取消息的时候需要遍历整个大文件，这是非常耗时的。\n\n所以，在 `RocketMQ` 中又使用了 `ConsumeQueue` 作为每个队列的索引文件来 **提升读取消息的效率**。我们可以直接根据队列的消息序号，计算出索引的全局位置（索引序号*索引固定⻓度 20），然后直接读取这条索引，再根据索引中记录的消息的全局位置，找到消息。\n\n讲到这里，你可能对 `RockeMQ` 的存储架构还有些模糊，没事，我们结合着图来理解一下。\n\n![](statistic/16ef388763c25c62.jpg.png)\n\nemmm，是不是有一点复杂 🤣，看英文图片和英文文档的时候就不要怂，硬着头皮往下看就行。\n\n\u003e 如果上面没看懂的读者一定要认真看下面的流程分析！\n\n首先，在最上面的那一块就是我刚刚讲的你现在可以直接 **把 `ConsumerQueue` 理解为 `Queue`**。\n\n在图中最左边说明了红色方块代表被写入的消息，虚线方块代表等待被写入的。左边的生产者发送消息会指定 `Topic`、`QueueId` 和具体消息内容，而在 `Broker` 中管你是哪门子消息，他直接 **全部顺序存储到了 CommitLog**。而根据生产者指定的 `Topic` 和 `QueueId` 将这条消息本身在 `CommitLog` 的偏移(offset)，消息本身大小，和 tag 的 hash 值存入对应的 `ConsumeQueue` 索引文件中。而在每个队列中都保存了 `ConsumeOffset` 即每个消费者组的消费位置(我在架构那里提到了，忘了的同学可以回去看一下)，而消费者拉取消息进行消费的时候只需要根据 `ConsumeOffset` 获取下一个未被消费的消息就行了。\n\n上述就是我对于整个消息存储架构的大概理解(这里不涉及到一些细节讨论，比如稀疏索引等等问题)，希望对你有帮助。\n\n因为有一个知识点因为写嗨了忘讲了，想想在哪里加也不好，所以我留给大家去思考 🤔🤔 一下吧。\n\n![](statistic/e314ee45gy1g05zgr67bbj20gp0b3aba.jpg)\n\n为什么 `CommitLog` 文件要设计成固定大小的长度呢？提醒：**内存映射机制**。\n\n## [#](#总结) 总结\n\n总算把这篇博客写完了。我讲的你们还记得吗 😅？\n\n这篇文章中我主要想大家介绍了\n\n1. 消息队列出现的原因\n2. 消息队列的作用(异步，解耦，削峰)\n3. 消息队列带来的一系列问题(消息堆积、重复消费、顺序消费、分布式事务等等)\n4. 消息队列的两种消息模型——队列和主题模式\n5. 分析了 `RocketMQ` 的技术架构(`NameServer`、`Broker`、`Producer`、`Comsumer`)\n6. 结合 `RocketMQ` 回答了消息队列副作用的解决方案\n7. 介绍了 `RocketMQ` 的存储机制和刷盘策略。\n\n等等。。。\n\n---\n\n著作权归Guide所有 原文链接：https://javaguide.cn/high-performance/message-queue/rocketmq-questions.html#%E5%AD%98%E5%82%A8%E6%9C%BA%E5%88%B6","lastmodified":"2023-08-02T03:10:42.50009367Z","tags":[]},"/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/%E5%9C%BA%E6%99%AF%E9%A2%98/%E5%A6%82%E4%BD%95":{"title":"如何","content":"\n![](statistic/Pasted%20image%2020230802012455.png)","lastmodified":"2023-08-02T03:10:42.50009367Z","tags":[]},"/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/%E5%9C%BA%E6%99%AF%E9%A2%98/%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E4%B8%80%E4%B8%AA%E6%8E%92%E8%A1%8C%E6%A6%9C":{"title":"如何设计一个排行榜？","content":"![](statistic/Pasted%20image%2020230802012459.png)","lastmodified":"2023-08-02T03:10:42.50009367Z","tags":[]},"/%E7%BD%91%E7%BB%9C/HTTP/7-HTTP3-%E5%BC%BA%E5%8A%BF%E6%9D%A5%E8%A2%AD":{"title":"7 HTTP3 强势来袭","content":"\nHTTP/3 现在（2022 年 5 月）还没正式推出，不过自 2017 年起，HTTP/3 已经更新到 34 个草案了，基本的特性已经确定下来了，对于包格式可能后续会有变化。\n\n所以，这次 HTTP/3 介绍不会涉及到包格式，只说它的特性。\n\n![](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/网络/http3/HTTP3提纲.png)\n\n## 美中不足的 HTTP/2 \n\nHTTP/2 通过头部压缩、二进制编码、多路复用、服务器推送等新特性大幅度提升了 HTTP/1.1 的性能，而美中不足的是 HTTP/2 协议是基于 TCP 实现的，于是存在的缺陷有三个。\n\n- 队头阻塞；\n- TCP 与 TLS 的握手时延迟；\n- 网络迁移需要重新连接；\n\n### 队头阻塞\n\nHTTP/2 多个请求是跑在一个 TCP 连接中的，那么当 TCP 丢包时，整个 TCP 都要等待重传，那么就会阻塞该 TCP 连接中的所有请求。\n\n比如下图中，Stream 2 有一个 TCP 报文丢失了，那么即使收到了 Stream 3 和 Stream 4 的 TCP 报文，应用层也是无法读取的，相当于阻塞了 Stream 3 和 Stream 4 请求。\n\n![](https://cdn.xiaolincoding.com/gh/xiaolincoder/network/quic/http2阻塞.jpeg)\n\n因为 TCP 是字节流协议，TCP 层必须保证收到的字节数据是完整且有序的，如果序列号较低的 TCP 段在网络传输中丢失了，即使序列号较高的 TCP 段已经被接收了，应用层也无法从内核中读取到这部分数据，从 HTTP 视角看，就是请求被阻塞了。\n\n举个例子，如下图：\n\n![](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/网络/http3/tcp队头阻塞.gif)\n\n图中发送方发送了很多个 Packet，每个 Packet 都有自己的序号，你可以认为是 TCP 的序列号，其中 Packet 3 在网络中丢失了，即使 Packet 4-6 被接收方收到后，由于内核中的 TCP 数据不是连续的，于是接收方的应用层就无法从内核中读取到，只有等到 Packet 3 重传后，接收方的应用层才可以从内核中读取到数据，这就是 HTTP/2 的队头阻塞问题，是在 TCP 层面发生的。\n\n### TCP 与 TLS 的握手时延迟\n\n发起 HTTP 请求时，需要经过 TCP 三次握手和 TLS 四次握手（TLS 1.2）的过程，因此共需要 3 个 RTT 的时延才能发出请求数据。\n\n![](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/网络/http3/TCP%2BTLS.gif)\n\n另外，TCP 由于具有「拥塞控制」的特性，所以刚建立连接的 TCP 会有个「慢启动」的过程，它会对 TCP 连接产生“减速”效果。\n\n### 网络迁移需要重新连接\n\n一个 TCP 连接是由四元组（源 IP 地址，源端口，目标 IP 地址，目标端口）确定的，这意味着如果 IP 地址或者端口变动了，就会导致需要 TCP 与 TLS 重新握手，这不利于移动设备切换网络的场景，比如 4G 网络环境切换成 WiFi。\n\n这些问题都是 TCP 协议固有的问题，无论应用层的 HTTP/2 在怎么设计都无法逃脱。要解决这个问题，就必须把**传输层协议替换成 UDP**，这个大胆的决定，HTTP/3 做了！\n\n![HTTP/1 ~ HTTP/3](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/计算机网络/HTTP/27-HTTP3.png)\n\n## QUIC 协议的特点\n\n我们深知，UDP 是一个简单、不可靠的传输协议，而且是 UDP 包之间是无序的，也没有依赖关系。\n\n而且，UDP 是不需要连接的，也就不需要握手和挥手的过程，所以天然的就比 TCP 快。\n\n当然，HTTP/3 不仅仅只是简单将传输协议替换成了 UDP，还基于 UDP 协议在「应用层」实现了 **QUIC 协议**，它具有类似 TCP 的连接管理、拥塞窗口、流量控制的网络特性，相当于将不可靠传输的 UDP 协议变成“可靠”的了，所以不用担心数据包丢失的问题。\n\nQUIC 协议的优点有很多，这里举例几个，比如：\n\n- 无队头阻塞；\n- 更快的连接建立；\n- 连接迁移；\n\n\n### 无队头阻塞\n\nQUIC 协议也有类似 HTTP/2 Stream 与多路复用的概念，也是可以在同一条连接上并发传输多个 Stream，Stream 可以认为就是一条 HTTP 请求。\n\n由于 QUIC 使用的传输协议是 UDP，UDP 不关心数据包的顺序，如果数据包丢失，UDP 也不关心。\n\n不过 QUIC 协议会保证数据包的可靠性，每个数据包都有一个序号唯一标识。当某个流中的一个数据包丢失了，即使该流的其他数据包到达了，数据也无法被 HTTP/3 读取，直到 QUIC 重传丢失的报文，数据才会交给 HTTP/3。\n\n而其他流的数据报文只要被完整接收，HTTP/3 就可以读取到数据。这与 HTTP/2 不同，HTTP/2 只要某个流中的数据包丢失了，其他流也会因此受影响。\n\n所以，QUIC 连接上的多个 Stream 之间并没有依赖，都是独立的，某个流发生丢包了，只会影响该流，其他流不受影响。\n\n![](https://cdn.xiaolincoding.com/gh/xiaolincoder/network/quic/quic无阻塞.jpeg)\n\n### 更快的连接建立\n\n\n对于 HTTP/1 和 HTTP/2 协议，TCP 和 TLS 是分层的，分别属于内核实现的传输层、OpenSSL 库实现的表示层，因此它们难以合并在一起，需要分批次来握手，先 TCP 握手，再 TLS 握手。\n\nHTTP/3 在传输数据前虽然需要 QUIC 协议握手，这个握手过程只需要 1 RTT，握手的目的是为确认双方的「连接 ID」，连接迁移就是基于连接 ID 实现的。\n\n但是 HTTP/3 的 QUIC 协议并不是与 TLS 分层，而是 **QUIC 内部包含了 TLS，它在自己的帧会携带 TLS 里的“记录”，再加上 QUIC 使用的是 TLS 1.3，因此仅需 1 个 RTT 就可以「同时」完成建立连接与密钥协商，甚至在第二次连接的时候，应用数据包可以和 QUIC 握手信息（连接信息 + TLS 信息）一起发送，达到 0-RTT 的效果**。\n\n如下图右边部分，HTTP/3 当会话恢复时，有效负载数据与第一个数据包一起发送，可以做到 0-RTT：\n\n![](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/网络/http3/0-rtt.gif)\n\n\n### 连接迁移\n\n在前面我们提到，基于 TCP 传输协议的 HTTP 协议，由于是通过四元组（源 IP、源端口、目的 IP、目的端口）确定一条 TCP 连接。\n\n![TCP 四元组](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jZG4uanNkZWxpdnIubmV0L2doL3hpYW9saW5jb2Rlci9JbWFnZUhvc3QyLyVFOCVBRSVBMSVFNyVBRSU5NyVFNiU5QyVCQSVFNyVCRCU5MSVFNyVCQiU5Qy9UQ1AtJUU0JUI4JTg5JUU2JUFDJUExJUU2JThGJUExJUU2JTg5JThCJUU1JTkyJThDJUU1JTlCJTlCJUU2JUFDJUExJUU2JThDJUE1JUU2JTg5JThCLzEwLmpwZw?x-oss-process=image/format,png)\n\n那么当移动设备的网络从 4G 切换到 WiFi 时，意味着 IP 地址变化了，那么就必须要断开连接，然后重新建立连接，而建立连接的过程包含 TCP 三次握手和 TLS 四次握手的时延，以及 TCP 慢启动的减速过程，给用户的感觉就是网络突然卡顿了一下，因此连接的迁移成本是很高的。\n\n\n而 QUIC 协议没有用四元组的方式来“绑定”连接，而是通过**连接 ID** 来标记通信的两个端点，客户端和服务器可以各自选择一组 ID 来标记自己，因此即使移动设备的网络变化后，导致 IP 地址变化了，只要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以“无缝”地复用原连接，消除重连的成本，没有丝毫卡顿感，达到了**连接迁移**的功能。\n\n## HTTP/3 协议\n\n了解完 QUIC 协议的特点后，我们再来看看 HTTP/3 协议在 HTTP 这一层做了什么变化。\n\nHTTP/3 同 HTTP/2 一样采用二进制帧的结构，不同的地方在于 HTTP/2 的二进制帧里需要定义 Stream，而  HTTP/3 自身不需要再定义 Stream，直接使用 QUIC 里的 Stream，于是 HTTP/3 的帧的结构也变简单了。 \n\n![](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/网络/http3/http3frame.png)\n\n 从上图可以看到，HTTP/3 帧头只有两个字段：类型和长度。\n\n\n根据帧类型的不同，大体上分为数据帧和控制帧两大类，Headers 帧（HTTP 头部）和 DATA 帧（HTTP 包体）属于数据帧。\n\n\nHTTP/3 在头部压缩算法这一方面也做了升级，升级成了 **QPACK**。与 HTTP/2 中的 HPACK 编码方式相似，HTTP/3 中的 QPACK 也采用了静态表、动态表及 Huffman 编码。\n\n对于静态表的变化，HTTP/2 中的 HPACK 的静态表只有 61 项，而 HTTP/3 中的 QPACK 的静态表扩大到 91 项。\n\nHTTP/2 和 HTTP/3 的 Huffman 编码并没有多大不同，但是动态表编解码方式不同。\n\n所谓的动态表，在首次请求-响应后，双方会将未包含在静态表中的 Header 项更新各自的动态表，接着后续传输时仅用 1 个数字表示，然后对方可以根据这 1 个数字从动态表查到对应的数据，就不必每次都传输长长的数据，大大提升了编码效率。\n\n可以看到，**动态表是具有时序性的，如果首次出现的请求发生了丢包，后续的收到请求，对方就无法解码出 HPACK 头部，因为对方还没建立好动态表，因此后续的请求解码会阻塞到首次请求中丢失的数据包重传过来**。\n\n\nHTTP/3 的 QPACK 解决了这一问题，那它是如何解决的呢？\n\nQUIC 会有两个特殊的单向流，所谓的单向流只有一端可以发送消息，双向则指两端都可以发送消息，传输 HTTP 消息时用的是双向流，这两个单向流的用法：\n\n- 一个叫 QPACK Encoder Stream，用于将一个字典（Key-Value）传递给对方，比如面对不属于静态表的 HTTP 请求头部，客户端可以通过这个 Stream 发送字典；\n- 一个叫 QPACK Decoder Stream，用于响应对方，告诉它刚发的字典已经更新到自己的本地动态表了，后续就可以使用这个字典来编码了。\n\n这两个特殊的单向流是用来**同步双方的动态表**，编码方收到解码方更新确认的通知后，才使用动态表编码 HTTP 头部。\n\n## 总结\n\nHTTP/2 虽然具有多个流并发传输的能力，但是传输层是 TCP 协议，于是存在以下缺陷：\n\n- **队头阻塞**，HTTP/2 多个请求跑在一个 TCP 连接中，如果序列号较低的 TCP 段在网络传输中丢失了，即使序列号较高的 TCP 段已经被接收了，应用层也无法从内核中读取到这部分数据，从 HTTP 视角看，就是多个请求被阻塞了；\n- **TCP 和 TLS 握手时延**，TCP 三次握手和 TLS 四次握手，共有 3-RTT 的时延；\n- **连接迁移需要重新连接**，移动设备从 4G 网络环境切换到 WiFi 时，由于 TCP 是基于四元组来确认一条 TCP 连接的，那么网络环境变化后，就会导致 IP 地址或端口变化，于是 TCP 只能断开连接，然后再重新建立连接，切换网络环境的成本高；\n\nHTTP/3 就将传输层从 TCP 替换成了 UDP，并在 UDP 协议上开发了 QUIC 协议，来保证数据的可靠传输。\n\nQUIC 协议的特点：\n\n- **无队头阻塞**，QUIC 连接上的多个 Stream 之间并没有依赖，都是独立的，也不会有底层协议限制，某个流发生丢包了，只会影响该流，其他流不受影响；\n- **建立连接速度快**，因为 QUIC 内部包含 TLS 1.3，因此仅需 1 个 RTT 就可以「同时」完成建立连接与 TLS 密钥协商，甚至在第二次连接的时候，应用数据包可以和 QUIC 握手信息（连接信息 + TLS 信息）一起发送，达到 0-RTT 的效果。\n- **连接迁移**，QUIC 协议没有用四元组的方式来“绑定”连接，而是通过「连接 ID 」来标记通信的两个端点，客户端和服务器可以各自选择一组 ID 来标记自己，因此即使移动设备的网络变化后，导致 IP 地址变化了，只要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以“无缝”地复用原连接，消除重连的成本；\n\n另外 HTTP/3 的 QPACK 通过两个特殊的单向流来同步双方的动态表，解决了 HTTP/2 的 HPACK 队头阻塞问题。\n\n**期待，HTTP/3 正式推出的那一天！**\n\n---\n\n参考资料：\n\n1. https://medium.com/faun/http-2-spdy-and-http-3-quic-bae7d9a3d484\n2. https://developers.google.com/web/fundamentals/performance/http2?hl=zh-cn\n3. https://blog.cloudflare.com/http3-the-past-present-and-future/\n4. https://tools.ietf.org/html/draft-ietf-quic-http-34\n5. https://tools.ietf.org/html/draft-ietf-quic-transport-34#section-17\n6. https://ably.com/topic/http3?amp%3Butm_campaign=evergreen\u0026amp%3Butm_source=reddit\u0026utm_medium=referral\n7. https://www.nginx.org.cn/article/detail/422\n8. https://www.bilibili.com/read/cv793000/\n9. https://www.chinaz.com/2020/1009/1192436.shtml\n\n\n---\n\n哈喽，我是小林，就爱图解计算机基础，如果文章对你有帮助，别忘记关注哦！\n\n![](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E5%85%B6%E4%BB%96/%E5%85%AC%E4%BC%97%E5%8F%B7%E4%BB%8B%E7%BB%8D.png)\n\n","lastmodified":"2023-08-02T03:10:42.504093718Z","tags":[]},"/%E7%BD%91%E7%BB%9C/HTTP/9-%E6%97%A2%E7%84%B6%E6%9C%89-HTTP-%E5%8D%8F%E8%AE%AE%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%98%E8%A6%81%E6%9C%89-WebSocket":{"title":"9 既然有 HTTP 协议，为什么还要有 WebSocket","content":"\n\u003e 来源：公众号@小白debug\n\u003e\n\u003e 原文地址：[既然有 HTTP 协议，为什么还要有 WebSocket？](https://mp.weixin.qq.com/s/jJNdXMNmXcE8wSE0gbtTAQ)\n\n平时我们打开网页，比如购物网站某宝。都是点一下「列表商品」，跳转一下网页就到了「商品详情」。\n\n从 HTTP 协议的角度来看，就是点一下网页上的某个按钮，**前端发一次 HTTP 请求，网站返回一次 HTTP 响应**。这种由客户端主动请求，服务器响应的方式也满足大部分网页的功能场景。\n\n但有没有发现，这种情况下，服务器从来就「不会主动」给客户端发一次消息。就像你喜欢的女生从来不会主动找你一样。\n\n但如果现在，你在刷网页的时候「右下角」突然弹出一个小广告，提示你【一个人在家偷偷才能玩哦】。\n\n**求知，好学，勤奋**，这些刻在你 DNA 里的东西都动起来了。\n\n你点开后发现。\n\n长相平平无奇的古某提示你\"道士 9 条狗，全服横着走\"。\n\n影帝某辉老师跟你说\"系兄弟就来砍我\"。\n\n![图片](https://img-blog.csdnimg.cn/img_convert/b8cca4b1291f25235bc8df3dddbb6da3.png)\n\n来都来了，你就选了个角色进到了游戏界面里。\n\n![图片](https://img-blog.csdnimg.cn/img_convert/95e5b4cee384b182d0e604378c3ca00a.jpeg)\n\n这时候，上来就是一个小怪，从远处走来，然后疯狂拿木棒子抽你。\n\n**你全程没点任何一次鼠标**。服务器就自动将怪物的移动数据和攻击数据源源不断发给你了。\n\n这….太暖心了。\n\n感动之余，问题就来了：\n\n像这种**看起来服务器主动发消息给客户端的场景**，是怎么做到的？\n\n在真正回答这个问题之前，我们先来聊下一些相关的知识背景。\n\n## 使用 HTTP 不断轮询\n\n其实问题的痛点在于，**怎么样才能在用户不做任何操作的情况下，网页能收到消息并发生变更。**\n\n最常见的解决方案是，**网页的前端代码里不断定时发 HTTP 请求到服务器，服务器收到请求后给客户端响应消息。**\n\n这其实时一种「**伪**」服务器推的形式。\n\n它其实并不是服务器主动发消息到客户端，而是客户端自己不断偷偷请求服务器，只是用户无感知而已。\n\n用这种方式的场景也有很多，最常见的就是**扫码登录**。\n\n比如，某信公众号平台，登录页面二维码出现之后，**前端**网页根本不知道用户扫没扫，于是不断去向**后端**服务器询问，看有没有人扫过这个码。而且是以大概 1 到 2 秒的间隔去不断发出请求，这样可以保证用户在扫码后能在 1 到 2 秒内得到及时的反馈，不至于**等太久**。\n\n## 使用 HTTP 定时轮询\n\n但这样，会有两个比较明显的问题：\n\n- 当你打开 F12 页面时，你会发现满屏的 HTTP 请求。虽然很小，但这其实也消耗带宽，同时也会增加下游服务器的负担。\n- 最坏情况下，用户在扫码后，需要等个 1~2 秒，正好才触发下一次 HTTP 请求，然后才跳转页面，用户会感到**明显的卡顿**。\n\n使用起来的体验就是，二维码出现后，手机扫一扫，然后在手机上点个确认，这时候**卡顿等个 1~2 秒**，页面才跳转。\n\n![图片](https://img-blog.csdnimg.cn/img_convert/5e0e0e25e8aca80812c9a2892032111c.png)\n\n那么问题又来了，**有没有更好的解决方案？**\n\n有，而且实现起来成本还非常低。\n\n## 长轮询\n\n我们知道，HTTP 请求发出后，一般会给服务器留一定的时间做响应，比如 3 秒，规定时间内没返回，就认为是超时。\n\n如果我们的 HTTP 请求**将超时设置的很大**，比如 30 秒，**在这 30 秒内只要服务器收到了扫码请求，就立马返回给客户端网页。如果超时，那就立马发起下一次请求。**\n\n这样就减少了 HTTP 请求的个数，并且由于大部分情况下，用户都会在某个 30 秒的区间内做扫码操作，所以响应也是及时的。\n\n![图片](https://img-blog.csdnimg.cn/img_convert/1058a96ba35215c0f30accc3ff5bb824.png)\n\n比如，某度云网盘就是这么干的。所以你会发现一扫码，手机上点个确认，电脑端网页就**秒跳转**，体验很好。\n\n![图片](https://img-blog.csdnimg.cn/img_convert/a3a8c95b97d2bac26cfab123a4da68b2.png)\n\n像这种发起一个请求，在较长时间内等待服务器响应的机制，就是所谓的**长轮询机制**。我们常用的消息队列 RocketMQ 中，消费者去取数据时，也用到了这种方式。\n\n![图片](https://img-blog.csdnimg.cn/img_convert/6173c1d25abc914ef17ee9e534ed6a5f.png)\n\n像这种，在用户不感知的情况下，服务器将数据推送给浏览器的技术，就是所谓的**服务器推送**技术，它还有个毫不沾边的英文名，**comet** 技术，大家听过就好。\n\n上面提到的两种解决方案（不断轮询和长轮询），本质上，其实还是客户端主动去取数据。\n\n对于像扫码登录这样的**简单场景**还能用用。但如果是网页游戏呢，游戏一般会有大量的数据需要从服务器主动推送到客户端。\n\n这就得说下 **WebSocket** 了。\n\n## WebSocket 是什么\n\n我们知道 TCP 连接的两端，**同一时间里**，**双方**都可以**主动**向对方发送数据。这就是所谓的**全双工**。\n\n而现在使用最广泛的 `HTTP/1.1`，也是基于 TCP 协议的，**同一时间里**，客户端和服务器**只能有一方主动**发数据，这就是所谓的**半双工**。\n\n也就是说，好好的全双工 TCP，被 HTTP/1.1 用成了半双工。\n\n为什么？\n\n这是由于 HTTP 协议设计之初，考虑的是看看网页文本的场景，能做到**客户端发起请求再由服务器响应**，就够了，根本就没考虑网页游戏这种，客户端和服务器之间都要互相主动发大量数据的场景。\n\n所以，为了更好的支持这样的场景，我们需要另外一个**基于 TCP 的新协议**。\n\n于是新的应用层协议 **WebSocket** 就被设计出来了。\n\n大家别被这个名字给带偏了。虽然名字带了个 socket，但其实 **socket 和 WebSocket 之间，就跟雷峰和雷峰塔一样，二者接近毫无关系**。\n\n![图片](https://img-blog.csdnimg.cn/img_convert/3bbe4c5db972513f912d30ba8cbddd65.png)\n\n### 怎么建立 WebSocket 连接\n\n我们平时刷网页，一般都是在浏览器上刷的，一会刷刷图文，这时候用的是 **HTTP 协议**，一会打开网页游戏，这时候就得切换成我们新介绍的 **WebSocket 协议**。\n\n为了兼容这些使用场景。浏览器在 **TCP 三次握手**建立连接之后，都**统一使用 HTTP 协议**先进行一次通信。\n\n- 如果此时是**普通的 HTTP 请求**，那后续双方就还是老样子继续用普通 HTTP 协议进行交互，这点没啥疑问。\n- 如果这时候是**想建立 WebSocket 连接**，就会在 HTTP 请求里带上一些**特殊的 header 头**，如下：\n\n```http\nConnection: Upgrade\nUpgrade: WebSocket\nSec-WebSocket-Key: T2a6wZlAwhgQNqruZ2YUyg==\\r\\n\n```\n\n这些 header 头的意思是，浏览器想**升级协议（Connection: Upgrade）**，并且**想升级成 WebSocket 协议（Upgrade: WebSocket）**。同时带上一段**随机生成的 Base64 码（Sec-WebSocket-Key）**，发给服务器。\n\n如果服务器正好支持升级成 WebSocket 协议。就会走 WebSocket 握手流程，同时根据客户端生成的 Base64 码，用某个**公开的**算法变成另一段字符串，放在 HTTP 响应的 `Sec-WebSocket-Accept` 头里，同时带上 `101 状态码`，发回给浏览器。HTTP 的响应如下：\n\n```http\nHTTP/1.1 101 Switching Protocols\\r\\n\nSec-WebSocket-Accept: iBJKv/ALIW2DobfoA4dmr3JHBCY=\\r\\n\nUpgrade: WebSocket\\r\\n\nConnection: Upgrade\\r\\n\n```\n\nHTTP 状态码=200（正常响应）的情况，大家见得多了。101 确实不常见，它其实是指**协议切换**。\n\n![图片](https://img-blog.csdnimg.cn/img_convert/dea71991b336c876cae2e1ebdf03b62d.png)\n\n之后，浏览器也用同样的**公开算法**将 `Base64 码` 转成另一段字符串，如果这段字符串跟服务器传回来的**字符串一致**，那验证通过。\n\n![图片](https://img-blog.csdnimg.cn/img_convert/117eebe06cc6b35ded3216a95706f080.png)\n\n就这样经历了一来一回两次 HTTP 握手，WebSocket 就建立完成了，后续双方就可以使用 WebSocket 的数据格式进行通信了。\n\n![图片](https://img-blog.csdnimg.cn/img_convert/f4edd3018914fe6eb38fad6aa3fd2d65.png)\n\n### WebSocket 抓包\n\n我们可以用 WireShark 抓个包，实际看下数据包的情况。\n\n![图片](https://img-blog.csdnimg.cn/img_convert/f756ca625523f0f9d40a402465179bbe.png)\n\n上面这张图，注意画了红框的第 `2445` 行报文，是 WebSocket 的**第一次握手**，意思是发起了一次带有 `特殊 Header` 的 HTTP 请求。\n\n![图片](https://img-blog.csdnimg.cn/img_convert/82d65f08dad05e6b537ea06b94224a5f.png)\n\n上面这个图里画了红框的 `4714` 行报文，就是服务器在得到第一次握手后，响应的**第二次握手**，可以看到这也是个 HTTP 类型的报文，返回的状态码是 101。同时可以看到返回的报文 Header 中也带有各种 `WebSocket` 相关的信息，比如 `Sec-WebSocket-Accept`。\n\n![图片](https://img-blog.csdnimg.cn/img_convert/382c7699530ea7e7b22f60bb68af21bd.png)\n\n上面这张图就是全貌了，从截图上的注释可以看出，WebSocket 和 HTTP 一样都是基于 TCP 的协议。**经历了三次 TCP 握手之后，利用 HTTP 协议升级为 WebSocket 协议**。\n\n你在网上可能会看到一种说法：“WebSocket 是基于 HTTP 的新协议”，**其实这并不对**，因为 WebSocket 只有在建立连接时才用到了 HTTP，**升级完成之后就跟 HTTP 没有任何关系了**。\n\n这就好像你喜欢的女生通过你要到了你大学室友的微信，然后他们自己就聊起来了。你能说这个女生是通过你去跟你室友沟通的吗？不能。你跟 HTTP 一样，都只是个**工具人**。\n\n![图片](https://img-blog.csdnimg.cn/img_convert/2e9d4b1652bdfa1e3ae4bb24f70a1b5a.png)\n\n这就有点\"**借壳生蛋**\"的那意思。\n\n## HTTP 和 WebSocket 的关系\n\n### WebSocket 的消息格式\n\n上面提到在完成协议升级之后，两端就会用 WebSocket 的数据格式进行通信。\n\n数据包在 WebSocket 中被叫做**帧**，我们来看下它的数据格式长什么样子。\n\n![图片](https://img-blog.csdnimg.cn/img_convert/3a63a86e5d7e72a37b9828fc6e65c21f.png)\n\n这里面字段很多，但我们只需要关注下面这几个。\n\n**opcode 字段**：这个是用来标志这是个**什么类型**的数据帧。比如。\n\n- 等于 1 ，是指text类型（`string`）的数据包\n- 等于 2 ，是二进制数据类型（`[]byte`）的数据包\n- 等于 8 ，是关闭连接的信号\n\n**payload 字段**：存放的是我们**真正想要传输的数据的长度**，单位是**字节**。比如你要发送的数据是 `字符串\"111\"`，那它的长度就是 `3`。\n\n![图片](https://img-blog.csdnimg.cn/img_convert/437a076935f82be1d36960c9a4785fbd.png)\n\n另外，可以看到，我们存放**payload 长度的字段有好几个**，我们既可以用最前面的 `7 bit`, 也可以用后面的 `7+16 bit` 或 `7+64 bit`。\n\n那么问题就来了。\n\n我们知道，在数据层面，大家都是 01 二进制流。我怎么知道**什么情况下应该读 7 bit，什么情况下应该读 7+16 bit 呢？**\n\nWebSocket 会用最开始的 7 bit 做标志位。不管接下来的数据有多大，都**先读最先的 7 个 bit**，根据它的取值决定还要不要再读个 16 bit 或 64 bit。\n\n- 如果 `最开始的 7 bit` 的值是 0~125，那么它就表示了 **payload 全部长度**，只读最开始的 `7 个 bit` 就完事了。\n\n![图片](https://img-blog.csdnimg.cn/img_convert/690f5a4deda2de50f3a35eddf0be4d75.png)\n\n- 如果是 `126（0x7E）`。那它表示payload的长度范围在 `126~65535` 之间，接下来还需要**再读 16 bit**。这 16 bit 会包含 payload 的真实长度。\n\n![图片](https://img-blog.csdnimg.cn/img_convert/c815c9dabc02fceb42a98c762705af33.png)\n\n- 如果是 `127（0x7F）`。那它表示 payload 的长度范围 `\u003e=65536`，接下来还需要**再读 64 bit**。这 64 bit 会包含 payload 的长度。这能放 2 的 64 次方 byte 的数据，换算一下好多个 TB，肯定够用了。\n\n![图片](https://img-blog.csdnimg.cn/img_convert/192b22b4fe46e8dfb7b17549306d5998.png)\n\n**payload data 字段**：这里存放的就是真正要传输的数据，在知道了上面的 payload 长度后，就可以根据这个值去截取对应的数据。\n\n大家有没有发现一个小细节，WebSocket 的数据格式也是**数据头（内含 payload 长度） + payload data** 的形式。\n\n![图片](https://img-blog.csdnimg.cn/img_convert/d449242f1bf41c6f95a5314ec8311d0d.jpeg)\n\n这是因为 TCP 协议本身就是全双工，但直接使用**纯裸 TCP** 去传输数据，会有**粘包**的\"问题\"。为了解决这个问题，上层协议一般会用**消息头+消息体**的格式去重新包装要发的数据。\n\n而**消息头**里一般含有**消息体的长度**，通过这个长度可以去截取真正的消息体。\n\nHTTP 协议和大部分 RPC 协议，以及我们今天介绍的 WebSocket 协议，都是这样设计的。\n\n![图片](https://img-blog.csdnimg.cn/img_convert/b91fedb1856897c231b8fb5932b7b2d2.png)\n\n### WebSocket 的使用场景\n\nWebSocket 完美继承了 TCP 协议的**全双工**能力，并且还贴心的提供了解决粘包的方案。\n\n它适用于**需要服务器和客户端（浏览器）频繁交互**的大部分场景，比如网页/小程序游戏，网页聊天室，以及一些类似飞书这样的网页协同办公软件。\n\n回到文章开头的问题，在使用 WebSocket 协议的网页游戏里，怪物移动以及攻击玩家的行为是**服务器逻辑**产生的，对玩家产生的伤害等数据，都需要由**服务器主动发送给客户端**，客户端获得数据后展示对应的效果。\n\n![图片](https://img-blog.csdnimg.cn/img_convert/31410d2e885aab55c2c588aad754bb5c.png)\n\n## 总结\n\n- TCP 协议本身是**全双工**的，但我们最常用的 HTTP/1.1，虽然是基于 TCP 的协议，但它是**半双工**的，对于大部分需要服务器主动推送数据到客户端的场景，都不太友好，因此我们需要使用支持全双工的 WebSocket 协议。\n- 在 HTTP/1.1 里，只要客户端不问，服务端就不答。基于这样的特点，对于登录页面这样的简单场景，可以使用**定时轮询或者长轮询**的方式实现**服务器推送**(comet)的效果。\n- 对于客户端和服务端之间需要频繁交互的复杂场景，比如网页游戏，都可以考虑使用 WebSocket 协议。\n- WebSocket 和 socket 几乎没有任何关系，只是叫法相似。\n- 正因为各个浏览器都支持 HTTP 协议，所以 WebSocket 会先利用 HTTP 协议加上一些特殊的 Header 头进行握手升级操作，升级成功后就跟 HTTP 没有任何关系了，之后就用 WebSocket 的数据格式进行收发数据。\n\n------\n\n***哈喽，我是小林，就爱图解计算机基础，如果觉得文章对你有帮助，欢迎微信搜索「小林coding」关注我***\n\n![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%E5%85%B6%E4%BB%96/%E5%85%AC%E4%BC%97%E5%8F%B7%E4%BB%8B%E7%BB%8D.png)","lastmodified":"2023-08-02T03:10:42.504093718Z","tags":[]},"/Dobbo/Dubbo%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93":{"title":"Dubbo常见问题总结","content":"这篇文章是我根据官方文档以及自己平时的使用情况，对 Dubbo 所做的一个总结。欢迎补充！\n\n## [#](#dubbo-基础) Dubbo 基础\n\n### [#](#什么是-dubbo) 什么是 Dubbo?\n\n![Dubbo 官网](statistic/Dubbo_官网.png)\n\nDubbo 官网\n\n[Apache Dubboopen in new window](https://github.com/apache/dubbo) |ˈdʌbəʊ| 是一款高性能、轻量级的开源 WEB 和 RPC 框架。\n\n根据 [Dubbo 官方文档open in new window](https://dubbo.apache.org/zh/)的介绍，Dubbo 提供了六大核心能力\n\n1. 面向接口代理的高性能 RPC 调用。\n2. 智能容错和负载均衡。\n3. 服务自动注册和发现。\n4. 高度可扩展能力。\n5. 运行期流量调度。\n6. 可视化的服务治理与运维。\n\n![Dubbo提供的六大核心能力](statistic/Dubbo提供的六大核心能力.png)\n\nDubbo提供的六大核心能力\n\n简单来说就是：**Dubbo 不光可以帮助我们调用远程服务，还提供了一些其他开箱即用的功能比如智能负载均衡。**\n\nDubbo 目前已经有接近 34.4 k 的 Star 。\n\n在 **2020 年度 OSC 中国开源项目** 评选活动中，Dubbo 位列开发框架和基础组件类项目的第 7 名。相比几年前来说，热度和排名有所下降。\n\n![](statistic/image-20210107153159545.png)\n\nDubbo 是由阿里开源，后来加入了 Apache 。正是由于 Dubbo 的出现，才使得越来越多的公司开始使用以及接受分布式架构。\n\n### [#](#为什么要用-dubbo) 为什么要用 Dubbo?\n\n随着互联网的发展，网站的规模越来越大，用户数量越来越多。单一应用架构、垂直应用架构无法满足我们的需求，这个时候分布式服务架构就诞生了。\n\n分布式服务架构下，系统被拆分成不同的服务比如短信服务、安全服务，每个服务独立提供系统的某个核心服务。\n\n我们可以使用 Java RMI（Java Remote Method Invocation）、Hessian 这种支持远程调用的框架来简单地暴露和引用远程服务。但是！当服务越来越多之后，服务调用关系越来越复杂。当应用访问压力越来越大后，负载均衡以及服务监控的需求也迫在眉睫。我们可以用 F5 这类硬件来做负载均衡，但这样增加了成本，并且存在单点故障的风险。\n\n不过，Dubbo 的出现让上述问题得到了解决。**Dubbo 帮助我们解决了什么问题呢？**\n\n1. **负载均衡**：同一个服务部署在不同的机器时该调用哪一台机器上的服务。\n2. **服务调用链路生成**：随着系统的发展，服务越来越多，服务间依赖关系变得错踪复杂，甚至分不清哪个应用要在哪个应用之前启动，架构师都不能完整的描述应用的架构关系。Dubbo 可以为我们解决服务之间互相是如何调用的。\n3. **服务访问压力以及时长统计、资源调度和治理**：基于访问压力实时管理集群容量，提高集群利用率。\n4. ......\n\n![Dubbo 能力概览](statistic/Dubbo_能力概览.jpg)\n\nDubbo 能力概览\n\n另外，Dubbo 除了能够应用在分布式系统中，也可以应用在现在比较火的微服务系统中。不过，由于 Spring Cloud 在微服务中应用更加广泛，所以，我觉得一般我们提 Dubbo 的话，大部分是分布式系统的情况。\n\n**我们刚刚提到了分布式这个概念，下面再给大家介绍一下什么是分布式？为什么要分布式？**\n\n## [#](#分布式基础) 分布式基础\n\n### [#](#什么是分布式) 什么是分布式?\n\n分布式或者说 SOA 分布式重要的就是面向服务，说简单的分布式就是我们把整个系统拆分成不同的服务然后将这些服务放在不同的服务器上减轻单体服务的压力提高并发量和性能。比如电商系统可以简单地拆分成订单系统、商品系统、登录系统等等，拆分之后的每个服务可以部署在不同的机器上，如果某一个服务的访问量比较大的话也可以将这个服务同时部署在多台机器上。\n\n![分布式事务示意图](statistic/分布式事务示意图.png)\n\n分布式事务示意图\n\n### [#](#为什么要分布式) 为什么要分布式?\n\n从开发角度来讲单体应用的代码都集中在一起，而分布式系统的代码根据业务被拆分。所以，每个团队可以负责一个服务的开发，这样提升了开发效率。另外，代码根据业务拆分之后更加便于维护和扩展。\n\n另外，我觉得将系统拆分成分布式之后不光便于系统扩展和维护，更能提高整个系统的性能。你想一想嘛？把整个系统拆分成不同的服务/系统，然后每个服务/系统 单独部署在一台服务器上，是不是很大程度上提高了系统性能呢？\n\n## [#](#dubbo-架构) Dubbo 架构\n\n### [#](#dubbo-架构中的核心角色有哪些) Dubbo 架构中的核心角色有哪些？\n\n[官方文档中的框架设计章节open in new window](https://dubbo.apache.org/zh/docs/v2.7/dev/design/) 已经介绍的非常详细了，我这里把一些比较重要的点再提一下。\n\n![dubbo-relation](statistic/dubbo-relation.jpg)\n\ndubbo-relation\n\n上述节点简单介绍以及他们之间的关系：\n\n- **Container：** 服务运行容器，负责加载、运行服务提供者。必须。\n- **Provider：** 暴露服务的服务提供方，会向注册中心注册自己提供的服务。必须。\n- **Consumer：** 调用远程服务的服务消费方，会向注册中心订阅自己所需的服务。必须。\n- **Registry：** 服务注册与发现的注册中心。注册中心会返回服务提供者地址列表给消费者。非必须。\n- **Monitor：** 统计服务的调用次数和调用时间的监控中心。服务消费者和提供者会定时发送统计数据到监控中心。 非必须。\n\n### [#](#dubbo-中的-invoker-概念了解么) Dubbo 中的 Invoker 概念了解么？\n\n`Invoker` 是 Dubbo 领域模型中非常重要的一个概念，你如果阅读过 Dubbo 源码的话，你会无数次看到这玩意。就比如下面我要说的负载均衡这块的源码中就有大量 `Invoker` 的身影。\n\n简单来说，`Invoker` 就是 Dubbo 对远程调用的抽象。\n\n![dubbo_rpc_invoke.jpg](statistic/dubbo_rpc_invoke.jpg)\n\ndubbo_rpc_invoke.jpg\n\n按照 Dubbo 官方的话来说，`Invoker` 分为\n\n- 服务提供 `Invoker`\n- 服务消费 `Invoker`\n\n假如我们需要调用一个远程方法，我们需要动态代理来屏蔽远程调用的细节吧！我们屏蔽掉的这些细节就依赖对应的 `Invoker` 实现， `Invoker` 实现了真正的远程服务调用。\n\n### [#](#dubbo-的工作原理了解么) Dubbo 的工作原理了解么？\n\n下图是 Dubbo 的整体设计，从下至上分为十层，各层均为单向依赖。\n\n\u003e 左边淡蓝背景的为服务消费方使用的接口，右边淡绿色背景的为服务提供方使用的接口，位于中轴线上的为双方都用到的接口。\n\n![dubbo-framework](statistic/dubbo-framework.jpg)\n\ndubbo-framework\n\n- **config 配置层**：Dubbo 相关的配置。支持代码配置，同时也支持基于 Spring 来做配置，以 `ServiceConfig`, `ReferenceConfig` 为中心\n- **proxy 服务代理层**：调用远程方法像调用本地的方法一样简单的一个关键，真实调用过程依赖代理类，以 `ServiceProxy` 为中心。\n- **registry 注册中心层**：封装服务地址的注册与发现。\n- **cluster 路由层**：封装多个提供者的路由及负载均衡，并桥接注册中心，以 `Invoker` 为中心。\n- **monitor 监控层**：RPC 调用次数和调用时间监控，以 `Statistics` 为中心。\n- **protocol 远程调用层**：封装 RPC 调用，以 `Invocation`, `Result` 为中心。\n- **exchange 信息交换层**：封装请求响应模式，同步转异步，以 `Request`, `Response` 为中心。\n- **transport 网络传输层**：抽象 mina 和 netty 为统一接口，以 `Message` 为中心。\n- **serialize 数据序列化层**：对需要在网络传输的数据进行序列化。\n\n### [#](#dubbo-的-spi-机制了解么-如何扩展-dubbo-中的默认实现) Dubbo 的 SPI 机制了解么？ 如何扩展 Dubbo 中的默认实现？\n\nSPI（Service Provider Interface） 机制被大量用在开源项目中，它可以帮助我们动态寻找服务/功能（比如负载均衡策略）的实现。\n\nSPI 的具体原理是这样的：我们将接口的实现类放在配置文件中，我们在程序运行过程中读取配置文件，通过反射加载实现类。这样，我们可以在运行的时候，动态替换接口的实现类。和 IoC 的解耦思想是类似的。\n\nJava 本身就提供了 SPI 机制的实现。不过，Dubbo 没有直接用，而是对 Java 原生的 SPI 机制进行了增强，以便更好满足自己的需求。\n\n**那我们如何扩展 Dubbo 中的默认实现呢？**\n\n比如说我们想要实现自己的负载均衡策略，我们创建对应的实现类 `XxxLoadBalance` 实现 `LoadBalance` 接口或者 `AbstractLoadBalance` 类。\n\n```\npackage com.xxx;\n\nimport org.apache.dubbo.rpc.cluster.LoadBalance;\nimport org.apache.dubbo.rpc.Invoker;\nimport org.apache.dubbo.rpc.Invocation;\nimport org.apache.dubbo.rpc.RpcException;\n\npublic class XxxLoadBalance implements LoadBalance {\n    public \u003cT\u003e Invoker\u003cT\u003e select(List\u003cInvoker\u003cT\u003e\u003e invokers, Invocation invocation) throws RpcException {\n        // ...\n    }\n}\n```\n\n我们将这个实现类的路径写入到`resources` 目录下的 `META-INF/dubbo/org.apache.dubbo.rpc.cluster.LoadBalance`文件中即可。\n\n```\nsrc\n |-main\n    |-java\n        |-com\n            |-xxx\n                |-XxxLoadBalance.java (实现LoadBalance接口)\n    |-resources\n        |-META-INF\n            |-dubbo\n                |-org.apache.dubbo.rpc.cluster.LoadBalance (纯文本文件，内容为：xxx=com.xxx.XxxLoadBalance)\n```\n\n`org.apache.dubbo.rpc.cluster.LoadBalance`\n\n```\nxxx=com.xxx.XxxLoadBalance\n```\n\n其他还有很多可供扩展的选择，你可以在[官方文档open in new window](https://cn.dubbo.apache.org/zh-cn/overview/home/)中找到。\n\n### [#](#dubbo-的微内核架构了解吗) Dubbo 的微内核架构了解吗？\n\nDubbo 采用 微内核（Microkernel） + 插件（Plugin） 模式，简单来说就是微内核架构。微内核只负责组装插件。\n\n**何为微内核架构呢？** 《软件架构模式》 这本书是这样介绍的：\n\n\u003e 微内核架构模式（有时被称为插件架构模式）是实现基于产品应用程序的一种自然模式。基于产品的应用程序是已经打包好并且拥有不同版本，可作为第三方插件下载的。然后，很多公司也在开发、发布自己内部商业应用像有版本号、说明及可加载插件式的应用软件（这也是这种模式的特征）。微内核系统可让用户添加额外的应用如插件，到核心应用，继而提供了可扩展性和功能分离的用法。\n\n微内核架构包含两类组件：**核心系统（core system）** 和 **插件模块（plug-in modules）**。\n\n![](statistic/%E5%BE%AE%E5%86%85%E6%A0%B8%E6%9E%B6%E6%9E%84%E7%A4%BA%E6%84%8F%E5%9B%BE.png)\n\n核心系统提供系统所需核心能力，插件模块可以扩展系统的功能。因此， 基于微内核架构的系统，非常易于扩展功能。\n\n我们常见的一些 IDE，都可以看作是基于微内核架构设计的。绝大多数 IDE 比如 IDEA、VSCode 都提供了插件来丰富自己的功能。\n\n正是因为 Dubbo 基于微内核架构，才使得我们可以随心所欲替换 Dubbo 的功能点。比如你觉得 Dubbo 的序列化模块实现的不满足自己要求，没关系啊！你自己实现一个序列化模块就好了啊！\n\n通常情况下，微核心都会采用 Factory、IoC、OSGi 等方式管理插件生命周期。Dubbo 不想依赖 Spring 等 IoC 容器，也不想自己造一个小的 IoC 容器（过度设计），因此采用了一种最简单的 Factory 方式管理插件：**JDK 标准的 SPI 扩展机制** （`java.util.ServiceLoader`）。\n\n### [#](#关于-dubbo-架构的一些自测小问题) 关于 Dubbo 架构的一些自测小问题\n\n#### [#](#注册中心的作用了解么) 注册中心的作用了解么？\n\n注册中心负责服务地址的注册与查找，相当于目录服务，服务提供者和消费者只在启动时与注册中心交互。\n\n#### [#](#服务提供者宕机后-注册中心会做什么) 服务提供者宕机后，注册中心会做什么？\n\n注册中心会立即推送事件通知消费者。\n\n#### [#](#监控中心的作用呢) 监控中心的作用呢？\n\n监控中心负责统计各服务调用次数，调用时间等。\n\n#### [#](#注册中心和监控中心都宕机的话-服务都会挂掉吗) 注册中心和监控中心都宕机的话，服务都会挂掉吗？\n\n不会。两者都宕机也不影响已运行的提供者和消费者，消费者在本地缓存了提供者列表。注册中心和监控中心都是可选的，服务消费者可以直连服务提供者。\n\n## [#](#dubbo-的负载均衡策略) Dubbo 的负载均衡策略\n\n### [#](#什么是负载均衡) 什么是负载均衡？\n\n先来看一下稍微官方点的解释。下面这段话摘自维基百科对负载均衡的定义：\n\n\u003e 负载均衡改善了跨多个计算资源（例如计算机，计算机集群，网络链接，中央处理单元或磁盘驱动）的工作负载分布。负载平衡旨在优化资源使用，最大化吞吐量，最小化响应时间，并避免任何单个资源的过载。使用具有负载平衡而不是单个组件的多个组件可以通过冗余提高可靠性和可用性。负载平衡通常涉及专用软件或硬件。\n\n**上面讲的大家可能不太好理解，再用通俗的话给大家说一下。**\n\n我们的系统中的某个服务的访问量特别大，我们将这个服务部署在了多台服务器上，当客户端发起请求的时候，多台服务器都可以处理这个请求。那么，如何正确选择处理该请求的服务器就很关键。假如，你就要一台服务器来处理该服务的请求，那该服务部署在多台服务器的意义就不复存在了。负载均衡就是为了避免单个服务器响应同一请求，容易造成服务器宕机、崩溃等问题，我们从负载均衡的这四个字就能明显感受到它的意义。\n\n### [#](#dubbo-提供的负载均衡策略有哪些) Dubbo 提供的负载均衡策略有哪些？\n\n在集群负载均衡时，Dubbo 提供了多种均衡策略，默认为 `random` 随机调用。我们还可以自行扩展负载均衡策略（参考 Dubbo SPI 机制）。\n\n在 Dubbo 中，所有负载均衡实现类均继承自 `AbstractLoadBalance`，该类实现了 `LoadBalance` 接口，并封装了一些公共的逻辑。\n\n```\npublic abstract class AbstractLoadBalance implements LoadBalance {\n\n    static int calculateWarmupWeight(int uptime, int warmup, int weight) {\n    }\n\n    @Override\n    public \u003cT\u003e Invoker\u003cT\u003e select(List\u003cInvoker\u003cT\u003e\u003e invokers, URL url, Invocation invocation) {\n    }\n\n    protected abstract \u003cT\u003e Invoker\u003cT\u003e doSelect(List\u003cInvoker\u003cT\u003e\u003e invokers, URL url, Invocation invocation);\n\n\n    int getWeight(Invoker\u003c?\u003e invoker, Invocation invocation) {\n\n    }\n}\n```\n\n`AbstractLoadBalance` 的实现类有下面这些：\n\n![](statistic/image-20210326105257812.png)\n\n官方文档对负载均衡这部分的介绍非常详细，推荐小伙伴们看看，地址：[https://dubbo.apache.org/zh/docs/v2.7/dev/source/loadbalance/#m-zhdocsv27devsourceloadbalanceopen in new window](https://dubbo.apache.org/zh/docs/v2.7/dev/source/loadbalance/#m-zhdocsv27devsourceloadbalance) 。\n\n#### [#](#randomloadbalance) RandomLoadBalance\n\n根据权重随机选择（对加权随机算法的实现）。这是 Dubbo 默认采用的一种负载均衡策略。\n\n`RandomLoadBalance` 具体的实现原理非常简单，假如有两个提供相同服务的服务器 S1,S2，S1 的权重为 7，S2 的权重为 3。\n\n我们把这些权重值分布在坐标区间会得到：S1-\u003e[0, 7) ，S2-\u003e[7, 10)。我们生成[0, 10) 之间的随机数，随机数落到对应的区间，我们就选择对应的服务器来处理请求。\n\n![RandomLoadBalance](statistic/RandomLoadBalance.png)\n\nRandomLoadBalance\n\n`RandomLoadBalance` 的源码非常简单，简单花几分钟时间看一下。\n\n\u003e 以下源码来自 Dubbo master 分支上的最新的版本 2.7.9。\n\n```\npublic class RandomLoadBalance extends AbstractLoadBalance {\n\n    public static final String NAME = \"random\";\n\n    @Override\n    protected \u003cT\u003e Invoker\u003cT\u003e doSelect(List\u003cInvoker\u003cT\u003e\u003e invokers, URL url, Invocation invocation) {\n\n        int length = invokers.size();\n        boolean sameWeight = true;\n        int[] weights = new int[length];\n        int totalWeight = 0;\n        // 下面这个for循环的主要作用就是计算所有该服务的提供者的权重之和 totalWeight（），\n        // 除此之外，还会检测每个服务提供者的权重是否相同\n        for (int i = 0; i \u003c length; i++) {\n            int weight = getWeight(invokers.get(i), invocation);\n            totalWeight += weight;\n            weights[i] = totalWeight;\n            if (sameWeight \u0026\u0026 totalWeight != weight * (i + 1)) {\n                sameWeight = false;\n            }\n        }\n        if (totalWeight \u003e 0 \u0026\u0026 !sameWeight) {\n            // 随机生成一个 [0, totalWeight) 区间内的数字\n            int offset = ThreadLocalRandom.current().nextInt(totalWeight);\n            // 判断会落在哪个服务提供者的区间\n            for (int i = 0; i \u003c length; i++) {\n                if (offset \u003c weights[i]) {\n                    return invokers.get(i);\n                }\n            }\n\n        return invokers.get(ThreadLocalRandom.current().nextInt(length));\n    }\n\n}\n\n```\n\n#### [#](#leastactiveloadbalance) LeastActiveLoadBalance\n\n`LeastActiveLoadBalance` 直译过来就是**最小活跃数负载均衡**。\n\n这个名字起得有点不直观，不仔细看官方对活跃数的定义，你压根不知道这玩意是干嘛的。\n\n我这么说吧！初始状态下所有服务提供者的活跃数均为 0（每个服务提供者的中特定方法都对应一个活跃数，我在后面的源码中会提到），每收到一个请求后，对应的服务提供者的活跃数 +1，当这个请求处理完之后，活跃数 -1。\n\n因此，**Dubbo 就认为谁的活跃数越少，谁的处理速度就越快，性能也越好，这样的话，我就优先把请求给活跃数少的服务提供者处理。**\n\n**如果有多个服务提供者的活跃数相等怎么办？**\n\n很简单，那就再走一遍 `RandomLoadBalance` 。\n\n```\npublic class LeastActiveLoadBalance extends AbstractLoadBalance {\n\n    public static final String NAME = \"leastactive\";\n\n    @Override\n    protected \u003cT\u003e Invoker\u003cT\u003e doSelect(List\u003cInvoker\u003cT\u003e\u003e invokers, URL url, Invocation invocation) {\n        int length = invokers.size();\n        int leastActive = -1;\n        int leastCount = 0;\n        int[] leastIndexes = new int[length];\n        int[] weights = new int[length];\n        int totalWeight = 0;\n        int firstWeight = 0;\n        boolean sameWeight = true;\n        // 这个 for 循环的主要作用是遍历 invokers 列表，找出活跃数最小的 Invoker\n        // 如果有多个 Invoker 具有相同的最小活跃数，还会记录下这些 Invoker 在 invokers 集合中的下标，并累加它们的权重，比较它们的权重值是否相等\n        for (int i = 0; i \u003c length; i++) {\n            Invoker\u003cT\u003e invoker = invokers.get(i);\n            // 获取 invoker 对应的活跃(active)数\n            int active = RpcStatus.getStatus(invoker.getUrl(), invocation.getMethodName()).getActive();\n            int afterWarmup = getWeight(invoker, invocation);\n            weights[i] = afterWarmup;\n            if (leastActive == -1 || active \u003c leastActive) {\n                leastActive = active;\n                leastCount = 1;\n                leastIndexes[0] = i;\n                totalWeight = afterWarmup;\n                firstWeight = afterWarmup;\n                sameWeight = true;\n            } else if (active == leastActive) {\n                leastIndexes[leastCount++] = i;\n                totalWeight += afterWarmup;\n                if (sameWeight \u0026\u0026 afterWarmup != firstWeight) {\n                    sameWeight = false;\n                }\n            }\n        }\n       // 如果只有一个 Invoker 具有最小的活跃数，此时直接返回该 Invoker 即可\n        if (leastCount == 1) {\n            return invokers.get(leastIndexes[0]);\n        }\n        // 如果有多个 Invoker 具有相同的最小活跃数，但它们之间的权重不同\n        // 这里的处理方式就和  RandomLoadBalance 一致了\n        if (!sameWeight \u0026\u0026 totalWeight \u003e 0) {\n            int offsetWeight = ThreadLocalRandom.current().nextInt(totalWeight);\n            for (int i = 0; i \u003c leastCount; i++) {\n                int leastIndex = leastIndexes[i];\n                offsetWeight -= weights[leastIndex];\n                if (offsetWeight \u003c 0) {\n                    return invokers.get(leastIndex);\n                }\n            }\n        }\n        return invokers.get(leastIndexes[ThreadLocalRandom.current().nextInt(leastCount)]);\n    }\n}\n\n```\n\n活跃数是通过 `RpcStatus` 中的一个 `ConcurrentMap` 保存的，根据 URL 以及服务提供者被调用的方法的名称，我们便可以获取到对应的活跃数。也就是说服务提供者中的每一个方法的活跃数都是互相独立的。\n\n```\npublic class RpcStatus {\n\n    private static final ConcurrentMap\u003cString, ConcurrentMap\u003cString, RpcStatus\u003e\u003e METHOD_STATISTICS =\n            new ConcurrentHashMap\u003cString, ConcurrentMap\u003cString, RpcStatus\u003e\u003e();\n\n   public static RpcStatus getStatus(URL url, String methodName) {\n        String uri = url.toIdentityString();\n        ConcurrentMap\u003cString, RpcStatus\u003e map = METHOD_STATISTICS.computeIfAbsent(uri, k -\u003e new ConcurrentHashMap\u003c\u003e());\n        return map.computeIfAbsent(methodName, k -\u003e new RpcStatus());\n    }\n    public int getActive() {\n        return active.get();\n    }\n\n}\n```\n\n#### [#](#consistenthashloadbalance) ConsistentHashLoadBalance\n\n`ConsistentHashLoadBalance` 小伙伴们应该也不会陌生，在分库分表、各种集群中就经常使用这个负载均衡策略。\n\n`ConsistentHashLoadBalance` 即**一致性 Hash 负载均衡策略**。 `ConsistentHashLoadBalance` 中没有权重的概念，具体是哪个服务提供者处理请求是由你的请求的参数决定的，也就是说相同参数的请求总是发到同一个服务提供者。\n\n![](statistic/consistent-hash-data-incline.jpg)\n\n另外，Dubbo 为了避免数据倾斜问题（节点不够分散，大量请求落到同一节点），还引入了虚拟节点的概念。通过虚拟节点可以让节点更加分散，有效均衡各个节点的请求量。\n\n![](statistic/consistent-hash-invoker.jpg)\n\n官方有详细的源码分析：[https://dubbo.apache.org/zh/docs/v2.7/dev/source/loadbalance/#23-consistenthashloadbalanceopen in new window](https://dubbo.apache.org/zh/docs/v2.7/dev/source/loadbalance/#23-consistenthashloadbalance) 。这里还有一个相关的 [PR#5440open in new window](https://github.com/apache/dubbo/pull/5440) 来修复老版本中 ConsistentHashLoadBalance 存在的一些 Bug。感兴趣的小伙伴，可以多花点时间研究一下。我这里不多分析了，这个作业留给你们！\n\n#### [#](#roundrobinloadbalance) RoundRobinLoadBalance\n\n加权轮询负载均衡。\n\n轮询就是把请求依次分配给每个服务提供者。加权轮询就是在轮询的基础上，让更多的请求落到权重更大的服务提供者上。比如假如有两个提供相同服务的服务器 S1,S2，S1 的权重为 7，S2 的权重为 3。\n\n如果我们有 10 次请求，那么 7 次会被 S1 处理，3 次被 S2 处理。\n\n但是，如果是 `RandomLoadBalance` 的话，很可能存在 10 次请求有 9 次都被 S1 处理的情况（概率性问题）。\n\nDubbo 中的 `RoundRobinLoadBalance` 的代码实现被修改重建了好几次，Dubbo-2.6.5 版本的 `RoundRobinLoadBalance` 为平滑加权轮询算法。\n\n## [#](#dubbo-序列化协议) Dubbo 序列化协议\n\n### [#](#dubbo-支持哪些序列化方式呢) Dubbo 支持哪些序列化方式呢？\n\n![Dubbo 支持的序列化协议](statistic/Dubbo_支持的序列化协议.png)\n\nDubbo 支持的序列化协议\n\nDubbo 支持多种序列化方式：JDK 自带的序列化、hessian2、JSON、Kryo、FST、Protostuff，ProtoBuf 等等。\n\nDubbo 默认使用的序列化方式是 hessian2。\n\n### [#](#谈谈你对这些序列化协议了解) 谈谈你对这些序列化协议了解？\n\n一般我们不会直接使用 JDK 自带的序列化方式。主要原因有两个：\n\n1. **不支持跨语言调用** : 如果调用的是其他语言开发的服务的时候就不支持了。\n2. **性能差**：相比于其他序列化框架性能更低，主要原因是序列化之后的字节数组体积较大，导致传输成本加大。\n\nJSON 序列化由于性能问题，我们一般也不会考虑使用。\n\n像 Protostuff，ProtoBuf、hessian2 这些都是跨语言的序列化方式，如果有跨语言需求的话可以考虑使用。\n\nKryo 和 FST 这两种序列化方式是 Dubbo 后来才引入的，性能非常好。不过，这两者都是专门针对 Java 语言的。Dubbo 官网的一篇文章中提到说推荐使用 Kryo 作为生产环境的序列化方式。\n\nDubbo 官方文档中还有一个关于这些[序列化协议的性能对比图open in new window](https://dubbo.apache.org/zh/docs/v2.7/user/serialization/#m-zhdocsv27userserialization)可供参考。\n\n![序列化协议的性能对比](statistic/序列化协议的性能对比.png)\n\n序列化协议的性能对比\n\n---\n\n著作权归Guide所有 原文链接：https://javaguide.cn/distributed-system/rpc/dubbo.html#%E8%B0%88%E8%B0%88%E4%BD%A0%E5%AF%B9%E8%BF%99%E4%BA%9B%E5%BA%8F%E5%88%97%E5%8C%96%E5%8D%8F%E8%AE%AE%E4%BA%86%E8%A7%A3","lastmodified":"2023-08-02T03:10:42.044088141Z","tags":[]},"/Obsidian/Front-Matter":{"title":"Front Matter","content":"\n\n使用 Front Matter 可以保存 note 待元数据，推荐使用 Hugo 的配置 [Front matter | Hugo (gohugo.io)](https://gohugo.io/content-management/front-matter/)\n\n","lastmodified":"2023-08-02T03:10:40.180065541Z","tags":["Obsidian"]},"/Obsidian/Obsidian-plugin":{"title":"Obsidian-plugin","content":"\n* [advanced-table](https://github.com/tgrosinger/advanced-tables-obsidian)\n* [banners](https://github.com/noatpad/obsidian-banners)\n* [calendar](https://github.com/liamcain/obsidian-calendar-plugin)\n* [commander](https://github.com/phibr0/obsidian-commander)\n* [dataview](https://github.com/blacksmithgu/obsidian-dataview)\n* [emoji-shortcodes](https://github.com/phibr0/obsidian-emoji-shortcodes)\n* [emoji-toolbar](https://github.com/oliveryh/obsidian-emoji-toolbar)\n* [excel-to-markdown-table](https://github.com/ganesshkumar/obsidian-excel-to-markdown-table)\n* [homepage](https://github.com/mirnovov/obsidian-homepage)\n* [hover-editor](https://github.com/nothingislost/obsidian-hover-editor)\n* [icon-folder)](https://github.com/FlorianWoelki/obsidian-icon-folder)\n* [icons](https://github.com/visini/obsidian-icons-plugin)\n* [image-toolkit](https://github.com/sissilab/obsidian-image-toolkit)\n* [minimal-settings](https://github.com/kepano/obsidian-minimal-settings)\n* [obsidian-git](https://github.com/denolehov/obsidian-git)\n* [recent-files](https://github.com/tgrosinger/recent-files-obsidian)\n* [settings-search](https://github.com/javalent/settings-search)\n* [style-settings](https://github.com/mgmeyers/obsidian-style-settings)\n* [tag-wrangler](https://github.com/pjeby/tag-wrangler)\n* [excalidraw](https://github.com/zsviczian/obsidian-excalidraw-plugin)","lastmodified":"2023-08-02T03:10:40.180065541Z","tags":["Obsidian"]},"/Obsidian/dataview":{"title":"dataview","content":"\n\n# 官方地址\n\n* [代码仓库](https://github.com/blacksmithgu/obsidian-dataview)\n* [文档地址](https://blacksmithgu.github.io/obsidian-dataview/)\n\n# 其他教程\n*  [Obsidian DataView 入门保姆级引导手册](https://zhuanlan.zhihu.com/p/614881764)\n\n# 元数据\n\n元数据是一系列的键值对,可以给笔记，可以给note,list item ,task 添加元数据\n\n## 如何添加元数据\n\n### Frontmatter\n\n* frontmatter 是markdown的一种扩展，可以使用yaml 来添加元数据\n\n```\n --- \n alias: \"document\" \n last-reviewed: 2021-08-17 \n thoughts: \n\t rating: 8 \n\t reviewable: false \n ---\n```\n\n###  inline fields\n* 使用方法为在文件的任意位置添加\n```text\n\nBasic Field:: Some random Value \n**Bold Field**:: Nice!\n  \n```\n\n* 如果你需要标注list itme 或者 task 需要使用中括号\n```\n- [ ] Send an mail to David about the deadline [due:: 2022-04-05].\n```\n\n\n# 另外还有隐含的元数据\n\n## page 中的元数据\n\n\n[# Metadata on Pages](https://blacksmithgu.github.io/obsidian-dataview/annotation/metadata-pages/)\n\n\n| Field Name       | Data Type      | Description                                                                                                                                                                   |\n|------------------|----------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| file.name        | Text           | The file name as seen in Obsidians sidebar.                                                                                                                                   |\n| file.folder      | Text           | The path of the folder this file belongs to.                                                                                                                                  |\n| file.path        | Text           | The full file path, including the files name.                                                                                                                                 |\n| file.ext         | Text           | The extension of the file type; generally md.                                                                                                                                 |\n| file.link        | Link           | A link to the file.                                                                                                                                                           |\n| file.size        | Number         | The size (in bytes) of the file.                                                                                                                                              |\n| file.ctime       | Date with Time | The date that the file was created.                                                                                                                                           |\n| file.cday        | Date           | The date that the file was created.                                                                                                                                           |\n| file.mtime       | Date with Time | The date that the file was last modified.                                                                                                                                     |\n| file.mday        | Date           | The date that the file was last modified.                                                                                                                                     |\n| file.tags        | List           | A list of all unique tags in the note. Subtags are broken down by each level, so #Tag/1/A will be stored in the list as [#Tag, #Tag/1, #Tag/1/A].                             |\n| file.etags       | List           | A list of all explicit tags in the note; unlike file.tags, does not break subtags down, i.e. [#Tag/1/A]                                                                       |\n| file.inlinks     | List           | A list of all incoming links to this file, meaning all files that contain a link to this file.                                                                                |\n| file.outlinks    | List           | A list of all outgoing links from this file, meaning all links the file contains.                                                                                             |\n| file.aliases     | List           | A list of all aliases for the note as defined via the YAML frontmatter.                                                                                                       |\n| file.tasks       | List           | A list of all tasks (I.e., \\| [ ] some task) in this file.                                                                                                                    |\n| file.lists       | List           | A list of all list elements in the file (including tasks); these elements are effectively tasks and can be rendered in task views.                                            |\n| file.frontmatter | List           | Contains the raw values of all frontmatter in form of key \\| value text values; mainly useful for checking raw frontmatter values or for dynamically listing frontmatter keys. |\n| file.day         | Date           | Only available if the file has a date inside its file name (of form yyyy-mm-dd or yyyymmdd), or has a Date field/inline field.                                                |\n| file.starred     | Boolean        | if this file has been starred via the Obsidian Core Plugin \"Starred Files\".                                                                                                   |\n\n\n## 列表和任务中的元数据\n\n[# Metadata on Tasks and Lists](https://blacksmithgu.github.io/obsidian-dataview/annotation/metadata-tasks/)\n\n| Field name     | Data Type | Description                                                                                                                                                                                                                                                                                               |\n|----------------|-----------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| status         | Text      | The completion status of this task, as determined by the character inside the [ ] brackets. Generally a space \" \" for incomplete tasks and a \"x\" for complete tasks, but allows for plugins which support alternative task statuses.                                                                      |\n| checked        | Boolean   | Whether or not this task status is empty, meaning it has a space in its [ ] brackets                                                                                                                                                                                                                      |\n| completed      | Boolean   | Whether or not this specific task has been completed; this does not consider the completionnon-completion of any child tasks. A task is explicitly considered \"completed\" if it has been marked with an 'x'. If you use a custom status, i.e. [-], checked will be true, whereas completed will be false. |\n| fullyCompleted | Boolean   | Whether or not this task and all of its subtasks are completed.                                                                                                                                                                                                                                           |\n| text           | Text      | The plain text of this task, including any metadata field annotations.                                                                                                                                                                                                                                    |\n| visual         | Text      | The text of this task, which is rendered by Dataview. It can be modified to render arbitary text.                                                                                                                                                                                                         |\n| line           | Number    | The line of the file this task shows up on.                                                                                                                                                                                                                                                               |\n| lineCount      | Number    | The number of Markdown lines that this task takes up.                                                                                                                                                                                                                                                     |\n| path           | Text      | The full path of the file this task is in. Equals to file.path for pages                                                                                                                                                                                                                                  |\n| section        | Link      | link to the section this task is contained in.                                                                                                                                                                                                                                                            |\n| tags           | List      | Any tags inside of the text task.                                                                                                                                                                                                                                                                         |\n| outlinks       | List      | Any links defined in this task.                                                                                                                                                                                                                                                                           |\n| link           | Link      | link to the closest linkable block near this task; useful for making links which go to the task.                                                                                                                                                                                                          |\n| children       | List      | ny subtasks or sublists of this task.                                                                                                                                                                                                                                                                     |\n| task           | Boolean   | If true, this is a task; otherwise, it is a regular list element.                                                                                                                                                                                                                                         |\n| annotated      | Boolean   | True if the task text contains any metadata fields, false otherwise.                                                                                                                                                                                                                                      |\n| parent         | Number    | The line number of the task above this task, if present; will be null if this is a root-level task.                                                                                                                                                                                                       |\n| blockId        | Text      | The block ID of this task / list element, if one has been defined with the ^blockId syntax; otherwise null.                                                                                                                                                                                               |\n\n\n# DQL\n\n比较类似于sql, 可是实现以下的功能\n\n- Choosing an **output format** of your output (the [Query Type](https://blacksmithgu.github.io/obsidian-dataview/queries/query-types/))\n- Fetch pages **from a certain [source](https://blacksmithgu.github.io/obsidian-dataview/reference/sources/)**, i.e. a tag, folder or link\n- **Filtering pages/data** by simple operations on fields, like comparison, existence checks, and so on\n- **Transforming fields** for displaying, i.e. with calculations or splitting up multi-value fields\n- **Sorting** results based on fields\n- **Grouping** results based on fields\n- **Limiting** your result count\n\n## 查询语法\n\n```text\n```dataview \n\t\u003cQUERY-TYPE\u003e \u003cfields\u003e \n\tFROM \u003csource\u003e \n\t\u003cDATA-COMMAND\u003e \u003cexpression\u003e \n\t\u003cDATA-COMMAND\u003e \u003cexpression\u003e \n\t...\n```\n```\t\n```\n\n\n## 输出类型\n\n* **TABLE**: A table of results with one row per result and one or many columns of **field data**.\n* **LIST**: A bullet point list of **pages** which match the query. You can output one field for each page alongside their file links.\n* **TASK**: An interactive task list of **tasks** that match the given query.\n* **CALENDAR**: A calendar view displaying each hit via a dot on its referred date.\n\n\n```text\nLists all pages in your vault as a bullet point list\n\t```dataview \n\tLIST \n\t```\n\t\nLists all tasks (completed or not) in your vault \n\t```dataview \n\tTASK \n\t```\n\t\nRenders a Calendar view where each page is represented as a dot on its creation date. \n\t```dataview \n\tCALENDAR file.cday \n\t```\n\t\nShows a table with all pages of your vault, their field value of due, the files' tags and an average of the values of multi-value field working-hours \n\t```dataview \n\tTABLE due, file.tags AS \"tags\", average(working-hours)\n\t ```\n\n```\n\n\n## 数据来源\n\n* tags\n* folders\n* note\n* lint\n\n```\nLists all pages inside the folder Books and its sub folders \n\t```dataview \n\tLIST FROM \"Books\" \n\t``` \n\t\nLists all pages that include the tag #status/open or #status/wip \n\t```dataview \n\tLIST FROM #status/open OR #status/wip \n\t``` \n\t\nLists all pages that have either the tag #assignment and are inside folder \"30 School\" (or its sub folders), or are inside folder \"30 School/32 Homeworks\" and are linked on the page School Dashboard Current To Dos \n\n\t```dataview \n\tLIST FROM (#assignment AND \"30 School\") OR (\"30 School/32 Homeworks\" AND outgoing([[School Dashboard Current To Dos]])) \n\t```\n\n```\n\n\n## Filter, sort, group or limit results\n\n* ***FROM** like explained [above](https://blacksmithgu.github.io/obsidian-dataview/queries/structure/#choose-your-source).\n*  **WHERE**: Filter notes based on information **inside** notes, the meta data fields.\n*  **SORT**: Sorts your results depending on a field and a direction.\n*  **GROUP BY**: Bundles up several results into one result row per group.\n*  **LIMIT**: Limits the result count of your query to the given number.\n*  **FLATTEN**: Splits up one result into multiple results based on a field or calculation.\n\n\n```\nLists all pages that have a metadata field `due` and where `due` is before today \n\n\t```dataview \n\tLIST WHERE due AND due \u003c date(today) \n\t``` \nLists the 10 most recently created pages in your vault that have the tag #status/open \n\t```dataview \n\tLIST FROM #status/open SORT file.ctime DESC LIMIT 10 \n\t``` \nLists the 10 oldest and incompleted tasks of your vault as an interactive task list, grouped by their containing file and sorted from oldest to newest file. \n\t```dataview \n\tTASK WHERE !completed SORT created ASC LIMIT 10 GROUP BY file.link SORT rows.file.ctime ASC \n\t```\n\n\n```","lastmodified":"2023-08-02T03:10:40.180065541Z","tags":["Obsidian"]},"/Obsidian/excalidraw":{"title":"excalidraw","content":"\n*  [代码仓库](https://github.com/zsviczian/obsidian-excalidraw-plugin)\n* note 中插入excalidraw 语法\n\n```\n![[excalidraw]]\n```","lastmodified":"2023-08-02T03:10:40.180065541Z","tags":["Obsidian"]},"/Obsidian/obsidian-overview":{"title":"obsidian overview","content":"\n# 主页内容\n\nobsidian 相关内容，包括插件\n\n\n# 结构\n\n","lastmodified":"2023-08-02T03:10:40.180065541Z","tags":["Obsidian"]},"/Obsidian/publish":{"title":"publish","content":"\n\n\n[obsidian 目前最完美的免费发布方案 渐进式教程 by oldwinter](https://publish.obsidian.md/chinesehelp/01+2021%E6%96%B0%E6%95%99%E7%A8%8B/obsidian+%E7%9B%AE%E5%89%8D%E6%9C%80%E5%AE%8C%E7%BE%8E%E7%9A%84%E5%85%8D%E8%B4%B9%E5%8F%91%E5%B8%83%E6%96%B9%E6%A1%88+%E6%B8%90%E8%BF%9B%E5%BC%8F%E6%95%99%E7%A8%8B+by+oldwinter#%E5%87%A0%E4%B8%AA%E5%8F%91%E5%B8%83%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94)","lastmodified":"2023-08-02T03:10:40.180065541Z","tags":["Obsidian"]},"/Obsidian/template":{"title":"template","content":"\n* *[模板的使用方法](https://publish.obsidian.md/help-zh/%E6%8F%92%E4%BB%B6/%E6%A8%A1%E6%9D%BF)\n* 默认存放的文件夹 `/template`\n\n","lastmodified":"2023-08-02T03:10:40.180065541Z","tags":["Obsidian"]},"/awesome/JavaGuide-%E7%9F%A5%E8%AF%86%E6%98%9F%E7%90%83%E4%BC%98%E8%B4%A8%E4%B8%BB%E9%A2%98%E6%B1%87%E6%80%BB":{"title":"JavaGuide 知识星球优质主题汇总","content":"为了避免这里成为知识杂货铺，我会对严格筛选入选的优质主题。  \n  \n更新日期：2023-06-11  \n  \n\n面试  \n  \n●[Java面试常见问题总结（2023最新版）](https://t.zsxq.com/0eRq7EJPy)  \n●[一位 HR 分享的求职建议](https://t.zsxq.com/0dSKX0jkK)  \n●[面试和简历上的一些大忌](https://t.zsxq.com/0eOgYt3qU)  \n●项目：  \n○[如何回答项目遇到什么困难，如何解决这类问题](https://t.zsxq.com/0dduy9CeQ)  \n○[项目太简单怎么办?](https://t.zsxq.com/0eV4BksDb)  \n○[商城项目到底能不能做？](https://t.zsxq.com/0eBcCNhbB)  \n  \n\n安抚心态  \n  \n如果你陷入精神内耗或者自我怀疑，不然看看下面这些内容：  \n  \n●[编程找工作现状 - 哔哩哔哩](https://t.zsxq.com/0edKnfcZW)  \n  \n\n技术资源  \n  \n学习路线：[Java 系统学习路线](https://t.zsxq.com/0dupYAEaq)  \n  \n总结 ：  \n  \n●[Java 后端开发常用的技术书籍+原创面试资料 PDF 版本](https://t.zsxq.com/0bWeUrBVq)  \n●[JavaGuide 网站总结的八股文合集  - 念神](https://t.zsxq.com/0biGG9UlX)  \n●[Java 后端常见知识点思维导图分享 - 吴不卷](https://t.zsxq.com/0bHk3wEDs)  \n  \n常用技术：  \n  \n●[SpringBoot 学习资源推荐](https://t.zsxq.com/0eEGBV1Md)  \n●[单测技术选型+学习资源推荐](https://t.zsxq.com/0d7jOz9Vm)  \n●[Redis 学习资源推荐](https://t.zsxq.com/0dwd4ONZ9)  \n●[Elasticsearch 学习资源推荐](https://t.zsxq.com/0dEWEThKR)  \n●[Kafka、RocketMQ、RabbitMQ 学习资源推荐](https://t.zsxq.com/0bEDFwgon)  \n●[分布式学习资源推荐（偏理论方向）](https://t.zsxq.com/0euwZ8uiP)  \n●[Git 学习资源推荐](https://t.zsxq.com/0bTheL01q)  \n●[《阿里开发者手册 - Redis 专题》PDF 文档](https://t.zsxq.com/0bEiLJIVW)  \n  \n\n代码质量  \n  \n●[24 个写出漂亮代码的小技巧](https://t.zsxq.com/0foGrZIc7)  \n●[程序员“起名”头痛根治指南](https://t.zsxq.com/0d8ODCefj)  \n●[5天带你读完《Effective Java》](https://t.zsxq.com/0dIkpk8AV)  \n●[提高代码质量的书籍和文章推荐](https://t.zsxq.com/0dWEHSiBW)  \n●[一个练习重构的开源教程](https://t.zsxq.com/0d221QNao)  \n●[分享3本对于提高代码质量有实际帮助的书籍](https://t.zsxq.com/0dFLaE2Lp)（《编写可读代码的艺术》、《Clean Code》、《The Clean Coder》）  \n  \n\n进阶攻略  \n  \n●[如何撰写一份令人赞叹的软件专利技术交底书？](https://articles.zsxq.com/id_2kdw0o0ovc44.html)  \n●[校招生如何参与开源项目？如何获得开源经历？](https://articles.zsxq.com/id_q0g14e71eqc3.html)  \n●[一些读书心得和看书做笔记的经验](https://t.zsxq.com/0cpx9pkIE)  \n●[一个关于提升学习能力和效率的视频](https://t.zsxq.com/0c2OboF1Q)（收益匪浅）  \n●[如何有效提升专注力？](https://t.zsxq.com/0eIuSBARU)  \n●[快速熟悉业务逻辑并付诸落地的建议 - 念神](https://t.zsxq.com/0cGu9HjPQ)  \n●[给初级 Java 工程师的一些学习建议 - 念神](https://t.zsxq.com/0ckNvT31a)  \n●[项目技术选型的建议](https://t.zsxq.com/0ciPGdBoZ)（听了一个技术选型分享之后的一些心得体会）  \n●[使用 Google 搜索的实用建议](https://t.zsxq.com/0c0K3zPRk)  \n●[不要把自己局限在技术上!](https://t.zsxq.com/0cdHCFWNw) （重视技术能力，但你的世界不能仅仅只有技术）  \n●[给一些想要换职业方向的朋友一些客观的建议](https://t.zsxq.com/0crTLD2hY)  \n●[如何做编程知识投资及减少知识失效的影响](https://t.zsxq.com/0ccagnzao) （感触很深的一篇文章，强烈推荐阅读）  \n●[碎片化知识可能会带来的坏处](https://t.zsxq.com/0cdfq7iR4)（碎片化知识泛滥的时代，应该注意其对自身的影响）  \n  \n\n开源项目  \n  \n●[一个简易版的IoC的轮子（球友自制，附笔记）](https://t.zsxq.com/0eCVtaUND)  \n●[Java 语言手写的一款简易版 Git（球友自制）](https://t.zsxq.com/0ekLd7XaX)  \n●[基于 SpringBoot 的国密前后端分离快速开发平台](https://t.zsxq.com/0b3wlSfjS)  \n●[《高并发的哲学原理》开源图书](https://t.zsxq.com/0bmQXO4bf)  \n●[zyplayer-doc：适合团队和个人使用的WIKI文档管理工具，同时还包含数据库文档、Api接口文档。](https://t.zsxq.com/0bcfjG15v)  \n●[《深入理解 Java 虚拟机》阅读笔记，基于第二版（目前最新版是第三版）](https://t.zsxq.com/0b1CDmh5H)  \n●[think：一款开源知识管理工具，支持创建知识库、多人协作、分享知识库、绘制思维导图、添加附加附件等功能](https://wx.zsxq.com/dweb2/index/group/48418884588288)  \n●[ip2region：高性能离线IP地址定位库，10微秒级别的查询效率，开箱即用，提供了多种主流编程语言（如 Go，Java，Python）的 xdb 数据生成和查询客户端 API。](https://t.zsxq.com/0b6BYX1rp)  \n●[novel：一套基于时下最新 Java 技术栈 Spring Boot 3 + Vue 3 开发的前后端分离学习型小说项目](https://t.zsxq.com/0b71m4luD)  \n●[lu-raft-kv：分布式 KV 存储轮子](https://t.zsxq.com/0baOCvT01)  \n●[MYDB：简易版数据库](https://t.zsxq.com/0b0d5pFHt)  \n●[mini-spring-cloud：手写的简化版的 Spring Cloud](https://t.zsxq.com/0bai0TuJX)  \n●[SurveyKing：号称功能最强大的调查问卷系统和考试系统](https://t.zsxq.com/0bJaH3GSP)  \n●[cs-self-learning：计算机自学指南](https://t.zsxq.com/0biDtoOF7)  \n●[upupor：小众但是功能强大的开源社区](https://t.zsxq.com/0bZrBeqMg)  \n●[Easy-Es： Elasticsearch 工具库](https://t.zsxq.com/0bWdejp6D)  \n  \n\n工具网站  \n  \n●[两个巨好用的 Linux 命令网站](https://t.zsxq.com/0eKkOJPDA)  \n●[GitHub Web IDE：直接通过多种在线 IDE 打开Github项目](https://t.zsxq.com/0eDXSZsBw)","lastmodified":"2023-08-02T03:10:42.044088141Z","tags":[]},"/elastic/KQL":{"title":"KQL","content":"\nKibana  Query Language\n\n\nhttps://juejin.cn/post/7003201901382598686\n\n\nhttps://www.elastic.co/guide/en/kibana/7.14/kuery-query.html#kuery-query\n\n\n","lastmodified":"2023-08-02T03:10:42.044088141Z","tags":[]},"/lua/Lua%E9%AB%98%E7%BA%A7":{"title":"Lua高级","content":"\n# 元表\n\n元表 _(metatable)_ 的**表现行为类似于 C++ 语言中的操作符重载**，例如我们可以重载 \"__add\" 元方法 _(metamethod)_，来计算两个 Lua 数组的并集；或者重载 \"__index\" 方法，来定义我们自己的 Hash 函数。Lua 提供了两个十分重要的用来处理元表的方法\n\n- setmetatable(table, metatable)：此方法用于为一个表设置元表。\n    \n- getmetatable(table)：此方法用于获取表的元表对象\n    \n\n设置元表\n\n```Lua\nlocal mytable = {}\nlocal mymetatable = {}\nsetmetatable(mytable, mymetatable)\n```\n\n  \n\n## **修改表的操作符行为**\n\n  \n\n通过重载 \"__add\" 元方法来计算集合的并集实例\n\n```Lua\nlocal set1 = {10, 20, 30}   -- 集合\nlocal set2 = {20, 40, 50}   -- 集合\n\n-- 将用于重载__add的函数，注意第一个参数是self\nlocal union = function (self, another)\n    local set = {}\n    local result = {}\n\n    -- 利用数组来确保集合的互异性\n    for i, j in pairs(self) do set[j] = true end\n    for i, j in pairs(another) do set[j] = true end\n\n    -- 加入结果集合\n    for i, j in pairs(set) do table.insert(result, i) end\n    return result\nend\nsetmetatable(set1, {__add = union}) -- 重载 set1 表的 __add 元方法\n\nlocal set3 = set1 + set2\nfor _, j in pairs(set3) do\n    io.write(j..\" \")               --\u003eoutput：30 50 20 40 10\nend\n```\n\n除了加法可以被重载之外，Lua 提供的所有操作符都可以被重载：\n| 元方法        | 含义                                                                         |\n|------------|----------------------------------------------------------------------------|\n| \"__add    | #NAME?                                                                     |\n| \"__sub   | - 操作 其行为类似于 \"add\" 操作                                                       |\n| \"__mul    | * 操作 其行为类似于 \"add\" 操作                                                       |\n| \"__div   | / 操作 其行为类似于 \"add\" 操作                                                       |\n| \"__mod   | % 操作 其行为类似于 \"add\" 操作                                                       |\n| \"__pow    | ^ （幂）操作 其行为类似于 \"add\" 操作                                                    |\n| \"__unm\"   | 一元 - 操作                                                                    |\n| \"__concat\" | .. （字符串连接）操作                                                               |\n| \"__len\"    | # 操作                                                                       |\n| \"__eq\"     | == 操作 函数 getcomphandler 定义了 Lua 怎样选择一个处理器来作比较操作 仅在两个对象类型相同且有对应操作相同的元方法时才起效 |\n| \"__lt\"     | \u003c 操作                                                                       |\n| \"__le\"     | \u003c= 操作                                                                      |\n\n\n除了操作符之外，如下元方法也可以被重载，下面会依次解释使用方法：\n\n|   |   |\n|---|---|\n|元方法|含义|\n|\"__index\"|取下标操作用于访问 table[key]|\n|\"__newindex\"|赋值给指定下标 table[key] = value|\n|\"__tostring\"|转换成字符串|\n|\"__call\"|当 Lua 调用一个值时调用|\n|\"__mode\"|用于弱表(week table)|\n|\"__metatable\"|用于保护metatable不被访问|\n\n## **__index 元方法**\n\n```Lua\nmytable = setmetatable({key1 = \"value1\"},   --原始表\n{__index = function(self, key)            --重载函数\n    if key == \"key2\" then\n        return \"metatablevalue\"\n    end\nend\n})\n\nprint(mytable.key1,mytable.key2)  --\u003e output：value1 metatablevalue\n```\n\n关于 __index 元方法，有很多比较高阶的技巧，例如：__index 的元方法不需要非是一个函数，他也可以是一个表。\n\n```Lua\nt = setmetatable({[1] = \"hello\"}, {__index = {[2] = \"world\"}})\nprint(t[1], t[2])   --\u003ehello wor\n```\n\n## **__tostring 元方法**\n\n  \n\n与 Java 中的 toString() 函数类似，可以实现自定义的字符串转换。\n\n```Lua\narr = {1, 2, 3, 4}\narr = setmetatable(arr, {__tostring = function (self)\n    local result = '{'\n    local sep = ''\n    for _, i in pairs(self) do\n        result = result ..sep .. i\n        sep = ', '\n    end\n    result = result .. '}'\n    return result\nend})\nprint(arr)  --\u003e {1, 2, 3, 4}\n```\n\n## **__call 元方法**\n\n__call 元方法的功能类似于 C++ 中的仿函数，使得普通的表也可以被调用。\n\n  \n\n```Lua\nfunctor = {}\nfunction func1(self, arg)\n    print (\"called from\", arg)\nend\nsetmetatable(functor, {__call = func1})\n\nfunctor(\"functor\")  --\u003e called from functor\nprint(functor)      --\u003e output：0x00076fc8 （后面这串数字可能不一样）\n```\n\n## **__metatable 元方法**\n\n假如我们想保护我们的对象使其使用者既看不到也不能修改 metatables。我**们可以对 metatable 设置了 __metatable 的值，getmetatable 将返回这个域的值，而调用 setmetatable 将会出错**：\n\n```Lua\nbject = setmetatable({}, {__metatable = \"You cannot access here\"})\n\nprint(getmetatable(Object)) --\u003e You cannot access heresetmetatable(Object, {})    --\u003e 引发编译器报错\n```\n\n  \n\n# 面向对象\n\n## 类\n\n在 Lua 中，我们可以使用表和函数实现面向对象。**将函数和相关的数据放置于同一个表中就形成了一个对象。**\n\n```Plaintext\nlocal _M = {}\n\nlocal mt = { __index = _M }\n\nfunction _M.deposit (self, v)\n    self.balance = self.balance + v\nend\n\nfunction _M.withdraw (self, v)\n    if self.balance \u003e v then\n        self.balance = self.balance - v\n    else\n        error(\"insufficient funds\")\n    end\nend\n\nfunction _M.new (self, balance)\n    balance = balance or 0\n    return setmetatable({balance = balance}, mt)\nend\n\nreturn _M\n```\n\n引用\n\n```Lua\nlocal account = require(\"account\")\n\nlocal a = account:new()\na:deposit(100)\n\nlocal b = account:new()\nb:deposit(50)\n\nprint(a.balance)  --\u003e output: 100\nprint(b.balance)  --\u003e output: 50\n```\n\n上面这段代码 \"setmetatable({balance = balance}, mt)\"，其中 mt 代表 `{ __index = _M }` ，这句话值得注意。根据我们在元表这一章学到的知识，我们明白，setmetatable 将 `_M` 作为新建表的原型，所以在自己的表内找不到 'deposit'、'withdraw' 这些方法和变量的时候，便会到 __index 所指定的 _M 类型中去寻找。\n\n  \n\n## 继承\n\n继承可以用元表实现，它提供了在父类中查找存在的方法和变量的机制。在 Lua 中是不推荐使用继承方式完成构造的，这样做引入的问题可能比解决的问题要多，下面一个是字符串操作类库，给大家演示一下。\n\n```Lua\n---------- s_base.lualocal _M = {}\n\nlocal mt = { __index = _M }\n\nfunction _M.upper (s)return string.upper(s)\nendreturn _M\n\n---------- s_more.lualocal s_base = require(\"s_base\")\n\nlocal _M = {}\n_M = setmetatable(_M, { __index = s_base })\n\n\nfunction _M.lower (s)return string.lower(s)\nendreturn _M\n\n---------- test.lualocal s_more = require(\"s_more\")\n\nprint(s_more.upper(\"Hello\"))   -- output: HELLOprint(s_more.lower(\"Hello\"))   -- output: hello\n```\n\n  \n\n## 成员私有性\n\n在动态语言中引入成员私有性并没有太大的必要，反而会显著增加运行时的开销，毕竟这种检查无法像许多静态语言那样在编译期完成。下面的技巧把对象作为各方法的 upvalue，本身是很巧妙的，但会让子类继承变得困难，同时构造函数动态创建了函数，会导致构造函数无法被 JIT 编译。\n\n在 Lua 中，成员的私有性，使用类似于函数闭包的形式来实现。在我们之前的银行账户的例子中，我们使用一个工厂方法来创建新的账户实例，通过工厂方法对外提供的闭包来暴露对外接口。而不想暴露在外的例如 balance 成员变量，则被很好的隐藏起来。\n\n```Lua\nfunction newAccount (initialBalance)\n    local self = {balance = initialBalance}\n    local withdraw = function (v)\n        self.balance = self.balance - v\n    end\n    local deposit = function (v)\n        self.balance = self.balance + v\n    end\n    local getBalance = function () \n        return self.balance \n    end\n    \n    return {\n        withdraw = withdraw,\n        deposit = deposit,\n        getBalance = getBalance\n    }\nend\n\na = newAccount(100)\na.deposit(100)\nprint(a.getBalance()) --\u003e 200print(a.balance)      --\u003e nil\n```\n\n  \n\n# 局部变量\n\nLua 的设计有一点很奇怪，**在一个 block 中的变量，如果之前没有定义过，那么认为它是一个全局变量**，**而不是这个 block 的局部变量**。这一点和别的语言不同。**容易造成不小心覆盖了全局同名变量的错误**。\n\n## **定义**\n\nLua 中的局部变量要用 local 关键字来显式定义，不使用 local 显式定义的变量就是全局变量\n\n```Lua\ng_var = 1         -- global var\nlocal l_var = 2   -- local var\n```\n\n## **作用域**\n\n**局部变量的生命周期是有限的，它的作用域仅限于声明它的块（block）**。一个块是一个控制结构的执行体、或者是一个函数的执行体再或者是一个程序块（chunk）。\n\n```Lua\nx = 10\nlocal i = 1         -- 程序块中的局部变量 i\n\nwhile i \u003c=x do\n    local x = i * 2   -- while 循环体中的局部变量 x\n    print(x)          -- output： 2, 4, 6, 8, ...\n    i = i + 1\nend\n\nif i \u003e 20 then\n    local x           -- then 中的局部变量 x\n    x = 20\n    print(x + 2)      -- 如果i \u003e 20 将会打印 22，此处的 x 是局部变量\nelse\n    print(x)          -- 打印 10，这里 x 是全局变量\nend\n\nprint(x)            -- 打印 10\n```\n\n  \n\n## 使用局部变量的好处\n\n  \n\n1. 局部变量可以避免因为命名问题污染了全局环境\n    \n2. local 变量的访问比全局变量更快\n    \n3. 由于局部变量出了作用域之后生命周期结束，这样可以被垃圾回收器及时释放\n    \n\n  \n\n  \n\n## 检测模块的函数使用局部变量\n\nfoo.lua\n\n```Lua\nlocal _M = { _VERSION = '0.01' }\n\nfunction _M.add(a, b)     --两个number型变量相加\n    return a + b\nend\n\nfunction _M.update_A()    --更新变量值\n    A = 365               -- A 是全局变量\nend\n\nreturn _M\n```\n\nuse_foo.lua\n\n```Lua\nA = 360     --定义全局变量\n\nlocal foo = require(\"foo\")\n\nlocal b = foo.add(A, A)\nprint(\"b = \", b)\n\nfoo.update_A()\nprint(\"A = \", A)\n```\n\n因为A 是全局变量，改变了A的值\n\nLua 上下文中应当严格避免使用自己定义的全局变量。**可以使用一个 lj-releng 工具来扫描 Lua 代码，定位使用 Lua 全局变量的地方**。lj-releng 的相关链接：[https://github.com/openresty/openresty-devel-utils/blob/master/lj-releng](https://github.com/openresty/openresty-devel-utils/blob/master/lj-releng)\n\nWindows 用户把 lj-releng 文件所在的目录的绝对路径添加进 PATH 环境变量。然后进入你自己的 Lua 文件所在的工作目录，得到如下结果：\n\n```Lua\n#  lj-releng\nfoo.lua: 0.01 (0.01)\nChecking use of Lua global variables in file foo.lua...\nop no.  line  instruction args  ; code\n2  [8] SETGLOBAL 0 -1  ; A\nChecking line length exceeding 80...\nWARNING: No \"_VERSION\" or \"version\" field found in `use_foo.lua`.\nChecking use of Lua global variables in file use_foo.lua...\nop no.  line  instruction args  ; code\n2  [1] SETGLOBAL 0 -1  ; A\n7  [4] GETGLOBAL 2 -1  ; A\n8  [4] GETGLOBAL 3 -1  ; A\n18 [8] GETGLOBAL 4 -1  ; A\n```\n\n当然，更推荐采用 **luacheck 来检查项目中全局变量，之后的“代码静态分析”一节，我们还会讲到如何使用 luacheck**。\n\n  \n\n# 判断数组的大小\n\n- table.getn(t) 等价于 t 但**计算的是数组元素，不包括 hash 键值**。而且数组是以第一个 nil 元素来判断数组结束。\n    \n- `#` 只计算 array 的元素个数，它实际上调用了对象的 metatable 的 `__len` 函数。对于有 `__len` 方法的函数返回函数返回值，不然就返回数组成员数目\n    \n- _Lua_ 内部实际采用哈希表和数组分别保存键值对、普通值，所以不推荐混合使用这两种赋值方式。\n    \n- Lua 数组中允许 nil 值的存在，但是数组默认结束标志却是 nil。这类比于 C 语言中的字符串，字符串中允许 '\\0' 存在，但当读到 '\\0' 时，就认为字符串已经结束了。\n    \n- 初始化是例外，在 Lua 相关源码中，初始化数组时首先判断数组的长度，若长度大于 0 ，并且最后一个值不为 nil，返回包括 nil 的长度；若最后一个值为 nil，则返回截至第一个非 nil 值的长度。\n    \n- **如果你要删除一个数组中的元素，请使用 remove 函数，而不是用 nil 赋值**\n    \n\n```Lua\n-- test.lua\nlocal tblTest1 = { 1, a = 2, 3 }\nprint(\"Test1 \" .. #(tblTest1))\n\nlocal tblTest2 = { 1, nil }\nprint(\"Test2 \" .. #(tblTest2))\n\nlocal tblTest3 = { 1, nil, 2 }\nprint(\"Test3 \" .. #(tblTest3))\n\nlocal tblTest4 = { 1, nil, 2, nil }\nprint(\"Test4 \" .. #(tblTest4))\n\nlocal tblTest5 = { 1, nil, 2, nil, 3, nil }\nprint(\"Test5 \" .. #(tblTest5))\n\nlocal tblTest6 = { 1, nil, 2, nil, 3, nil, 4, nil }\nprint(\"Test6 \" .. #(tblTest6))\n```\n\n我们分别使用 Lua 和 LuaJIT 来执行一下：\n\n```Lua\n➜ luajit test.lua\nTest1 2\nTest2 1\nTest3 1\nTest4 1\nTest5 1\nTest6 1\n\n➜ lua test.lua\nTest1 2\nTest2 1\nTest3 3\nTest4 1\nTest5 3\nTest6 1\n```\n\n这一段的输出结果，就是这么 **匪夷所思**。不要在 Lua 的 table 中使用 nil 值，**如果一个元素要删除，直接 remove，不要用 nil 去代替**。\n\n  \n\n# 非空判断\n\n  \n\n有时候不小心引用了一个没有赋值的变量，这时它的值默认为 nil。如果对一个 nil 进行索引的话，会导致异常。\n\n```Plaintext\nlocal person = {name = \"Bob\", sex = \"M\"}\n\n-- do something\nperson = nil\n-- do something\nprint(person.name)\n```\n\n会报错\n\n```Lua\nstdin:1:attempt to index global 'person' (a nil value)\nstack traceback:\n   stdin:1: in main chunk\n   [C]: ?\n```\n\n在实际的工程代码中，我们很难这么轻易地发现我们引用了 nil 变量。因此，在很多情况下我们在访问一些 table 型变量时，需要先判断该变量是否为 nil，例如将上面的代码改成\n\n```Lua\nlocal person = {name = \"Bob\", sex = \"M\"}\n\n-- do something\nperson = nil\n-- do something\nif person ~= nil and person.name ~= nil then\n    print(person.name)\nelse\n-- do somethingend\n```\n\n对于简单类型的变量，我们可以用 _if (var == nil) then_ 这样的简单句子来判断。**但是对于 table 型的 Lua 对象，就不能这么简单判断它是否为空了。一个 table 型变量的值可能是** **`{}`**，这时它不等于 nil。我们来看下面这段代码：\n\n```Lua\nlocal next = next\nlocal a = {}\nlocal b = {name = \"Bob\", sex = \"Male\"}\nlocal c = {\"Male\", \"Female\"}\nlocal d = nil\n\nprint(#a)\nprint(#b)\nprint(#c)\n--print(#d)    -- error\n\nif a == nil then\n    print(\"a == nil\")\nend\n\nif b == nil then\n    print(\"b == nil\")\nend\n\nif c == nil then\n    print(\"c == nil\")\nend\n\nif d== nil then\n    print(\"d == nil\")\nend\n\nif next(a) == nil then\n    print(\"next(a) == nil\")\nend\n\nif next(b) == nil then\n    print(\"next(b) == nil\")\nend\n\nif next(c) == nil then\n    print(\"next(c) == nil\")\nend\n```\n\n输出\n\n```Lua\n0\n0\n2\nd == nil\nnext(a) == nil\n```\n\n因此，我们要判断一个 table 是否为 `{}`，不能采用 `#table == 0` 的方式来判断。可以用下面这样的方法来判断：\n\n```Plaintext\nfunction isTableEmpty(t)\n    return t == nil or next(t) == nil\nend\n```\n\n注意：**`next`** **指令是不能被 LuaJIT 的 JIT 编译优化，并且 LuaJIT 貌似没有明确计划支持这个指令优化，在不是必须的情况下，尽量少用。**\n\n  \n\n# 正则表达式\n\n同时存在两套正则表达式规范：_Lua_ 语言的规范和 `ngx.re.*` 的规范，即使您对 _Lua_ 语言中的规范非常熟悉，我们仍不建议使用 _Lua_ 中的正则表达式。\n\n- 一是因为 _Lua_ 中正则表达式的性能并不如 `ngx.re.*` 中的正则表达式优秀；\n    \n- 二是 _Lua_ 中的正则表达式并不符合 _POSIX_ 规范，而 `ngx.re.*` 中实现的是标准的 _POSIX_ 规范，后者明显更具备通用性。\n    \n\n`ngx.re.*` 中的 `o` 选项，指明该参数，被编译的 Pattern 将会在工作进程中缓存，并且被当前工作进程的每次请求所共享。Pattern 缓存的上限值通过 `lua_regex_cache_max_entries` 来修改，它的默认值为1024。\n\n`ngx.re.*` 中的 `j` 选项，指明该参数，如果使用的 PCRE 库支持 JIT，OpenResty 会在编译 Pattern 时启用 JIT。启用 JIT 后正则匹配会有明显的性能提升。较新的平台，自带的 PCRE 库均支持 JIT。如果系统自带的 PCRE 库不支持 JIT，出于性能考虑，最好自己编译一份 libpcre.so，然后在编译 OpenResty 时链接过去。要想验证当前 PCRE 库是否支持 JIT，可以这么做\n\n1. 编译 OpenResty 时在 `./configure` 中指定 `--with-debug` 选项\n    \n2. 在 `error_log` 指令中指定日志级别为 `debug`\n    \n3. 运行正则匹配代码，查看日志中是否有 `pcre JIT compiling result: 1`\n    \n\n即使运行在不支持 JIT 的 OpenResty 上，加上 `j` 选项也不会带来坏的影响。在 OpenResty 官方的 Lua 库中，正则匹配至少都会带上 `jo` 这两个选项。\n\n```Lua\nlocation /test {\n    content_by_lua_block {\n        local regex = [[\\d+]]\n\n        -- 参数 \"j\" 启用 JIT 编译，参数 \"o\" 是开启缓存必须的\n        local m = ngx.re.match(\"hello, 1234\", regex, \"jo\")\n        if m then\n            ngx.say(m[0])\n        else\n            ngx.say(\"not matched!\")\n        end\n    }\n}\n```\n\n#### **Lua 正则简单汇总**\n\n_Lua_ 中正则表达式语法上最大的区别，_Lua_ 使用 _'%'_ 来进行转义，而其他语言的正则表达式使用 _'\\'_ 符号来进行转义。其次，_Lua_ 中并不使用 _'?'_ 来表示非贪婪匹配，而是定义了不同的字符来表示是否是贪婪匹配。定义如下：\n\n|符号|匹配次数|匹配模式|\n|---|---|---|\n|+|匹配前一字符 1 次或多次|非贪婪|\n|`*`|匹配前一字符 0 次或多次|贪婪|\n|-|匹配前一字符 0 次或多次|非贪婪|\n|?|匹配前一字符 0 次或1次|仅用于此，不用于标识是否贪婪|\n\n|符号|匹配模式|\n|---|---|\n|.|任意字符|\n|%a|字母|\n|%c|控制字符|\n|%d|数字|\n|%l|小写字母|\n|%p|标点字符|\n|%s|空白符|\n|%u|大写字母|\n|%w|字母和数字|\n|%x|十六进制数字|\n|%z|代表 0 的字符|\n\n  \n\n# 虚变量\n\n当一个方法返回多个值时，有些返回值有时候用不到，要是声明很多变量来一一接收，显然不太合适（不是不能）。**Lua 提供了一个虚变量(dummy variable)的概念， 按照****[惯例](https://www.lua.org/pil/1.3.html)****以一个下划线（“_”）来命名，用它来表示丢弃不需要的数值，仅仅起到占位的作用。**\n\n  \n\n## 返回值\n\n```Lua\n-- string.find (s,p) 从string 变量s的开头向后匹配 string\n-- p，若匹配不成功，返回nil，若匹配成功，返回第一次匹配成功\n-- 的起止下标。\n\nlocal start, finish = string.find(\"hello\", \"he\") --start 值为起始下标，finish\n--值为结束下标\nprint ( start, finish )                          --输出 1   2\n\nlocal start = string.find(\"hello\", \"he\")      -- start值为起始下标\nprint ( start )                               -- 输出 1\n\n\nlocal _,finish = string.find(\"hello\", \"he\")   --采用虚变量（即下划线），接收起\n--始下标值，然后丢弃，finish接收\n--结束下标值\nprint ( finish )                              --输出 2\nprint ( _ )    \n```\n\n  \n\n## 迭代\n\n```Lua\n-- test.lua 文件\nlocal t = {1, 3, 5}\n\nprint(\"all  data:\")\nfor i,v in ipairs(t) do\n    print(i,v)\nend\n\nprint(\"\")\nprint(\"part data:\")\nfor _,v in ipairs(t) do\n    print(v)\nend\n```\n\n输出\n\n```Lua\n# luajit test.lua\nall  data:\n1   1\n2   3\n3   5\n\npart data:\n1\n3\n5\n```\n\n# **抵制使用 module() 定义模块**\n\n旧式的模块定义方式是通过 `module(\"filename\"[,package.seeall])*` 来显式声明一个包，现在官方不推荐再使用这种方式\n\n这种方式将会返回一个由 `filename` 模块函数组成的 `table`，并且还会定义一个包含该 `table` 的全局变量。\n\n  \n\n1. `package.seeall` 这种方式破坏了模块的高内聚，原本引入 \"filename\" 模块只想调用它的 _foobar()_ 函数，但是它却可以读写全局属性，例如 `\"filename.os\"`。\n    \n2. `module` 函数压栈操作引发的副作用，污染了全局环境变量。例如 `module(\"filename\")` 会创建一个 `filename` 的 `table`，并将这个 `table` 注入全局环境变量中，这样使得没有引用它的文件也能调用 `filename` 模块的方法。\n    \n\n  \n\n推荐的模块定义\n\n```Lua\n-- square.lua 长方形模块\nlocal _M = {}           -- 局部的变量\n_M._VERSION = '1.0'     -- 模块版本\n\nlocal mt = { __index = _M }\n\nfunction _M.new(self, width, height)\n    return setmetatable({ width=width, height=height }, mt)\nend\n\nfunction _M.get_square(self)\n    return self.width * self.height\nend\n\nfunction _M.get_circumference(self)\n    return (self.width + self.height) * 2\nend\n\nreturn _M\n```\n\n使用\n\n```Lua\nlocal square = require \"square\"\nlocal s1 = square:new(1, 2)\nprint(s1:get_square())          --output: 2\nprint(s1:get_circumference())   --output: 6\n```\n\n另一个跟 Lua 的 module 模块相关需要注意的点是，当 lua_code_cache on 开启时，require 加载的模块是会被缓存下来的，这样我们的模块就会以最高效的方式运行，直到被显式地调用如下语句（这里有点像模块卸载）：\n\n```Plaintext\npackage.loaded[\"square\"] = nil\n```\n\n  \n\n## 调用函数前先定义函数\n\nLua 里面的函数必须放在调用的代码之前，下面的代码是一个常见的错误：\n\n```Lua\n-- test.lua 文件local i = 100\ni = add_one(i)\n\nfunction add_one(i)\n    return i + 1\nend\n```\n\n因此在函数定义之前使用函数相当于在变量赋值之前使用变量，Lua 世界对于没有赋值的变量，默认都是 nil，所以这里也就产生了一个 nil 的错误。\n\n  \n\n# 点号操作符和冒号操作符的区别\n\n```Plaintext\nlocal str = \"abcde\"\n\nprint(\"case 1:\", str:sub(1, 2))\nprint(\"case 2:\", str.sub(str, 1, 2))\n```\n\n输出\n\n```Lua\ncase 1: ab\ncase 2: ab\n```\n\n- **冒号操作会带入一个** **`self`** **参数，用来代表** **`自己`****。**\n    \n- 而点号操作，只是 `内容` 的展开。\n    \n\n在函数定义时，使用冒号将默认接收一个 `self` 参数，而使用点号则需要显式传入 `self` 参数\n\n示例代码：\n\n```Plaintext\nobj = { x = 20 }\n\nfunction obj:fun1()\n    print(self.x)\nend\n```\n\n等价于\n\n```Plaintext\nobj = { x = 20 }\n\nfunction obj.fun1(self)\n    print(self.x)\nend\n```\n\n# module的缺点\n\n由于 `lua_code_cache off` 情况下，缓存的代码会伴随请求完结而释放。module 的最大好处缓存这时候是无法发挥的，所以本章的内容都是基于 `lua_code_cache on` 的情况下。\n\n先看看下面代码：\n\n```Plaintext\nlocal ngx_socket_tcp = ngx.socket.tcp           -- ①\n\nlocal _M = { _VERSION = '0.06' }                -- ②\nlocal mt = { __index = _M }                     -- ③\n\nfunction _M.new(self)\n    local sock, err = ngx_socket_tcp()          -- ④\n    if not sock then\n        return nil, err\n    end\n    return setmetatable({ sock = sock }, mt)    -- ⑤\nend\n\nfunction _M.set_timeout(self, timeout)\n    local sock = self.sock\n    if not sock then\n        return nil, \"not initialized\"\n    end\n\n    return sock:settimeout(timeout)\nend\n\n-- ... 其他功能代码，这里简略\n\nreturn _M\n```\n\n1. 对于比较底层的模块，内部使用到的非本地函数，都需要 local 本地化，这样做的好处：\n    \n    1. 避免命名冲突：防止外部是 `require(...)` 的方法调用造成全局变量污染\n        \n    2. 访问局部变量的速度比全局变量更快、更快、更快（重要事情说三遍）\n        \n\n  \n\n2. 每个基础模块最好有自己 `_VERSION` 标识，方便后期利用 `_VERSION` 完成热代码部署等高级特性，也便于使用者对版本有整体意识。\n    \n3. 其实 `_M` 和 `mt` 对于不同的请求实例（require 方法得到的对象）是相同的，因为 module 会被缓存到全局环境中。所以在这个位置千万不要放单请求内个性信息，例如 ngx.ctx 等变量。\n    \n4. **这里需要实现的是给每个实例绑定不同的 tcp 对象**，后**面 setmetatable 确保了每个实例拥有自己的 socket 对象，所以必须放在 new 函数中**。如果放在 ③ 的下面，那么这时候所有的不同实例内部将绑定了同一个 socket 对象。\n    \n\n```Plaintext\nlocal mt = { __index = _M }                     -- ③\nlocal sock = ngx_socket_tcp()                   -- ④ 错误的\n\nfunction _M.new(self)\n    return setmetatable({ sock = sock }, mt)    -- ⑤\nend\n```\n\n5. Lua 的 module 有两种类型：\n    \n    1. 支持面向对象痕迹可以保留私有属性；静态方法提供者，没有任何私有属性。\n        \n    2. 真正起到区别作用的就是 setmetatable 函数，是否有自己的个性元表，最终导致两种不同的形态。\n        \n\n# FFI\n\nhttps://moonbingbing.gitbooks.io/openresty-best-practices/content/lua/FFI.html\n\nFFI 库，是 LuaJIT 中最重要的一个扩展库。它允许从纯 Lua 代码调用外部 C 函数，使用 C 数据结构。\n\n  \n\nFFI 库最大限度的省去了使用 C 手工编写繁重的 `Lua/C` 绑定的需要。不需要学习一门独立/额外的绑定语言——它解析普通 C 声明。这样可以从 C 头文件或参考手册中，直接剪切，粘贴。它的任务就是绑定很大的库，但不需要捣鼓脆弱的绑定生成器。\n\nFFI 紧紧的整合进了 LuaJIT（几乎不可能作为一个独立的模块）。`JIT` 编译器在 C 数据结构上所产生的代码，等同于一个 C 编译器应该生产的代码。在 `JIT` 编译过的代码中，调用 C 函数，可以被内连处理，不同于基于 `Lua/C API` 函数调用。\n\n  \n\n## **ffi 库 词汇**\n\n|   |   |\n|---|---|\n|noun|Explanation|\n|cdecl|A definition of an abstract C type(actually, is a lua string)|\n|ctype|C type object|\n|cdata|C data object|\n|ct|C type format, is a template object, may be cdecl, cdata, ctype|\n|cb|callback object|\n|VLA|An array of variable length|\n|VLS|A structure of variable length|\n\n## **ffi.* API**\n\n**功能：** _Lua ffi 库的 API，与 LuaJIT 不可分割。_\n\n毫无疑问，在 `lua` 文件中使用 `ffi` 库的时候，必须要有下面的一行。\n\n```Plaintext\nlocal ffi = require \"ffi\"\n```\n\n# JIT\n\n看一下 LuaJIT 官方的解释：LuaJIT is a Just-In-Time Compilerfor the Lua programming language。\n\n**LuaJIT 的运行时环境包括一个用手写汇编实现的 Lua 解释器和一个可以直接生成机器代码的 JIT 编译器**\n\n- 一开始的时候，Lua 字节码总是被 LuaJIT 的解释器解释执行。LuaJIT 的解释器会在执行字节码时同时记录一些运行时的统计信息，比如每个 Lua 函数调用入口的实际运行次数，还有每个 Lua 循环的实际执行次数。\n    \n- 当这些次数超过某个预设的阈值时，便认为对应的 Lua 函数入口或者对应的 Lua 循环足够的“热”，这时便会触发 JIT 编译器开始工作。\n    \n- JIT 编译器会从热函数的入口或者热循环的某个位置开始尝试编译对应的 Lua 代码路径。编译的过程是把 LuaJIT 字节码先转换成 LuaJIT 自己定义的中间码（IR），然后再生成针对目标体系结构的机器码（比如 x86_64 指令组成的机器码）\n    \n- 如果当前 Lua 代码路径上的所有的操作都可以被 JIT 编译器顺利编译，则这条编译过的代码路径便被称为一个“trace”，在物理上对应一个 `trace` 类型的 GC 对象（即参与 Lua GC 的对象）。\n    \n\n  \n\nJIT 编译器不支持的原语被称为 **NYI（Not Yet Implemented）原语**。比较完整的 NYI 列表在这篇文档里面：\n\n```Plaintext\nhttp://wiki.luajit.org/NYI\n```\n\n所谓“让更多的 Lua 代码被 JIT 编译”，其实就是帮助更多的 Lua 代码路径能为 JIT 编译器所接受。这一般通过两种途径来实现：\n\n1. 调整对应的 Lua 代码，**避免使用 NYI 原语**。\n    \n2. 增强 JIT 编译器，让越来越多的 NYI 原语能够被编译。\n    \n\n## **可以被 JIT 编译的元操作**\n\n下面给大家列一下截止到目前已经可以被 JIT 编译的元操作。 其他还有 IO、Bit、FFI、Coroutine、OS、Package、Debug、JIT 等分类，使用频率相对较低，这里就不罗列了，可以参考官网：[http://wiki.luajit.org/NYI](http://wiki.luajit.org/NYI)。\n\n### **基础库的支持情况**\n\n|   |   |   |\n|---|---|---|\n|函数|编译?|备注|\n|assert|yes||\n|collectgarbage|no||\n|dofile|never||\n|error|never||\n|getfenv|2.1 partial|只有 getfenv(0) 能编译|\n|getmetatable|yes||\n|ipairs|yes||\n|load|never||\n|loadfile|never||\n|loadstring|never||\n|next|no||\n|pairs|no||\n|pcall|yes||\n|print|no||\n|rawequal|yes||\n|rawget|yes||\n|rawlen (5.2)|yes||\n|rawset|yes||\n|select|partial|第一个参数是静态变量的时候可以编译|\n|setfenv|no||\n|setmetatable|yes||\n|tonumber|partial|不能编译非10进制，非预期的异常输入|\n|tostring|partial|只能编译：字符串、数字、布尔、nil 以及支持 __tostring元方法的类型|\n|type|yes||\n|unpack|no||\n|xpcall|yes||\n\n### **字符串库**\n\n|   |   |   |\n|---|---|---|\n|函数|编译?|备注|\n|string.byte|yes||\n|string.char|2.1||\n|string.dump|never||\n|string.find|2.1 partial|只有字符串样式查找（没有样式）|\n|string.format|2.1 partial|不支持 %p 或 非字符串参数的 %s|\n|string.gmatch|no||\n|string.gsub|no||\n|string.len|yes||\n|string.lower|2.1||\n|string.match|no||\n|string.rep|2.1||\n|string.reverse|2.1||\n|string.sub|yes||\n|string.upper|2.1||\n\n### **表**\n\n|   |   |   |\n|---|---|---|\n|函数|编译?|备注|\n|table.concat|2.1||\n|table.foreach|no|2.1: 内部编译，但还没有外放|\n|table.foreachi|2.1||\n|table.getn|yes||\n|table.insert|partial|只有 push 操作|\n|table.maxn|no||\n|table.pack (5.2)|no||\n|table.remove|2.1|部分，只有 pop 操作|\n|table.sort|no||\n|table.unpack (5.2)|no||\n\n### **math 库**\n\n|   |   |   |\n|---|---|---|\n|函数|编译?|备注|\n|math.abs|yes||\n|math.acos|yes||\n|math.asin|yes||\n|math.atan|yes||\n|math.atan2|yes||\n|math.ceil|yes||\n|math.cos|yes||\n|math.cosh|yes||\n|math.deg|yes||\n|math.exp|yes||\n|math.floor|yes||\n|math.fmod|no||\n|math.frexp|no||\n|math.ldexp|yes||\n|math.log|yes||\n|math.log10|yes||\n|math.max|yes||\n|math.min|yes||\n|math.modf|yes||\n|math.pow|yes||\n|math.rad|yes||\n|math.random|yes||\n|math.randomseed|no||\n|math.sin|yes||\n|math.sinh|yes||\n|math.sqrt|yes||\n|math.tan|yes||\n|math.tanh|yes||","lastmodified":"2023-08-02T03:10:42.044088141Z","tags":["lua"]},"/lua/lua%E5%9F%BA%E7%A1%80":{"title":"lua基础","content":"\n\n# Lua 简介\n\nLua 是一个小巧的脚本语言。是巴西里约热内卢天主教大学（Pontifical Catholic University of Rio de Janeiro）里的一个研究小组并于 1993 年开发。**其设计目的是为了嵌入应用程序中，从而为应用程序提供灵活的扩展和定制功能**。Lua 由标准 C 编写而成，几乎在所有操作系统和平台上都可以编译、运行。Lua 并没有提供强大的库，这是由它的定位决定的。所以 Lua 不适合作为开发独立应用程序的语言。**Lua 有一个同时进行的 JIT 项目，提供在特定平台上的即时编译功能**。\n\n- **Lua 脚本可以很容易的被 C/C++ 代码调用，也可以反过来调用 C/C++ 的函数，这使得 Lua 在应用程序中可以被广泛应用**。\n    \n- **不仅仅作为扩展脚本，也可以作为普通的配置文件，代替 XML、ini 等文件格式，并且更容易理解和维护**。\n    \n- 标准 Lua 5.1 解释器由标准 C 编写而成，代码简洁优美，几乎在所有操作系统和平台上都可以编译和运行；\n    \n- 一个完整的标准 Lua 5.1 解释器不足 200 KB。而本书推荐使用的 LuaJIT 2 的代码大小也只有不足 500 KB\n    \n- 同时也支持大部分常见的体系结构。在目前所有脚本语言引擎中，LuaJIT 2 实现的速度应该算是最快的之一。这一切都决定了 Lua 是作为嵌入式脚本的最佳选择。\n    \n\nLua 语言的各个版本是不相兼容的。因此本书只介绍 Lua 5.1 语言，这是为标准 Lua 5.1 解释器和 LuaJIT 2 所共同支持的。LuaJIT 支持的对 Lua 5.1 向后兼容的 Lua 5.2 和 Lua 5.3 的特性，我们也会在方便的时候予以介绍。\n\n  \n\n# Lua 环境搭建\n\n[http://openresty.org](http://openresty.org/)\n\n  \n\n## Helloworld\n\n```Go\n# cat hello.lua\nprint(\"hello world\")\n# luajit hello.lua\nhello world\n```\n\n  \n\n# 基本数据类型\n\n  \n\n```Go\nprint(type(\"helloworld\"))\nprint(type('helloworld'))\nprint(type('true'))\nprint(type(1))\nprint(type(2.1))\nprint(type(nil))\nfunction hello()\n    print(\"hello\")\nend\nprint(type(hello))\n```\n\n输出\n\n```Go\nstring\nstring\nstring\nnumber\nnumber\nnil\nfunction\n```\n\n## Nil\n\nNil 是一种类型，Lua 将 nil 用于表示“无效值”。\n\n- 一个变量在第一次赋值前的默认值是 nil，\n    \n- 将 nil 赋予给一个全局变量就等同于删除它。\n    \n\n```Go\nlocal num\nprint(num)        --\u003eoutput:nil\n\nnum = 100\nprint(num)        --\u003eoutput:100\n```\n\n## Boolean (布尔)\n\n布尔类型，可选值 true/false；\n\n- Lua 中 nil 和 false 为“假”\n    \n- 其它所有值均为“真”。比如 0 和空字符串就是“真”；\n    \n\n```Go\nlocal a = true\nlocal b = 0\nlocal c = nil\nif a then\n    print(\"a\")        --\u003eoutput:a\nelse\n    print(\"not a\")    --这个没有执行\nend\n\nif b then\n    print(\"b\")        --\u003eoutput:b\nelse\n    print(\"not b\")    --这个没有执行\nend\n\nif c then\n    print(\"c\")        --这个没有执行\nelse\n    print(\"not c\")    --\u003eoutput:not c\nend\n```\n\n## **number（数字）**\n\nNumber 类型用于表示实数，和 C/C++ 里面的 double 类型很类似。可以使用数学函数 math. Floor（向下取整）和 math. Ceil（向上取整）进行取整操作。\n\n一般地，Lua 的 number 类型就是用双精度浮点数来实现的。值得一提的是，LuaJIT 支持所谓的“dual-number”（双数）模式，\n\n- 即 **LuaJIT 会根据上下文用整型来存储整数，而用双精度浮点数来存放浮点数。**\n    \n\n```Go\nlocal order = 3.99\nlocal score = 98.01\nprint(math.floor(order))   --\u003eoutput:3\nprint(math.ceil(score))    --\u003eoutput:99\nprint(9223372036854775807LL - 1)  --\u003eoutput:9223372036854775806LL\n```\n\n## String（字符串）\n\nLua 中有三种方式表示字符串:\n\n1. 使用一对匹配的单引号。例：'hello'。\n    \n2. 使用一对匹配的双引号。例：\"abclua\"。\n    \n3. 字符串还可以用一种长括号（即 [[ ]]）括起来的方式定义\n    \n    1. 我们把两个正的方括号（即[[）间插入 n 个等号定义为第 n 级正长括号。\n        \n    2. 0 级正的长括号写作 [[ ，一级正的长括号写作 [=[\n        \n    3. 反的长括号也作类似定义；举个例子，4 级反的长括号写作 ]====]\n        \n    4. **一个长字符串可以由任何一级的正的长括号开始，而由第一个碰到的同级反的长括号结束**。整个词法分析过程将**不受分行限制，不处理任何转义符，并且忽略掉任何不同级别的长括号**\n        \n\n  \n\n```Plaintext\nlocal str1 = 'hello world'\nlocal str2 = \"hello lua\"\nlocal str3 = [[\"add\\name\",'hello']]\nlocal str4 = [=[string have a [[]].]=]\nlocal str5 = [=[asdfasd]=]\n\nprint(str1)    --\u003eoutput:hello world\nprint(str2)    --\u003eoutput:hello lua\nprint(str3)    --\u003eoutput:\"add\\name\",'hello'\nprint(str4)    --\u003eoutput:string have a [[]].\nprint(str5)    --\u003eoutput:asdfasd\n```\n\n在 Lua 实现中，Lua 字符串一般都会经历一个“内化”（intern）的过程，**即两个完全一样的 Lua 字符串在 Lua 虚拟机中只会存储一份**。每一个 Lua 字符串在创建时都会**插入到 Lua 虚拟机内部的一个全局的哈希表**中\n\n1. 创建相同的 Lua 字符串并不会引入新的动态内存分配操作，所以相对便宜（但仍有全局哈希表查询的开销），\n    \n2. 内容相同的 Lua 字符串不会占用多份存储空间，\n    \n3. 已经创建好的 Lua 字符串之间进行相等性比较时是 `O(1)` 时间度的开销，而不是通常见到的 `O(n)`.\n    \n\n## Table (表)\n\nTable 类型实现了一种抽象的“关联数组”。“关联数组”是一种具有特殊索引方式的数组，\n\n- 索引通常是**字符串（string）或者 number 类型，但也可以是除** **`nil`** **以外的任意类型的值**\n    \n\n```Go\n\nlocal corp = {\n    web = \"www.google.com\",   --索引为字符串，key = \"web\",\n    --            value = \"www.google.com\"\n    telephone = \"12345678\",   --索引为字符串\n    staff = {\"Jack\", \"Scott\", \"Gary\"}, --索引为字符串，值也是一个表\n    100876,              --相当于 [1] = 100876，此时索引为数字\n    --      key = 1, value = 100876\n    100191,              --相当于 [2] = 100191，此时索引为数字\n    [10] = 360,          --直接把数字索引给出\n    [\"city\"] = \"Beijing\" --索引为字符串\n}\n\nprint(corp.web)               --\u003eoutput:www.google.com\nprint(corp[\"web\"])               --\u003eoutput:www.google.com\nprint(corp[\"telephone\"])      --\u003eoutput:12345678\nprint(corp[2])                --\u003eoutput:100191\nprint(corp[\"city\"])           --\u003eoutput:\"Beijing\"\nprint(corp.staff[1])          --\u003eoutput:Jack\nprint(corp[\"staff\"][1])          --\u003eoutput:Jack\nprint(corp[10])               --\u003eoutput:360\n```\n\n在内部实现上，table 通常实现为一个哈希表、一个数组、或者两者的混合。具体的实现为何种形式，动态依赖于具体的 table 的键分布特点。\n\n## Function (函数)\n\n在 Lua 中，**函数** 也是一种数据类型，函数可以存储在变量中，可以通过参数传递给其他函数，还可以作为其他函数的返回值\n\n```Go\nlocal function foo()\n    print(\"in the function\")\n    --dosomething()\n    local x = 10\n    local y = 20\n    return x + y\nend\n\nlocal a = foo    --把函数赋给变量\n\nprint(a())\n\n--output:\n--in the function\n--30\n\nfunction foo()\nend\n--等价于\n\nfoo = function ()\nend\n\nlocal function foo()\nend\n-- 等价于\n\nlocal foo = function ()\nend\n```\n\n  \n\n# 表达式\n\n## 算术运算符\n\n|            |      |\n| ---------- | ---- |\n| 算术运算符 | 说明 |\n| +          | 加法 |\n| -          | 减法 |\n| *          | 乘法 |\n| /          | 除法 |\n| ^          | 指数 |\n| %          | 取模 |\n\n```Go\nprint(1 + 2)       --\u003e打印 3\nprint(5 / 10)      --\u003e打印 0.5。 这是Lua不同于c语言的\nprint(5.0 / 10)    --\u003e打印 0.5。 浮点数相除的结果是浮点数\n-- print(10 / 0)   --\u003e注意除数不能为0，计算的结果会出错\nprint(2 ^ 10)      --\u003e打印 1024。 求2的10次方\n\nlocal num = 1357\nprint(num % 2)       --\u003e打印 1\nprint((num % 2) == 1) --\u003e打印 true。 判断num是否为奇数\n```\n\n## 关系运算符\n\n  \n\n|            |          |\n| ---------- | -------- |\n| 关系运算符 | 说明     |\n| \u003c          | 小于     |\n| \u003e          | 大于     |\n| \u003c=         | 小于等于 |\n| \u003e=         | 大于等于 |\n| ==         | 等于     |\n| ~=         | 不等于   |\n\n  \n\n```Go\nprint(1 \u003c 2)    --\u003e打印 true\nprint(1 == 2)   --\u003e打印 false\nprint(1 ~= 2)   --\u003e打印 true\nlocal a, b = true, false\nprint(a == b)  --\u003e打印 false\n```\n\n- 在使用“==”做等于判断时，要注意对于 table, userdate 和函数， Lua 是作引用比较的。也就是说，只有当两个变量引用同一个对象时，才认为它们相等\n    \n\n```Go\nlocal a = { x = 1, y = 0}\nlocal b = { x = 1, y = 0}\nif a == b then\n    print(\"a==b\")\nelse\n    print(\"a~=b\")\nend\n---output:\na~=b\n```\n\n- Lua 字符串总是会被“内化”，即相同内容的字符串只会被保存一份，因此 Lua 字符串之间的相等性比较可以简化为其内部存储地址的比较。\n    \n- 这意味着 Lua 字符串的相等性比较总是为 O (1)\n    \n\n## 逻辑运算符\n\n|            |        |\n| ---------- | ------ |\n| 逻辑运算符 | 说明   |\n| and        | 逻辑与 |\n| or         | 逻辑或 |\n| not        | 逻辑非 |\n\n在 c 语言中，and 和 or 只得到两个值 1 和 0，其中 1 表示真，0 表示假。而 Lua 中 and 的执行过程是这样的：\n\n- `a and b` 如果 a 为 nil，则返回 a，否则返回 b;\n    \n- `a or b` 如果 a 为 nil，则返回 b，否则返回 a。\n    \n- **所有逻辑操作符将 false 和 nil 视作假，其他任何值视作真，对于 and 和 or，“短路求值”，对于 not，永远只返回 true 或者 false。**\n    \n\n```Go\nlocal c = nil\nlocal d = 0\nlocal e = 100\nprint(c and d)  --\u003e打印 nil\nprint(c and e)  --\u003e打印 nil\nprint(d and e)  --\u003e打印 100\nprint(c or d)   --\u003e打印 0\nprint(c or e)   --\u003e打印 100\nprint(not c)    --\u003e打印 true\nprint(not d)    --\u003e打印 false\n```\n\n## 字符串连接\n\nLua 中连接两个字符串，可以使用操作符“..”（两个点）\n\n- 如果其任意一个操作数是数字的话，Lua 会将这个数字转换成字符串。\n    \n- 注意，连接操作符只会创建一个新字符串，而不会改变原操作数\n    \n- 也可以使用 string 库函数 `string.format` 连接字符串\n    \n\n```Go\nprint(\"Hello \" .. \"World\")    --\u003e打印 Hello Worldprint(0 .. 1)                 --\u003e打印 01\n\nstr1 = string.format(\"%s-%s\",\"hello\",\"world\")\nprint(str1)              --\u003e打印 hello-world\n\nstr2 = string.format(\"%d-%s-%.2f\",123,\"world\",1.21)\nprint(str2)              --\u003e打印 123-world-1.21\n```\n\n于 Lua 字符串本质上是只读的，**因此字符串连接运算符几乎总会创建一个新的（更大的）字符串**。这意味着如果有很多这样的连接操作（比如在循环中使用 .. 来拼接最终结果），则性能损耗会非常大。在这种情况下，推荐使用 table 和 `table.concat()` 来进行很多字符串的拼接\n\n```Go\nlocal pieces = {}\nfor i, elem in ipairs(my_list) do\n    pieces[i] = my_process(elem)\nend\nlocal res = table.concat(pieces)\n```\n\n上面的例子还可以使用 LuaJIT 独有的 `table.new` 来恰当地初始化 `pieces` 表的空间，以避免该表的动态生长。\n\n## 优先级\n\n| f               |     |\n| --------------- | --- |\n| ^               |     |\n| not # -         |     |\n| * / %           |     |\n| + -             |     |\n| ..              |     |\n| \u003c \u003e \u003c= \u003e= == ~= |     |\n| and             |     |\n| or              |     |\n  \n\n```Go\nlocal a, b = 1, 2\nlocal x, y = 3, 4\nlocal i = 10\nlocal res = 0\nres = a + i \u003c b/2 + 1  --\u003e等价于res =  (a + i) \u003c ((b/2) + 1)\nres = 5 + x^2*8        --\u003e等价于res =  5 + ((x^2) * 8)\nres = a \u003c y and y \u003c=x  --\u003e等价于res =  (a \u003c y) and (y \u003c= x)\n```\n\n  \n\n# 控制结构\n\n## If-else\n\n### **单个 if 分支型**\n\n```Go\nx = 10\nif x \u003e 0 then\n    print(\"x is a positive number\")\nend\n```\n\n### **两个分支 if-else 型**\n\n```Go\nx = 10\nif x \u003e 0 then\n    print(\"x is a positive number\")\nelse\n    print(\"x is a non-positive number\")\nend\n```\n\n### 多个分支的 if-elseif-else\n\n```Go\n\nscore = 90\nif score == 100 then\n    print(\"Very good!Your score is 100\")\nelseif score \u003e= 60 then\n    print(\"Congratulations, you have passed it,your score greater or equal to 60\")\n    --此处可以添加多个elseif\nelse\n    print(\"Sorry, you do not pass the exam! \")\nend\n```\n\n与 C 语言的不同之处是 else 与 if 是连在一起的，若将 else 与 if 写成 \"else if\" 则相当于在 else 里嵌套另一个 if 语句，如下代码：\n\n```Go\nscore = 0\nif score == 100 then\n    print(\"Very good!Your score is 100\")\nelseif score \u003e= 60 then\n    print(\"Congratulations, you have passed it,your score greater or equal to 60\")\nelse\n    if score \u003e 0 then\n        print(\"Your score is better than 0\")\n    else\n        print(\"My God, your score turned out to be 0\")\n    end --与上一示例代码不同的是，此处要添加一个end\nend\n```\n\n## While\n\n```Go\nwhile 表达式 do\n    --body\nend\n```\n\n  \n\n## Repeat\n\nLua 中的 repeat 控制结构类似于其他语言（如：C++ 语言）中的 do-while，但是控制方式是刚好相反的。简单点说，**执行 repeat 循环体后，直到 until 的条件为真时才结束**\n\n```Lua\n-- 以下代码会死循环\nx = 10\nrepeat\n    print(x)\nuntil false\n```\n\n  \n\n## For\n\n### **for 数字型**\n\n```Lua\nfor var = begin, finish, step do\n    --body\nend\n```\n\n1. Var 从 begin 变化到 finish，每次变化都以 step 作为步长递增 var\n    \n2. Begin、finish、step 三个表达式只会在循环开始时执行一次\n    \n3. 第三个表达式 step 是可选的，默认为 1\n    \n4. 控制变量 var 的作用域仅在 for 循环内，需要在外面控制，则需将值赋给一个新的变量\n    \n5. 循环过程中不要改变控制变量的值，那样会带来不可预知的影响\n    \n\n```Lua\nfor i = 1, 5 do\n    print(i)\nend\n-- output:\n1\n2\n3\n4\n5\n\nfor i = 1, 10, 2 do\n    print(i)\nend\n-- output:\n1\n3\n5\n7\n9\n```\n\n## For 泛型\n\n泛型 for 循环通过一个迭代器（iterator）函数来遍历所有值：\n\n```Lua\n-- 打印数组a的所有值local a = {\"a\", \"b\", \"c\", \"d\"}\nfor i, v in ipairs(a) do\n    print(\"index:\", i, \" value:\", v)\nend\n-- output:\nindex:  1  value: a\nindex:  2  value: b\nindex:  3  value: c\nindex:  4  value: d\n```\n\nLua 的基础库提供了 **ipairs，这是一个用于遍历数组的迭代器函数**。在每次循环中，i 会被赋予一个索引值，同时 v 被赋予一个对应于该索引的数组元素值。\n\n```Lua\n-- 打印table t中所有的\nkeyfor k in pairs(t) do\n    print(k)\nend\n```\n\n通过不同的迭代器，几乎可以遍历所有的东西，而且写出的代码极具可读性。标准库提供了几种迭代器，包括用于迭代文件中每行的（io. Lines）、迭代 table 元素的（pairs）、迭代数组元素的（ipairs）、迭代字符串中单词的（string. Gmatch）\n\n泛型 for 循环与数字型 for 循环有两个相同点：\n\n1. 循环变量是循环体的局部变量；\n    \n2. 决不应该对循环变量作任何赋值。\n    \n\n在 LuaJIT 2.1 中，**`ipairs()`** **内建函数是可以被 JIT 编译的，而** **`pairs()`** **则只能被解释执行。因此在性能敏感的场景，应当合理安排数据结构，避免对哈希表进行遍历**\n\n  \n\n## Break\n\n语句 `break` 用来终止 `while`、`repeat` 和 `for` 三种循环的执行，并跳出当前循环体，继续执行当前循环之后的语句\n\n```Lua\n-- 计算最小的x,使从1到x的所有数相加和大于100\nsum = 0\ni = 1while true do\n    sum = sum + i\n    if sum \u003e 100 then\n        break\n    end\n    i = i + 1\nend\nprint(\"The result is \" .. i)  \n--\u003eoutput:The result is 14\n```\n\n## Return\n\n  \n\n`return` 主要用于从函数中返回结果，或者用于简单的结束一个函数的执行。\n\n```Lua\nlocal function add(x, y)\n    return x + y\n    --print(\"add: I will return the result \" .. (x + y))\n    --因为前面有个return，若不注释该语句，则会报错\nend\n\nlocal function is_positive(x)\n    if x \u003e 0 then\n        return x .. \" is positive\"\n    else\n        return x .. \" is non-positive\"\n    end\n\n    --由于return只出现在前面显式的语句块，所以此语句不注释也不会报错\n    --，但是不会被执行，此处不会产生输出\n    print(\"function end!\")\nend\n\nlocal sum = add(10, 20)\nprint(\"The sum is \" .. sum)  --\u003eoutput:The sum is 30\nlocal answer = is_positive(-10)\nprint(answer)                --\u003eoutput:-10 is non-positive\n```\n\n  \n\n## Goto\n\n有了 `goto`，我们可以实现 `continue` 的功能：\n\n```Lua\nfor i=1, 3 do\n    if i \u003c= 2 then\n        print(i, \"yes continue\")\n        goto continue\n    end\n    print(i, \" no continue\")\n\n    ::continue::\n    print([[i'm end]])\nend\n```\n\n输出结果\n\n```Lua\n$ luajit test.lua\n1   yes continue\ni'm end\n2   yes continue\ni'm end\n3    no continue\ni'm end\n```\n\n# 函数\n\n## 定义\n\n```Lua\nfunction function_name (arc)  -- arc 表示参数列表，函数的参数列表可以为空\n    -- body\nend\n```\n\n上面的语法定义了一个全局函数，名为 `function_name`. 全局函数本质上就是函数类型的值赋给了一个全局变量，即上面的语法等价于\n\n```Lua\nfunction_name = function (arc)\n     -- body\nend\n```\n\n由于全局变量一般会污染全局名字空间，同时也有性能损耗（即查询全局环境表的开销），因此我们应当尽量使用“局部函数”，其记法是类似的，只是开头加上 `local` 修饰符：\n\n```Lua\nlocal function function_name (arc)\n    -- body\nend\n```\n\n定义函数\n\n1. 利用名字来解释函数、变量的目的，使人通过名字就能看出来函数、变量的作用。\n    \n2. 每个函数的长度要尽量控制在一个屏幕内，一眼可以看明白。\n    \n3. 让代码自己说话，不需要注释最好。\n    \n\n  \n\n由于函数定义等价于变量赋值，我们也可以把函数名替换为某个 Lua 表的某个字段，例如\n\n```Lua\nlocal foo = {}\nfunction foo.pr()\n    print(\"ssss\")\nend\n\nfoo.pr()\n```\n\n  \n\n## 参数\n\n### 按值传递\n\n**Lua 函数的参数大部分是按值传递的**。**当函数参数是 table 类型时，传递进来的是实际参数的引用**\n\n值传递就是调用函数时，实参把它的值通过赋值运算传递给形参，然后形参的改变和实参就没有关系了。在这个过程中，实参是通过它在参数表中的位置与形参匹配起来的。\n\n```Lua\nlocal function swap(a, b) --定义函数swap,函数内部进行交换两个变量的值\n    local temp = a\n    a = b\n    b = temp\n    print(a, b)\nend\n\nlocal x = \"hello\"\nlocal y = 20\nprint(x, y)\nswap(x, y)    --调用swap函数\nprint(x, y)   --调用swap函数后，x和y的值并没有交换\n\n--\u003eoutput\nhello 20\n20  hello\nhello 20\n```\n\n在调用函数的时候，**若形参个数和实参个数不同时，Lua 会自动调整实参个数**。调整规则：\n\n- 若实参个数大于形参个数，从左向右，多余的实参被忽略；\n    \n- 若实参个数小于形参个数，从左向右，**没有被实参初始化的形参会被初始化为 nil**\n    \n\n```Lua\nlocal function fun1(a, b)       --两个形参，多余的实参被忽略掉\n    print(a, b)\nend\n\nlocal function fun2(a, b, c, d) --四个形参，没有被实参初始化的形参，用nil初始化\n    print(a, b, c, d)\nend\n\nlocal x = 1\nlocal y = 2\nlocal z = 3\n\nfun1(x, y, z)         -- z被函数fun1忽略掉了，参数变成 x, y\nfun2(x, y, z)         -- 后面自动加上一个nil，参数变成 x, y, z, nil\n\n--\u003eoutput\n1   2\n1   2   3   nil\n```\n\n### 变长参数\n\n其实 Lua 还支持变长参数。若形参为 `...`，表示该函数可以接收不同长度的参数。访问参数的时候也要使用 `...`\n\n```Lua\n\nlocal function func( ... )                -- 形参为 ... ,表示函数采用变长参数\n\n    local temp = {...}                     -- 访问的时候也要使用 ...\n    local ans = table.concat(temp, \" \")    -- 使用 table.concat 库函数对数\n    -- 组内容使用 \" \" 拼接成字符串。\n    print(ans)\nend\n\nfunc(1, 2)        -- 传递了两个参数\nfunc(1, 2, 3, 4)  -- 传递了四个参数\n\n--\u003eoutput\n1 2\n\n1 2 3 4\n```\n\n### **具名参数**\n\nLua 还支持通过名称来指定实参，这时候要把所有的实参组织到一个 table 中，并将这个 table 作为唯一的实参传给函数。\n\n```Lua\nlocal function change(arg) -- change 函数，改变长方形的长和宽，使其各增长一倍\n  arg.width = arg.width * 2\n  arg.height = arg.height * 2return arg\nendlocal rectangle = { width = 20, height = 15 }\nprint(\"before change:\", \"width  =\", rectangle.width,\n                        \"height =\", rectangle.height)\nrectangle = change(rectangle)\nprint(\"after  change:\", \"width  =\", rectangle.width,\n                        \"height =\", rectangle.height)\n\n--\u003eoutput\nbefore change: width = 20  height =  15\nafter  change: width = 40  height =  30\n```\n\n  \n\n### 按引用传递\n\n**当函数参数是 table 类型时，传递进来的是实际参数的引用**，此时在函数内部对该 table 所做的修改，会直接对调用者所传递的实际参数生效，而无需自己返回结果和让调用者进行赋值\n\n```Plaintext\nfunction change(arg) --change函数，改变长方形的长和宽，使其各增长一倍\n  arg.width = arg.width * 2  --表arg不是表rectangle的拷贝，他们是同一个表\n  arg.height = arg.height * 2end                  -- 没有return语句了local rectangle = { width = 20, height = 15 }\nprint(\"before change:\", \"width = \", rectangle.width,\n                        \" height = \", rectangle.height)\nchange(rectangle)\nprint(\"after change:\", \"width = \", rectangle.width,\n                       \" height =\", rectangle.height)\n\n--\u003e output\nbefore change: width = 20  height = 15\nafter  change: width = 40  height = 30\n```\n\n## 函数返回值\n\nLua 具有一项与众不同的特性，允许函数返回多个值。\n\n```Lua\nlocal function swap(a, b)   \n    -- 定义函数 swap，实现两个变量交换值\n    return b, a              \n    -- 按相反顺序返回变量的值\nend\n\nlocal x = 1\nlocal y = 20\nx, y = swap(x, y)           -- 调用 swap 函数\nprint(x, y)                 --\u003e output   20     1\n```\n\n  \n\n当函数返回值的个数和接收返回值的变量的个数不一致时，Lua 也会自动调整参数个数调整规则：\n\n- 若返回值个数大于接收变量的个数，多余的返回值会被忽略掉；\n    \n- 若返回值个数小于参数个数，从左向右，没有被返回值初始化的变量会被初始化为 nil。\n    \n\n```Lua\nfunction init()             \n    --init 函数 返回两个值 1 和 \"lua\"\n    return 1, \"lua\"\nend\n\nx = init()\nprint(x)\n\nx, y, z = init()\nprint(x, y, z)\n\n--output\n1\n1 lua nil\n```\n\n  \n\n当一个函数有一个以上返回值，且函数调用不是一个列表表达式的最后一个元素，那么函数调用只会产生一个返回值, 也就是第一个返回值。\n\n```Lua\nlocal function init()       -- init 函数 返回两个值 1 和 \"lua\"\n    return 1, \"lua\"\nend\n\nlocal x, y, z = init(), 2   -- init 函数的位置不在最后，此时只返回 1\nprint(x, y, z)              --\u003eoutput  1  2  nil\n\nlocal a, b, c = 2, init()   -- init 函数的位置在最后，此时返回 1 和 \"lua\"\nprint(a, b, c)              --\u003eoutput  2  1  lua\n```\n\n函数调用的实参列表也是一个列表表达式。考虑下面的例子：\n\n```Lua\nlocal function init()\n    return 1, \"lua\"\nend\n\nprint(init(), 2)   --\u003eoutput  1  2\nprint(2, init())   --\u003eoutput  2  1  lua\n```\n\n如果你确保只取函数返回值的第一个值，可以使用括号运算符\n\n```Lua\nlocal function init()\n    return 1, \"lua\"\nend\nprint((init()), 2)   --\u003eoutput  1  2\nprint(2, (init()))   --\u003eoutput  2  1\n```\n\n**值得一提的是，如果实参列表中某个函数会返回多个值，同时调用者又没有显式地使用括号运算符来筛选和过滤，则这样的表达式是不能被 LuaJIT 2 所 JIT 编译的，而只能被解释执行。**\n\n  \n\n  \n\n# 全动态函数调用\n\n调用回调函数，并把一个数组参数作为回调函数的参数。\n\n```Lua\nlocal args = {...} or {}\nmethod_name(unpack(args, 1, table.maxn(args)))\n```\n\n```Lua\nlocal function run(x, y)\n    print('run', x, y)\nend\n\nlocal function attack(targetId)\n    print('targetId', targetId)\nend\n\nlocal function do_action(method, ...)\n    local args = {...} or {}\n    method(unpack(args, 1, table.maxn(args)))\nend\n\ndo_action(run, 1, 2)         -- output: run 1 2\ndo_action(attack, 1111)      -- output: targetId    1111\n```\n\n  \n\n# 模块\n\n从 Lua 5.1 语言添加了对模块和包的支持。一**个 Lua 模块的数据结构是用一个 Lua 值（通常是一个 Lua 表或者 Lua 函数）**。**一个 Lua 模块代码就是一个会返回这个 Lua 值的代码块**\n\n- 可以使用内建函数 `require()` 来加载和缓存模块。\n    \n- 简单的说，一个代码模块就是一个程序库，可以通过 `require` 来加载。**模块加载后的结果通过是一个 Lua table**\n    \n- **这个表就像是一个命名空间**，其内容就是模块中导出的所有东西，**比如函数和变量**。`require` 函数会返回 Lua 模块加载后的结果，即用于表示该 Lua 模块的 Lua 值。\n    \n\n  \n\n  \n\nLua 提供了一个名为 `require` 的函数用来加载模块。**要加载一个模块，只需要简单地调用** **`require`** **\"file\" 就可以了，file 指模块所在的文件名**。这个调用会返回一个由模块函数组成的 table，并且还会定义一个包含该 table 的全局变量。\n\n在 Lua 中创建一个模块最简单的方法是：**创建一个 table，并将所有需要导出的函数放入其中，最后返回这个 table 就可以了。相当于将导出的函数作为 table 的一个字段，在 Lua 中函数是第一类值，提供了天然的优势。**\n\n- 创建 my. Lua\n    \n\n```Lua\nlocal _M = {}\n\nlocal function get_name()\n    return \"Lucy\"\n    end\nfunction _M.greeting()\n    print(\"hello \" .. get_name())\nend\n\nreturn _M\n```\n\n- 把下面代码保存在文件 main. Lua 中，然后执行 main. Lua，调用上述模块。\n    \n\n```Lua\nlocal my_module = require(\"my\")\nmy_module.greeting()     --\u003eoutput: hello Lucy\n```\n\n  \n\n\u003e - 对于需要导出给外部使用的公共模块，处于安全考虑，**是要避免全局变量的出现**。我们可以使用 lj-releng 或 luacheck 工具完成全局变量的检测。至于如何做，到后面再讲。\n\u003e     \n\u003e - 另一个要注意的是，由于在 LuaJIT 中，**require 函数内不能进行上下文切换**，**所以不能够在模块的顶级上下文中调用 cosocket 一类的 API**。否则会报 `attempt to yield across C-call boundary` 错误。\n\u003e     \n\n  \n\n# String\n\nLua 字符串总是由字节构成的。Lua 核心并不尝试理解具体的字符集编码（比如 GBK 和 UTF-8 这样的多字节字符编码）\n\nLua 字符串内部用来标识各个组成字节的下标是从 1 开始的，这不同于像 C 和 Perl 这样的编程语言。这样数字符串位置的时候再也不用调整，对于非专业的开发者来说可能也是一个好事情，**string.Sub (str, 3, 7) 直接表示从第三个字符开始到第七个字符（含）为止的子串。**\n\n## **string.Byte (s [, i [, j ]])**\n\n返回字符 s[i]、s[i + 1]、s[i + 2]、······、s[j] 所对应的 ASCII 码\n\n```Lua\nprint(string.byte(\"abc\", 1, 3))\nprint(string.byte(\"abc\", 3)) -- 缺少第三个参数，第三个参数默认与第二个相同，此时为 3\nprint(string.byte(\"abc\"))    -- 缺少第二个和第三个参数，此时这两个参数都默认为 1\n\n--\u003eoutput\n97    98    99\n99\n97\n```\n\n## **string. Char (...)**\n\n接收 0 个或更多的整数（整数范围：0~255），返回这些整数所对应的 ASCII 码字符组成的字符串。当参数为空时，默认是一个 0。\n\n```Lua\nprint(string.char(96, 97, 98))\nprint(string.char())        -- 参数为空，默认是一个0，-- 你可以用string.byte(string.char())测试一下print(string.char(65, 66))\n\n--\u003e output\n`ab\n\nAB\n```\n\n## **string.Upper (s)**\n\n接收一个字符串 s，返回一个把所有小写字母变成大写字母的字符串。\n\n```Lua\nprint(string.upper(\"Hello Lua\"))  --\u003eoutput  HELLO LUA\n```\n\n## **string.Lower (s)**\n\n接收一个字符串 s，返回一个把所有大写字母变成小写字母的字符串。\n\n```Lua\nprint(string.lower(\"Hello Lua\"))  --\u003eoutput   hello lua\n```\n\n## **string.Len (s)**\n\n接收一个字符串，返回它的长度。\n\n```Lua\nprint(string.len(\"hello lua\")) --\u003eoutput  9\n```\n\n使用此函数是不推荐的。应当总是使用 `#` 运算符来获取 Lua 字符串的长度\n\n## **string.Find (s, p [, init [, plain]])**\n\n在 s 字符串中第一次匹配 p 字符串。若匹配成功，则返回 p 字符串在 s 字符串中出现的开始位置和结束位置；若匹配失败，则返回 nil,\n\n第三个参数第三个参数 init 默认为 1，并且可以为负整数，\n\n当 init 为负数时，表示从 s 字符串的 string.Len (s) + init + 1 索引处开始向后匹配字符串 p 。\n\n第四个参数默认为 false，当其为 true 时，只会把 p 看成一个字符串对待。\n\n```Lua\nlocal find = string.find\nprint(find(\"abc cba\", \"ab\"))\nprint(find(\"abc cba\", \"ab\", 2))     -- 从索引为2的位置开始匹配字符串：ab\nprint(find(\"abc cba\", \"ba\", -1))    -- 从索引为7的位置开始匹配字符串：ba\nprint(find(\"abc cba\", \"ba\", -3))    -- 从索引为5的位置开始匹配字符串：ba\nprint(find(\"abc cba\", \"(%a+)\", 1))  -- 从索引为1处匹配最长连续且只含字母的字符串\nprint(find(\"abc cba\", \"(%a+)\", 1, true)) --从索引为1的位置开始匹配字符串：(%a+)\n\n--\u003eoutput\n1   2\nnil\nnil\n6   7\n1   3   abc\nnil\n```\n\n## **string.Format (formatstring, ...)**\n\n按照格式化参数 formatstring，返回后面 `...` 内容的格式化版本\n\n```Plaintext\nprint(string.format(\"%.4f\", 3.1415926))     -- 保留4位小数\nprint(string.format(\"%d %x %o\", 31, 31, 31))-- 十进制数31转换成不同进制\nd = 29; m = 7; y = 2015                     -- 一行包含几个语句，用；分开\nprint(string.format(\"%s %02d/%02d/%d\", \"today is:\", d, m, y))\n\n--\u003eoutput\n3.1416\n31 1f 37\ntoday is: 29/07/2015\n```\n\n## **string.Match (s, p [, init])**\n\n在字符串 s 中匹配（模式）字符串 p，若匹配成功，则返回目标字符串中与模式匹配的子串；否则返回 nil。第三个参数 init 默认为 1，并且可以为负整数，当 init 为负数时，表示从 s 字符串的 string.Len (s) + init + 1 索引处开始向后匹配字符串 p。\n\n```Lua\nprint(string.match(\"hello lua\", \"lua\"))\nprint(string.match(\"lua lua\", \"lua\", 2))  --匹配后面那个luaprint(string.match(\"lua lua\", \"hello\"))\nprint(string.match(\"today is 27/7/2015\", \"%d+/%d+/%d+\"))\n\n--\u003eoutput\nlua\nlua\nnil27/7/2015\n```\n\n## **string.Gmatch (s, p)**\n\n返回一个迭代器函数，通过这个迭代器函数可以遍历到在字符串 s 中出现模式串 p 的所有地方。\n\n```Lua\ns = \"hello world from Lua\"\nfor w in string.gmatch(s, \"%a+\") do  --匹配最长连续且只含字母的字符串\n    print(w)\nend\n\n--\u003eoutput\nhello\nworld\nfrom\nLua\n\n\nt = {}\ns = \"from=world, to=Lua\"\nfor k, v in string.gmatch(s, \"(%a+)=(%a+)\") do  --匹配两个最长连续且只含字母的\n    t[k] = v                                    --字符串，它们之间用等号连接\nend\nfor k, v in pairs(t) do\n    print (k,v)\nend\n\n--\u003eoutput\nto      Lua\nfrom    worl\n```\n\n## **string.Rep (s, n)**\n\n返回字符串 s 的 n 次拷贝。\n\n```Lua\nprint(string.rep(\"abc\", 3)) \n\n--拷贝3次\"abc\"--\u003eoutput  abcabcabc\n```\n\n## **string.Sub (s, i [, j])**\n\n返回字符串 s 中，索引 i 到索引 j 之间的子字符串。当 j 缺省时，默认为 -1，也就是字符串 s 的最后位置。I 可以为负数。当索引 i 在字符串 s 的位置在索引 j 的后面时，将返回一个空字符串。\n\n```Lua\nprint(string.sub(\"Hello Lua\", 4, 7))\nprint(string.sub(\"Hello Lua\", 2))\nprint(string.sub(\"Hello Lua\", 2, 1))    --看到返回什么了吗print(string.sub(\"Hello Lua\", -3, -1))\n\n--\u003eoutput\nlo L\nello Lua\n\nLua\n```\n\n## **string.Gsub (s, p, r [, n])**\n\n将目标字符串 s 中所有的子串 p 替换成字符串 r。可选参数 n，表示限制替换次数。返回值有两个，第一个是被替换后的字符串，第二个是替换了多少次。\n\n```Plaintext\nprint(string.gsub(\"Lua Lua Lua\", \"Lua\", \"hello\"))\nprint(string.gsub(\"Lua Lua Lua\", \"Lua\", \"hello\", 2)) --指明第四个参数--\u003eoutput\nhello hello hello   3\nhello hello Lua     2\n```\n\n## **string. Reverse (s)**\n\n接收一个字符串 s，返回这个字符串的反转\n\n```Lua\nprint(string.reverse(\"Hello Lua\"))  --\u003e output: auL olleH\n```\n\n  \n\n# Table\n\n## **下标从 1 开始**\n\n数组下标从 1 开始计数。\n\n而 Lua 最初设计是一种类似 XML 的数据描述语言，所以索引（index）反应的是数据在里面的位置，而不是偏移量。\n\n  \n\n在初始化一个数组的时候，**若不显式地用键值对方式赋值，则会默认用数字作为下标**，从 1 开始。由于在 _Lua_ 内部实际采用哈希表和数组分别保存键值对、普通值，所以不推荐混合使用这两种赋值方式\n\n```Lua\nlocal color={first=\"red\", \"blue\", third=\"green\", \"yellow\"}\nprint(color[\"first\"])                 --\u003e output: red\nprint(color[1])                       --\u003e output: blue\nprint(color[\"third\"])                 --\u003e output: green\nprint(color[2])                       --\u003e output: yellow\nprint(color[3])                       --\u003e output: nil\n```\n\n- **当我们把 table 当作栈或者队列使用的时候，容易犯错，追加到 table 的末尾用的是** **`s[#s+1] = something`****, 而不是** **`s[#s] = something`**\n    \n- 而且如果这个 something 是一个 nil 的话**，会导致这一次压栈（或者入队列）没有存入任何东西**， s 的值没有变\n    \n- 如果 `s = { 1, 2, 3, 4, 5, 6 }`，你令 `s[4] = nil`， s 会令你“匪夷所思”地变成 3。\n    \n\n## **table. Getn 获取长度**\n\n取长度操作符写作一元操作 。字符串的长度是它的字节数（就是以一个字符一个字节计算的字符串长度）\n\n- 对于常规的数组，里面从 1 到 n 放着一些非空的值的时候，它的长度就精确的为 n，即最后一个值的下标\n    \n- 如果数组有一个“空洞”（**就是说，nil 值被夹在非空值之间**），**那么 t 可能是指向任何一个是 nil 值的前一个位置的下标**\n    \n- 这也就说明对于有“空洞”的情况，table 的长度存在一定的 **不可确定性**\n    \n\n```Lua\nlocal tblTest1 = { 1, a = 2, 3 }\nprint(\"Test1 \" .. table.getn(tblTest1))\n\nlocal tblTest2 = { 1, nil }\nprint(\"Test2 \" .. table.getn(tblTest2))\n\nlocal tblTest3 = { 1, nil, 2 }\nprint(\"Test3 \" .. table.getn(tblTest3))\n\nlocal tblTest4 = { 1, nil, 2, nil }\nprint(\"Test4 \" .. table.getn(tblTest4))\n\nlocal tblTest5 = { 1, nil, 2, nil, 3, nil }\nprint(\"Test5 \" .. table.getn(tblTest5))\n\nlocal tblTest6 = { 1, nil, 2, nil, 3, nil, 4, nil }\nprint(\"Test6 \" .. table.getn(tblTest6))\n```\n\n我们使用 Lua 5.1 和 LuaJIT 2.1 分别执行这个用例，结果如下：\n\n```Lua\n# lua test.lua\nTest1 2\nTest2 1\nTest3 3\nTest4 1\nTest5 3\nTest6 1\n# luajit test.lua\nTest1 2\nTest2 1\nTest3 1\nTest4 1\nTest5 1\nTest6 1\n```\n\n不要在 Lua 的 table 中使用 nil 值，**如果一个元素要删除，直接 remove，不要用 nil 去代替**。\n\n## **table. Concat (table [, sep [, i [, j ] ] ])**\n\n对于元素是 string 或者 number 类型的表 table，返回 `table[i]..sep..table[i+1] ··· sep..table[j]` 连接成的字符串。填充字符串 sep 默认为空白字符串。起始索引位置 i 默认为 1，结束索引位置 j 默认是 table 的长度。\n\n```Lua\nlocal a = {1, 3, 5, \"hello\" }\nprint(table.concat(a))              -- output: 135hello\nprint(table.concat(a, \"|\"))         -- output: 1|3|5|hello\nprint(table.concat(a, \" \", 4, 2))   -- output:\nprint(table.concat(a, \" \", 2, 4))   -- output: 3 5 hello\n```\n\n## **table. Insert (table, [pos ,] value)**\n\n在（数组型）表 table 的 pos 索引位置插入 value，其它元素向后移动到空的地方。Pos 的默认值是表的长度加一，即默认是插在表的最后\n\n```Lua\nlocal a = {1, 8}             --a[1] = 1,a[2] = 8\ntable.insert(a, 1, 3)   --在表索引为1处插入3\nprint(a[1], a[2], a[3])\ntable.insert(a, 10)    --在表的最后插入10\nprint(a[1], a[2], a[3], a[4])\n\n--\u003eoutput\n3    1    8\n3    1    8    10\n```\n\n## **table. Maxn (table)**\n\n返回（数组型）表 table 的最大索引编号；如果此表没有正的索引编号，返回 0。\n\n```Lua\nlocal a = {}\na[-1] = 10\nprint(table.maxn(a))\na[5] = 10\nprint(table.maxn(a))\n\n--\u003eoutput05\n```\n\n## **table. Remove (table [, pos])**\n\n在表 table 中删除索引为 pos（pos 只能是 number 型）的元素，并返回这个被删除的元素，它后面所有元素的索引值都会减一。Pos 的默认值是表的长度，即默认是删除表的最后一个元素。\n\n```Lua\nlocal a = { 1, 2, 3, 4}\nprint(table.remove(a, 1)) --删除速索引为1的元素print(a[1], a[2], a[3], a[4])\n\nprint(table.remove(a))   --删除最后一个元素print(a[1], a[2], a[3], a[4])\n\n--\u003eoutput12    3    4    nil42    3    nil    nil\n```\n\n## **table. Sort (table [, comp])**\n\n按照给定的比较函数 comp 给表 table 排序，也就是从 table[1] 到 table[n]，这里 n 表示 table 的长度。比较函数有两个参数，如果希望第一个参数排在第二个的前面，就应该返回 true，否则返回 false。如果比较函数 comp 没有给出，默认从小到大排序。\n\n```Lua\n\nlocal function compare(x, y) --从大到小排序\n    return x \u003e y         --如果第一个参数大于第二个就返回true，否则返回false\nend\n\nlocal a = { 1, 7, 3, 4, 25}\ntable.sort(a)           --默认从小到大排序\nprint(a[1], a[2], a[3], a[4], a[5])\ntable.sort(a, compare) --使用比较函数进行排序\nprint(a[1], a[2], a[3], a[4], a[5])\n\n--\u003eoutput\n1    3    4    7    25\n25    7    4    3    1\n```\n\n## 其他\n\nLuaJIT 2.1 新增加的 `table.new` 和 `table.clear` 函数是非常有用的。前者主要用来预分配 Lua table 空间，后者主要用来高效的释放 table 空间，并且它们都是可以被 JIT 编译的\n\n  \n\n# 日期时间\n\n函数 time、date 和 difftime 提供了所有的日期和时间功能。\n\n在 OpenResty 的世界里，不推荐使用这里的标准时间函数，因为这些函数通常会引发不止一个昂贵的系统调用，同时无法为 LuaJIT JIT 编译，对性能造成较大影响。推荐使用 ngx_lua 模块提供的带缓存的时间接口，如 `ngx.today`, `ngx.time`, `ngx.utctime`, `ngx.localtime`, `ngx.now`, `ngx.http_time`，以及 `ngx.cookie_time` 等。\n\n  \n\n## **os. Time ([table])**\n\n如果不使用参数 table 调用 time 函数，\n\n- 它会返回当前的时间和日期（它表示从某一时刻到现在的秒数）。\n    \n- 如果用 table 参数，它会返回一个数字，表示该 table 中所描述的日期和时间（它表示从某一时刻到 table 中描述日期和时间的秒数）。Table 的字段如下：\n    \n\n|          |                            |\n| -------- | -------------------------- |\n| 字段名称 | 取值范围                   |\n| year     | 四位数字                   |\n| month    | 1--12                      |\n| day      | 1--31                      |\n| hour     | 0--23                      |\n| min      | 0--59                      |\n| sec      | 0--61                      |\n| isdst    | boolean（true 表示夏令时） |\n\n对于 time 函数，如果参数为 table，那么 table 中必须含有 year、month、day 字段。其他字缺省时段默认为中午（12:00:00）。\n\n\u003e 示例代码：（地点为北京）\n\n```Plaintext\nprint(os.time())    --\u003eoutput  1438243393\na = { year = 1970, month = 1, day = 1, hour = 8, min = 1 }\nprint(os.time(a))   --\u003eoutput  60\n```\n\n## **os. Difftime (t 2, t 1)**\n\n返回 t 1 到 t 2 的时间差，单位为秒。\n\n\u003e 示例代码:\n\n```Plaintext\nlocal day1 = { year = 2015, month = 7, day = 30 }\nlocal t1 = os.time(day1)\n\nlocal day2 = { year = 2015, month = 7, day = 31 }\nlocal t2 = os.time(day2)\nprint(os.difftime(t2, t1))   --\u003eoutput  86400\n```\n\n## **os. Date ([format [, time]])**\n\n把一个表示日期和时间的数值，转换成更高级的表现形式。\n\n- 其第一个参数 format 是一个格式化字符串，描述了要返回的时间形式。\n    \n- 第二个参数 time 就是日期和时间的数字表示，缺省时默认为当前的时间。\n    \n- 使用格式字符 \"*t\"，创建一个时间表。\n    \n\n\u003e 示例代码：\n\n```Plaintext\nlocal tab1 = os.date(\"*t\")  --返回一个描述当前日期和时间的表\nlocal ans1 = \"{\"\nfor k, v in pairs(tab1) do  --把tab1转换成一个字符串\n    ans1 = string.format(\"%s %s = %s,\", ans1, k, tostring(v))\nend\n\nans1 = ans1 .. \"}\"\nprint(\"tab1 = \", ans1)\n\n\nlocal tab2 = os.date(\"*t\", 360)  --返回一个描述日期和时间数为360秒的表\nlocal ans2 = \"{\"\nfor k, v in pairs(tab2) do      --把tab2转换成一个字符串\n    ans2 = string.format(\"%s %s = %s,\", ans2, k, tostring(v))\nend\n\nans2 = ans2 .. \"}\"\nprint(\"tab2 = \", ans2)\n\n--\u003eoutput\ntab1 = { hour = 17, min = 28, wday = 5, day = 30, month = 7, year = 2015, sec = 10, yday = 211, isdst = false,}\ntab2 = { hour = 8, min = 6, wday = 5, day = 1, month = 1, year = 1970, sec = 0, yday = 1, isdst = false,}\n```\n\n该表中除了使用到了 time 函数参数 table 的字段外，这还提供了星期（wday，星期天为 1）和一年中的第几天（yday，一月一日为 1）。除了使用 \"*t\" 格式字符串外，如果使用带标记（见下表）的特殊字符串，os. Date 函数会将相应的标记位以时间信息进行填充，得到一个包含时间的字符串。表如下：\n\n|          |                                           |\n| -------- | ----------------------------------------- |\n| 格式字符 | 含义                                      |\n| %a       | 一星期中天数的简写（例如：Wed）           |\n| %A       | 一星期中天数的全称（例如：Wednesday）     |\n| %b       | 月份的简写（例如：Sep）                   |\n| %B       | 月份的全称（例如：September）             |\n| %c       | 日期和时间（例如：07/30/15 16:57:24）     |\n| %d       | 一个月中的第几天[01 ~ 31]                 |\n| %H       | 24 小时制中的小时数[00 ~ 23]              |\n| %I       | 12 小时制中的小时数[01 ~ 12]              |\n| %j       | 一年中的第几天[001 ~ 366]                 |\n| %M       | 分钟数[00 ~ 59]                           |\n| %m       | 月份数[01 ~ 12]                           |\n| %p       | “上午（am）”或“下午（pm）”                |\n| %S       | 秒数[00 ~ 59]                             |\n| %w       | 一星期中的第几天[1 ~ 7 = 星期天 ~ 星期六] |\n| %x       | 日期（例如：07/30/15）                    |\n| %X       | 时间（例如：16:57:24）                    |\n| %y       | 两位数的年份[00 ~ 99]                     |\n| %Y       | 完整的年份（例如：2015）                  |\n| %%       | 字符'%'                                   |\n\n\u003e 示例代码：\n\n```Plaintext\nprint(os.date(\"today is %A, in %B\"))\nprint(os.date(\"now is %x %X\"))\n\n--\u003eoutput\ntoday is Thursday, in July\nnow is 07/30/15 17:39:22\n```\n\n  \n\n# 数学库\n\nUa 数学库由一组标准的数学函数构成。数学库的引入丰富了 Lua 编程语言的功能，同时也方便了程序的编写。常用数学函数见下表：\n\n|               asd           |                                                                                        sdfa                                                                                                      | \n| ------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| 函数名                   | 函数功能                                                                                                                                                                                     |\n| math.Rad (x)             | 角度 x 转换成弧度                                                                                                                                                                            |\n| math.Deg (x)             | 弧度 x 转换成角度                                                                                                                                                                            |\n| math.Max (x, ...)        | 返回参数中值最大的那个数，参数必须是 number 型                                                                                                                                               |\n| math.Min (x, ...)        | 返回参数中值最小的那个数，参数必须是 number 型                                                                                                                                               |\n| math. Random ([m [, n]]) | 不传入参数时，返回一个在区间[0,1)内均匀分布的伪随机实数；只使用一个整数参数 m 时，返回一个在区间[1, m]内均匀分布的伪随机整数；使用两个整数参数时，返回一个在区间[m, n]内均匀分布的伪随机整数 |\n| math. Randomseed (x)     | 为伪随机数生成器设置一个种子 x，相同的种子将会生成相同的数字序列                                                                                                                             |\n| math.Abs (x)             | 返回 x 的绝对值                                                                                                                                                                              |\n| math.Fmod (x, y)         | 返回 x 对 y 取余数                                                                                                                                                                           |\n| math.Pow (x, y)          | 返回 x 的 y 次方                                                                                                                                                                             |\n| math.Sqrt (x)            | 返回 x 的算术平方根                                                                                                                                                                          |\n| math.Exp (x)             | 返回自然数 e 的 x 次方                                                                                                                                                                       |\n| math.Log (x)             | 返回 x 的自然对数                                                                                                                                                                            |\n| math. Log 10 (x)         | 返回以 10 为底，x 的对数                                                                                                                                                                     |\n| math.Floor (x)           | 返回最大且不大于 x 的整数                                                                                                                                                                    |\n| math.Ceil (x)            | 返回最小且不小于 x 的整数                                                                                                                                                                    |\n| math. Pi                 | 圆周率                                                                                                                                                                                       |\n| math.Sin (x)             | 求弧度 x 的正弦值                                                                                                                                                                            |\n| math.Cos (x)             | 求弧度 x 的余弦值                                                                                                                                                                            |\n| math.Tan (x)             | 求弧度 x 的正切值                                                                                                                                                                            |\n| math.Asin (x)            | 求 x 的反正弦值                                                                                                                                                                              |\n| math.Acos (x)            | 求 x 的反余弦值                                                                                                                                                                              |\n| math.Atan (x)            | 求 x 的反正切值                                                                                                                                                                              |\n\n```Lua\nprint(math.pi)           --\u003eoutput  3.1415926535898\nprint(math.rad(180))     --\u003eoutput  3.1415926535898\nprint(math.deg(math.pi)) --\u003eoutput  180\n\nprint(math.sin(1))       --\u003eoutput  0.8414709848079\nprint(math.cos(math.pi)) --\u003eoutput  -1\nprint(math.tan(math.pi / 4))  --\u003eoutput  1\n\nprint(math.atan(1))      --\u003eoutput  0.78539816339745\nprint(math.asin(0))      --\u003eoutput  0\n\nprint(math.max(-1, 2, 0, 3.6, 9.1))     --\u003eoutput  9.1\nprint(math.min(-1, 2, 0, 3.6, 9.1))     --\u003eoutput  -1\n\nprint(math.fmod(10.1, 3))   --\u003eoutput  1.1\nprint(math.sqrt(360))      --\u003eoutput  18.97366596101\n\nprint(math.exp(1))         --\u003eoutput  2.718281828459\nprint(math.log(10))        --\u003eoutput  2.302585092994\nprint(math.log10(10))      --\u003eoutput  1\n\nprint(math.floor(3.1415))  --\u003eoutput  3\nprint(math.ceil(7.998))    --\u003eoutput  8\n```\n\n使用 `math.random()` 函数获得伪随机数时，如果不使用 `math.randomseed()` 设置伪随机数生成种子或者设置相同的伪随机数生成种子，那么得得到的伪随机数序列是一样的。\n\n```Lua\nmath.randomseed (100) --把种子设置为100\nprint(math.random())         --\u003eoutput  0.0012512588885159\nprint(math.random(100))      --\u003eoutput  57\nprint(math.random(100, 360)) --\u003eoutput  150\n```\n\n稍等片刻，再次运行上面的代码。\n\n```Lua\nmath.randomseed (100) --把种子设置为100\nprint(math.random())         --\u003eoutput  0.0012512588885159\nprint(math.random(100))      --\u003eoutput  57\nprint(math.random(100, 360)) --\u003eoutput  150\n```\n\n两次运行的结果一样。为了避免每次程序启动时得到的都是相同的伪随机数序列，通常是使用当前时间作为种子。\n\n\u003e 修改上例中的代码：\n\n```Lua\nmath.randomseed (os.time())   --把100换成os.time()\nprint(math.random())          --\u003eoutput 0.88369396038697\nprint(math.random(100))       --\u003eoutput 66\nprint(math.random(100, 360))  --\u003eoutput 228\n```\n\n稍等片刻，再次运行上面的代码。\n\n```Plaintext\nmath.randomseed (os.time())   --把100换成os.time()\nprint(math.random())          --\u003eoutput 0.88946195867794\nprint(math.random(100))       --\u003eoutput 68\nprint(math.random(100, 360))  --\u003eoutput 129\n```\n\n  \n\n# 文件\n\nLua I/O 库提供两种不同的方式处理文件：隐式文件描述，显式文件描述。\n\n这些文件 I/O 操作，**在 OpenResty 的上下文中对事件循环是会产生阻塞效应**。OpenResty 比较擅长的是高并发网络处理，在这个环境中，任何文件的操作，都将阻塞其他并行执行的请求。**实际中的应用，在 OpenResty 项目中应尽可能让网络处理部分、文件 I/0 操作部分相互独立，不要揉和在一起**。\n\n## **隐式文件描述**\n\n设置一个默认的输入或输出文件，然后在这个文件上进行所有的输入或输出操作。所有的操作函数由 io 表提供。\n\n\u003e 打开已经存在的 `test1.txt` 文件，并读取里面的内容\n\n```Plaintext\nfile = io.input(\"test1.txt\")    -- 使用 io.input() 函数打开文件repeat\n    line = io.read()            -- 逐行读取内容，文件结束时返回nil\n    if nil == line then\n        break\n    end\n    print(line)\nuntil (false)\n\nio.close(file)                  -- 关闭文件--\u003e output\nmy test file\nhello\nlua\n```\n\n\u003e 在 `test1.txt` 文件的最后添加一行 \"hello world\"\n\n```Plaintext\nfile = io.open(\"test1.txt\", \"a+\")   -- 使用 io.open() 函数，以添加模式打开文件\nio.output(file)                     -- 使用 io.output() 函数，设置默认输出文件\nio.write(\"\\nhello world\")           -- 使用 io.write() 函数，把内容写到文件\nio.close(file)\n```\n\n在相应目录下打开 `test1.txt` 文件，查看文件内容发生的变化。\n\n## **显式文件描述**\n\n使用 file: XXX () 函数方式进行操作, 其中 file 为 io.Open () 返回的文件句柄。\n\n\u003e 打开已经存在的 test 2. Txt 文件，并读取里面的内容\n\n```Plaintext\nfile = io.open(\"test2.txt\", \"r\")    -- 使用 io.open() 函数，以只读模式打开文件\n\nfor line in file:lines() do         -- 使用 file:lines() 函数逐行读取文件\n    print(line)\nend\n\nfile:close()\n\n--\u003eoutput\nmy test2\nhello lua\n```\n\n\u003e 在 test 2. Txt 文件的最后添加一行 \"hello world\"\n\n```Plaintext\nfile = io.open(\"test2.txt\", \"a\")  -- 使用 io.open() 函数，以添加模式打开文件\nfile:write(\"\\nhello world\")       -- 使用 file:write() 函数，在文件末尾追加内容\nfile:close()\n```\n\n在相应目录下打开 `test2.txt` 文件，查看文件内容发生的变化。\n\n## **文件操作函数**\n\n#### **io. Open (filename [, mode])**\n\n按指定的模式 mode，打开一个文件名为 `filename` 的文件，成功则返回文件句柄，失败则返回 nil 加错误信息。模式：\n\n|      |                                                |                     | \n| ---- | ---------------------------------------------- | ------------------- |\n| 模式 | 含义                                           | 文件不存在时        |\n| \"r\"  | 读模式 (默认)                                  | 返回 nil 加错误信息 |\n| \"w\"  | 写模式                                         | 创建文件            |\n| \"a\"  | 添加模式                                       | 创建文件            |\n| \"r+\" | 更新模式，保存之前的数据                       | 返回 nil 加错误信息 |\n| \"w+\" | 更新模式，清除之前的数据                       | 创建文件            |\n| \"a+\" | 添加更新模式，保存之前的数据, 在文件尾进行添加 | 创建文件            |\n\n模式字符串后面可以有一个 'b'，用于在某些系统中打开二进制文件。\n\n注意 \"w\" 和 \"wb\" 的区别\n\n- \"w\" 表示文本文件。某些文件系统 (如 Linux 的文件系统)认为 0 x 0 A 为文本文件的换行符，Windows 的文件系统认为 0 x 0 D 0 A 为文本文件的换行符。为了兼容其他文件系统（如从 Linux 拷贝来的文件），Windows 的文件系统在写文件时，会在文件中 0 x 0 A 的前面加上 0 x 0 D。使用 \"w\"，其属性要看所在的平台。\n    \n- \"wb\" 表示二进制文件。文件系统会按纯粹的二进制格式进行写操作，因此也就不存在格式转换的问题。（Linux 文件系统下 \"w\" 和 \"wb\" 没有区别）\n    \n\n#### **file: close ()**\n\n关闭文件。注意：当文件句柄被垃圾收集后，文件将自动关闭。句柄将变为一个不可预知的值。\n\n#### **io. Close ([file])**\n\n关闭文件，和 file: close () 的作用相同。没有参数 file 时，关闭默认输出文件。\n\n#### **file: flush ()**\n\n把写入缓冲区的所有数据写入到文件 file 中。\n\n#### **io. Flush ()**\n\n相当于 file: flush ()，把写入缓冲区的所有数据写入到默认输出文件。\n\n#### **io. Input ([file])**\n\n当使用一个文件名调用时，打开这个文件（以文本模式），并设置文件句柄为默认输入文件；当使用一个文件句柄调用时，设置此文件句柄为默认输入文件；当不使用参数调用时，返回默认输入文件句柄。\n\n#### **file: lines ()**\n\n返回一个迭代函数, 每次调用将获得文件中的一行内容, 当到文件尾时，将返回 nil，但不关闭文件。\n\n#### **io. Lines ([filename])**\n\n打开指定的文件 filename 为读模式并返回一个迭代函数, 每次调用将获得文件中的一行内容, 当到文件尾时，将返回 nil，并自动关闭文件。若不带参数时 io.Lines () 等价于 io.Input (): lines () 读取默认输入设备的内容，结束时不关闭文件。\n\n#### **io. Output ([file])**\n\n类似于 io. Input，但操作在默认输出文件上。\n\n#### **file: read (...)**\n\n按指定的格式读取一个文件。按每个格式将返回一个字符串或数字, 如果不能正确读取将返回 nil，若没有指定格式将指默认按行方式进行读取。格式：\n\n|        |                                                                                                        |\n| ------ | ------------------------------------------------------------------------------------------------------ |\n| 格式   | 含义                                                                                                   |\n| \"*n\"   | 读取一个数字                                                                                           |\n| \"*a\"   | 从当前位置读取整个文件。若当前位置为文件尾，则返回空字符串                                             |\n| \"*l\"   | 读取下一行的内容。若为文件尾，则返回 nil。(默认)                                                       |\n| number | 读取指定字节数的字符。若为文件尾，则返回 nil。如果 number 为 0, 则返回空字符串，若为文件尾, 则返回 nil |\n\n#### **io. Read (...)**\n\n相当于 io.Input ():read\n\n#### **io. Type (obj)**\n\n检测 obj 是否一个可用的文件句柄。如果 obj 是一个打开的文件句柄，则返回 \"file\" 如果 obj 是一个已关闭的文件句柄，则返回 \"closed file\" 如果 obj 不是一个文件句柄，则返回 nil。\n\n#### **file: write (...)**\n\n把每一个参数的值写入文件。参数必须为字符串或数字，若要输出其它值，则需通过 tostring 或 string. Format 进行转换。\n\n#### **io. Write (...)**\n\n相当于 io.Output (): write。\n\n#### **file: seek ([whence] [, offset])**\n\n设置和获取当前文件位置，成功则返回最终的文件位置 (按字节，相对于文件开头), 失败则返回 nil 加错误信息。缺省时，whence 默认为 \"cur\"，offset 默认为 0 。参数 whence：\n\n|        |                     |\n| ------ | ------------------- |\n| whence | 含义                |\n| \"set\"  | 文件开始            |\n| \"cur\"  | 文件当前位置 (默认) |\n| \"end\"  | 文件结束            |\n\n#### **file: setvbuf (mode [, size])**\n\n设置输出文件的缓冲模式。模式：\n\n|        |                                                              |\n| ------ | ------------------------------------------------------------ |\n| 模式   | 含义                                                         |\n| \"no\"   | 没有缓冲，即直接输出                                         |\n| \"full\" | 全缓冲，即当缓冲满后才进行输出操作 (也可调用 flush 马上输出) |\n| \"line\" | 以行为单位，进行输出                                         |\n\n最后两种模式，size 可以指定缓冲的大小（按字节），忽略 size 将自动调整为最佳的大小。","lastmodified":"2023-08-02T03:10:42.044088141Z","tags":["lua"]},"/netty/%E4%BC%A0%E8%BE%93%E5%92%8CChannel":{"title":"传输和Channel","content":"在某些时候，你需要支撑比预期多很多的并发连接。如果你随后尝试从阻塞传输切换到非阻塞传输，那么你可能会因为这两种网络 API 的截然不同而遇到问题。\n\n**Netty 为它所有的传输实现提供了一个通用 API，这使得这种转换比你直接使用 JDK 所能够达到的简单得多。**\n\n# 传输方式\n\n- OIO\n    \n- NIO\n    \n- AIO\n    \n\n  \n\n# Channel\n\n传输 API 的核心是 interface Channel，它被用于所有的 I/O 操作\n\n![](statistic/asynccode-670.png)\n\n- 每个 Channel 都将会被分配一个 ChannelPipeline 和 ChannelConfig。\n    \n    - ChannelConfig 包含了该 Channel 的所有配置设置，并且支持热更新。由于特定的传输可能 具有独特的设置，所以它可能会实现一个 ChannelConfig 的子类型。\n        \n- 由于 Channel 是独一无二的，所以为了保证顺序将 Channel 声明为 java.lang.Comparable 的一个子接口\n    \n- ChannelPipeline **持有所有将应用于入站和出站数据以及事件的 ChannelHandler实例**，这些 ChannelHandler 实现了应用程序用于处理状态变化以及数据处理的逻辑\n    \n    - ChannelHandler 的典型用途包括：\n        \n        -  将数据从一种格式转换为另一种格式；\n            \n        -  提供异常的通知；\n            \n        -  提供 Channel 变为活动的或者非活动的通知；\n            \n        -  提供当 Channel 注册到 EventLoop 或者从 EventLoop 注销时的通知；\n            \n        -  提供有关用户自定义事件的通知。\n            \n- 也可以利用 Channel 的其他方法\n    \n\n![](statistic/asynccode-668.png)\n\nNetty 的 **Channel 实现是线程安全的.**\n\n# NIO\n\n  \n\nNIO 提供了一个所有 I/O 操作的全异步的实现。\n\n选择器背后的基本概念是充当一个注册表，在那里你将可以请求在 Channel 的状态发生变化时得到通知。可能的状态变化有：\n\n-  新的 Channel 已被接受并且就绪；\n    \n-  Channel 连接已经完成；\n    \n-  Channel 有已经就绪的可供读取的数据；\n    \n-  Channel 可用于写数据。\n    \n\n**选择器运行在一个检查状态变化并对其做出相应响应的线程上，在应用程序对状态的改变做出响应之后，选择器将会被重置**，并将重复这个过程\n\n的常量值代表了由class java.nio.channels.SelectionKey定义的位模式。这些位模式可以组合起来定义一组应用程序正在请求通知的状态变化集。\n\n![](statistic/asynccode-669.png)\n\n![](statistic/asynccode-667.png)\n\n# 零拷贝\n\n零拷贝（zero-copy）是一种目前只有在使用 NIO 和 Epoll 传输时才可使用的特性**。它使你可以快速 高效地将数据从文件系统移动到网络接口，而不需要将其从内核空间复制到用户空间，**其在像 FTP 或者 HTTP 这样的协议中可以显著地提升性能。但是，并不是所有的操作系统都支持这一特性。特别地，它对于实现了数据加密或者压缩的文件系统是不可用的——只能传输文件的原始内容。","lastmodified":"2023-08-02T03:10:42.044088141Z","tags":[]},"/netty/%E6%A6%82%E5%BF%B5%E5%92%8C%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84":{"title":"概念和体系结构","content":"# IO 模型\n\n[IO模型详解](https://jovbd87bon.feishu.cn/wiki/wikcnlmBPltNAH5jI0rrD6bpNWf)\n\n  \n\n  \n\n# Java 网络编程\n\n最早期的 Java API（java.net）只支持由本地系统套接字库提供的所谓的阻塞函数\n\n```Java\n//  创建一个新的 ServerSocket，用以 监听指定端口上的连接请求\nServerSocket serverSocket = new ServerSocket(portNumber); \n// 对accept 阻塞，知道创建一个\nSocket clientSocket = serverSocket.accept(); \nBufferedReader in = new BufferedReader(new InputStreamReader(clientSocket.getInputStream())); \nPrintWriter out = new PrintWriter(clientSocket.getOutputStream(), true); \nString request, response; \nwhile ((request = in.readLine()) != null) { \n    if (\"Done\".equals(request)) { \n        break; \n    } \n    response = processRequest(request); \n    out.println(response); \n} \n```\n\n  \n\n# Java Nio\n\n本地套接字库很早就提供了非阻塞调用， 其为网络资源的利用率提供了相当多的控制：\n\n- 可以使用 setsockopt()方法配置套接字，以便读/写调用在没有数据的时候立即返回， 也就是说，如果是一个阻塞调用应该已经被阻塞了① ；\n    \n- 可以使用操作系统的事件通知 API②注册一组非阻塞套接字，以确定它们中是否有任何的套接字已经有数据可供读写。\n    \n\nJava 对于非阻塞 I/O 的支持是在 2002 年引入的，位于 JDK 1.4 的 java.nio 包中\n\n  \n\n## 选择器\n\n![](statistic/asynccode-657.png)\n\nclass java.nio.channels.Selector 是 Java 的非阻塞 I/O 实现的关键。它使用了事件通知 API\n\n以确定在一组非阻塞套接字中有哪些已经就绪能够进 行 I/O 相关的操作。**因为可以在任何的时间检查任意**\n\n**的读操作或者写操作的完成状态，一个单一的线程便可以处理多个并发的连接。**\n\n与阻塞 I/O 模型相比，这种模型提供了更好的资源管理：\n\n- 使用较少的线程便可以处理许多连接，因此也减少了内存管理和上下文切换所带来开销；\n    \n- 当没有 I/O 操作需要处理的时候，线程也可以被用于其他任务。\n    \n\n  \n\n# Netty\n\n在网络编程领域，Netty是Java的卓越框架。 它驾驭了Java高级API的能力，并将其隐藏在一个易于使用的API之后。\n\nNetty 的关键特性\n\n![](statistic/asynccode-665.png)\n\n## Netty 的主要构件块\n\n- Channel；\n    \n- 回调；\n    \n- Future；\n    \n- 事件和 ChannelHandler。\n    \n\n这些构建块代表了不同类型的构造：资源、逻辑以及通知\n\n  \n\n### Channel\n\nChannel 是 Java NIO 的一个基本构造。\n\n\u003e 它代表一个到实体（如一个硬件设备、一个文件、一个网络套接字或者一个能够执行一个或者多个不同的I/O操作的程序组件）的开放连接，如读操作和写操作 ①\n\n**把 Channel 看作是传入（入站）或者传出（出站）数据的载体。因此，它可以被打开或者被关闭，连接或者断开连接。**\n\n### 回调\n\n一个回调其实就是一个方法，**一个指向已经被提供给另外一个方法的方法的引用**。\n\nNetty 在内部使用了回调来处理事件；当一个回调被触发时，相关的事件可以被一个 interface ChannelHandler 的实现处理。\n\n![](statistic/asynccode-663.png)\n\n当一个新的连接已经被建立时，ChannelHandler 的 channelActive()回调方法将会被调用，并将打印出一条信息。\n\n  \n\n### Future\n\nFuture 提供了另一种在操作完成时通知应用程序的方式。这个对象可以看作是一个异步操作的结果的占位符；它将在未来的某个时刻完成，并提供对其结果的访问\n\n- JDK 预置了 interface java.util.concurrent.Future，但是其所提供的实现，只 允许手动检查对应的操作是否已经完成，或者一直阻塞直到它完成。这是非常繁琐的，\n    \n- 所以 Netty 提供了它自己的实现——ChannelFuture，用于在执行异步操作的时候使用\n    \n\n  \n\n- ChannelFuture提供了几种额外的方法，这些方法使得我们能够注册一个或者多个 ChannelFutureListener实例。监听器的回调方法operationComplete()，将会在对应的操作完成时被调用\n    \n- 每个 Netty 的出站 I/O 操作都将返回一个 ChannelFuture；也就是说，它们都不会阻塞。正如我们前面所提到过的一样，Netty 完全是异步和事件驱动的\n    \n\n![](statistic/asynccode-656.png)\n\n  \n\nChannel 回调的用法\n\n![](statistic/asynccode-662.png)\n\n### 事件和ChannelHandler\n\nNetty 使用不同的事件来通知我们状态的改变或者是操作的状态。这使得我们能够基于已经 =发生的事件来触发适当的动作。\n\nNetty 是一个网络编程框架，所以事件是按照它们与入站或出站数据流的相关性进行分类的。\n\n  \n\n可能由**入站**数据或者相关的状态更改而触发的事件包括：\n\n-  连接已被激活或者连接失活；\n    \n-  数据读取；\n    \n-  用户事件；\n    \n-  错误事件。\n    \n\n**出站事件**是未来将会触发的某个动作的操作结果，这些动作包括：\n\n-  打开或者关闭到远程节点的连接；\n    \n-  将数据写到或者冲刷到套接字。\n    \n\n每个事件都可以被分发给 ChannelHandler 类中的某个用户实现的方法。这是一个很好的将事件驱动范式直接转换为应用程序构件块的例子。\n\n![](statistic/asynccode-664.png)\n\n  \n\n## Netty 的组件和设计\n\n- 首先，它的基于 Java NIO 的异步的和事件驱动的实现，保证了高负载下应用程序 性能的最大化和可伸缩性。\n    \n- 其次，Netty 也包含了一组设计模式，将应用程序逻辑从网络层解耦，简化了开发过程，同时也最大限度地提高了可测试性、模块化以及代码的可重用性。\n    \n\n### Channel\n\nNetty 的 Channel 接 口所提供的 API，大大地降低了直接使用 Socket 类的复杂性。其基本的构造是 class Socket。\n\nChannel 也是拥有许多 预定义的、专门化实现的广泛类层次结构的根，下面是一个简短的部分清单：\n\n- EmbeddedChannel；\n    \n- LocalServerChannel；\n    \n- NioDatagramChannel；\n    \n- NioSctpChannel；\n    \n- NioSocketChannel。\n    \n\n### EventLoop\n\nEventLoop 定义了 Netty 的核心抽象，用于处理连接的生命周期中所发生的事件\n\n![](statistic/asynccode-659.png)\n\nChannel、EventLoop、Thread 以及 EventLoopGroup 之间的关系\n\n- 一个 EventLoopGroup 包含一个或者多个 EventLoop；\n    \n- 一个 EventLoop 在它的生命周期内只和一个 Thread 绑定；\n    \n- 所有由 EventLoop 处理的 I/O 事件都将在它专有的 Thread 上被处理；\n    \n- 一个 Channel 在它的生命周期内只注册于一个 EventLoop；\n    \n- 一个 EventLoop 可能会被分配给一个或多个 Channel。\n    \n\n### ChannelFuture\n\n- Netty 中所有的 I/O 操作都是异步的。因为一个操作可能不会立即返回，所以我们需要一种用于在之后的某个时间点确定其结果的方法。\n    \n- Netty 提供了 ChannelFuture 接口，其 addListener()方法注册了一个 ChannelFutureListener，以便在某个操作完成时（无论是否成功）得到通知。\n    \n\n### ChannelHandler\n\n- 从应用程序开发人员的角度来看，Netty 的主要组件是 ChannelHandler，它充当了所有处理入站和出站数据的应用程序逻辑的容器\n    \n- 事实上，ChannelHandler 可专 门用于几乎任何类型的动作，例如将数据从一种格式转换为另外一种格式，或者处理转换过程中所抛出的异常。\n    \n\n### ChannaelPipeline\n\n- ChannelPipeline 提供了 ChannelHandler 链的容器，并**定义了用于在该链上传播入站和出站事件**流的 API\n    \n- 当 Channel 被创建时，它会被自动地分配到它专属的 ChannelPipeline。\n    \n- ChannelHandler 安装到 ChannelPipeline 中的过程如下所示\n    \n    - 一个ChannelInitializer的实现被注册到了ServerBootstrap中 ① ；\n        \n    - 当 ChannelInitializer.initChannel()方法被调用时，ChannelInitializer将在 ChannelPipeline 中安装一组自定义的 ChannelHandler；\n        \n    - ChannelInitializer **将它自己从 ChannelPipeline 中移除**。\n        \n\n  \n\n从 ChannelHandler 派生的 ChannelInboundHandler 和 ChannelOutboundHandler 接口\n\n![](statistic/asynccode-661.png)\n\n  \n\n- 上面的接口使得事件流经 ChannelPipeline 是 ChannelHandler 的工作，它们是在应用程序的**初始化或者引导阶段被安装的**。\n    \n- 这些对象接收事件、执行它们所实现的处理逻辑，并将数据传递给链中的下一个 ChannelHandler。\n    \n\n![](statistic/asynccode-658.png)\n\n- 它们的执行顺序是由它们被添加的顺序所决定的。实际上，被我们称为 ChannelPipeline 的是这些 ChannelHandler 的编排顺序\n    \n- 虽然 ChannelInboundHandle 和 ChannelOutboundHandle 都扩展自 ChannelHandler，但是 Netty 能区分 ChannelInboundHandler 实现和 ChannelOutboundHandler 实现，并确保数据只会在具有相同定向类型的两个 ChannelHandler 之间传递。\n    \n- 在 Netty 中，有**两种发送消息的方式。**\n    \n    - 你可以**直接写到 Channel** 中，会导致消息**从Channe-lPipeline 的尾端开始流动**\n        \n    - 也可以写到和 ChannelHandler相关联的**ChannelHandlerContext对象**中将导致消息从 **ChannelPipeline 中的下一个 ChannelHandler 开始流动。**\n        \n\n  \n\n#### 适配器\n\nNetty 以适配器类的形式提供了大量默认的 ChannelHandler 实现，\n\n- 其旨在简化应用程序处理逻辑的开发过程。\n    \n- 你已经看到了，ChannelPipeline中的每个ChannelHandler 将负责把事件转发到链中的下一个 ChannelHandler。这些适配器类（及它们的子类）将自动 执行这个操作，所以你可以只重写那些你想要特殊处理的方法和事件。\n    \n- 常用的适配器\n    \n    -  ChannelHandlerAdapter\n        \n    -  ChannelInboundHandlerAdapter\n        \n    -  ChannelOutboundHandlerAdapter\n        \n    -  ChannelDuplexHandler\n        \n\n  \n\n#### 编解码器\n\n- 通常来说，这些基类的名称将类似于 ByteToMessageDecoder 或 MessageToByteEncoder。\n    \n- 对于特殊的类型，你可能会发现类似于 ProtobufEncoder 和 ProtobufDecoder 这样的名称——预置的用来支持 Google 的 Protocol Buffers。\n    \n- 严格地说，其他的处理器也可以完成编码器和解码器的功能。但是，正如有用来简化ChannelHandler 的创建的适配器类一样，所有由 Netty 提供的编码器/解码器适配器类都实现 ChannelOutboundHandler 或者 ChannelInboundHandler 接口。\n    \n\n  \n\n#### SimpleChannelInboundHandler\n\n- 最常见的情况是，你的应用程序会利用一个 ChannelHandler 来接收解码消息，并对该数据应用业务逻辑。\n    \n- 要创建一个这样的 ChannelHandler,你只需要扩展基类 `SimpleChannelInboundHandler\u003cT\u003e`，其中 T 是你要处理的消息的 Java 类型 。\n    \n    - 在这种类型的 ChannelHandler 中，最重要的方法是 channelRead0(ChannelHandlerContext,T)**。除了要求不要阻塞当前的 I/O 线程之外**，其具体实现完全取决于你\n        \n\n### BootStrap\n\nNetty 的引导类为应用程序的网络层配置提供了容器，\n\n- 这涉及将一个进程绑定到某个指定的端口，ServerBootStrap\n    \n- 或者将一个进程连接到另一个运行在某个指定主机的指定端口上的进程,BootStrap\n    \n\n![](statistic/asynccode-660.png)\n\n引导一个客户端只需要一个 EventLoopGroup，但是一个ServerBootstrap 则需要两个（也可以是同一个实例）。为什么呢？\n\n因为服务器需要两组不同的 Channel。\n\n- 第一组将只包含一个 ServerChannel，代表服务器自身的已绑定到某个本地端口的正在监听的套接字。\n    \n- 而第二组将包含所有已创建的用来处理传 入客户端连接（**对于每个服务器已经接受的连接都有一个**）的 Channel。\n    \n\n![](statistic/asynccode-666.png)","lastmodified":"2023-08-02T03:10:42.044088141Z","tags":[]},"/netty/%E7%BC%96%E8%A7%A3%E7%A0%81%E5%99%A8":{"title":"编解码器","content":"每个网络应用程序都必须定义如何解析在\n\n- **两个节点之间来回传输的原始字节**\n    \n- **其和 目标应用程序的数据格式做相互转换**\n    \n\n  \n\n- 编码器是将消息转换为适合于传输的格式（最有可能的就是字节流）；\n    \n- 而对应的解码器则是将网络字节流转换回应用程序的消息格式\n    \n\n  \n\n# 解码器\n\n因为解码器是负责将入站数据从一种格式转换到另一种格式的，所以知道 Netty 的解码器实现了 **ChannelInboundHandler** 也不会让你感到意外。\n\n我们将研究 Netty 所提供的解码器类，并提供关于何时以及如何使用它们的具 体示例。这些类覆盖了两个不同的用例：\n\n- 将字节解码为消息——**ByteToMessageDecoder 和 ReplayingDecoder；**\n    \n- 将一种消息类型解码为另一种——**MessageToMessageDecoder**\n    \n\n  \n\n## ByteToMessageDecoder\n\n将字节解码为消息（或者另一个字节序列）是一项如此常见的任务，以至于 Netty 为它提供了一个抽象的基类：ByteToMessageDecoder\n\n![](statistic/asynccode-750.png)\n\n![](statistic/asynccode-745.png)\n\n![](statistic/asynccode-748.png)\n\n虽然 ByteToMessageDecoder 使得可以很简单地实现这种模式，但是你可能会发现，**在调用 readInt()方法前不得不验证所输入的 ByteBuf 是否具有足够的数据有点繁琐**。在下一节中，\n\n我们将讨论 ReplayingDecoder，它是一个特殊的解码器，以少量的开销消除了这个步骤\n\n  \n\n## ReplayingDecoder\n\nReplayingDecoder扩展了ByteToMessageDecoder类（如代码清单 10-1 所示），使得我们不必调用 readableBytes()方法，它通过使用一个自定义的ByteBuf实现 ，\n\nReplayingDecoderByteBuf，包装传入的ByteBuf实现了这一点，其将在内部执行该调用\n\n![](statistic/asynccode-750.png)\n\n- ByteBuf中提取的int将会被添加到List中。**如果没有足够的字节可用，这个readInt()方法的实现将会抛出一个Error**\n    \n- 并不是所有的 ByteBuf 操作都被支持，如果调用了一个不被支持的方法，将会抛出一个 UnsupportedOperationException；\n    \n- ReplayingDecoder 稍慢于 ByteToMessageDecoder。\n    \n\n  \n\n## MessageToMessageDecoder\n\n```Go\npublic abstract class MessageToMessageDecoder\u003cI\u003e extends ChannelInboundHandlerAdapter\n```\n\n![](statistic/asynccode-750.png)\n\n  \n\n![](statistic/asynccode-745.png)\n\n![](statistic/asynccode-745.png)\n\n## TooLongFrameException 类\n\n由于 Netty 是一个异步框架，所以需要在字节可以解码之前在内存中缓冲它们。因此，不能让解码器缓冲大量的数据以至于耗尽可用的内存.Netty 提供了TooLongFrameException 类，其将由解码器在帧超出指定的大小限制时抛出。\n\nByteToMessageDecoder 是如何使用 TooLongFrameException 来通知 ChannelPipeline 中的其他 ChannelHandler 发生了帧大小溢出的。\n\n![](statistic/asynccode-745.png)\n\n  \n\n# 编码器\n\n编码器实现了 ChannelOutboundHandler，并将出站数据从一种格式转换为另一种格式，\n\n-  将消息编码为字节；\n    \n-  将消息编码为消息 ①\n    \n\n我们将首先从抽象基类 MessageToByteEncoder 开始来对这些类进行考察。\n\n## MessageToByteEncoder\n\n使 用 MessageToByteEncoder 将消息转化为字节\n\n![](statistic/asynccode-744.png)\n\n![](statistic/asynccode-745.png)\n\n![](statistic/asynccode-743.png)\n\n## MessageToMessageEncoder\n\n数据将如何从一种消息编码为另一种\n\n![](statistic/asynccode-745.png)\n\n![](statistic/asynccode-745.png)\n\n![](statistic/asynccode-726.png)\n\n  \n\n  \n\n# 抽象的编解码\n\n们一直将解码器和编码器作为单独的实体讨论，但是你有时将会发现在同一个类中管理入站和出站数据和消息的转换是很有用的。\n\n这些类同时实现了 ChannelInboundHandler 和 ChannelOutboundHandler 接口。\n\n  \n\n## ByteToMessageCodec\n\n![](statistic/asynccode-728.png)\n\n## MessageToMessageCodec\n\n![](statistic/asynccode-727.png)\n\n## CombinedChannelDuplexHandler\n\n结合一个解码器和编码器可能会对可重用性造成影响。但是，有一 种方法既能够避免这种惩罚，又不会牺牲将一个解码器和一个编码器作为一个单独的单元部署所带来的便利性。CombinedChannelDuplexHandler 提供了这个解决方案\n\n```Go\npublic class CombinedChannelDuplexHandler \u003cI extends ChannelInboundHandler, O extends ChannelOutboundHandler\u003e\n```\n\n这个类充当了 ChannelInboundHandler 和 ChannelOutboundHandler（该类的类型 参数 I 和 O）的容器。\n\n通过提供分别继承了解码器类和编码器类的类型，我们可以实现一个编解码器，**而又不必直接扩展抽象的编解码器类**\n\n![](statistic/asynccode-745.png)\n\n![](statistic/asynccode-745.png)\n\n![](statistic/asynccode-745.png)","lastmodified":"2023-08-02T03:10:42.044088141Z","tags":[]},"/netty/BootStrap":{"title":"BootStrap","content":"\n简单来说，**引导一个应用程序是指对它进行配置，并使它运行起来的过程**—尽管该过程的具体细节可能并不如它的定义那样简单，尤其是对于一个网络应用程序来说\n\n  \n\nNetty处理引导的方式**使你的应用程序和网络层相隔离**，无论它是客户端还是服务器\n\n  \n\n# BootStrap类\n\n引导类的层次结构包括一个抽象的父类和两个具体的引导子类\n\n![](statistic/asynccode-699.png)\n\n相对于将具体的引导类分别看作用于服务器和客户端的引导来说，记住它们的本意是用来支撑不同的应用程序的功能的将有所裨益。\n\n- 服务器致力于使用一个父 Channel 来接受来自客户端的连接，并创建子 Channel 以用于它们之间的通信\n    \n- 而客户端将最可能只需要一个单独的、没有父 Channel 的 Channel 来用于所有的网络交互\n    \n\n  \n\n两种应用程序类型之间通用的引导步骤由 AbstractBootstrap 处理，而特定于客户端或者服务器的引导步骤则分别由 Bootstrap 或 ServerBootstrap 处理\n\n  \n\nAbstractBootstrap 类的完整声明是：\n\n```Go\npublic abstract class AbstractBootstrap \u003cB extends AbstractBootstrap\u003cB,C\u003e,C extends Channel\u003e\n```\n\n在这个签名中，子类型 B 是其父类型的一个类型参数，**因此可以返回到运行时实例的引用以支持方法的链式调用**\n\n其子类的声明如下：\n\n```Go\npublic class Bootstrap extends AbstractBootstrap\u003cBootstrap,Channel\u003e\n\npublic class ServerBootstrap extends AbstractBootstrap\u003cServerBootstrap,ServerChannel\u003e\n```\n\n  \n\n# 引导客户端和无连接协议\n\n**Bootstrap 类被用于客户端或者使用了无连接协议的应用程序中**\n\n![](statistic/asynccode-732.png)\n\n![](statistic/asynccode-708.png)\n\n## BootStrap\n\nBootstrap 类负责为客户端和使用无连接协议的应用程序创建 Channel\n\n![](statistic/asynccode-709.png)\n\n![](statistic/asynccode-734.png)\n\n![](statistic/asynccode-703.png)\n\n## Channel 和 EventLoopGroup 的兼容性\n\n你可以从包名以及与其相对应 的类名的前缀看到，对于 NIO 以及 OIO 传输两者来说，都有相关的 EventLoopGroup 和Channel 实现。\n\n![](statistic/asynccode-733.png)\n\n不能混用具有不同前缀的组件，如 NioEventLoopGroup 和 OioSocketChannel，会导致 IllegalStateException，\n\n![](statistic/asynccode-710.png)\n\n# 引导服务端\n\n  \n\n## ServerBootStrap\n\n  \n\n![](statistic/asynccode-702.png)\n\n列出了一些bootStrap不存在的方法：childHandler()、 childAttr()和 childOption()。这些调用支持特别用于服务器应用程序的操作。具体来说， **ServerChannel 的实现负责创建子 Channel，这些子 Channel 代表了已被接受的连接。**负责引导 ServerChannel 的 ServerBootstrap 提供了这些方法，以简化将设置应用到已被接受的子 Channel 的 ChannelConfig 的任务\n\n- ServerBootstrap 在 bind()方法被调用时创建了一个 ServerChannel， 且该 ServerChannel 管理了多个子 Channel。\n    \n\n![](statistic/asynccode-704.png)\n\n![](statistic/asynccode-700.png)\n\n  \n\n# 从Channel引导客户端\n\n我们都在引导的过程中调用了 handler()或者 childHandler()方法来添加单个的 ChannelHandler。\n\n通过在 ChannelPipeline 中将它们链接在一起来部署尽可能多的 ChannelHandler。\n\n![](statistic/asynccode-707.png)\n\n![](statistic/asynccode-706.png)\n\n  \n\n# 使用Netty的ChannelOption属性\n\n可以使用 option()方法来将 ChannelOption 应用到引\n\n在某些常用的属性和数据不可用时，Netty 提供了 AttributeMap 抽象（一个由 Channel 和引导类提供的集合）以及 `AttributeKey\u003cT\u003e`（一 个用于插入和获取属性值的泛型类）。\n\n使用这些工具，便可以安全地将任何类型的数据项与客户端和服务器 Channel（包含 ServerChannel 的子 Channel）相关联了。\n\n![](statistic/asynccode-705.png)\n\n# 引导DataGramChannel\n\nNetty 提供了各种 DatagramChannel 的实现。唯一区别就是，**不再调用 connect()方法，而是只调用 bind()方法**\n\n![](statistic/asynccode-701.png)\n\n# 关闭\n\n- 引导使你的应用程序启动并且运行起来，但是迟早你都需要优雅地将它关闭\n    \n- 最重要的是，你需要关闭 EventLoopGroup，它将处理任何挂起的事件和任务，并且随后释放所有活动的线程。\n    \n- 这就是调用 EventLoopGroup.shutdownGracefully()方法的作用。\n    \n\n![](statistic/asynccode-729.png)","lastmodified":"2023-08-02T03:10:42.044088141Z","tags":[]},"/netty/ByteBuf":{"title":"ByteBuf","content":"网络数据的基本单位总是字节。Java NIO 提供了 ByteBuffer 作为它的字节容器，但是这个类使用起来过于复杂，而且也有些繁琐。\n\nNetty 的 ByteBuffer 替代品是 ByteBuf，一个强大的实现，既解决了 JDK API 的局限性，又为网络应用程序的开发者提供了更好的 API。\n\n# ByteBuf 的优点\n\nNetty 的数据处理 API 通过两个组件暴露——abstract class ByteBuf 和 interface ByteBufHolder。\n\n下面是一些 ByteBuf API 的优点：\n\n 它可以被用户自定义的缓冲区类型扩展；\n\n 通过内置的复合缓冲区类型实现了透明的零拷贝；\n\n 容量可以按需增长（类似于 JDK 的 StringBuilder）；\n\n 在读和写这两种模式之间切换不需要调用 ByteBuffer 的 flip()方法；\n\n 读和写使用了不同的索引；\n\n 支持方法的链式调用；\n\n# ByteBuf 如何工作\n\n**ByteBuf 维护了两个不同的索引：一个用于读取，一个用于写入**。当你从 ByteBuf 读取时， 它的 readerIndex 将会被递增已经被读取的字节数。同样地，当你写入 ByteBuf 时，它的 writerIndex 也会被递增。\n\n![](statistic/asynccode-671.png)\n\nreaderIndex 达到 和 writerIndex 同样的值时, 试图读取超出该点的数据将会触发一个 IndexOutOfBoundsException。\n\n  \n\n# ByteBuf 的使用模式\n\n## 堆缓冲区\n\n最常用的 ByteBuf 模式是将数据存储在 **JVM 的堆空间**中，这种模式被称为**支撑数组** （backing array），它能在**没有使用池化的情况下提供快速的分配和释放**\n\n![](statistic/asynccode-673.png)\n\n## 直接缓冲区\n\nNIO 在 JDK 1.4 中引入的 ByteBuffer 类允许 JVM 实现通过本地调 用来分配内存。这主要是为了避**免在每次调用本地 I/O 操作之前（或者之后）将缓冲区的内容复 制到一个中间缓冲区（或者从中间缓冲区把内容复制到缓冲区）。**\n\n直接缓冲区的主要缺点是，相对于基于堆的缓冲区，**它们的分配和释放都较为昂贵。**\n\n![](statistic/asynccode-679.png)\n\n## 符合缓冲区\n\n它为**多个 ByteBuf 提供一个聚合视图。**在这里你可以根据需要添加或者删除 ByteBuf 实例，这是一个 JDK 的 ByteBuffer 实现完全缺失的特性。\n\nNetty 通过一个 ByteBuf 子类——**CompositeByteBuf——实现了这个模式**，它提供了一个将多个**缓冲区表示为单个合并缓冲区的虚拟表示**。\n\n为了举例说明，让我们考虑一下一个由两部分——头部和主体——组成的将通过 HTTP 协议 传输的消息。**这两部分由应用程序的不同模块产生，将会在消息被发送的时候组装**。该应用程序 可以选择为多个消息重用相同的消息主体。当这种情况发生时，对于每个消息都将会创建一个新的头部。\n\n![](statistic/asynccode-683.png)\n\n- 使用ByteBuffer 的符合缓冲区模式\n    \n\n![](statistic/asynccode-684.png)\n\n- 使用 **CompositeByteBuf** 的复合缓冲区模式\n    \n\n![](statistic/asynccode-684.png)\n\n- 访问 **CompositeByteBuf** 中的数据\n    \n\n![](statistic/asynccode-687.png)\n\n  \n\n# 字节级操作\n\n## 随机访问索引\n\n![](statistic/asynccode-672.png)\n\n那些需要一个索引值参数的方法（的其中）之一来访问数据既不会改变readerIndex 也不会改变 writerIndex。\n\n  \n\n## 顺序访问索引\n\n虽然 ByteBuf 同时具有读索引和写索引，\n\n![](statistic/asynccode-677.png)\n\n## 可丢弃字节\n\n记为可丢弃字节的分段包含了已经被读过的字节。通过调用 discardReadBytes()方法，可以丢弃它们并回收空间\n\n  \n\n## 可读字节\n\nByteBuf 的可读字节分段存储了实际数据。新分配的、包装的或者复制的缓冲区的默认的\n\nreaderIndex 值为 0。任何名称以 read 或者 skip 开头的操作都将检索或者跳过位于当前\n\nreaderIndex 的数据，并且将它增加已读字节数。\n\n  \n\n## 可写字节\n\n可写字节分段是指一个拥有未定义内容的、写入就绪的内存区域。新分配的缓冲区的 writerIndex 的默认值为 0。任何名称以 write 开头的操作都将从当前的 writerIndex 处 开始写数据，并将它增加已经写入的字节数。如果写操作的目标也是 ByteBuf，并且没有指定源索引的值，则源缓冲区的 readerIndex 也同样会被增加相同的大小。这个调用如下所示：\n\nwriteBytes(ByteBuf dest);\n\n  \n\n## 读写操作\n\n正如我们所提到过的，有两种类别的读/写操作：\n\n get()和 set()操作，从给定的索引开始，并且保持索引不变；\n\n read()和 write()操作，从给定的索引开始，并且会根据已经访问过的字节数对索\n\n引进行调整\n\n![](statistic/asynccode-685.png)\n\n![](statistic/asynccode-675.png)\n\n![](statistic/asynccode-680.png)\n\n![](statistic/asynccode-686.png)\n\n## 其他操作\n\n![](statistic/asynccode-674.png)\n\n![](statistic/asynccode-681.png)\n\n  \n\n# ByteBufHolder\n\n- 除了实际的数据负载之外，我们还需要**存储各种属性值**。 为了处理这种常见的用例，Netty 提供了 ByteBufHolder\n    \n- ByteBufHolder 也为 Netty 的 高级特性提供了支持，如缓冲区池化，其中可以从池中借用 ByteBuf，并且在需要时自动释放\n    \n- ByteBufHolder 只有几种用于访问底层数据和引用计数的方法\n    \n\n![](statistic/asynccode-676.png)\n\n  \n\n# ByteBuf分配\n\n## 按需分配ByteBufAllocator\n\n，Netty 通过 interface ByteBufAllocator 实现了 （ByteBuf 的）**池化**，它可以用来分配我们所描述过的任意类型的 ByteBuf 实例\n\n![](statistic/asynccode-682.png)\n\n可以通过 Channel（每个都可以有一个不同的 ByteBufAllocator 实例）或者绑定到 ChannelHandler 的 ChannelHandlerContext 获取一个到 ByteBufAllocator 的引用。\n\n![](statistic/asynccode-686.png)\n\nNetty提供了两种ByteBufAllocator的实现：PooledByteBufAllocator和UnpooledByteBufAllocator。\n\n- PooledByteBufAllocator，池化了ByteBuf的实例以提高性能并最大限度地减少内存碎片\n    \n- UnpooledByteBufAllocator，非池化ByteBuf实例，并且在每次它被调用时都会返回一个新的实例\n    \n\n**Netty默认使用了PooledByteBufAllocator**，但这可以很容易地通过ChannelConfig API或者在引导你的应用程序时指定一个不同的分配器来更改\n\n  \n\n## Unpooled 缓冲区\n\n你未能获取一个到 ByteBufAllocator 的引用。对于这种情况，Netty 提供了一个简单的称为 Unpooled 的工具类，它提供了静态的辅助方法来创建未池化的 ByteBuf 实例。\n\n![](statistic/asynccode-678.png)\n\n## ByteBufUtil\n\nByteBufUtil 提供了用于操作 ByteBuf 的静态的辅助方法。因为这个 API 是通用的，并\n\n且和池化无关，所以这些方法已然在分配类的外部实现\n\n  \n\n# 引用计数\n\nNetty 在第 4 版中为 ByteBuf 和 ByteBufHolder 引入了引用计数技术，它们都实现了 interface ReferenceCounted。\n\n它主要涉及跟踪到某个特定对象的活动引用的数量。一个 ReferenceCounted 实现的实例将通常以活动的引用计数为 1 作为开始。\n\n只要引用计数大于 0，就能保证对象不会被释放。当活动引用的数量减少到 0 时，该实例就会被释放\n\n引用计数对于池化实现（如 PooledByteBufAllocator）来说是至关重要的，它降低了内存分配的开销。","lastmodified":"2023-08-02T03:10:42.044088141Z","tags":[]},"/netty/ChannelHandlerChannelPipelineChannelContext":{"title":"ChannelHandler、ChannelPipeline、ChannelContext","content":"当我们在本章中探讨 Netty 的数据流以及处理组件\n\n在 ChannelPipeline 中将 ChannelHandler 链接在一起以组织处理逻辑。我们将会研究涉及这些类的各种用例，以及一个重要的关系—ChannelHandlerContext\n\n  \n\n# ChannelHandler\n\n  \n\n## Channel 的生命周期\n\n![](statistic/asynccode-731.png)\n\n![](statistic/asynccode-731.png)\n\n![](statistic/asynccode-689.png)\n\n  \n\nChannelHandler的生命周期\n\n![](statistic/asynccode-731.png)\n\n  \n\nNetty定义了两个重要的ChannelHandler\n\n-  ChannelInboundHandler——处理入站数据以及各种状态变化；\n    \n-  ChannelOutboundHandler——处理出站数据并且允许拦截所有的操作。\n    \n\n  \n\n## ChannelInBoundHandler接口\n\nChannelInBoundHandler的生命周期方法。这些方法将会在数据被接收时或者与其对应的 Channel 状态发生改变时被调用。\n\n![](statistic/asynccode-721.png)\n\n当某个 ChannelInboundHandler 的实现重写 channelRead()方法时，它将负责显式地释放与池化的 ByteBuf 实例相关的内存。Netty 为此提供了一个实用方法 ReferenceCountUtil.release()\n\n![](statistic/asynccode-711.png)\n\n一个更加简单的方式是使用 SimpleChannelInboundHandler\n\n![](statistic/asynccode-722.png)\n\n由于 SimpleChannelInboundHandler 会自动释放资源，所以你不应该存储指向任何消 息的引用供将来使用\n\n## ChannelOutboundHandler\n\n出站操作和数据将由 ChannelOutboundHandler 处理。它的方法将被 Channel、ChannelPipeline 以及 ChannelHandlerContext 调用。\n\nChannelOutboundHandler 的一个强大的功能**是可以按需推迟操作或者事件**，这使得可以通过一些复杂的方法来处理请求。例如，如果到远程节点的写入被暂停了，那么你可以推迟冲刷操作并在稍后继续\n\n![](statistic/asynccode-714.png)\n\n  \n\n\u003e **ChannelPromise**与**ChannelFuture** ChannelOutboundHandler中的大部分方法都需要一个\n\u003e \n\u003e ChannelPromise参数，以便在操作完成时得到通知。ChannelPromise是ChannelFuture的一个\n\u003e \n\u003e 子类，其定义了一些可写的方法，如setSuccess()和setFailure()，从而使ChannelFuture不\n\u003e \n\u003e 可变\n\n  \n\n## 适配器\n\n![](statistic/asynccode-723.png)\n\n## 资源管理\n\n- 每当通过调用 ChannelInboundHandler.channelRead()或者 ChannelOutboundHandler.write()方法来处理数据时，你都需要确保没有任何的资源泄漏。\n    \n- Netty 使用引用计数来处理池化的 ByteBuf。所以在完全使用完某个ByteBuf 后，**调整其引用计数是很重要的**\n    \n\n  \n\nNetty提供了class ResourceLeakDetector①，它将对你应用程序的缓冲区分配做大约 1%的采样来检测内存泄露\n\nNetty的泄露级别\n\n![](statistic/asynccode-713.png)\n\n消费并释放入站消息\n\n![](statistic/asynccode-737.png)\n\n丢弃并释放出站消息\n\n![](statistic/asynccode-731.png)\n\n  \n\n# ChannelPipeline\n\n\u003e - ChannelPipeline 保存了与 Channel 相关联的 ChannelHandler；\n\u003e     \n\u003e - ChannelPipeline 可以根据需要，通过添加或者删除 ChannelHandler 来动态地修改；\n\u003e     \n\u003e - ChannelPipeline 有着丰富的 API 用以被调用，以响应入站和出站事件。\n\u003e     \n\n  \n\n- 每一个新创建的 Channel 都将会被分配一个新的 ChannelPipeline。这项关联是永久性的；\n    \n- Channel 既不能附加另外一个 ChannelPipeline，也不能分离其当前的\n    \n- 根据事件的起源，事件将会被 ChannelInboundHandler 或者 ChannelOutboundHandler处理，随后，通过调用 ChannelHandlerContext 实现，它将被转发给同一超类型的下一个 ChannelHandler\n    \n\n  \n\n\u003e ChannelHandlerContext使得ChannelHandler能够和它的ChannelPipeline以及其他的ChannelHandler 交互，\n\u003e \n\u003e - ChannelHandler 可以通知其所属的 ChannelPipeline 中的下一 个ChannelHandler，\n\u003e     \n\u003e - 甚至可以动态修改它所属的ChannelPipeline\n\u003e     \n\n  \n\n了一个典型的同时具有入站和出站 ChannelHandler 的 ChannelPipeline 的布 局，并且印证了我们之前的关于 ChannelPipeline 主要由一系列的 ChannelHandler 所组成的说法。\n\n  \n\n![](statistic/asynccode-718.png)\n\n- ChannelPipeline 还提供了通过 ChannelPipeline 本身传播事件的方法。\n    \n    - 如果一个入站事件被触发，它将被从 ChannelPipeline 的头部开始一直被传播到 Channel Pipeline 的尾端\n        \n    - 一个出站 I/O 事件将从 ChannelPipeline 的最右边开始，然后向左传播。\n        \n- 在 ChannelPipeline 传播事件时，它会测试 ChannelPipeline 中的下一个 ChannelHandler 的类型是否和事件的运动方向相匹配。\n    \n    - 如果不匹配，ChannelPipeline 将跳过该ChannelHandler 并前进到下一个，直到它找到和该事件所期望的方向相匹配的为止。\n        \n\n  \n\n## 修改ChannelPipeline\n\nChannelHandler 可以通过添加、删除或者替换其他的 ChannelHandler 来实时地修改ChannelPipeline 的布局。\n\n![](statistic/asynccode-697.png)\n\n![](statistic/asynccode-749.png)\n\n  \n\n## ChannelHandler 的阻塞和执行\n\n- 通常 ChannelPipeline 中的每一个 ChannelHandler 都是通过它的 EventLoop（I/O 线程）来处 理传递给它的事件的。所以**至关重要的是不要阻塞这个线程**，因为这会对整体的 I/O 处理产生负面的影响。\n    \n- 但有时可能需要与那些使用阻塞 API 的遗留代码进行交互。对于这种情况，ChannelPipeline 有一些接受一个 EventExecutorGroup 的 add()方法。如果一个事件被传递给一个自定义的 EventExecutorGroup，它将被包含在这个 EventExecutorGroup 中的某个 **EventExecutor** 所处理，**从而被从该 Channel 本身的 EventLoop 中移除**。对于这种用例，Netty 提供了一个叫 DefaultEventExecutorGroup 的默认实现。\n    \n\n## 其他获取ChannelHandler的方法\n\n还有别的通过类型或者名称来访问 ChannelHandler 的方法\n\n![](statistic/asynccode-731.png)\n\n## 触发事件\n\n入站操作，用于通知 ChannelInboundHandler 在 ChannelPipeline 中所发生的事件\n\n![](statistic/asynccode-712.png)\n\nChannelPipeline API 的出站操作。\n\n![](statistic/asynccode-719.png)\n\n  \n\n# ChannelHandlerContext\n\n- ChannelHandlerContext 代表了 ChannelHandler 和 ChannelPipeline 之间的关联，每当有 ChannelHandler 添加到 ChannelPipeline 中时，都会创建 ChannelHandlerContext\n    \n- ChannelHandlerContext 的主要功能是管理它所关联的 ChannelHandler 和在 同一个 ChannelPipeline 中的其他 ChannelHandler 之间的交互\n    \n\n  \n\nChannelHandlerContext 有很多的方法，其中一些方法也存在于 Channel 和 ChannelPipeline 本身上，但是有一点重要的不同。\n\n- 如果调用 Channel 或者 ChannelPipeline 上的这些方法，它们将沿着整个 ChannelPipeline 进行传播\n    \n- 而调用位于 ChannelHandlerContext 上的相同方法，则将从当前所关联的 ChannelHandler 开始，并且**只会传播给位于该 ChannelPipeline 中的下一个能够处理该事件的 ChannelHandler**\n    \n\n![](statistic/asynccode-698.png)\n\n![](statistic/asynccode-731.png)\n\n当使用 ChannelHandlerContext 的 API 的时候，请牢记以下两点：\n\n-  ChannelHandlerContext 和 ChannelHandler 之间的关联（绑定）是永远不会改变的，所以缓存对它的引用是安全的；\n    \n-  如同我们在本节开头所解释的一样，相对于其他类的同名方法，ChannelHandleContext 的方法将产生更短的事件流，应该尽可能地利用这个特性来获得最大的性能\n    \n\n## 使用\n\n![](statistic/asynccode-730.png)\n\n  \n\n### **ChannelHandlerContext** 访问 **Channel**\n\n![](statistic/asynccode-741.png)\n\n### 通过 **ChannelHandlerContext** 访问 **ChannelPipeline**\n\n![](statistic/asynccode-715.png)\n\n- 虽然被调用的 Channel 或 ChannelPipeline 上的 write()方法将**一直传播事件通过整个 ChannelPipeline**，\n    \n- 但是在 ChannelHandler 的级别上，事件从一个 ChannelHandler 到下一个 ChannelHandler 的移动是由ChannelHandlerContext 上的调用完成的\n    \n\n![](statistic/asynccode-716.png)\n\n### 调用 **ChannelHandlerContext** 的 **write()**方法\n\n![](statistic/asynccode-731.png)\n\n消息将从下一个 ChannelHandler 开始流经 ChannelPipeline，绕过了所有前面的 ChannelHandler\n\n![](statistic/asynccode-736.png)\n\n### 可共享的ChannelHandler\n\n![](statistic/asynccode-738.png)\n\n  \n\n# 异常处理\n\n## 处理入站点异常\n\n- 如果在处理入站事件的过程中有异常被抛出，那么它将从它在 ChannelInboundHandler里被触发的那一点开始流经 ChannelPipeline\n    \n- 要想处理这种类型的入站异常，你需要在你的 ChannelInboundHandler 实现中重写下面的方法\n    \n\n![](statistic/asynccode-742.png)\n\n- ChannelHandler.exceptionCaught()的默认实现是简单地将当前异常转发给 ChannelPipeline 中的下一个 ChannelHandler；\n    \n- 如果异常到达了 ChannelPipeline 的尾端，它将会被记录为未被处理；\n    \n- 要想定义自定义的处理逻辑，你需要重写 exceptionCaught()方法。然后你需要决定是否需要将该异常传播出去。\n    \n\n  \n\n## 处理出站异常\n\n用于处理出站操作中的正常完成以及异常的选项，都基于以下的通知机制。\n\n- 每个出站操作都将返回一个 ChannelFuture。注册到 ChannelFuture 的 ChannelFutureListener 将在操作完成时被通知该操作是成功了还是出错了\n    \n\n![](statistic/asynccode-720.png)\n\n- 几乎所有的 ChannelOutboundHandler 上的方法都会传入一个 ChannelPromise 的实例。作为 ChannelFuture 的子类，ChannelPromise 也可以被分配用于异步通知的监听器。但是，ChannelPromise 还具有提供立即通知的可写方法：\n    \n    - ChannelPromise setSuccess();\n        \n    - ChannelPromise setFailure(Throwable cause)\n        \n\n![](statistic/asynccode-690.png)","lastmodified":"2023-08-02T03:10:42.044088141Z","tags":[]},"/netty/EventLoop-%E5%92%8C%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B":{"title":"EventLoop 和线程模型","content":"# 常见的线程模型\n\n基本的线程池化模式\n\n- 从池的空闲线程列表中选择一个 Thread，并且指派它去运行一个已提交的任务（一个 Runnable 的实现）；\n    \n- 当任务完成时，将该 Thread 返回给该列表，使其可被重用\n    \n\n![](statistic/asynccode-717.png)\n\n虽然池化和重用线程相对于简单地为每个任务都创建和销毁线程是一种进步，但是它并不能消除由上下文切换所带来的开销\n\n# EventLoop\n\n运行任务来**处理在连接的生命周期内发生的事件是任何网络框架的基本功能**。与之相应的编程上的构造通常被称为**事件循环**—一个 Netty 使用了 interface io.netty.channel.EventLoop 来适配的术语。\n\n  \n\nNetty 的 EventLoop 是协同设计的一部分，它采用了两个基本的 API：并发和网络编程。\n\n- 首先，io.netty.util.concurrent 包构建在 JDK 的 java.util.concurrent 包上，用来提供线程执行器。\n    \n- 其次，io.netty.channel 包中的类，为了与 Channel 的事件进行交互，扩展了这些接口/类\n    \n\n![](statistic/asynccode-691.png)\n\n线程的关系\n\n- 在这个模型中，一个 EventLoop 将由一个永远都不会改变的 Thread 驱动\n    \n- 同时任务 （Runnable 或者 Callable）可以直接提交给 EventLoop 实现，以立即执行或者调度执行。\n    \n- 根据配置和可用核心的不同，可能会创建多个 EventLoop 实例用以优化资源的使用，\n    \n- 并且单个 EventLoop 可能会被指派用于服务多个 Channel\n    \n- netty的EventLoop在继承了ScheduledExecutorService的同时，只定 义了一个方法，parent(),用于返回到当前EventLoopGroup的引用。\n    \n\n```Go\npublic interface EventLoop extends EventExecutor, EventLoopGroup { \n    @Override \n    EventLoopGroup parent(); \n}\n```\n\n  \n\n## Netty4 中的I/O和事件处理\n\nI/O 操作触发的事件将流经安装了一个或者多个 ChannelHandler 的 ChannelPipeline。**传播这些事件的方法调用可以随后被 ChannelHandler 所拦截，并且可以按需地处理事件**\n\n- 在Netty 4 中，所有的I/O操作和事件都由已经被分配给了EventLoop的那个Thread来处理\n    \n\n不同于 Netty 3 中所使用的模型\n\n  \n\n## Netty3 中的I/O操作\n\n在以前的版本中\n\n- 所使用的线程模型只保证了入站（之前称为上游）事件会在所谓的 I/O 线程（对应于 Netty 4 中的 EventLoop）中执行。\n    \n- 所有的出站（下游）事件都由调用线程处理，其可能是 I/O 线程也可能是别的线程\n    \n\n  \n\n已经被发现**是有问题的**， **因为需要在 ChannelHandler 中对出站事件进行仔细的同步。简而言之，不可能保证多个线程不会在同一时刻尝试访问出站事件**\n\n  \n\nNetty 4 中所采用的线程模型，通过在**同一个线程中处理某个给定的 EventLoop 中所产生的所有事件**，解决了这个问题。这提供了一个更加简单的执行体系架构，并且消除了在多个 ChannelHandler 中进行同步的需要（除了任何可能需要在多个 Channel 中共享的）\n\n  \n\n# 任务调度\n\n  \n\n偶尔，你将需要调度一个任务**以便稍后（延迟）执行或者周期性地执行**。例如，你可能想要注册一个在客户端已经**连接了 5 分钟之后触发的任务。**\n\n  \n\nJDK 的任务调度\n\n- 在 Java 5 之前，任务调度是建立在 java.util.Timer 类之上的，其使用了一个后台 Thread，并且具有与标准线程相同的限制。、\n    \n- 随后，JDK 提供了 java.util.concurrent 包，它定义了 interface ScheduledExecutorService。表 7-1 展示了 java.util.concurrent.Executors的相关工厂方法。\n    \n\n![](statistic/asynccode-724.png)\n\n![](statistic/asynccode-746.png)\n\n  \n\n## EventLoop调度任务\n\nNetty 通 过 Channel 的 EventLoop 实现任务调度解决了这一问题\n\n  \n\n- 使用EventLoop调度任务\n    \n\n![](statistic/asynccode-692.png)\n\n- 使用 **EventLoop** 调度周期性的任务\n    \n\n![](statistic/asynccode-695.png)\n\n- 使用 **ScheduledFuture** 取消任务\n    \n\n![](statistic/asynccode-725.png)\n\n  \n\n# 实现细节\n\n## 线程管理\n\nNetty线程模型的卓越性能取决于对于当前执行的Thread的身份的确定 ，**它是否是分配给当前Channel以及它的EventLoop的那一个线程，**\n\n- 如果（当前）调用线程正是支撑 EventLoop 的线程，那么所提交的代码块将会被（直接执行）\n    \n- 否则，EventLoop 将调度该任务以便稍后执行，**并将它放入到内部队列中**。当 EventLoop 下次处理它的事件时，它会执行队列中的那些任务/事件。这也就解释了任何的\n    \n\n![](statistic/asynccode-696.png)\n\n  \n\n- 每个 EventLoop 都有它自已的任务队列，独立于任何其他的 EventLoop\n    \n- “永 远不要将一个长时间运行的任务放入到执行队列中，因为它将阻塞需要在同一线程上执行的任何其他任务。”如果必须要进行阻塞调用或者执行长时间运行的任务，我们建议使用一个专门的EventExecutor\n    \n\n## EventLoop线程的分配\n\n服务于 Channel 的 I/O 和事件的 EventLoop 包含在 EventLoopGroup 中。根据不同的传输实现，EventLoop 的创建和分配方式也不同\n\n#### 异步传输\n\n异步传输实现**只使用了少量的 EventLoop**（以及和它们相关联的 Thread），而且在当前的线程模型中，**它们可能会被多个 Channel 所共享**，这使得可以通过**尽可能少量的 Thread 来支撑大量的 Channel**，而不是每个 Channel 分配一个 Thread\n\n![](statistic/asynccode-693.png)\n\n- EventLoopGroup 负责为**每个新创建的 Channel 分配一个 EventLoop**。\n    \n    - 在当前实现中，使用顺序循环（round-robin）的方式进行分配以获取一个均衡的分布，并且相同的 **EventLoop可能会被分配给多个 Channel。**（这一点在将来的版本中可能会改变。）\n        \n- 一旦一个 Channel 被分配给一个 EventLoop，它将在它的整个生命周期中都使用这个 EventLoop（以及相关联的 Thread）\n    \n- EventLoop 的分配方式对 ThreadLocal 的使用的影响。因为一个EventLoop 通常会被用于支撑多个 Channel，所以对于所有相关联的 Channel 来说， ThreadLocal 都将是一样的\n    \n\n  \n\n#### 阻塞传输\n\n用于像 OIO（旧的阻塞 I/O）这样的其他传输的设计略有不同\n\n![](statistic/asynccode-694.png)\n\n这里每一个 Channel 都将被分配给一个 EventLoop（以及它的 Thread）。如果你开发的应用程序使用过 java.io 包中的阻塞 I/O 实现，你可能就遇到过这种模型\n\n但是，正如同之前一样，得到的保证是**每个 Channel 的 I/O 事件都将只会被一个 Thread** （用于支撑该 Channel 的 EventLoop 的那个 Thread）处理。","lastmodified":"2023-08-02T03:10:42.044088141Z","tags":[]},"/statistic/%E5%BA%94%E7%94%A8%E5%B1%82.png":{"title":"应用层.png","content":"","lastmodified":"2023-08-02T03:10:42.484093476Z","tags":[]},"/statistic/%E7%BD%91%E7%BB%9C%E6%8E%A5%E5%8F%A3%E5%B1%82.png":{"title":"网络接口层.png","content":"","lastmodified":"2023-08-02T03:10:42.488093525Z","tags":[]}}