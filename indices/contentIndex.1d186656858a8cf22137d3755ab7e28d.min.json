{"/":{"title":"_index","content":"\n😀😁😲🌞🙀\n\n这是我的 [Obsidian](https://obsidian.md/) 的 vault ,我使用了 [quartz](https://github.com/jackyzha0/quartz) 搭建了这个页面。\n\n\u003e 关于如何搭建可以看这篇文章 [使用quartz发布obsidian  vault](Obsidian/使用quartz发布obsidian%20%20vault.md)\n\n可以算是我的博客，和资源库。主要包括的内容：\n\n* [工具](工具和环境/工具.md)\n\n* [环境搭建](工具和环境/环境搭建.md)\n\n* 各种笔记\n\n* [资源汇总](资源/资源汇总.md)\n\n\n\n\n\n\n\n\n","lastmodified":"2024-03-02T12:01:53.86221037Z","tags":[]},"/%E5%88%86%E5%B8%83%E5%BC%8F%E9%AB%98%E5%B9%B6%E5%8F%91%E9%AB%98%E6%80%A7%E8%83%BD%E9%AB%98%E5%8F%AF%E7%94%A8/%E6%97%A5%E5%BF%97/%E6%9C%8D%E5%8A%A1%E6%B2%BB%E7%90%86%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%8B%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86":{"title":"服务治理：分布式下如何进行日志管理？","content":"![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticPasted%20image%2020230802010117.png)","lastmodified":"2024-03-02T12:01:53.97421Z","tags":[]},"/%E5%88%86%E5%B8%83%E5%BC%8F%E9%AB%98%E5%B9%B6%E5%8F%91%E9%AB%98%E6%80%A7%E8%83%BD%E9%AB%98%E5%8F%AF%E7%94%A8/%E7%9B%91%E6%8E%A7/%E6%9C%8D%E5%8A%A1%E6%B2%BB%E7%90%86%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E5%A6%82%E4%BD%95%E5%81%9A":{"title":"服务治理：监控系统如何做？","content":"![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticPasted%20image%2020230802010009.png)","lastmodified":"2024-03-02T12:01:53.97421Z","tags":[]},"/%E5%B7%A5%E5%85%B7%E5%92%8C%E7%8E%AF%E5%A2%83/%E5%B7%A5%E5%85%B7":{"title":"工具","content":"","lastmodified":"2024-03-02T12:01:53.978209987Z","tags":[]},"/%E5%B7%A5%E5%85%B7%E5%92%8C%E7%8E%AF%E5%A2%83/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA":{"title":"环境搭建","content":"","lastmodified":"2024-03-02T12:01:53.978209987Z","tags":[]},"/%E5%B7%A5%E5%85%B7%E5%92%8C%E7%8E%AF%E5%A2%83/emacs/%E5%AE%89%E8%A3%85":{"title":"安装","content":"https://github.com/kiennq/emacs-build\n\n\n### 添加到菜单栏\n\n* 需要打开 server-mode\n\n```\n(server-mode 1)\n```\n\n\n* 新建文件 `emacs.reg`\n\n\u003e 注意修改路径\n\n```\nWindows Registry Editor Version 5.00\n\n[HKEY_CLASSES_ROOT\\*\\shell]\n[HKEY_CLASSES_ROOT\\*\\shell\\openwemacs]\n@=\"\u0026Edit with Emacs\"\n[HKEY_CLASSES_ROOT\\*\\shell\\openwemacs\\command]\n@=\"C:\\\\emax64\\\\bin\\\\emacsclientw.exe -n \\\"%1\\\"\"\n[HKEY_CLASSES_ROOT\\Directory\\shell\\openwemacs]\n@=\"Edit \u0026with Emacs\"\n[HKEY_CLASSES_ROOT\\Directory\\shell\\openwemacs\\command]\n@=\"C:\\\\emax64\\\\bin\\\\emacsclientw.exe -n \\\"%1\\\"\"\n```","lastmodified":"2024-03-02T12:01:53.97421Z","tags":[]},"/%E5%B7%A5%E5%85%B7%E5%92%8C%E7%8E%AF%E5%A2%83/emacs/%E5%BF%AB%E6%8D%B7%E9%94%AE":{"title":"快捷键","content":"Emacs 这个东东听说功能很强大。不过感觉有些难学，还好网络上的资源还是比较丰富的。目前基于最基本的文本编辑来学习。而且它的快捷键很多，所以要在使用过程中学习会比较容易记住。这个是从网上搜索来的，总结的比较好的，贴在自己这里当做摘录了，方便查询。\n\nC = Control  \nM = Meta = Alt \nS =  Super = APPs\nDel = Backspace  \nRET = Enter\n\n\n**我常用的**\nM-x  所以命令\nC-x  C-r 最近的文件\nC-c C-l 重新加载配置\n\n\u003cf11\u003e 全屏\n\n\u003cf6\u003e 功能配置\n\nC-\u003cf6\u003e  mode-line功能配置\n\n  \n\n\n**基本快捷键 (Basic)**  \nC-x C-f  “find”文件, 即在缓冲区打开/新建一个文件  \nC-x C-s 保存文件  \nC-x C-w 使用其他文件名另存为文件  \nC-x C-v 关闭当前缓冲区文件并打开新文件  \nC-x i 在当前光标处插入文件  \nC-x b 新建/切换缓冲区  \nC-x C-b 显示缓冲区列表  \nC-x k 关闭当前缓冲区  \nC-z 挂起 emacs  \nC-x C-c 关闭 emacs\n\n**光标移动基本快捷键 (Basic Movement)**  \nC-f 后一个字符  \nC-b 前一个字符  \nC-p 上一行  \nC-n 下一行  \nM-f 后一个单词  \nM-b 前一个单词  \nC-a 行首  \nC-e 行尾  \nC-v 向下翻一页  \nM-v 向上翻一页  \nM-\u003c 到文件开头注意这里是‘\u003c’不是‘,’需要按 shift，遇到相同情况下同  \nM-\u003e 到文件末尾\n\n**编辑 (Editint)**  \nM-n 重复执行后一个命令 n 次  \nC-u 重复执行后一个命令 4 次  \nC-u n 重复执行后一个命令 n 次  \nC-d 删除 (delete)后一个字符  \nM-d 删除后一个单词  \nDel 删除前一个字符  \nM-Del 删除前一个单词  \nC-k 移除 (kill)一行\n\nC-Space 设置开始标记 (例如标记区域)  \nC-@ 功能同上, 用于 C-Space 被操作系统拦截的情况  \nC-w 移除 (kill)标记区域的内容  \nM-w 复制标记区域的内容  \nC-y 召回 (yank)复制/移除的区域/行  \nM-y 召回更早的内容 (在 kill 缓冲区内循环)  \nC-x C-x 交换光标和标记\n\nC-t 交换两个字符的位置  \nM-t 交换两个单词的位置  \nC-x C-t 交换两行的位置  \nM-u 使从光标位置到单词结尾处的字母变成大写  \nM-l 与 M-u 相反  \nM-c 使从光标位置开始的单词的首字母变为大写\n\n**重要快捷键 (Important)**  \nC-g 停止当前运行/输入的命令  \nC-x u 撤销前一个命令  \nM-x revert-buffer RETURN (照着这个输入)撤销上次存盘后所有改动  \nM-x recover-file RETURN 从自动存盘文件恢复  \nM-x recover-session RETURN 如果你编辑了几个文件, 用这个恢复\n\n**在线帮助 (Online-Help)**  \nC-h c 显示快捷键绑定的命令  \nC-h k 显示快捷键绑定的命令和它的作用  \nC-h l 显示最后 100 个键入的内容  \nC-h w 显示命令被绑定到哪些快捷键上  \nC-h f 显示函数的功能  \nC-h v 显示变量的含义和值  \nC-h b 显示当前缓冲区所有可用的快捷键  \nC-h t 打开 emacs 教程  \nC-h i 打开 info 阅读器  \nC-h C-f 显示 emacs FAQ  \nC-h p 显示本机 Elisp 包的信息\n\n**搜索/替换 (Seach/Replace)**  \nC-s 向后搜索  \nC-r 向前搜索  \nC-g 回到搜索开始前的位置 (如果你仍然在搜索模式中)  \nM-% 询问并替换 (query replace)\n\nSpace 或 y 替换当前匹配  \nDel 或 n 不要替换当前匹配  \n. 仅仅替换当前匹配并退出 (替换)  \n, 替换并暂停 (按 Space 或 y 继续)  \n! 替换以下所有匹配  \n^ 回到上一个匹配位置  \nRETURN 或 q 退出替换\n\n**使用正则表达式 (Regular expression)搜索/替换**  \n可在正则表达式中使用的符号:  \n^ 行首  \n$ 行尾  \n. 单个字符  \n.\\* 任意多个 (包括没有)字符  \n/\u003c 单词开头  \n/\u003e 单词结尾  \n\\[\\] 括号中的任意一个字符 (例如\\[a-z\\]表示所有的小写字母)\n\nM C-s RETURN 使用正则表达式向后搜索  \nM C-r RETURN 使用正则表达式向前搜索  \nC-s 增量搜索  \nC-s 重复增量搜索  \nC-r 向前增量搜索  \nC-r 重复向前增量搜索  \nM-x query-replace-regexp 使用正则表达式搜索并替换\n\n**窗口命令 (Window Commands)**  \nC-x 2 水平分割窗格  \nC-x 3 垂直分割窗格  \nC-x o 切换至其他窗格  \nC-x 0 关闭窗格  \nC-x 1 关闭除了光标所在窗格外所有窗格  \nC-x ^ 扩大窗格  \nM-x shrink-window 缩小窗格  \nM C-v 滚动其他窗格内容  \nC-x 4 f 在其他窗格中打开文件  \nC-x 4 0 关闭当前缓冲区和窗格  \nC-x 5 2 新建窗口 (frame)  \nC-x 5 f 在新窗口中打开文件  \nC-x 5 o 切换至其他窗口  \nC-x 5 0 关闭当前窗口\n\n**书签命令 (Bookmark commands)**  \nC-x r m 在光标当前位置创建书签  \nC-x r b 转到书签  \nM-x bookmark-rename 重命名书签  \nM-x bookmark-delete 删除书签  \nM-x bookmark-save 保存书签  \nC-x r l 列出书签清单\n\nD 标记等待删除  \nDel 取消删除标记  \nX 删除被标记的书签  \nR 重命名  \nS 保存列表内所有书签  \nF 转到当前书签指向的位置  \nM 标记在多窗口中打开  \nV 显示被标记的书签 (或者光标当前位置的书签)  \nT 切换是否显示路径列表  \nW 显示当前文件路径  \nQ 退出书签列表\n\nM-x bookmark-write 将所有书签导出至指定文件  \nM-x bookmark-load 从指定文件导入书签\n\n**Shell**  \nM-x shell 打开 shell 模式  \nC-c C-c 类似 unix 里的 C-c (停止正在运行的程序)  \nC-d 删除光标后一个字符  \nC-c C-d 发送 EOF  \nC-c C-z 挂起程序 (unix 下的 C-z)  \nM-p 显示前一条命令  \nM-n 显示后一条命令\n\n**DIRectory EDitor (dired)**  \nC-x d 打开 dired  \nC (大写 C) 复制  \nD 标记等待删除  \nD 立即删除  \nE 或 f 打开文件或目录  \nG 刷新当前目录  \nG 改变文件所属组 (chgrp)  \nK 从屏幕上的列表里删除一行 (不是真的删除)  \nM 用\\*标记  \nN 光标移动到下一行  \nO 在另一个窗格打开文件并移动光标  \nC-o 在另一个窗格打开文件但不移动光标  \nP 打印文件  \nQ 退出 dired  \nQ 在标记的文件中替换  \nR 重命名文件  \nU 移除标记  \nV 显示文件内容  \nX 删除有 D 标记的文件  \nZ 压缩/解压缩文件  \nM-Del 移除标记 (默认为所有类型的标记)  \n~ 标记备份文件 (文件名有~的文件)等待删除  \n\\# 标记自动保存文件 (文件名形如 #name #)等待删除  \n\\*/ 用\\*标记所有文件夹 (用 C-u \\*/n 移除标记)  \n\\= 将当前文件和标记文件 (使用 C-@标记而不是 dired 的 m 标记)比较  \nM-= 将当前文件和它的备份比较  \n! 对当前文件应用 shell 命令  \nM-} 移动光标至下一个用\\*或 D 标记的文件  \nM-{ 移动光标至上一个用\\*或 D 标记的文件  \n% d 使用正则表达式标记文件等待删除  \n% m 使用正则表达式标记文件为\\*  \n\\+ 新建文件夹  \n\\\u003e 移动光标至后一个文件夹  \n\u003c 移动光标至前一个文件夹  \nS 切换排序模式 (按文件名/日期)\n\n或许把这个命令归入这一类也很合适:  \nM-x speedbar 打开一个独立的目录显示窗口\n\n**Telnet**（大致了解）  \nM-x telnet 打开 telnet 模式  \nC-d 删除后一个字符或发送 EOF  \nC-c C-c 停止正在运行的程序 (和 unix 下的 C-c 类似)  \nC-c C-d 发送 EOF  \nC-c C-o 清除最后一个命令的输出  \nC-c C-z 挂起正在运行的命令  \nC-c C-u 移除前一行  \nM-p 显示前一条命令\n\n**Text**  \n只能在 text 模式里使用  \nM-s 使当前行居中  \nM-S 使当前段落居中  \nM-x center-region 使被选中的区域居中\n\n**宏命令 (Macro-commands)**（大致了解）  \nC-x ( 开始定义宏  \nC-x ) 结束定义宏  \nC-x e 运行最近定义的宏  \nM-n C-x e 运行最近定义的宏 n 次  \nM-x name-last-kbd-macro 给最近定义的宏命名 (用来保存)  \nM-x insert-kbd-macro 将已命名的宏保存到文件  \nM-x load-file 载入宏\n\n**编程 (Programming)**  \nM C-/ 自动缩进光标和标记间的区域  \nM-m 移动光标到行首第一个 (非空格)字符  \nM-^ 将当前行接到上一行末尾处  \nM-; 添加缩进并格式化的注释  \nC, C++和 Java 模式  \nM-a 移动光标到声明的开始处  \nM-e 移动光标到声明的结尾处  \nM C-a 移动光标到函数的开始处  \nM C-e 移动光标到函数的结尾处  \nC-c RETURN 将光标移动到函数的开始处并标记到结尾处  \nC-c C-q 根据缩进风格缩进整个函数  \nC-c C-a 切换自动换行功能  \nC-c C-d 一次性删除光标后的一串空格 (greedy delete)\n\n为了实现下面的一些技术, 你需要在保存源代码的目录里运行”etags  \n\\*. C \\*. H \\*. Cpp”(或者源代码的其他的扩展名)  \nM-. (点) 搜索标签  \nM-x tags-search ENTER 在所有标签里搜索 (使用正则表达式)  \nM-, (逗号) 在 tags-search 里跳至下一个匹配处  \nM-x tags-query-replace 在设置过标签的所有文件里替换文本\n\n**GDB (调试器)（大致了解）**  \nM-x gdb 在另一个的窗格中打开 gdb\n\n**版本控制 (Version Control)（以后会用到现在大致了解就可以了）**  \nC-x v d 显示当前目录下所有注册过的文件 (show all registered files in this dir)  \nC-x v = 比较不同版本间的差异 (show diff between versions)  \nC-x v u 移除上次提交之后的更改 (remove all changes since last checkin)  \nC-x v ~ 在不同窗格中显示某个版本 (show certain version in different window)  \nC-x v l 打印日志 (print log)  \nC-x v i 标记文件等待添加版本控制 (mark file for version control add)  \nC-x v h 给文件添加版本控制文件头 (insert version control header into file)  \nC-x v r 获取命名过的快照 (check out named snapshot)  \nC-x v s 创建命名的快照 (create named snapshot)  \nC-x v a 创建 gnu 风格的更改日志 (create changelog file in gnu-style)\n\n**文件操作：**\n\nC+x C+f  \n打开文件  \nC+x C+r  \n以只读的方式打开文件  \nC+x C+q  \n进行只读/读写模式切换  \nC+x C+v  \n切换缓冲区  \nC+x C+s  \n保存文件  \nC+x C+w  \n文件另存为  \nC+x i  \n向缓冲区中插入文件\n\n移动操作：C+f  \n前进一个字符 C+b  \n后退一个字符 M+f  \n前进一个单词 M+b  \n后退一个单词 C+a  \n移动到行首 C+e  \n移动到行尾 M+a  \n移动到句首 M+e  \n移动到句尾 C+p  \n后退一行 C+n  \n前进一行 M+g g  \n跳到指定行 C+v  \n向下翻页 M+v  \n向上翻页 M+\u003c 移动到缓冲区首M+\u003e  \n移动到缓冲区尾 C+M+f  \n向前匹配括号 C+M+b  \n向后匹配括号标记/复制/剪切/粘贴：C+xh  \n全选 C+@  \n标记开始 M+w  \n复制区域到 kill ring 中，但不删除 C+w  \n删除区域 C+y  \n将 kill ring 中的内容粘贴到缓冲区 C+Del  \n剪切光标到单词结束 M+Del  \n剪切光标到单词开始 C+k  \n剪切光标到行结尾 M+k  \n剪切光标到句结尾 (C+d)/Del  \n删除光标上的字 M+d  \n剪切光标到下一个单词结尾 ctrl-S (shift+s)-Backspace  \n删除当前行\n\n**缓冲区操作：**\n\nC+x C+f 打开/创建一个文件，并创建一个新的缓冲区\n\nC+x C+s 保存缓冲区内容到文件\n\nC+x C+w 保存缓冲区内容到其它文件\n\nC+xk 关闭当前缓冲区\n\nC+x C+b 显示缓冲区列表，可以使用方向键来选择缓冲区\n\nC+x C+c 关闭所有缓冲区，并推出 emacs\n\n**M+x 命令：**\n\n查找和替换：  \nC+s 向前查找 C+r 向后查找按下这两个快捷键后，  \nM+p 显示上一个搜索词，  \nM+n 显示下一个搜索词。输入查找内容后，按 C+s 跳到下一个结果，  \nC+r 跳到上一个结果。  \nEnter 结束查找光标在当前位置，C+g 取消查找光标返回原处。\n\n2，查找单词\n\n按 C - s RET C - w 或 C - r RET C - w 来使用单词搜索。\n\n3，查找及替换\n\n按 M - %启动查找替换，输入要被替换的词，回车，然后输入要替换的词，再回车。\n\n被替换的词会高亮起来，这时，输入 y 替换并跳到下一个，输入 n 忽略并跳到下一个，输入 q 结束，输入！替换剩下的全部。\n\n一些常用的选项：\n\nC - g 中断查找替换过程。\n\n^ 返回上一个替换点，按 y 继续下一个，如果不想替换上一个的话，用^返回到上一个，然后按 C - r 进入编辑，修改完后按 C- M - c 退出继续下一个。\n\nC - l 使当前匹配显示在文档中间。\n\nC - r 进入修改。\n\n4，列出匹配的模式\n\n有时候想列出匹配的全面模式，而不是在文档中浏览，这个可以使用 occur 这个函数。\n\n例子：M - x occur RET Create RET\n\n这时，emacs 会新开一个窗口来列出匹配的行，用鼠标点击或把光标移到一行按回车就会跳转到那里。\n\n执行 SHELL 命令\n\nM-x shell  \n打开 shell 命令  \nM-!  \n执行 shell 命令（shell-command）  \nM-1 M-!  \n执行 Shell 命令，命令输出插入光标位置，不打开新输入窗口  \nM-|  \n针对某一特定区域执行命令 (shell-command-on-region), 比如 C-x h M-juuencode\n\n窗口操作\n\nC-x 0  \n关闭本窗口  \nC-x 1  \n只留下一个窗口  \nC-x 2  \n垂直均分窗口  \nC-x 3  \n水平均分窗口  \nC-x o  \n切换到别的窗口  \nC-x s  \n保存所有窗口的缓冲  \nC-x b  \n选择当前窗口的缓冲区  \nC-x ^  \n纵向扩大窗口  \nC-x }  \n横向扩大窗口\n\n目录操作\n\nC-x d  \n打开目录模式  \nS  \n按日期/文件名排序显示  \nV  \n阅读光标所在的文件  \nQ  \n退出阅读的文件  \nD  \n标记为删除  \nX  \n执行标记  \nD  \n马上删除当前文件  \nC  \n拷贝当前文件  \nR  \n重命名当前文件  \n+  \n新建文件  \nZ  \n压缩文件  \n！  \n对光标所在的文件执行 SHELL 命令  \nG  \n刷新显示  \nI  \n在当前缓冲区的末尾插入子目录的内容  \n\\[n\\]m  \n标记光标所在的文件，如果指定 n, 则从光标所在的文件后 n 个文件被标记  \n\\[n\\]u  \n取消当前光标标记的文件，n 的含义同上  \nT  \n反向标记文件  \n%-m  \n正则标记  \nQ  \n退出目录模式\n\n其他：\n\nC+x u 撤销\n\nC+x C+c 退出 emacs","lastmodified":"2024-03-02T12:01:53.97421Z","tags":[]},"/%E5%B7%A5%E5%85%B7%E5%92%8C%E7%8E%AF%E5%A2%83/git/git":{"title":"git","content":"\n## 版本控制\n\n### 什么是版本控制\n\n版本控制是一种记录一个或若干文件内容变化，以便将来查阅特定版本修订情况的系统。除了项目源代码，你可以对任何类型的文件进行版本控制。\n\n### 为什么要版本控制\n\n有了它你就可以将某个文件回溯到之前的状态，甚至将整个项目都回退到过去某个时间点的状态，你可以比较文件的变化细节，查出最后是谁修改了哪个地方，从而找出导致怪异问题出现的原因，又是谁在何时报告了某个功能缺陷等等。\n\n### 本地版本控制系统\n\n许多人习惯用复制整个项目目录的方式来保存不同的版本，或许还会改名加上备份时间以示区别。这么做唯一的好处就是简单，但是特别容易犯错。有时候会混淆所在的工作目录，一不小心会写错文件或者覆盖意想外的文件。\n\n为了解决这个问题，人们很久以前就开发了许多种本地版本控制系统，大多都是采用某种简单的数据库来记录文件的历次更新差异。\n\n![本地版本控制系统](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic%E6%9C%AC%E5%9C%B0%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6%E7%B3%BB%E7%BB%9F.png)\n\n### 集中化的版本控制系统\n\n接下来人们又遇到一个问题，如何让在不同系统上的开发者协同工作？ 于是，集中化的版本控制系统（Centralized Version Control Systems，简称 CVCS）应运而生。\n\n集中化的版本控制系统都有一个单一的集中管理的服务器，保存所有文件的修订版本，而协同工作的人们都通过客户端连到这台服务器，取出最新的文件或者提交更新。\n\n![集中化的版本控制系统](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic%E9%9B%86%E4%B8%AD%E5%8C%96%E7%9A%84%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6%E7%B3%BB%E7%BB%9F.png)\n\n这么做虽然解决了本地版本控制系统无法让在不同系统上的开发者协同工作的诟病，但也还是存在下面的问题：\n\n- **单点故障：** 中央服务器宕机，则其他人无法使用；如果中心数据库磁盘损坏又没有进行备份，你将丢失所有数据。本地版本控制系统也存在类似问题，只要整个项目的历史记录被保存在单一位置，就有丢失所有历史更新记录的风险。\n- **必须联网才能工作：** 受网络状况、带宽影响。\n\n### 分布式版本控制系统\n\n于是分布式版本控制系统（Distributed Version Control System，简称 DVCS）面世了。 Git 就是一个典型的分布式版本控制系统。\n\n这类系统，客户端并不只提取最新版本的文件快照，而是把代码仓库完整地镜像下来。这么一来，任何一处协同工作用的服务器发生故障，事后都可以用任何一个镜像出来的本地仓库恢复。因为每一次的克隆操作，实际上都是一次对代码仓库的完整备份。\n\n![分布式版本控制系统](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic%E5%88%86%E5%B8%83%E5%BC%8F%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6%E7%B3%BB%E7%BB%9F.png)\n\n分布式版本控制系统可以不用联网就可以工作，因为每个人的电脑上都是完整的版本库，当你修改了某个文件后，你只需要将自己的修改推送给别人就可以了。但是，在实际使用分布式版本控制系统的时候，很少会直接进行推送修改，而是使用一台充当“中央服务器”的东西。这个服务器的作用仅仅是用来方便“交换”大家的修改，没有它大家也一样干活，只是交换修改不方便而已。\n\n分布式版本控制系统的优势不单是不必联网这么简单，后面我们还会看到 Git 极其强大的分支管理等功能。\n\n## 认识 Git\n\n### Git 简史\n\nLinux 内核项目组当时使用分布式版本控制系统 BitKeeper 来管理和维护代码。但是，后来开发 BitKeeper 的商业公司同 Linux 内核开源社区的合作关系结束，他们收回了 Linux 内核社区免费使用 BitKeeper 的权力。 Linux 开源社区（特别是 Linux 的缔造者 Linus Torvalds）基于使用 BitKeeper 时的经验教训，开发出自己的版本系统，而且对新的版本控制系统做了很多改进。\n\n### Git 与其他版本管理系统的主要区别\n\nGit 在保存和对待各种信息的时候与其它版本控制系统有很大差异，尽管操作起来的命令形式非常相近，理解这些差异将有助于防止你使用中的困惑。\n\n下面我们主要说一个关于 Git 与其他版本管理系统的主要差别：**对待数据的方式**。\n\n**Git 采用的是直接记录快照的方式，而非差异比较。我后面会详细介绍这两种方式的差别。**\n\n大部分版本控制系统（CVS、Subversion、Perforce、Bazaar 等等）都是以文件变更列表的方式存储信息，这类系统**将它们保存的信息看作是一组基本文件和每个文件随时间逐步累积的差异。**\n\n具体原理如下图所示，理解起来其实很简单，每当我们提交更新一个文件之后，系统都会记录这个文件做了哪些更新，以增量符号 Δ(Delta)表示。\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic2019-3deltas.png)\n\n**我们怎样才能得到一个文件的最终版本呢？**\n\n很简单，高中数学的基本知识，我们只需要将这些原文件和这些增加进行相加就行了。\n\n**这种方式有什么问题呢？**\n\n比如我们的增量特别特别多的话，如果我们要得到最终的文件是不是会耗费时间和性能。\n\nGit 不按照以上方式对待或保存数据。反之，Git 更像是把数据看作是对小型文件系统的一组快照。每次你提交更新，或在 Git 中保存项目状态时，它主要对当时的全部文件制作一个快照并保存这个快照的索引。为了高效，如果文件没有修改，Git 不再重新存储该文件，而是只保留一个链接指向之前存储的文件。 Git 对待数据更像是一个 **快照流**。\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic2019-3snapshots.png)\n\n### Git 的三种状态\n\nGit 有三种状态，你的文件可能处于其中之一：\n\n1. **已提交（committed）**：数据已经安全的保存在本地数据库中。\n2. **已修改（modified）**：已修改表示修改了文件，但还没保存到数据库中。\n3. **已暂存（staged）**：表示对一个已修改文件的当前版本做了标记，使之包含在下次提交的快照中。\n\n由此引入 Git 项目的三个工作区域的概念：**Git 仓库 (. Git directory)**、**工作目录 (Working Directory)** 以及 **暂存区域 (Staging Area)** 。\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic2019-3areas.png)\n\n**基本的 Git 工作流程如下：**\n\n1. 在工作目录中修改文件。\n2. 暂存文件，将文件的快照放入暂存区域。\n3. 提交更新，找到暂存区域的文件，将快照永久性存储到 Git 仓库目录。\n\n## Git 使用快速入门\n\n### 获取 Git 仓库\n\n有两种取得 Git 项目仓库的方法。\n\n1. 在现有目录中初始化仓库: 进入项目目录运行 `git init` 命令, 该命令将创建一个名为 `.git` 的子目录。\n2. 从一个服务器克隆一个现有的 Git 仓库: `git clone [url]` 自定义本地仓库的名字: `git clone [url] directoryname`\n\n### 记录每次更新到仓库\n\n1. **检测当前文件状态** : `git status`\n2. **提出更改（把它们添加到暂存区**）：`git add filename` (针对特定文件)、`git add *` (所有文件)、`git add *.txt`（支持通配符，所有 .txt 文件）\n3. **忽略文件**：`.gitignore` 文件\n4. **提交更新:** `git commit -m \"代码提交信息\"` （每次准备提交前，先用 `git status` 看下，是不是都已暂存起来了，然后再运行提交命令 `git commit`）\n5. **跳过使用暂存区域更新的方式** : `git commit -a -m \"代码提交信息\"`。 `git commit` 加上 `-a` 选项，Git 就会自动把所有已经跟踪过的文件暂存起来一并提交，从而跳过 `git add` 步骤。\n6. **移除文件**：`git rm filename` （从暂存区域移除，然后提交。）\n7. **对文件重命名**：`git mv README.md README` (这个命令相当于 `mv README.md README`、`git rm README.md`、`git add README` 这三条命令的集合)\n\n### 一个好的 Git 提交消息\n\n一个好的 Git 提交消息如下：\n\n```\n标题行：用这一行来描述和解释你的这次提交\n\n主体部分可以是很少的几行，来加入更多的细节来解释提交，最好是能给出一些相关的背景或者解释这个提交能修复和解决什么问题。\n\n主体部分当然也可以有几段，但是一定要注意换行和句子不要太长。因为这样在使用 \"git log\" 的时候会有缩进比较好看。\n```\n\n提交的标题行描述应该尽量的清晰和尽量的一句话概括。这样就方便相关的 Git 日志查看工具显示和其他人的阅读。\n\n### 推送改动到远程仓库\n\n- 如果你还没有克隆现有仓库，并欲将你的仓库连接到某个远程服务器，你可以使用如下命令添加：`git remote add origin \u003cserver\u003e` ,比如我们要让本地的一个仓库和 GitHub 上创建的一个仓库关联可以这样 `git remote add origin https://github.com/Snailclimb/test.git`\n- 将这些改动提交到远端仓库：`git push origin master` (可以把 _master_ 换成你想要推送的任何分支)\n\n  如此你就能够将你的改动推送到所添加的服务器上去了。\n\n### 远程仓库的移除与重命名\n\n- 将 test 重命名为 test 1：`git remote rename test test 1`\n- 移除远程仓库 test 1:`git remote rm test 1`\n\n### 查看提交历史\n\n在提交了若干更新，又或者克隆了某个项目之后，你也许想回顾下提交历史。完成这个任务最简单而又有效的工具是 `git log` 命令。`git log` 会按提交时间列出所有的更新，最近的更新排在最上面。\n\n**可以添加一些参数来查看自己希望看到的内容：**\n\n只看某个人的提交记录：\n\n```shell\nGit log --author=bob\n```\n\n### 撤销操作\n\n有时候我们提交完了才发现漏掉了几个文件没有添加，或者提交信息写错了。此时，可以运行带有 `--amend` 选项的提交命令尝试重新提交：\n\n```shell\nGit commit --amend\n```\n\n取消暂存的文件\n\n```shell\nGit reset filename\n```\n\n撤消对文件的修改:\n\n```shell\nGit checkout -- filename\n```\n\n假如你想丢弃你在本地的所有改动与提交，可以到服务器上获取最新的版本历史，并将你本地主分支指向它：\n\n```shell\nGit fetch origin\nGit reset --hard origin/master\n```\n\n### 分支\n\n分支是用来将特性开发绝缘开来的。在你创建仓库的时候，_master_ 是“默认”的分支。在其他分支上进行开发，完成后再将它们合并到主分支上。\n\n我们通常在开发新功能、修复一个紧急 bug 等等时候会选择创建分支。单分支开发好还是多分支开发好，还是要看具体场景来说。\n\n创建一个名字叫做 test 的分支\n\n```shell\nGit branch test\n```\n\n切换当前分支到 test（当你切换分支的时候，Git 会重置你的工作目录，使其看起来像回到了你在那个分支上最后一次提交的样子。 Git 会自动添加、删除、修改文件以确保此时你的工作目录和这个分支最后一次提交时的样子一模一样）\n\n```shell\nGit checkout test\n```\n\n\n你也可以直接这样创建分支并切换过去 (上面两条命令的合写)\n\n```shell\nGit checkout -b feature_x\n```\n\n切换到主分支\n\n```shell\nGit checkout master\n```\n\n合并分支 (可能会有冲突)\n\n```shell\n Git merge test\n```\n\n把新建的分支删掉\n\n```shell\nGit branch -d feature_x\n```\n\n将分支推送到远端仓库（推送成功后其他人可见）：\n\n```shell\nGit push origin\n```\n\n\n---\nTitle: Github 实用小技巧总结\nCategory: 开发工具\nTag:\n  - Git\n---\n\n我使用 Github 已经有 6 年多了，今天毫无保留地把自己觉得比较有用的 Github 小技巧送给关注 JavaGuide 的各位小伙伴。\n\n## 一键生成 Github 简历 \u0026 Github 年报\n\n通过 [https://resume.github.io/](https://resume.github.io/) 这个网站你可以一键生成一个在线的 Github 简历。\n\n当时我参加的校招的时候，个人信息那里就放了一个在线的 Github 简历。我觉得这样会让面试官感觉你是一个内行，会提高一些印象分。\n\n但是，如果你的 Github 没有什么项目的话还是不要放在简历里面了。生成后的效果如下图所示。\n\n![Github简历](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticGithub%E7%AE%80%E5%8E%86.png)\n\n通过 \u003chttps://www.githubtrends.io/wrapped\u003e 这个网站，你可以生成一份 Github 个人年报，这个年报会列举出你在这一年的项目贡献情况、最常使用的编程语言、详细的贡献信息。\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticimage-20211226144607457.png)\n\n## 个性化 Github 首页\n\nGithub 目前支持在个人主页自定义展示一些内容。展示效果如下图所示。\n\n![个性化首页展示效果](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic%E4%B8%AA%E6%80%A7%E5%8C%96%E9%A6%96%E9%A1%B5%E5%B1%95%E7%A4%BA%E6%95%88%E6%9E%9C.png)\n\n想要做到这样非常简单，你只需要创建一个和你的 Github 账户同名的仓库，然后自定义 `README.md` 的内容即可。\n\n展示在你主页的自定义内容就是 `README.md` 的内容（_不会 Markdown 语法的小伙伴自行面壁 5 分钟_）。\n\n![创建一个和你的Github账户同名的仓库](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AA%E5%92%8C%E4%BD%A0%E7%9A%84Github%E8%B4%A6%E6%88%B7%E5%90%8C%E5%90%8D%E7%9A%84%E4%BB%93%E5%BA%93.png)\n\n这个也是可以玩出花来的！比如说：通过 [github-readme-stats](https://hellogithub.com/periodical/statistics/click/?target=https://github.com/anuraghazra/github-readme-stats) 这个开源项目，你可以 README 中展示动态生成的 GitHub 统计信息。展示效果如下图所示。\n\n![通过github-readme-stats动态生成GitHub统计信息 ](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic%E9%80%9A%E8%BF%87github-readme-stats%E5%8A%A8%E6%80%81%E7%94%9F%E6%88%90GitHub%E7%BB%9F%E8%AE%A1%E4%BF%A1%E6%81%AF_.png)\n\n关于个性化首页这个就不多提了，感兴趣的小伙伴自行研究一下。\n\n## 自定义项目徽章\n\n你在 Github 上看到的项目徽章都是通过 [https://shields.io/](https://shields.io/) 这个网站生成的。我的 JavaGuide 这个项目的徽章如下图所示。\n\n![项目徽章](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic%E9%A1%B9%E7%9B%AE%E5%BE%BD%E7%AB%A0.png)\n\n并且，你不光可以生成静态徽章，shield. Io 还可以动态读取你项目的状态并生成对应的徽章。\n\n![自定义项目徽章](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic%E8%87%AA%E5%AE%9A%E4%B9%89%E9%A1%B9%E7%9B%AE%E5%BE%BD%E7%AB%A0.png)\n\n生成的描述项目状态的徽章效果如下图所示。\n\n![描述项目状态的徽章](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic%E6%8F%8F%E8%BF%B0%E9%A1%B9%E7%9B%AE%E7%8A%B6%E6%80%81%E7%9A%84%E5%BE%BD%E7%AB%A0.png)\n\n## 自动为项目添加贡献情况图标\n\n通过 repobeats 这个工具可以为 Github 项目添加如下图所示的项目贡献基本情况图表，挺不错的 👍\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticrepobeats.png)\n\n地址：\u003chttps://repobeats.axiom.co/\u003e 。\n\n## Github 表情\n\n![Github表情](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticGithub%E8%A1%A8%E6%83%85.png)\n\n如果你想要在 Github 使用表情的话，可以在这里找找：[www.webfx.com/tools/emoji-cheat-sheet/](https://www.webfx.com/tools/emoji-cheat-sheet/)。\n\n![在线Github表情](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic%E5%9C%A8%E7%BA%BFGithub%E8%A1%A8%E6%83%85.png)\n\n## 高效阅读 Github 项目的源代码\n\nGithub 前段时间推出的 Codespaces 可以提供类似 VS Code 的在线 IDE，不过目前还没有完全开发使用。\n\n简单介绍几种我最常用的阅读 Github 项目源代码的方式。\n\n### Chrome 插件 Octotree\n\n这个已经老生常谈了，是我最喜欢的一种方式。使用了 Octotree 之后网页侧边栏会按照树形结构展示项目，为我们带来 IDE 般的阅读源代码的感受。\n\n![Chrome插件Octotree](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticChrome%E6%8F%92%E4%BB%B6Octotree.png)\n\n### Chrome 插件 SourceGraph\n\n我不想将项目 clone 到本地的时候一般就会使用这种方式来阅读项目源代码。SourceGraph 不仅可以让我们在 Github 优雅的查看代码，它还支持一些骚操作，比如：类之间的跳转、代码搜索等功能。\n\n当你下载了这个插件之后，你的项目主页会多出一个小图标如下图所示。点击这个小图标即可在线阅读项目源代码。\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticimage-20201107145749659.png)\n\n使用 SourceGraph 阅读代码的就像下面这样，同样是树形结构展示代码，但是我个人感觉没有 Octotree 的手感舒服。不过，SourceGraph 内置了很多插件，而且还支持类之间的跳转！\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticimage-20201107150307314.png)\n\n### 克隆项目到本地\n\n先把项目克隆到本地，然后使用自己喜欢的 IDE 来阅读。可以说是最酸爽的方式了！\n\n如果你想要深入了解某个项目的话，首选这种方式。一个 `git clone` 就完事了。\n\n## 扩展 Github 的功能\n\n**Enhanced GitHub** 可以让你的 Github 更好用。这个 Chrome 插件可以可视化你的 Github 仓库大小，每个文件的大小并且可以让你快速下载单个文件。\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticimage-20201107160817672.png)\n\n## 自动为 Markdown 文件生成目录\n\n如果你想为 Github 上的 Markdown 文件生成目录的话，通过 VS Code 的 **Markdown Preview Enhanced** 这个插件就可以了。\n\n生成的目录效果如下图所示。你直接点击目录中的链接即可跳转到文章对应的位置，可以优化阅读体验。\n\n![](\u003chttps://oss.javaguide.cn/2020-11/iShot2020-11-07%2016.14.14%20(1).png\u003e)\n\n不过，目前 Github 已经自动为 Markdown 文件生成了目录，只是需要通过点击的方式才能显示出来。\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticimage-20211227093215005.png)\n\n## 善用 Github Explore\n\n其实，Github 自带的 Explore 是一个非常强大且好用的功能。不过，据我观察，国内很多 Github 用户都不知道这个到底是干啥的。\n\n简单来说，Github Explore 可以为你带来下面这些服务：\n\n1. 可以根据你的个人兴趣为你推荐项目；\n2. Githunb Topics 按照类别/话题将一些项目进行了分类汇总。比如 [Data visualization](https://github.com/topics/data-visualization) 汇总了数据可视化相关的一些开源项目，[Awesome Lists](https://github.com/topics/awesome) 汇总了 Awesome 系列的仓库；\n3. 通过 Github Trending 我们可以看到最近比较热门的一些开源项目，我们可以按照语言类型以及时间维度对项目进行筛选；\n4. Github Collections 类似一个收藏夹集合。比如 [Teaching materials for computational social science](https://github.com/collections/teaching-computational-social-science) 这个收藏夹就汇总了计算机课程相关的开源资源，[Learn to Code](https://github.com/collections/learn-to-code) 这个收藏夹就汇总了对你学习编程有帮助的一些仓库；\n5. ......\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticgithub-explore.png)\n\n## GitHub Actions 很强大\n\n你可以简单地将 GitHub Actions 理解为 Github 自带的 CI/CD ，通过 GitHub Actions 你可以直接在 GitHub 构建、测试和部署代码，你还可以对代码进行审查、管理 API、分析项目依赖项。总之，GitHub Actions 可以自动化地帮你完成很多事情。\n\n关于 GitHub Actions 的详细介绍，推荐看一下阮一峰老师写的 [GitHub Actions 入门教程](https://www.ruanyifeng.com/blog/2019/09/getting-started-with-github-actions.html) 。\n\nGitHub Actions 有一个官方市场，上面有非常多别人提交的 Actions ，你可以直接拿来使用。\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticimage-20211227100147433.png)\n\n## 后记\n\n这一篇文章，我毫无保留地把自己这些年总结的 Github 小技巧分享了出来，真心希望对大家有帮助，真心希望大家一定要利用好 Github 这个专属程序员的宝藏。\n\n另外，这篇文章中，我并没有提到 Github 搜索技巧。在我看来，Github 搜索技巧不必要记网上那些文章说的各种命令啥的，真没啥卵用。你会发现你用的最多的还是关键字搜索以及 Github 自带的筛选功能。\n\n\n\n## 学习资料推荐\n\n**在线演示学习工具：**\n\n「补充，来自 [issue729](https://github.com/Snailclimb/JavaGuide/issues/729) 」Learn Git Branching \u003chttps://oschina.gitee.io/learn-git-branching/\u003e 。该网站可以方便的演示基本的 git 操作，讲解得明明白白。每一个基本命令的作用和结果。\n\n**推荐阅读：**\n\n- [Git 入门图文教程(1.5W 字 40 图)](https://www.cnblogs.com/anding/p/16987769.html)：超用心的一篇文章，内容全面且附带详细的图解，强烈推荐！\n- [Git - 简明指南](https://rogerdudler.github.io/git-guide/index.zh.html)：涵盖 Git 常见操作，非常清晰。\n- [图解 Git](https://marklodato.github.io/visual-git-guide/index-zh-cn.html)：图解 Git 中的最常用命令。如果你稍微理解 git 的工作原理，这篇文章能够让你理解的更透彻。\n- [猴子都能懂得 Git 入门](https://backlog.com/git-tutorial/cn/intro/intro1_1.html)：有趣的讲解。\n- [Pro Git book](https://git-scm.com/book/zh/v2)：国外的一本 Git 书籍，被翻译成多国语言，质量很高。","lastmodified":"2024-03-02T12:01:53.978209987Z","tags":[]},"/%E5%B7%A5%E5%85%B7%E5%92%8C%E7%8E%AF%E5%A2%83/msys2/pacman":{"title":"pacman","content":"# 安装软件\n\n- `pacman -S (软件名)`：安装软件，若有多个软件包，空格分隔\n- `pacman -S --needed （软件名）`：安装软件，若存在，不重新安装最新的软件\n- `pacman -Sy (软件名)`：安装软件前，先从远程仓库下载软件包数据库\n- `pacman -Sv (软件名)`：输出操作信息后安装\n- `pacman -Sw (软件名)`：只下载软件包，而不安装\n- `pacman -U (软件名.pkg.tar.gz)`：安装本地软件包\n- `pacman -U (http://www.xxx.com/xxx.pkg.tar.xz)`：安装一个远程包\n\n# 卸载软件\n\n- `pacman -R (软件名)`：只卸载软件包不卸载依赖的软件\n- `pacman -Rv (软件名)`：卸载软件，并输出卸载信息\n- `pacman -Rs (软件名)`：卸载软件，并同时卸载该软件的依赖软件\n- `pacman -Rsc (软件名)`：卸载软件，并卸载依赖该软件的程序\n- `pacman -Ru (软件名)`：卸载软件，同时卸载不被任何软件所依赖\n\n# 搜索软件\n\n- `pacman -Ss (关键字)`：在仓库搜索包含关键字的软件包\n- `pacman -Sl`：显示软件仓库所有软件的列表\n- `pacman -Qs (关键字)`：搜索已安装的软件包\n- `pacman -Qu`：列出可升级的软件包\n- `pacman -Qt`：列出不被任何软件要求的软件包\n- `pacman -Q (软件名)`：查看软件包是否已安装\n- `pacman -Qi (软件包)`：查看某个软件包详细信息\n- `pacman -Ql (软件名)`：列出软件包所有文件安装路径\n\n# 软件包组\n\n- `pacman -Sg`：列出软件仓库上所有软件包组\n- `pacman -Qg`：列出本地已经安装的软件包组和子软件包\n- `pacman -Sg (软件包组)`：查看软件包组所包含的软件包\n- `pacman -Qg (软件包组)`：查看软件包组所包含的软件包\n\n# 更新系统\n\n- `pacman -Sy`：从服务器下载最新的软件包数据库到本地\n- `pacman -Su`：升级所有已安装的软件包\n- `pacman -Syu`：升级整个系统\n\n# 清理缓存\n\n- `pacman -Sc`：清理未安装的软件包文件\n- `pacman -Scc`：清理所有的缓存文件","lastmodified":"2024-03-02T12:01:53.978209987Z","tags":[]},"/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E5%AF%B9%E6%AF%94":{"title":"消息队列对比","content":"\n# 性能和可靠性\n\n## 副本与存储结构\n\nPulsar通过BookKeeper实现了数据的高可靠。在BookKeeper中Ledger是基本的持久化存储单元。Pulsar的每个主题的数据都会在逻辑上映射为多个Ledger。每个Ledger在服务端会存储多个副本。为了灵活地控制存储时的一致性，BookKeeper在存储时提供了3个关键的参数—数据存储的副本数（Ensemble Size，直译为集合数量）、最大写入副本数（Write Quorum Size，直译为法定写入数量）、最小写入副本数（Ack Quorum Size，直译为法定确认数量）\n集群的高可用一般通过多副本机制来保障。Pulsar、Kafka、RabbitMQ 与 RocketMQ 都依赖副本或备份来保障高可用。\n\n* Kafka 以分区维度进行高可用保障，每个分区的数据会保存多个副本。在多个副本中会有一个被选为主副本并负责数据的读取与写入。与此同时，主副本还负责将数据同步至其他副本。在集群视角下，各个主副本会分布在不同的节点上，从全局来看，每个服务端的负载是相对均衡的\n* RocketMQ 依赖主从复制机制来实现数据的多副本，从而保证服务的可靠性。不同于 Kafka 采用物理分区方式（每个分区对应一个真实的日志文件），RocketMQ 采用逻辑分区的方式。RocketMQ 消息的存储由逻辑队列和物理日志一同实现，其中物理日志负责将消息存储在物理存储介质中，而消息的逻辑队列里存储对应消息的物理存储地址。在物理存储部分，RabbitMQ 也采用类似的主从复制机制来保障高可用。\n* Pulsar 通过 BookKeeper 实现了数据的高可靠。在 BookKeeper 中 Ledger 是基本的持久化存储单元。Pulsar 的每个主题的数据都会在逻辑上映射为多个 Ledger。每个 Ledger 在服务端会存储多个副本。为了灵活地控制存储时的一致性，BookKeeper 在存储时提供了 3 个关键的参数—数据存储的副本数（Ensemble Size，直译为集合数量）、最大写入副本数（Write Quorum Size，直译为法定写入数量）、最小写入副本数（Ack Quorum Size，直译为法定确认数量）\n\n## 语义支持与一致性级别\n\n\n根据 CAP 定理，在一个分布式系统中，一致性 (Consistency)、可用性 (Availability)、分区容错性 (Partition tolerance)三者不能同时满足。\n\n消息在生产者和消费者之间进行传输的方式有 3 种—**至多一次 (At most once)**、**至少一次 (At least once)**、**精确一次（Exactly once，又称精准一次）**\n\n* Kafka，其具有幂等性和事务功能。Kafka 的幂等性是指单个生产者对于单分区单会话的幂等，而事务可以保证消息原子性地写入多个分区，即消息写入多个分区要么全部成功，要么全部回滚。**Kafka 具备精确一次语义的能力**\n* Pulsar 可以通过幂等生产者在单个分区上写入数据，并保证其可靠性。通过客户端的自增序列 ID、重试机制与服务端的去重机制，幂等生产者可以保证发送到单个分区的每条消息只会被持久化一次，且不会丢失数据\n\t* Pulsar 事务中的所有生产或消费操作都作为一个单元提交。一个事务中的所有操作要么全部提交，要么全部失败。，Kafka 与 Pulsar 的事务功能都是为了支持精确一次语义的\n* RocketMQ 的事务流程被分为正常事务消息的发送和提交以及事务消息的补偿两个阶段。\n\t* 在消息发送过程中，生产者将消息发送到服务端后，若服务端未收到生产者对该消息的二次确认，则该消息会被标记成不可用状态。处于不可用状态的消息称为半事务消息，此时消费者无法正常消费这条消息。\n\t* 另外，若发生网络闪断、生产者应用重启等情况，导致某条消息的二次确认丢失，那么 RocketMQ 服务端需要主动向消息生产者询问该消息的最终状态（Commit 或 Rollback），该询问过程即消息回查\n\n## 扩展能力\n\n消息队列集群到达瓶颈的时候，需要对集群进行扩容。扩容一般分为水平扩容和垂直扩容两种方式：\n\n* 水平扩容指的是往集群中增加节点，\n* 垂直扩容指的是把集群中部分节点的配置调高以增加其处理能力\n\n在分布式系统中，大家更加期待能够发挥分布式集群的水平扩容能力。\n\n* Kafka 是一个存储与计算混合的消息队列。由于 Kafka 集群采用主题物理分区设计，数据会存储在服务端节点上，而**新加入集群的节点并没有存储分区，所以无法马上对外提供服务**。因此需要把一些主题的分区分配到新加入的节点，此时需要运维人员介入。\n* 由于采用了主备设计，RocketMQ 的服务端扩展能力比较强，只要将主备设备新增到集群中即可。但是需要在扩容完毕后，在新增的服务端节点创建对应的主题和订阅组信息。\n* RocketMQ 服务端具备读、写权限控制能力，可以针对单个主题的单个队列进行读写控制，这非常便于进行运维操作。\n\n# 功能特性\n\n## 消息模式\n\n* 消息队列一般有两种消息读取模式—点对点 (Point to Point, P 2 P)模式和发布订阅模式 \n\t* RabbitMQ 采用的是点对点模式，而 Kafka、Pulsar 与 RocketMQ 采用的是发布订阅模式。不过在 RabbitMQ 中可以通过设置交换器类型实现发布订阅模式以达到广播消费的效果，在发布订阅模式中也能以点对点的形式进行消息消费。\n\n\n* 消息的可回溯性也是消息队列的重要特性。一般消息在消费完成之后就被处理了，之后再也不能消费该条消息。通过消息回溯可在消息被消费完成之后，再次消费该消息\n\t* Kafka、Pulsar、RocketMQ 都支持消息回溯，可以根据时间戳或指定消费位置，重置消费组的偏移量使对应消息可以被重复消费。RabbitMQ 不支持回溯，消息一旦被标记确认就会被删除\n\n* 对于业务场景中对消息队列的使用需求，我们称为传统的消息队列应用场景。消息队列的主要应用场景包括**低延迟订阅服务、流量削峰、异步请求处理**等\n* 在大数据系统中，消息队列是**流数据的存储介质**，是连接实时计算的基础组件，为大数据系统提供缓存与部分存储能力\n\t* 高吞吐量是最先被考虑的指标。例如，目前大数据的流处理系统事实标准 Kafka 就用了诸多设计来保障高吞吐量。首先，Kafka 使用了物理分区的设计（每个分区对应独立的存储文件），这使我们可以利用磁盘的顺序写入特性来增加吞吐量；其次，Kafka 使用了页缓存与零拷贝的底层技术，这也增加了消息队列的吞吐量\n\n## 多租户\n\n多租户是一种软件架构技术，主要用来实现多用户的环境下共用相同的系统或程序组件，并确保各用户的数据具有一定的隔离性。\n\n* RabbitMQ 支持多租户技术，每一个租户为一个虚拟主机 (vhost)，本质上是一个独立的小型 RabbitMQ 服务器，具有自己独立的队列、交换器、绑定关系及权限等*\n* 官方原生的 Kafka 没有完善的体系化多租户功能，但是包含一些配额管理与用户管理功能。基于 Kafka 协议的部分商业版消息队列支持多租户功能。例如 CKafka (Cloud Kafka)是一个具有分布式、高吞吐量、高可扩展等特性的消息系统，完全兼容开源 Kafka API 0.9.0 至 2.8.0版本\n* Pulsar 是天生支持多租户的消息队列。Pulsar 租户可以分布在多个集群中，并且每个租户都可以应用自己的身份验证和授权方案。命名空间是租户内的独立管理单元。在命名空间上设置的配置策略适用于在该命名空间中创建的所有主题\n\n## 优先级队列\n\n优先级队列不同于先进先出队列，优先级高的消息具备优先被消费的特权，这样可以为下游提供不同消息级别。\n\n优先级队列在消费速度小于生产速度时才有意义，因为只有这样才可以保证高优先级消息总是被消费\n\n\n* **RabbitMQ 支持优先级队列**，使用客户端提供的可选参数即可为任何队列设定优先级。\n* Kafka、RocketMQ、Pulsar 皆**不支持原生的优先级队列**，若想在这 3 类消息队列中使用优先级队列功能，需要**用户通过不同主题或分区在业务层进行优先级划分**。\n\n## 延迟队列\n\n在一般的消息队列中，消息一旦入队就会被马上消费，而进入延迟队列的消息会被延迟消费。延迟队列存储的是延迟消息。所谓延迟消息是指消息被发送以后，并不想让消费者立刻拿到，而是等到特定时间消费者才能拿到的消息\n\n* RabbitMQ：在 3.6 版本后，RabbitMQ **官方提供了延迟队列的插件**。RabbitMQ 需要在服务端插件目录中安装 rabbitmq_delayed_message_exchange 插件才能使用延迟队列功能 \n* Kafka：Kafka 基于时间轮 (TimingWheel)自定义了一个用于实现延迟功能的定时器。但是该定时器无法被用户使用，仅用于实现内部的延时操作，比如延时请求和延时删除等。**因此 Kafka 不支持用户使用延迟队列**\n* RocketMQ 开源版：RocketMQ 将延迟消息临时存储在一个内部主题中，**不支持任意时间精度，支持特定的延迟级别**，如 5 s、10 s、1 min 等。RocketMQ 发送延迟消息时，会在写入存储数据前将消息按照设置的延迟时间发送到指定的定时队列中。**每个定时队列对应一个定时器**。RocketMQ 通过定时器对定时队列进行轮询，并查看消息是否到期。若消息到期，RocketMQ 会将这条消息写入存储\n* Pulsar：支持秒级的延迟消息，所有延迟投递的消息都会被内部组件跟踪，消费组在消费消息时，会先去延迟消息追踪器中检查，以明确是否有到期需要投递的消息 \n\n## 重试队列和死信队列\n\n\n在提供消息不丢失保障功能的消息队列中，这条消息就可能会被不断处理，从而导致消息队列陷入死循环。为了解决这个问题，消息队列系统可以为需要重试的消息提供一个**重试队列**，由重试队列进行消息重试\n\n在消息队列中，当由于某些原因导致消息多次重试，仍无法被正确投递时，为了确保消息不被无故丢弃，一般将其置于一个特殊角色的队列，这个队列一般称为**死信队列** (Dead-Letter Queue)。\n\n\n* RabbitMQ 支持消息重试，可以对最大重试次数、重试间隔时间等进行设置。RabbitMQ 也支持死信队列。当队列中的消息超出重试次数或生存时间时，如果 RabbitMQ 配置了死信队列，那么这些应该被丢弃的消息会被放入死信队列中。\n* RocketMQ 中每个消费组都有一个重试队列，并且消息重试超过一定次数后就会被放入死信队列中\n* Kafka 暂不支持死信队列。\n* Pulsar 也支持死信队列。在 Pulsar 中某些消息可能会被多次重新传递，甚至可能永远都在重试中。通过使用死信队列，可让消息具有最大重新传递次数。当实际传递次数超过最大重新传递次数时，对应的消息会被发送到死信主题并自动确认。","lastmodified":"2024-03-02T12:01:53.982209973Z","tags":[]},"/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Pulsar/1.Pulsar%E6%A6%82%E8%BF%B0":{"title":"1.Pulsar概述","content":"Pulsar 是一个分布式发布、订阅 (pub-sub)消息的平台，具有非常灵活的消息传递模型以及跨语言的客户端 API。Pulsar 也是一个集消息传递、消息存储、轻量化函数式计算于一体的流数据平台。Pulsar 采用了计算与存储分离的架构，支持**云原生、多租户、持久化存储、多机房跨区域数据复制**等，具有高一致性、高吞吐、低延时及高可扩展性等流数据存储系统特性\n\n# Pular 不只是消息队列\n\n1. Pulsar 是一个分布式消息平台，可以同时处理**流式数据和异构系统数据对**接这两类问题\n2. 1Pulsar 是一个分布式消息平台，可以同时处理流式数据和异构系统数据对接这两类问题\n3. Pulsar 是一个集消息传递、消息存储、轻量化函数式计算于一体的流数据平台\n4. Pulsar 是一个分布式可扩展的流式存储系统，并在数据存储的基础上构建了消息队列和流服务的统一模型\n\n# 存储计算分离\n\n### 存储计算结合\n\n* 在 Kafka 中，每个分区的管理与存储职能都依赖其中一个服务端节点（承担分区 Leader 角色的 Broker 节点）。\n* 该节点在处理数据写入请求的同时，会将数据写到本机的存储路径下，并负责向其他副本写入数据。\n* 在数据的读取过程中，该节点负责读取磁盘数据并发送回客户端。\n\n\n存储与计算功能都由一个 Kafka Broker 节点负责，这样可简化服务端处理流程，增大单机的处理吞吐量。RabbitMQ 和 RocketMQ 与 Kafka 类似，采用的也是存储与计算相结合的设计方式。\n\n\n### Pulsar 存储与计算分离的原理\n\nPulsar 是一个存储与计算分离的消息队列，其中\n\n* 提供计算服务的角色被称为 **Broker**，提供的是无状态的计算服务\n* 提供存储服务的角色被称为 **Bookie**，提供的是有状态的存储服务\n\n\n\nPulsar 中的数据会以数据块的形式分配到不同的 Bookie 节点。当存储资源不够时，可通过增加 Bookie 节点进行扩容。Pulsar 会感知 Bookie 集群的变化，并在合适的时机使用新增加的 Bookie 节点进行存储\n\n\n\n# 云原生架构\n\n云原生的代表技术包括**容器、服务网格 (Service Mesh)、微服务、不可变基础设施和声明式 API** 等。利用这些技术能够构建容错性好、易于管理和便于观察的松耦合系统。\n\n\n* Pulsar 是一个云原生应用，拥有诸多云原生应用的特性，如无状态计算层、计算与存储分离，可以很好地利用云的弹性（伸缩能力），从而具有足够高的扩容性和容错性 \n* Pulsar 对 Kubernetes 有良好的支持。在开源项目 Apache Pulsar Helm Chart[插图]的支持下，Pulsar 可以保障业务轻松迁移到 Kubernetes 环境中。在 Apache Pulsar Helm Chart 项目中，Kubernetes 可以单独管理各类组件，如 Zookeeper、Bookie、Broker、Function、Proxies。除此之外，Apache Pulsar Helm Chart 项目中还集成了 Pulsar 的管理与监控工具，如 Pulsar Manager、Prometheus 与 Grafana。\\\n\n\n# Pulsar 的存储特性\n\nPulsar 依赖 BookKeeper 构建存储能力，并因此具备了分块存储、分层存储、存储与计算分离的特性\n\n\n使用**分块存储**的系统有着悠久的历史，从 GFS（Google File System，Google 文件系统）到开源的 HDFS (Hadoop File System)。基于分块存储的文件系统可以运行在廉价的普通硬件设备上，并提供灾难冗余的能力\n\n通过对比 Kafka 与 RocketMQ 来介绍 Pulsar 的分块存储结构。\n\n\n### Kafka 的存储结构 \n\n* Kafka 基于**只追加日志文件**策略构建了核心存储结构，消息队列中的数据以日志的方式进行组织，对日志的所有写操作都提交在日志的最末端，而对日志的读取也只能按顺序进行\n* 每个主题的每个分区都对应着一个独立文件，Kafka 的分区对应着文件系统的物理分区. 该设计让 Kafka 具有了高吞吐量与低成本的优\n\n\nKafka 可以借助多分区来实现主题级别的扩展，也可以通过增加物理机的方式实现一定程度的横向扩容。但是，也正是因为这种存储结构，在大规模集群中使用 Kafka 会引入了新的问题。\n\n* 会带来额外的运维成本。在 Kafka 中每一个分区都只能归属于一台机器，即 ISR（In-Sync Replicas，同步的副本）集合中的一个主节点。**Kafka 的多个数据副本只能保证高可用性**，每个分区的容量大小受限于主节点的磁盘大小\n* 有单机分区上限问题。每个 Kafka 分区都会使用一个顺序写入的文件进行数据存储。有单机分区上限问题。每个 Kafka 分区都会使用一个顺序写入的文件进行数据存储。\n\n### RocketMQ 的存储结构\n\n* 在 RocketMQ 消息队列中，消息的存储是由内部的消费队列 (ConsumeQueue)和提交日志 (CommitLog)配合完成的消息的物理存储文件是 CommitLog,ConsumeQueue 是消息的逻辑队列，在消息队列中起索引的作用\n* 在 RocketMQ 中每个实际的主题都对应着一个 ConsumeQueue，其中存放着 CommitLog 中所有消息的存放位置。\n* CommitLog 以物理文件的形式存放在服务器中，并被当前服务器中所有 ConsumeQueue 共享。不同于 Kafka 使每个逻辑队列都对应着一个物理分区，RocketMQ 采用**物理存储与逻辑队列相互分离的分区方式**\n\n\n\n### Pulsar的存储结构\n\n\nPulsar 利用 BookKeeper 实现了分块存储的能力，它在一定程度上兼具 Kafka 物理分区与 RocketMQ 逻辑分区的优点\n\n\nEdger 代表一个独立日志块或一段数据流，是持久化存储的单元。记录会被有序地写入 Ledger 中。数据一经写入就不允许进行修改了。Pulsar 能够将每个主题映射为多个独立的数据段，**每个数据段对应一个 Ledger**\n\n**每个 Ledger 都拥有独立的 I/O 能力**，Pulsar 可以将 Broker 上的网络 I/O 均匀分布在不同的 Bookie 节点上，又可以充分利用 Bookie 节点的 I/O 能力。Pulsar 通过 BookKeeper 获得了容量和吞吐量方面的水平可扩展能力.\n\nPulsar 通过 BookKeeper 获得了容量和吞吐量方面的水平可扩展能力，通过向集群添加更多 Bookie 节点，可以立即增加容量与吞吐量。\n\n\n\n# 消息协议\n\n\nPulsar 支持可插拔的协议处理机制，可以在运行时动态加载额外的**协议处理程序**。**基于消息队列协议层**，目前 Pulsar 已经支持 Kafka、RocketMQ、AMQP 和 MQTT 等多种协议。并将自身云原生、分层存储、自动负载管理等诸多特性推广至更多的消息队列系统\n\n\nPulsar 协议层支持的 Kafka 项目为 Kafka on Pulsar (KoP)协议。通过将 KoP 协议部署在现有的 Pulsar 集群中，用户可以在 Pulsar 集群中继续使用原生的 Kafka 协议，同时能够利用 Pulsar 的强大功能，完善存量 Kafka 应用的使用体验。\n\n\n\n# 消费方式\n\n\n消费者从消息队列中读取数据有两种方法—主动拉取（Pull 模式）与被动接收（Push 模式）\n\n* 在 Pull 模式下，消费者会不断轮询消息队列，判断是否有新的数据，如果有就读取该数据。 \n* 在 Push 模式下，一旦生产者有新数据放入消息队列中，系统就会推送给消费者。\n\n\n**RocketMQ 与 Kafk都基于 Pull 模式进行数据读取**。Pull 模式的优势在于可以控制数据的消费速度和消费数量，保证消费者不会达到饱和状态\n\n\n**Pulsar 中的消费者在读取数据时采用以 Push 模式为主、Pull 模式为辅的同步模式**。Pulsar 中的客户端有一个缓冲队列。客户端会向服务端发送流量配额请求，服务端会主动向客户端推送配额允许范围内的数据。\n\n* 消费者连接建立后，服务端通过配额向消费者推送数据。\n* 与此同时，消费者每消费一条数据都会增加客户端流量配额计数，在配额计数达到队列的一半时，客户端会再次发送流量配额请求，请求服务端推送数据\n\n\n# 生态\n\nPulsar 官方提供了多种导入与导出数据的连接器。通过简单地配置 Pulsar I/O，可灵活地将 Pulsar 与关系型数据库、非关系型数据库（如 MongoDB）、数据湖、Hadoop 生态等外部系统相结合\n\n\nPulsar 可以用于存储结构化数据。结构化数据由预定义的字段构成，Pulsar 提供了 Schema 功能来进行结构化定义。通过 Pulsar SQL 功能，Trino Pulsar 连接器使 Trino 集群内的 Trino Worker 能够通过 SQL 语句查询数据。\n\n\n在 Pulsar 中使用运维管理与监控工具，如 Prometheus、Grafana、Pulsar Manager 等，能够减少在运维、优化、排错方面的投入\n\n\nPulsar 可以与多种大数据生态结合，如 Kafka、HDFS、HBase、Flink、Spark、Trino\n\n\n\n# 消息队列对比\n\n### RabbitMQ\n\nRabbitMQ 是采用 Erlang 语言实现的 AMQP 消息中间件, AMQP 是一种用于异步消息传递的应用层协议，AMQP 客户端能够无视消息来源，任意发送和接收消息，服务端负责提供消息路由、队列等功能。\n\n\nRabbitMQ 的服务端节点称为 Broker。Broker 主要由交换器 (Exchange)和队列 (Queue)组成。\n\n* 交换器负责接收与转发消息。\n* 队列负责存储消息，提供持久化等功能。\n* AMQP 客户端通过 AMQP 信道 (Channel)与 Broker 通信，通过该信道生产者与消费者完成数据发送与接收。\n\n### RocketMQ\n\n\nRocketMQ 的架构可以分为 4 个部分—Broker、NameServer、Producer、Consumer。\n\n* RocketMQ 的服务端节点称为 Broker，Broker 负责管理消息存储分发、主备数据同步、为消息建立索引、提供消息查询等。\n* NameServer 主要用来管理所有的 Broker 节点及路由信息。\n* Producer 与 Consumer 负责数据发送与接收。\n\nRocketMQ Broker 依靠主备同步实现高可用，消息到达主服务器后，需要同步到备用服务器上，默认情况下 RocketMQ 会优先选择从主服务器拉取消息, 如果主服务器宕机，消费者可从备用服务器拉取消息。备用服务器会通过定时任务从主服务器定时同步路由信息、消息消费进度、延迟队列处理进度、消费组订阅信息等\n\n\nRocketMQ 5.0 版本在架构上进行了存储与计算的分离改造。它引入无状态的 Proxy 集群来承担计算职责，原 Broker 节点逐步演化为以存储为核心的有状态集群。在不同场景下，可以根据应用场景和部署环境（公有云或私有云）为 RocketMQ 选择存储与计算一体化或者分离的使用方式","lastmodified":"2024-03-02T12:01:53.978209987Z","tags":[]},"/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Pulsar/2.doccker-%E4%B8%AD%E5%90%AF%E5%8A%A8-standalone-Pulsar":{"title":"2.doccker 中启动 standalone Pulsar","content":"\n```\n\n$ docker run -it -p 6650:6650  -p 8080:8080 --mount source=pulsardata,target=/pulsar/data --mount source=pulsarconf,target=/pulsar/conf apachepulsar/pulsar:@pulsar:version@ bin/pulsar standalone\n\n```","lastmodified":"2024-03-02T12:01:53.978209987Z","tags":[]},"/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/%E5%9C%BA%E6%99%AF%E9%A2%98/%E5%A6%82%E4%BD%95":{"title":"如何","content":"\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticPasted%20image%2020230802012455.png)","lastmodified":"2024-03-02T12:01:53.982209973Z","tags":[]},"/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/%E5%9C%BA%E6%99%AF%E9%A2%98/%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E4%B8%80%E4%B8%AA%E6%8E%92%E8%A1%8C%E6%A6%9C":{"title":"如何设计一个排行榜？","content":"![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticPasted%20image%2020230802012459.png)","lastmodified":"2024-03-02T12:01:53.982209973Z","tags":[]},"/%E8%B5%84%E6%BA%90/%E8%B5%84%E6%BA%90%E6%B1%87%E6%80%BB":{"title":"资源汇总","content":"","lastmodified":"2024-03-02T12:01:53.98620996Z","tags":[]},"/GO/%E5%85%AB%E8%82%A1%E6%96%87/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E5%92%8CGC":{"title":"内存管理","content":"\n# 内存管理\n\n## Golang 的内存模型，为什么小对象多了会造成 gc 压力。\n\n通常小对象过多会导致 GC 三色法消耗过多的 GPU。优化思路是，减少对象分配。\n\n## Go 语言什么时候垃圾回收，写代码的时候如何减少对象分配\n\n当 **goroutine 申请新的内存管理单元时触发垃圾回收**。\n\n写代码的时候如何减少对象分配，这是一个关于性能的问题，\n\n* 例如如果需要把数字转换成字符串，使用 strconv.Itoa () 比 fmt.Sprintf () 要快一倍左右。\n\n* 如果需要把数字转换成字符串，使用 strconv.Itoa () 比 fmt.Sprintf () 要快一倍左右。这里就不一一展开了。\n\n\n## 给大家丢脸了，用了三年 Golang，我还是没答对这道内存泄漏题\n\nhttps://mp.weixin.qq.com/s?__biz=MzkxNTU5MjE0MQ==\u0026mid=2247492761\u0026idx=1\u0026sn=7b3660c3da402fa7f4c49b1ca8048f22\u0026source=41#wechat_redirect\n\n## Go 内存泄漏？不是那么简单\n\n[https://colobu.com/2019/08/28/go-memory-leak-i-dont-think-so/](https://colobu.com/2019/08/28/go-memory-leak-i-dont-think-so/) \n\n##  Go 内存分配，和 tcmalloc 的区别?\n\n### GO 内存分配\n\nGo 内存分配核心思想就是把内存分为多级管理，从而降低锁的粒度。\n\n它将可用的堆内存采用二级分配的方式进行管理：**每个线程都会自行维护一个独立的内存池，进行内存分配时优先从该内存池中分配，当内存池不足时才会向全局内存池申请，以避免不同线程对全局内存池的频繁竞争**。\n\n- Go 在程序启动时，会向操作系统申请一大块内存，之后自行管理。\n- Go 内存管理的基本单元是 mspan，它由若干个页组成，每种 mspan 可以分配特定大小的 object。\n- Mcache, mcentral, mheap 是 Go 内存管理的三大组件，层层递进。\n\t- Mcache 管理线程在本地缓存的 mspan；\n\t- mcentral 管理全局的 mspan 供所有线程使用；\n\t- mheap 管理 Go 的所有动态分配内存。\n- 分配对象\n\t- 极小的对象 (\u003c=16B)会分配在一个 object 中，以节省资源，使用 tiny 分配器分配内存；\n\t- 一般对象(16B-32KB)通过 mspan 分配内存；\n\t- 大对象(\u003e32 KB)则直接由 mheap 分配内存。\n\n### **tcmalloc**  \n\n\nTcmalloc 是 google 开发的内存分配算法库，最开始它是作为 google 的一个性能工具库 perftools 的一部分。TCMalloc 是用来替代传统的 malloc 内存分配函数。它有减少内存碎片，适用于多核，更好的并行性支持等特性。  \n**TC 就是 Thread Cache 两英文的简写**。它提供了很多优化，如：  \n1. TCMalloc 用**固定大小的 page (页)来执行内存获取、分配等操作**。这个特性跟 Linux 物理内存页的划分是不是有同样的道理。  \n\t1. TCMalloc 用固定大小的对象，比如 8 KB，16 KB 等用于特定大小对象的内存分配，这对于内存获取或释放等操作都带来了简化的作用。  \n2. TCMalloc 还**利用缓存常用对象来提高获取内存的速度**。  \n3. TCMalloc 还可以**基于每个线程或者每个 CPU 来设置缓存大小**，这是默认设置。  \n\t1. TCMalloc 基于每个线程独立设置缓存分配策略，减少了多线程之间锁的竞争。\n\nGo 中的内存分类并不像 TCMalloc 那样分成小、中、大对象，但是它的小对象里又细分了一个 Tiny 对象，Tiny 对象指大小在 1 Byte 到 16 Byte 之间并且不包含指针的对象。小对象和大对象只用大小划定，无其他区分。  \n\n\n\nGo 内存管理与 tcmalloc 最大的不同在于，**它提供了逃逸分析和垃圾回收机制。**\n\n\n\n## Go 语言中的堆和栈\n\n* **栈主要用来存储值类型的数据**，如**整数、浮点数、布尔值**等。因为值类型的数据大小是固定的，所以可以直接分配在栈上，访问速度非常快。\n\n* **堆主要用来存储引用类型的数据**，如字**符串、切片、字典**等。因**为引用类型的数据大小是不固定的，所以需要动态分配内存，通常在堆上进行**。同时，由于引用类型的数据通常需要共享和修改，因此使用指针来进行引用和操作，从而避免了复制大量的数据。\n\n可以看出，栈的性能会更好——**不需要额外的垃圾回收机制**（离开该作用域，它们的内存就会被自动回收），**CPU 可以连续缓存**（内存空间是连续的）。堆是通过**GC 回收内存**的。\n\n\n# Go 内存分配机制？\n\nGo 语言内置运行时（就是 runtime），抛弃了传统的内存分配方式，改为自主管理。这样可以自主地实现更好的内存使用模式，比如内存池、预分配等等。这样，不会每次内存分配都需要进行系统调用。\n\n\n\n## 操作系统的内存管理\n\n###  操作系统存储模型\n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240227194910.png)\n\n观察上图，我们可以从中捕捉到的关键词是：\n\n- 多级模型\n    \n- 动态切换\n\n### 虚拟内存与物理内存\n\n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240227194940.png)\n\n\n操作系统内存管理中，另一个重要概念是虚拟内存，其作用如下：\n\n- 在用户与硬件间添加中间代理层（没有什么是加一个中间层解决不了的）\n    \n-  优化用户体验（进程感知到获得的内存空间是“连续”的）\n    \n-  “放大”可用内存（虚拟内存可以由物理内存+磁盘补足，并根据冷热动态置换，用户无感知）\n\n###  分页管理\n\n\n操作系统中通常会将虚拟内存和物理内存切割成固定的尺寸，于虚拟内存而言叫作“页”，于物理内存而言叫作“帧”，原因及要点如下：\n\n- 提高内存空间利用（以页为粒度后，消灭了不稳定的外部碎片，取而代之的是相对可控的内部碎片）\n    \n-  提高内外存交换效率（更细的粒度带来了更高的灵活度）\n    \n-  与虚拟内存机制呼应，便于建立虚拟地址-\u003e物理地址的映射关系（聚合映射关系的数据结构，称为页表）\n    \n-  linux 页/帧的大小固定，为 4KB（这实际是由实践推动的经验值，太粗会增加碎片率，太细会增加分配频率影响效率）\n\n\n## GO 内存模型设计思想\n\n- 内存分配算法采用 Google 的 `TCMalloc算法`，**每个线程都会自行维护一个独立的内存池**，进行内存分配时优先从该内存池中分配，当内存池不足时才会向加锁向全局内存池申请，减少系统调用并且避免不同线程对全局内存池的锁竞争\n- 把内存切分的非常的细小，**分为多级管理**，以降低锁的粒度\n- 回收对象内存时，并没有将其真正释放掉，只是放**回预先分配的大块内存中**，以便复用。只有内存闲置过多的时候，才会尝试归还部分内存给操作系统，降低整体开销\n\n\n具体来说\n\n1. 以空间换时间，一次缓存，多次复用\n    \n\n由于**每次向操作系统申请内存的操作很重，那么不妨一次多申请一些**，以备后用.\n\nGolang 中的堆 mheap 正是基于该思想，产生的数据结构. 我们可以从两个视角来解决 Golang 运行时的堆：\n\n* I 对操作系统而言，这是用户进程中缓存的内存\n\n* II 对于 Go 进程内部，堆是所有对象的内存起源\n\n2.  多级缓存，实现无/细锁化\n    \n\n![图片](https://mmbiz.qpic.cn/mmbiz_png/3ic3aBqT2ibZuXibKvib2fj2vlIia93waBCNwL6syk6puNxa0Wx0XfnO48n3o4AM8MNRSicNOcDp3Q9Eicib2j7BIibkqEA/640?wx_fmt=png\u0026wxfrom=5\u0026wx_lazy=1\u0026wx_co=1)\n\n堆是 Go 运行时中最大的临界共享资源，这意味着**每次存取都要加锁**，在性能层面是一件很可怕的事情.\n\n在解决这个问题，Golang 在堆 mheap 之上，依次细化粒度，建立了 mcentral、mcache 的模型，下面对三者作个梳理：\n\n- mheap：全局的内存起源，访问要加全局锁\n    \n- mcentral：每种对象大小规格（全局共划分为 68 种）对应的缓存，锁的粒度也仅限于同一种规格以内\n    \n-  mcache：每个 P（正是 GMP 中的 P）持有一份的内存缓存，访问时无锁\n\n这些概念，我们在第 2 节中都会再作详细展开，此处可以先不深究，注重于宏观架构即可.\n\n-  多级规格，提高利用率\n    \n\n![图片](https://mmbiz.qpic.cn/mmbiz_png/3ic3aBqT2ibZuXibKvib2fj2vlIia93waBCNwkDibfnBcJn5nOCyDic2gHABzy2TKIKrqN27Nnw3jXrudGb8rcYIjcHCQ/640?wx_fmt=png\u0026wxfrom=5\u0026wx_lazy=1\u0026wx_co=1)\n\n首先理下 page 和 mspan 两个概念：\n\n（1）page：最小的存储单元.\n\nGolang 借鉴操作系统分页管理的思想，每个最小的存储单元也称之为页 page，但大小为 8 KB\n\n（2）mspan：最小的管理单元.\n\nmspan 大小为 page 的整数倍，且从 8B 到 80 KB 被划分为 67 种不同的规格，分配对象时，会根据大小映射到不同规格的 mspan，从中获取空间.\n\n于是，我们回头小节多规格 mspan 下产生的特点：\n\n* I 根据规格大小，产生了等级的制度\n\n* II 消除了外部碎片，但不可避免会有内部碎片\n\n* III 宏观上能提高整体空间利用率\n\n* IV 正是因为有了规格等级的概念，才支持 mcentral 实现细锁化\n\n4. • 全局总览，留个印象\n    \n\n![图片](https://mmbiz.qpic.cn/mmbiz_png/3ic3aBqT2ibZuXibKvib2fj2vlIia93waBCNwkd8rJZ9b0h745aibfNReUePg2bqzT4ibrB6rrxzlzf6fMZnXib87O5o4w/640?wx_fmt=png\u0026wxfrom=5\u0026wx_lazy=1\u0026wx_co=1)\n\n上图是 Thread-Caching Malloc 的整体架构图，Golang 正是借鉴了该内存模型. 我们先看眼架构，有个整体概念，后续小节中，我们会不断对细节进行补充.\n\n\n\n## 分配组件\n\nGo 的内存管理组件主要有：`mspan`、`mcache`、`mcentral` 和 `mheap`\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226003340.png)\n## 内存管理单元：mspan\n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240227195526.png)\n\n\n\n\n-  mspan 是 Golang 内存管理的最小单元，该结构体中包含 `next` 和 `prev` 两个字段，它们分别指向了前一个和后一个 mspan\n    \n- mspan 大小是 page 的整数倍（Go 中的 page 大小为 8KB），且内部的页是连续的（至少在虚拟内存的视角中是这样），这里的页不是操作系统中的内存页，它们是操作系统内存页的整数倍。\n    \n-  每个 mspan 根据空间大小以及面向分配对象的大小，会被划分为不同的等级（2.2小节展开）\n    \n-  同等级的 mspan 会从属同一个 mcentral，最终会被组织成链表，因此带有前后指针（prev、next）\n    \n-  由于同等级的 mspan 内聚于同一个 mcentral，所以会基于同一把互斥锁管理\n    \n-  mspan 会基于 **bitMap 辅助快速找到空闲内存块**（块大小为对应等级下的 object 大小），此时需要使用到 **Ctz64 算法**.\n\n`page` 是内存存储的基本单元，“对象”放到 `page` 中\n\n```\ntype mspan struct {\n    // 标识前后节点的指针 \n    next *mspan     \n    prev *mspan    \n    // ...\n    // 起始地址\n    startAddr uintptr \n    // 包含几页，页是连续的\n    npages    uintptr \n\n\n    // 标识此前的位置都已被占用 \n    freeindex uintptr\n    // 最多可以存放多少个 object\n    nelems uintptr // number of object in the span.\n\n\n    // bitmap 每个 bit 对应一个 object 块，标识该块是否已被占用\n    allocCache uint64\n    // ...\n    // 标识 mspan 等级，包含 class 和 noscan 两部分信息\n    spanclass             spanClass    \n    // ...\n}\n```\n\n\n\n## 内存单元等级 spanClass\n\nGo 有 68 种不同大小的 spanClass，用于小对象的分配\n\n```\nconst _NumSizeClasses = 68\nvar class_to_size = [_NumSizeClasses]uint16{0, 8, 16, 32, 48, 64, 80, 96, 112, 128, 144, 160, 176, 192, 208, 224, 240, 256, 288, 320, 352, 384, 416, 448, 480, 512, 576, 640, 704, 768, 896, 1024, 1152, 1280, 1408, 1536,1792, 2048, 2304, 2688, 3072, 3200, 3456, 4096, 4864, 5376, 6144, 6528, 6784, 6912, 8192, 9472, 9728, 10240, 10880, 12288, 13568, 14336, 16384, 18432, 19072, 20480, 21760, 24576, 27264, 28672, 32768}\n```\n\n如果按照序号为 1 的 spanClass（对象规格为 8 B）分配，每个 span 占用堆的字节数：8 k，mspan 可以保存 1024个对象\n\n如果按照序号为 2 的 spanClass（对象规格为 16 B）分配，每个 span 占用堆的字节数：8 k，mspan 可以保存 512个对象\n\n…\n\n如果按照序号为 67 的 spanClass（对象规格为 32 K）分配，每个 span 占用堆的字节数：32 k，mspan 可以保存1个对象\n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226003424.png)\n\n\n字段含义：\n\n- Class： class ID，每个 span 结构中都有一个 class ID, 表示该 span 可处理的对象类型\n- Bytes/obj：该 class 代表对象的字节数\n- Bytes/span：每个 span 占用堆的字节数，也即页数*页大小\n- Objects: 每个 span 可分配的对象个数，也即（bytes/spans）/（bytes/obj）\n- Waste bytes: 每个 span 产生的内存碎片，也即（bytes/spans）%（bytes/obj）\n\n大于 32 k 的对象出现时，会直接从 heap 分配一个特殊的 span，这个特殊的 span 的类型 (class)是 0, 只包含了一个大对象\n\n\n代码位于 runtime/mheap.go\n\n```\ntype spanClass uint8\n\n\n// uint8 左 7 位为 mspan 等级，最右一位标识是否为 noscan\nfunc makeSpanClass(sizeclass uint8, noscan bool) spanClass {\n    return spanClass(sizeclass\u003c\u003c1) | spanClass(bool2int(noscan))\n}\n\n\nfunc (sc spanClass) sizeclass() int8 {\n    return int8(sc \u003e\u003e 1)\n}\n\n\nfunc (sc spanClass) noscan() bool {\n    return sc\u00261 != 0\n}\n```\n\n## 线程缓存：mcache\n\n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240227201105.png)\n\n\n\nmcache 管理线程在本地缓存的 mspan，每个 goroutine 绑定的 P 都有一个 `mcache` 字段\n\n```\ntype mcache struct {\n\t // 微对象分配器相关\n    tiny       uintptr\n    tinyoffset uintptr\n    tinyAllocs uintptr\n\n\t // mcache 中缓存的 mspan，每种 spanClass 各一个\n    alloc [numSpanClasses]*mspan\n    \n}\n\n_NumSizeClasses = 68\nnumSpanClasses = _NumSizeClasses \u003c\u003c 1\n```\n\n* `mcache` 是每个 P 独有的缓存，因此交互无锁\n\n* `mcache` 用 `Span Classes` 作为索引管理多个用于分配的 `mspan`，它包含所有规格的 `mspan`。它是 `_NumSizeClasses` 的 2 倍，也就是 `68*2=136`，\n\t* 其中* 2 是将 spanClass 分成了有指针和没有指针两种, 方便与垃圾回收。\n\t* 对于每种规格，有 2 个 mspan，一个 mspan 不包含指针，另一个 mspan 则包含指针。对于无指针对象的 `mspan` 在进行垃圾回收的时候无需进一步扫描它是否引用了其他活跃的对象。\n\n* `mcache` 在初始化的时候是没有任何 `mspan` 资源的，在使用过程中会动态地从 `mcentral` 申请，之后会缓存下来。当对象小于等于 32 KB 大小时，使用 `mcache` 的相应规格的 `mspan` 进行分配。\n* mcache 中还有一个为对象分配器 tiny allocator，用于处理小于 16B 对象的内存分配，在 3.3 小节中详细展开.\n\n## 中心缓存：mcentral\n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240227201114.png)\n\n\n\n\nMcentral 管理全局的 mspan 供所有线程使用，全局 mheap 变量包含 central 字段，每个 mcentral 结构都维护在**mheap**结构内\n \n```\ntype mcentral struct {\n    spanclass spanClass // 指当前规格大小\n\n    partial [2]spanSet // 有空闲object的mspan列表\n    full    [2]spanSet // 没有空闲object的mspan列表\n}\n```\n\n* 每个 mcentral 管理一种 spanClass 的 mspan，\n* 每个 mcentral 下聚合了该 spanClass 下的 mspan\n* 并将有空闲空间和没有空闲空间的 mspan 分开管理。Partial 和 full `的数据类型为` spanSet，表示 `mspans` 集，可以通过 pop、push 来获得 mspans\n* 每个 mcentral 一把锁\n\n```\ntype spanSet struct {\n    spineLock mutex\n    spine     unsafe.Pointer // 指向[]span的指针\n    spineLen  uintptr        // Spine array length, accessed atomically\n    spineCap  uintptr        // Spine array cap, accessed under lock\n\n    index headTailIndex  // 前32位是头指针，后32位是尾指针\n}\n```\n\n简单说下 `mcache` 从 `mcentral` 获取和归还 `mspan` 的流程：\n\n- 获取；加锁，从 `partial` 链表找到一个可用的 `mspan`；并将其从 `partial` 链表删除；将取出的 `mspan` 加入到 `full` 链表；将 `mspan` 返回给工作线程，解锁。\n- 归还；加锁，将 `mspan` 从 `full` 链表删除；将 `mspan` 加入到 `partial` 链表，解锁。\n\n## 页堆：mheap\n\nMheap 管理 Go 的所有动态分配内存，可以认为是 Go 程序持有的整个堆空间，全局唯一\n\n```\nvar mheap_ mheap\n\ntype mheap struct {\n    // 堆的全局锁\n    lock mutex\n\n\n    // 空闲页分配器，底层是多棵基数树组成的索引，每棵树对应 16 GB 内存空间\n    pages pageAlloc \n\n\n    // 记录了所有的 mspan. 需要知道，所有 mspan 都是经由 mheap，使用连续空闲页组装生成的\n    allspans []*mspan\n\n\n    // heapAreana 数组，64 位系统下，二维数组容量为 [1][2^22]\n    // 每个 heapArena 大小 64M，因此理论上，Golang 堆上限为 2^22*64M = 256T\n    arenas [1 \u003c\u003c arenaL1Bits]*[1 \u003c\u003c arenaL2Bits]*heapArena\n\n\n    // ...\n    // 多个 mcentral，总个数为 spanClass 的个数\n    central [numSpanClasses]struct {\n        mcentral mcentral\n        // 用于内存地址对齐\n        pad      [cpu.CacheLinePadSize - unsafe.Sizeof(mcentral{})%cpu.CacheLinePadSize]byte\n    }\n\n\n    // ...\n}\n```\n\n\n- 对于 Golang 上层应用而言，堆是操作系统虚拟内存的抽象\n  \n- 所有 `mcentral` 的集合则是存放于 `mheap` 中的。`mheap` 里的 `arena` 区域是堆内存的抽象，运行时会将 `8KB` 看做一页，这些内存页中存储了所有在堆上初始化的对象\n    \n- 以页（8KB）为单位，作为最小内存存储单元\n    \n- 负责将连续页组装成 mspan\n    \n- 全局内存基于 **bitMap 标识其使用情况**，每个 bit 对应一页，为 0 则自由，为 1 则已被 mspan 组装\n    \n- 通过 **heapArena 聚合页**，记录了页到 mspan 的映射信息（2.7小节展开）\n    \n- 建立空闲页基数树索引 radix tree index，辅助快速寻找空闲页（2.6小节展开）\n    \n- 是 mcentral 的持有者，持有所有 spanClass 下的 mcentral，作为自身的缓存\n    \n- 内存不够时，向操作系统申请，申请单位为 heapArena（64M） 运行时使用二维的 runtime. HeapArena 数组管理所有的内存，每个 runtime. HeapArena 都会管理 64 MB 的内存。\n\n* 当申请内存时，依次经过 `mcache` 和 `mcentral` 都没有可用合适规格的大小内存，这时候会向 `mheap` 申请一块内存。然后按指定规格划分为一些列表，并将其添加到相同规格大小的 `mcentral` 的 `非空闲列表` 后面\n\n\n##  空闲页索引 pageAlloc\n\n\n代码位于 runtime/mpagealloc.go\n\n```\nconst summaryLevels = 5\n\n\ntype pageAlloc struct {\n    // 共有五层基数树，第一层有 2^14 个节点，因此共用 2^14棵基数树\n    // 总空间大小为 2^14*16GB = 256T\n    // 接下来每层的节点数为上层的 8 倍\n    summary [summaryLevels][]pallocSum\n    \n    // ...\n    // 类似于 tiny offset，小于此值的地址无锁检索，必然没有空间可用\n    searchAddr offAddr\n\n\n    // ...\n}\n```\n\n\n\n\n（1）数据结构背后的含义：\n\n* mheap 会基于 bitMap 标识内存中各页的使用情况，bit 位为 0 代表该页是空闲的，为 1 代表该页已被 mspan 占用.\n\n* 每棵基数树聚合了 16 GB 内存空间中各页使用情况的索引信息，用于帮助 mheap 快速找到指定长度的连续空闲页的所在位置\n\n* mheap 持有 2^14 棵基数树，因此索引全面覆盖到 2^14 * 16 GB = 256 T 的内存空间.\n\n（2）基数树节点设定\n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240227202838.png)\n\n基数树中，每个节点称之为 PallocSum，是一个 **uint64** 类型，体现了索引的聚合信息，包含以下四部分：\n\n-  start：最右侧 21 个 bit，**标识了当前节点映射的 bitMap 范围中首端有多少个连续的 0 bit（空闲页）**，\n    \n- •max：中间 21 个 bit，**标识了当前节点映射的 bitMap 范围中最多有多少个连续的 0 bit（空闲页）**，称之为 max；\n    \n- • end：左侧 21 个 bit，**标识了当前节点映射的 bitMap 范围中最末端有多少个连续的 0 bit（空闲页）**，称之为 end.\n    \n- • 最左侧一个 bit，弃置不用\n\n（2）基数树节点设定\n\n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240227203338.png)\n\n\n- 每个父 pallocSum 有 8 个子 pallocSum\n    \n- 根 pallocSum 总览全局，**映射的 bitMap 范围为全局的 16 GB 空间**（其 max 最大值为 2^21，因此总空间大小为 2^21*8KB=16GB）；\n    \n- 从首层向下是一个依次八等分的过程，每一个 pallocSum 映射其父节点 bitMap 范围的八分之一，因此第二层 pallocSum 的 bitMap 范围为 16GB/8 = 2GB，以此类推，第五层节点的范围为 16GB / (8^4) = 4 MB，已经很小 \n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240227203715.png)\n\n    \n- •聚合信息时，自底向上. 每个父 pallocSum 聚合 8 个子 pallocSum 的 start、max、end 信息，形成自己的信息，直到根 pallocSum，坐拥全局 16 GB 的 start、max、end 信息\n    \n-  mheap 寻页时，自顶向下. 对于遍历到的每个 pallocSum，\n\t- 先看起 start 是否符合，是则寻页成功；\n\t- 再看 max 是否符合，是则进入其下层孩子 pallocSum 中进一步寻访；\n\t- 最后看 end 和下一个同辈 pallocSum 的 start 聚合后是否满足，是则寻页成功.\n\n\t基数树节点 \n\n```\nconst(\n    logMaxPackedValue = 21\n    maxPackedValue    = 1 \u003c\u003c logMaxPackedValue\n)\n\n\ntype pallocSum uint64\n\n\n// 基于 start、max、end 组装成一个基数树节点 pallocSum\nfunc packPallocSum(start, max, end uint) pallocSum {\n    // ...\n    return pallocSum((uint64(start) \u0026 (maxPackedValue - 1)) |\n        ((uint64(max) \u0026 (maxPackedValue - 1)) \u003c\u003c logMaxPackedValue) |\n        ((uint64(end) \u0026 (maxPackedValue - 1)) \u003c\u003c (2 * logMaxPackedValue)))\n}\n\n\n// 当前节点对应区域内，首部连续空闲页的长度\n// 通过 uint64 最右侧 21 个 bit 标识\nfunc (p pallocSum) start() uint {\n    // ...\n    return uint(uint64(p) \u0026 (maxPackedValue - 1))\n}\n\n\n// 当前节点对应区域内，连续空闲页的最大长度\n// 通过 uint64 左数 23~43 个 bit 标识\nfunc (p pallocSum) max() uint {\n    // ...\n    return uint((uint64(p) \u003e\u003e logMaxPackedValue) \u0026 (maxPackedValue - 1))\n}\n\n\n// 当前节点对应区域内，尾部连续空闲页的长度\n// 通过 uint64 左数 2~22 个 bit 标识\nfunc (p pallocSum) end() uint {\n    return uint((uint64(p) \u003e\u003e (2 * logMaxPackedValue)) \u0026 (maxPackedValue - 1))\n}\n```\n\n\n## 记录页到 mspan 的映射：heapArena \n\n\n- 每个 heapArena 包含 8192 个页，大小为 8192 * 8KB = 64 MB\n    \n-  heapArena 记录了页到 mspan 的映射. 因为 GC 时，通过地址偏移找到页很方便，但找到其所属的 mspan 不容易. 因此需要通过这个映射信息进行辅助.\n    \n-  heapArena 是 mheap 向操作系统申请内存的单位（64MB）\n\n```\nconst pagesPerArena = 8192\n\n\ntype heapArena struct {\n    // ...\n    // 实现 page 到 mspan 的映射\n    spans [pagesPerArena]*mspan\n\n\n    // ...\n}\n```\n\n\n\n\n\n## 分配流程\n\n下面来串联 Golang 中分配对象的流程，不论是以下哪种方式，最终都会殊途同归步入 mallocgc 方法中，并且根据 3.1 小节中的策略执行分配流程：\n\n- new(T)\n    \n-  \u0026T{}\n    \n-  make(xxxx)\n### 分配对象\n\n- 微对象 (0, 16 B)：先使用线程缓存上的微型分配器 (tiny allocator)，再依次尝试线程缓存、中心缓存、堆分配内存；\n- 小对象 [16 B, 32 KB]：依次尝试线程缓存、中心缓存、堆分配内存；\n- 大对象 (32 KB, +∞)：直接尝试堆分配内存；\n\n\n### 分配策略\n不同类型的对象，会有着不同的分配策略，这些内容在 mallocgc 方法中都有体现.\n\n核心流程类似于读多级缓存的过程，由上而下，每一步只要成功则直接返回. 若失败，则由下层方法兜底.\n\n对于微对象的分配流程：\n\n（1）从 P 专属 mcache 的 tiny 分配器取内存（无锁）\n\n（2）根据所属的 spanClass，从 P 专属 mcache 缓存的 mspan 中取内存（无锁）\n\n（3）根据所属的 spanClass 从对应的 mcentral 中取 mspan 填充到 mcache，然后从 mspan 中取内存（spanClass 粒度锁）\n\n（4）根据所属的 spanClass，从 mheap 的页分配器 pageAlloc 取得足够数量空闲页组装成 mspan 填充到 mcache，然后从 mspan 中取内存（全局锁）\n\n（5）mheap 向操作系统申请内存，更新页分配器的索引信息，然后重复（4）.\n\n对于小对象的分配流程是跳过（1）步，执行上述流程的（2）-（5）步；\n\n对于大对象的分配流程是跳过（1）-（3）步，执行上述流程的（4）-（5）步.\n\n![图片](https://mmbiz.qpic.cn/mmbiz_png/3ic3aBqT2ibZuXibKvib2fj2vlIia93waBCNwralF3nEibKSbypbCcrSMDpAEgVJJE1ibaO6QCV2MNjwwibpt8PZiaw686g/640?wx_fmt=png\u0026wxfrom=5\u0026wx_lazy=1\u0026wx_co=1)\n# Go 内存逃逸机制？\n\n## 概念\n\n在一段程序中，**每一个函数都会有自己的内存区域存放自己的局部变量、返回地址等**，这些内存会由编译器在栈中进行分配，**每一个函数都会分配一个栈桢**，在函数运行结束后进行销毁，**但是有些变量我们想在函数运行结束后仍然使用它，那么就需要把这个变量在堆上分配**，这种从”栈”上逃逸到”堆”上的现象就成为**内存逃逸**。\n\n在栈上分配的地址，一般由系统申请和释放，不会有额外性能的开销，比如函数的入参、局部变量、返回值等。在堆上分配的内存，如果要回收掉，需要进行 GC，那么 GC 一定会带来额外的性能开销。编程语言不断优化 GC 算法，主要目的都是为了减少 GC 带来的额外性能开销，变量一旦逃逸会导致性能开销变大。\n\n## 逃逸机制\n\n编译器会根据变量是否被外部引用来决定是否逃逸：\n\n1. 如果函数外部没有引用，则优先放到栈中；\n2. 如果函数外部存在引用，则必定放到堆中;\n3. 如果栈上放不下，则必定放到堆上;\n\n逃逸分析也就是由编译器决定哪些变量放在栈，哪些放在堆中，通过编译参数 `-gcflag=-m` 可以查看编译过程中的逃逸分析，发生逃逸的几种场景如下：\n\n### 指针逃逸\n\n```\npackage main\n\nfunc escape1() *int {\n    var a int = 1\n    return \u0026a\n}\n\nfunc main() {\n    escape1()\n}\n```\n\n通过 `go build -gcflags=-m main.go` 查看逃逸情况：\n\n```\n./main.go:4:6: moved to heap: a\n```\n\n函数返回值为局部变量的指针，函数虽然退出了，但是因为指针的存在，指向的内存不能随着函数结束而回收，因此只能分配在堆上。\n\n### 栈空间不足\n\n```\npackage main\n\nfunc escape2() {\n    s := make([]int, 0, 10000)\n    for index, _ := range s {\n        s[index] = index\n    }\n}\n\nfunc main() {\n    escape2()\n}\n```\n\n通过 `go build -gcflags=-m main.go` 查看逃逸情况：\n\n```\n./main.go:4:11: make([]int, 10000, 10000) escapes to heap\n```\n\n当栈空间足够时，不会发生逃逸，但是当变量过大时，已经完全超过栈空间的大小时，将会发生逃逸到堆上分配内存。局部变量 s 占用内存过大，编译器会将其分配到堆上\n\n### 变量大小不确定\n\n```\npackage main\n\nfunc escape3() {\n    number := 10\n    s := make([]int, number) // 编译期间无法确定slice的长度\n    for i := 0; i \u003c len(s); i++ {\n        s[i] = i\n    }\n}\n\nfunc main() {\n    escape3()\n}\n```\n\n编译期间无法确定 slice 的长度，这种情况为了保证内存的安全，编译器也会触发逃逸，在堆上进行分配内存。直接 `s := make([]int, 10)` 不会发生逃逸\n\n### 动态类型\n\n动态类型就是编译期间不确定参数的类型、参数的长度也不确定的情况下就会发生逃逸\n\n空接口 interface{} 可以表示任意的类型，如果函数参数为 interface{}，编译期间很难确定其参数的具体类型，也会发生逃逸。\n\n```\npackage main\n\nimport \"fmt\"\n\nfunc escape4() {\n    fmt.Println(1111)\n}\n\nfunc main() {\n    escape4()\n}\n```\n\n通过 `go build -gcflags=-m main.go` 查看逃逸情况：\n\n```\n./main.go:4:6: moved to heap: i\n```\n\nFmt.Println (a …interface{})函数参数为 interface，编译器不确定参数的类型，会将变量分配到堆上\n\n### 闭包引用对象\n\n\n```\npackage main\n\nfunc escape5() func() int {\n    var i int = 1\n    return func() int {\n        i++\n        return i\n    }\n}\n\nfunc main() {\n    escape5()\n}\n```\n\n通过 `go build -gcflags=-m main.go` 查看逃逸情况：\n\n```\n./main.go:4:6: moved to heap: i\n```\n\n闭包函数中局部变量 i 在后续函数是继续使用的，编译器将其分配到堆上\n\n## 总结\n\n1. 栈上分配内存比在堆中分配内存效率更高\n2. 栈上分配的内存不需要 GC 处理，而堆需要\n3. 逃逸分析目的是决定内分配地址是栈还是堆\n4. 逃逸分析在编译阶段完成\n\n因为无论变量的大小，只要是指针变量都会在堆上分配，所以对于小变量我们还是使用传值效率（而不是传指针）更高一点。\n\n\n\n## 怎么避免内存逃逸？\n\n1. **不要盲目使用变量指针作为参数**，虽然减少了复制，但变量逃逸的开销更大。\n2. **预先设定好 slice 长度**，避免频繁超出容量，重新分配。\n3. 一个经验是，**指针指向的数据大部分在堆上分配的**，请注意。\n\n出现内存逃逸的情况有：\n\n1. 发送指针或带有指针的值到 channel，因为编译时候无法知道那个 goroutine 会在 channel 接受数据，编译器无法知道什么时候释放。\n\n2. 在一个切片上存储指针或带指针的值。比如[]*string，导致切片内容逃逸，其引用值一直在堆上。\n\n3. 切片的 append 导致超出容量，切片重新分配地址，切片背后的存储基于运行时的数据进行扩充，就会在堆上分配。\n\n4. 调用接口类型时，接口类型的方法调用是动态调度，实际使用的具体实现只能在运行时确定，如一个接口类型为 io. Reader 的变量 r，对r.Read (b)的调用将导致 r 的值和字节片 b 的后续转义并因此分配到堆上。\n\n5. 在方法内把局部变量指针返回，被外部引用，其生命周期大于栈，导致内存溢出。\n\n# Go 内存对齐机制？\n\n## 什么是内存对齐\n\n为了能让 CPU 可以更快的存取到各个字段，Go 编译器会帮你把 struct 结构体做数据的对齐。**所谓的数据对齐，是指内存地址是所存储数据大小（按字节为单位）的整数倍，以便 CPU 可以一次将该数据从内存中读取出来。** 编译器通过在结构体的各个字段之间填充一些空白已达到对齐的目的。\n\n## 对齐系数\n\n*  不同硬件平台占用的大小和对齐值都可能是不一样的 **32 位系统对齐系数是 4，64 位系统对齐系数是 8**\n\n* 不同类型的对齐系数也可能不一样，使用 `Go` 语言中的 `unsafe.Alignof` 函数可以返回相应类型的对齐系数，**对齐系数都符合 `2^n` 这个规律**，最大也不会超过8\n\n```\npackage main\n\nimport (\n    \"fmt\"\n    \"unsafe\"\n)\n\nfunc main() {\n    fmt.Printf(\"bool alignof is %d\\n\", unsafe.Alignof(bool(true)))\n    fmt.Printf(\"string alignof is %d\\n\", unsafe.Alignof(string(\"a\")))\n    fmt.Printf(\"int alignof is %d\\n\", unsafe.Alignof(int(0)))\n    fmt.Printf(\"float alignof is %d\\n\", unsafe.Alignof(float64(0)))\n    fmt.Printf(\"int32 alignof is %d\\n\", unsafe.Alignof(int32(0)))\n    fmt.Printf(\"float32 alignof is %d\\n\", unsafe.Alignof(float32(0)))\n}\n\n```\n\n可以查看到各种类型在 Mac 64 位上的对齐系数如下：\n\n```\nbool alignof is 1\nstring alignof is 8\nint alignof is 8\nint32 alignof is 4\nfloat32 alignof is 4\nfloat alignof is 8\n```\n\n## 优点\n\n1. 提高可移植性，有些 `CPU` 可以访问任意地址上的任意数据，而有些 `CPU` 只能在特定地址访问数据，因此不同硬件平台具有差异性，这样的代码就不具有移植性，如果在编译时，将分配的内存进行对齐，这就具有平台可以移植性了\n2. 提高内存的访问效率，32 位 CPU 下一次可以从内存中读取 32 位（4 个字节）的数据，64 位 CPU 下一次可以从内存中读取 64 位（8 个字节）的数据，这个长度也称为 CPU 的字长。CPU 一次可以读取 1 个字长的数据到内存中，如果所需要读取的数据正好跨了 1 个字长，那就得花两个 CPU 周期的时间去读取了。因此在内存中存放数据时进行对齐，可以提高内存访问效率。\n\n## 缺点\n\n1. 存在内存空间的浪费，实际上是空间换时间\n\n## 结构体对齐\n\n对齐原则：\n\n1. **结构体变量中成员的偏移量必须是成员大小的整数倍**\n2. **整个结构体的地址必须是最大字节的整数倍**（结构体的内存占用是 1/4/8/16 byte…)\n\n```\npackage main\n\nimport (\n    \"fmt\"\n    \"runtime\"\n    \"unsafe\"\n)\n\ntype T1 struct {\n    i16  int16 // 2 byte\n    bool bool  // 1 byte\n}\n\ntype T2 struct {\n    i8  int8  // 1 byte\n    i64 int64 // 8 byte\n    i32 int32 // 4 byte\n}\n\ntype T3 struct {\n    i8  int8  // 1 byte\n    i32 int32 // 4 byte\n    i64 int64 // 8 byte\n}\n\nfunc main() {\n    fmt.Println(runtime.GOARCH) // amd64\n\n    t1 := T1{}\n    fmt.Println(unsafe.Sizeof(t1)) // 4 bytes\n\n    t2 := T2{}\n    fmt.Println(unsafe.Sizeof(t2)) // 24 bytes\n\n    t3 := T3{}\n    fmt.Println(unsafe.Sizeof(t3)) // 16 bytes\n}\n```\n\n以 T 1 结构体为例，实际存储数据的只有 3 字节，但实际用了 4 字节，浪费了 1 个字节：\n\nI 16 并没有直接放在 bool 的后面，而是在 bool 中填充了一个空白后，放到了偏移量为 2 的位置上。如果 i 16 从偏移量为 1 的位置开始占用 2 个字节，根据对齐原则 2：构体变量中成员的偏移量必须是成员大小的整数倍，套用公式 1 % 2 = 1，就不满足对齐的要求，所以 i 16 从偏移量为2的位置开始\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226004114.png)\n\n以 T 2 结构体为例，实际存储数据的只有 13 字节，但实际用了 24 字节，浪费了 11 个字节：\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226004122.png)\n\n以 T 3 结构体为例，实际存储数据的只有 13 字节，但实际用了 16 字节，浪费了 3 个字节：\n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226004134.png)\n\n\n# Go GC 实现原理？\n\n## 什么是 GC？\n\n垃圾回收也称为 GC（Garbage Collection），**是一种自动内存管理机制。由垃圾收集器以类似守护协程的方式在后台运作，按照既定的策略为用户回收那些不再被使用的对象，释放对应的内存空间**\n\n现代高级编程语言管理内存的方式分为两种：自动和手动，\n\n* 像 C、C++ 等编程语言使用手动管理内存的方式，工程师编写代码过程中需要主动申请或者释放内存；\n* 而 PHP、Java 和 Go 等语言使用自动的内存管理系统，有内存分配器和垃圾收集器来代为分配和回收内存，其中垃圾收集器就是我们常说的 GC。\n\n在应用程序中会使用到两种内存，分别为堆（Heap）和栈（Stack），\n\n* G**C 负责回收堆内存，而不负责回收栈中的内存**：\n\n* 栈是线程的专用内存，专门为了函数执行而准备的，存储着函数中的局部变量以及调用栈，函数执行完后，编译器可以将栈上分配的内存可以直接释放，不需要通过 GC 来回收。\n\n堆是程序共享的内存，需要 GC 进行回收在堆上分配的内存。\n\n垃圾回收器的执行过程被划分为两个半独立的组件：\n\n- 赋值器（Mutator）：这一名称本质上是在指代用户态的代码。因为对垃圾回收器而言，用户态的代码仅仅只是在修改对象之间的引用关系，也就是在对象图（对象之间引用关系的一个有向图）上进行操作。\n- 回收器（Collector）：负责执行垃圾回收的代码。\n\n## 主流 GC 算法\n\n目前比较常见的垃圾回收算法有三种：\n\n1. 引用计数：为每个对象维护一个引用计数，当引用该对象的对象销毁时，引用计数 -1，当对象引用计数为 0 时回收该对象。\n\t![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240227212501.png)\n\n    - 代表语言：**Python**、**PHP**、**Swift**\n    - 优点：对象回收快，不会出现内存耗尽或达到某个阈值时才回收。\n    - 缺点：不能很好的处理循环引用，而实时维护引用计数也是有损耗的。\n1. 分代收集：按照对象生命周期长短划分不同的代空间，生命周期长的放入老年代，短的放入新生代，不同代有不同的回收算法和回收频率。\n    - 代表语言：**Java**\n    - 优点：回收性能好\n    - 缺点：算法复杂\n2. 标记-清除：从根变量开始遍历所有引用的对象，标记引用的对象，没有被标记的进行回收。 \n\n\n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240227213214.png)\n\n    - 代表语言：**Golang**（三色标记法）\n    - 优点：解决了引用计数的缺点。\n    - 缺点：需要 STW，暂时停掉程序运行。 \n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226004206.png)\n4. 标记-压缩：是在标记清扫算法的基础上做了升级，在第二步”清扫“的同时还会对存活对象进行压缩整合，使得整体空间更为紧凑，从而解决内存碎片问题.\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240227213148.png)\n\n1. 半空间复制:\n- 分配两片相等大小的空间，称为 fromspace 和 tospace\n- 每轮只使用 fromspace 空间，以GC作为分水岭划分轮次\n- GC时，将fromspace存活对象转移到tospace中，并以此为契机对空间进行压缩整合\n-  GC后，交换fromspace和tospace，开启新的轮次\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240227213422.png)\n## **三色标记法**\n\n此算法是在 Go 1.5 版本开始使用，Go 语言采用的是标记清除算法，并在此基础上使用了三色标记法和混合写屏障技术，GC 过程和其他用户 goroutine 可并发运行，但需要一定时间的 STW\n\n这里的三色，对应了垃圾回收过程中对象的三种状态：\n\n- 灰色：对象还在标记队列中等待\n- 黑色：对象已被标记，`gcmarkBits` 对应位为 `1` （该对象不会在本次 GC 中被回收）\n- 白色：对象未被标记，`gcmarkBits` 对应位为 `0` （该对象将会在本次 GC 中被清理）\n\n\n简单概括：\n- 标记开始前，将根对象（全局对象、栈上局部变量等）置黑，将其所指向的对象置灰\n    \n- 标记规则是，从灰对象出发，将其所指向的对象都置灰. 所有指向对象都置灰后，当前灰对象置黑\n    \n-  标记结束后，白色对象就是不可达的垃圾对象，需要进行清扫.\n\n\n\n执行的步骤\n\n- Step 1: 创建：白、灰、黑三个集合\n\n- Step 2: 将所有对象放入白色集合中\n\n- Step 3: 遍历所有**root 对象**，把遍历到的对象从白色集合放入灰色集合 (这里放入灰色集合的都是根节点的对象)\n\n- Step 4: 遍历灰色集合，将灰色对象引用的对象从白色集合放入灰色集合，自身标记为黑色\n\n- Step 5: 重复步骤 4，直到灰色中无任何对象，其中用到 2 个机制：\n\n\t- **写屏障（Write Barrier）**：上面说到的 STW 的目的是防止 GC 扫描时内存变化引起的混乱，而写屏障就是让 goroutine 与 GC 同时运行的手段，虽然不能完全消除 STW，但是可以大大减少 STW 的时间。写屏障在 GC 的特定时间开启，开启后**指针传递时**会把指针标记，即本轮不回收，下次 GC 时再确定。\n\t- **辅助 GC（Mutator Assist）**：为了防止内存分配过快，在 GC 执行过程中，GC 过程中 mutator 线程会并发运行，而 mutator assist 机制会协助 GC 做一部分的工作。\n\n* Step 6: 收集所有白色对象（垃圾）\n\n\n### 并发垃圾回收会遇到的问题\n\n#### 漏标问题\n\n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240227214346.png)\n\n\n- 条件：初始时刻，对象 B 持有对象 C 的引用\n-  moment1：GC协程下，对象A被扫描完成，置黑；此时对象B是灰色，还未完成扫描\n-  momen2：用户协程下，对象A建立指向对象C的引用\n-  moment3：用户协程下，对象B删除指向对象C的引用\n-  moment4：GC 协程下，开始执行对对象 B 的扫描\n\n漏标问题是无法接受，其引起的误删现象可能会导致程序出现致命的错误. 针对漏标问题，Golang 给出的解决方案是屏障机制的使用\n\n\n#### 多标问题\n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240227214657.png)\n\n-  条件：初始时刻，对象 A 持有对象 B 的引用\n- moment1：GC协程下，对象A被扫描完成，置黑；对象B被对象A引用，因此被置灰\n-  momen2：用户协程下，对象 A 删除指向对象 B 的引用\n\n#### 内存碎片\n\n标记清扫算法会存在产生“内存碎片”的缺陷\n\nGolang 采用 TCMalloc 机制，依据对象的大小将其归属为到事先划分好的 spanClass 当中，这样能够消解外部碎片的问题，将问题限制在相对可控的内部碎片当中..\n\n#### 为什么不选择分代垃圾回收机制\n\nGolang中存在内存逃逸机制，会在编译过程中将生命周期更长的对象转移到堆中，将生命周期短的对象分配在栈上，并以栈为单位对这部分对象进行回收.\n\nGolang中存在内存逃逸机制，会在编译过程中将生命周期更长的对象转移到堆中，将生命周期短的对象分配在栈上，并以栈为单位对这部分对象进行回收.\n### **root 对象**\n\n根对象在垃圾回收的术语中又叫做根集合，它是垃圾回收器在标记过程时最先检查的对象，包括：\n\n* 全局变量：程序在编译期就能确定的那些存在于程序整个生命周期的变量。\n* 执行栈：每个 goroutine 都包含自己的执行栈，这些执行栈上指向堆内存的指针。\n* 寄存器：寄存器的值可能表示一个指针，参与计算的这些指针可能指向某些赋值器分配的堆内存区块。\n\n\n### 强弱三色不变式\n\n漏标问题的本质就是，**一个已经扫描完成的黑对象指向了一个被灰\\白对象删除引用的白色对象.**\n\n\n构成这一场景的要素拆分如下：\n\n（1）黑色对象指向了白色对象\n\n（2）灰、白对象删除了白色对象\n\n（3）（1）、（2）步中谈及的白色对象是同一个对象\n\n（4）（1）发生在（2）之前\n\n\n一套用于解决漏标问题的方法论称之为强弱三色不变式：\n\n- • 强三色不变式：白色对象不能被黑色对象直接引用（直接破坏（1））\n    \n- • 弱三色不变式：白色对象可以被黑色对象引用，但要从某个灰对象出发仍然可达该白对象（间接破坏了（1）、（2）的联动）\n\n\n\n### **插入写屏障**\n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240227220514.png)\n\n**保证当一个黑色对象指向一个白色对象前，会先触发屏障将白色对象置为灰色，再建立引用.**\n\n\n对象被引用时触发的机制（只在堆内存中生效）：赋值器这一行为通知给并发执行的回收器，被引用的对象标记为灰色\n\n缺点：结束时需要 STW 来重新扫描栈，标记栈上引用的白色对象的存活\n\n### **删除写屏障**\n\n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240227220546.png)\n\n**保证当一个白色对象即将被上游删除引用前，会触发屏障将其置灰，之后再删除上游指向其的引用.**\n\n对象被删除时触发的机制（只在堆内存中生效）：赋值器将这一行为通知给并发执行的回收器，被删除的对象，如果自身为灰色或者白色，那么标记为灰色\n\n缺点：一个对象的引用被删除后，即使没有其他存活的对象引用它，它仍然会活到下一轮，会产生很大冗余扫描成本，且降低了回收精度\n\n### **混合写屏障**\n\n插入写屏障、删除写屏障二者择其一，即可解决并发GC的漏标问题，至于错标问题，则采用容忍态度，放到下一轮GC中进行延后处理即可.\n\nGC 没有混合写屏障前，一直是插入写屏障；**混合写屏障是插入写屏障 + 删除写屏障，写屏障只应用在堆上应用，栈上不启用（栈上启用成本很高）**\n\n- • GC 开始前，以栈为单位分批扫描，将栈中所有对象置黑\n    \n- • GC 期间，栈上新创建对象直接置黑\n    \n- • 堆对象正常启用插入写屏障\n    \n- • 堆对象正常启用删除写屏障\n\n###  show case \n\n（1）case 1：堆对象删除引用，栈对象建立引用\n\n![图片](https://mmbiz.qpic.cn/mmbiz_png/3ic3aBqT2ibZsX03L7kZaOrjpArjV5Tfmib0PFRxUrFryicq6TW7qN5aQibT6aD9aE3Eo0oPibbmKnthQZX21pshcic6Q/640?wx_fmt=png\u0026wxfrom=5\u0026wx_lazy=1\u0026wx_co=1)\n\n- 背景：存在栈上对象A，黑色（扫描完）；\n    \n存在堆上对象B，白色（未被扫描）；\n\n存在堆上对象C，被堆上对象B引用，白色（未被扫描）\n\n- moment1：A建立对C的引用，由于栈无屏障机制，因此正常建立引用，无额外操作\n    \n- moment2：B尝试删除对C的引用，删除写屏障被触发，C被置灰，因此不会漏标\n    \n\n（2）case 2：一个堆对象删除引用，成为另一个堆对象下游\n\n![图片](https://mmbiz.qpic.cn/mmbiz_png/3ic3aBqT2ibZsX03L7kZaOrjpArjV5TfmibxaRBiaBV6h44eqG5fA92WuDGbtXE5XIibyI7QLbmgMLwxkAndaqDWUSw/640?wx_fmt=png\u0026wxfrom=5\u0026wx_lazy=1\u0026wx_co=1)\n\n- • 背景：存在堆上对象A，白色（未被扫描）；\n    \n\n存在堆上对象B，黑色（已完成扫描）；\n\n存在堆上对象C，被堆上对象B引用，白色（未被扫描）\n\n- • moment1：B尝试建立对C的引用，插入写屏障被触发，C被置灰\n    \n- • moment2：A删除对C的引用，此时C已置灰，因此不会漏标\n    \n\n（3）case 3：栈对象删除引用，成为堆对象下游\n\n![图片](https://mmbiz.qpic.cn/mmbiz_png/3ic3aBqT2ibZsX03L7kZaOrjpArjV5TfmibxHWaKDFs60CDNWs6NvCFaBibqe0PCFoMibUe7Ptc1xAicu5aFwpEP2LYg/640?wx_fmt=png\u0026wxfrom=5\u0026wx_lazy=1\u0026wx_co=1)\n\n- • 背景：存在栈上对象A，白色（未完成扫描，说明对应的栈未扫描）；\n    \n\n存在堆上对象B，黑色（已完成扫描）；\n\n存在堆上对象C，被栈上对象A引用，白色（未被扫描）\n\n- • moment1：B尝试建立对C的引用，插入写屏障被触发，C被置灰\n    \n- • moment2：A删除对C的引用，此时C已置灰，因此不会漏标\n    \n\n（4）case 4：一个栈中对象删除引用，另一个栈中对象建立引用\n\n![图片](https://mmbiz.qpic.cn/mmbiz_png/3ic3aBqT2ibZsX03L7kZaOrjpArjV5TfmibyjmjfS5mTiaH4EKOuKpDdWToJWfy9iaBvLg9AcicHu8bRqanQk7jCZZ1w/640?wx_fmt=png\u0026wxfrom=5\u0026wx_lazy=1\u0026wx_co=1)\n\n- • 背景：存在栈上对象A，白色（未扫描，这是因为对应的栈还未开始扫描）；\n    \n\n存在栈上对象B，黑色（已完成扫描，说明对应的栈均已完成扫描）；\n\n存在堆上对象C，被栈上对象A引用，白色（未被扫描）\n\n- • moment1：B建立对C的引用；\n    \n- • moment2：A删除对C的引用.\n    \n- • 结论：这种场景下，C要么已然被置灰，要么从某个灰对象触发仍然可达C.\n    \n- • 原因在于，对象的引用不是从天而降，一定要有个来处. 当前 case 中，对象B能建立指向C的引用，至少需要满足如下三个条件之一：\n    \n\nI 栈对象B原先就持有C的引用，如若如此，C就必然已处于置灰状态（因为B已是黑色）\n\nII 栈对象B持有A的引用，通过A间接找到C. 然而这也是不可能的，因为倘若A能同时被另一个栈上的B引用到，那样A必然会升级到堆中，不再满足作为一个栈对象的前提；\n\nIII B同栈内存在其他对象X可达C，此时从X出发，必然存在一个灰色对象，从其出发存在可达C的路线.\n\n综上，我们得以证明混合写屏障是能够胜任并发GC场景的解决方案，并且满足栈无须添加屏障的前提.\n\n##  GC 流程\n\n一次完整的垃圾回收会分为四个阶段，分别是标记准备、标记开始、标记终止、清理：\n\n1. **标记准备（Mark Setup）**：打开写屏障（Write Barrier），需 STW（stop the world)\n2. **标记开始（Marking）**：使用三色标记法并发标记，与用户程序并发执行\n3. **标记终止（Mark Termination**）：对触发写屏障的对象进行重新扫描标记，关闭写屏障（Write Barrier），需 STW（stop the world)\n4. **清理（Sweeping）**：将需要回收的内存归还到堆中，将过多的内存归还给操作系统，与用户程序并发执行\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226004354.png)\n\n## GC 触发时机\n\n**主动触发：**\n\n- 调用 runtime.GC () 方法，触发 GC\n\n**被动触发：**\n\n- 定时触发，该触发条件由 `runtime.forcegcperiod` 变量控制，默认为 2 分钟。当超过两分钟没有产生任何 GC 时，触发 GC\n- 根据内存分配阈值触发，该触发条件由环境变量 GOGC 控制，默认值为 100（100%），当前堆内存占用是上次 GC 结束后占用内存的 2 倍时，触发 GC\n\n\n## Go GC 如何调优？\n\n- 控制内存分配的速度，限制 Goroutine 的数量，提高赋值器 mutator 的 CPU 利用率（降低 GC 的 CPU 利用率）\n- 少量使用 `+` 连接 string\n- Slice 提前分配足够的内存来降低扩容带来的拷贝\n- 避免 map key 对象过多，导致扫描时间增加\n- 变量复用，减少对象分配，例如使用 sync. Pool 来复用需要频繁创建临时对象、使用全局变量等\n- 增大 GOGC 的值，降低 GC 的运行频率\n\n##  Go 如何查看 GC 信息？\n\n###  1. GODEBUG=’gctrace=1’\n\n```\npackage main\nfunc main() {\n    for n := 1; n \u003c 100000; n++ {\n        _ = make([]byte, 1\u003c\u003c20)\n    }\n}\n```\n\n```\n$ GODEBUG='gctrace=1' go run main.go\n\ngc 1 @0.003s 4%: 0.013+1.7+0.008 ms clock, 0.10+0.67/1.2/0.018+0.064 ms cpu, 4-\u003e6-\u003e2 MB, 5 MB goal, 8 P\ngc 2 @0.006s 2%: 0.006+4.5+0.058 ms clock, 0.048+0.070/0.027/3.6+0.47 ms cpu, 4-\u003e5-\u003e1 MB, 5 MB goal, 8 P\ngc 3 @0.011s 3%: 0.021+1.3+0.009 ms clock, 0.17+0.041/0.41/0.046+0.072 ms cpu, 4-\u003e6-\u003e2 MB, 5 MB goal, 8 P\ngc 4 @0.013s 5%: 0.025+0.38+0.26 ms clock, 0.20+0.054/0.15/0.009+2.1 ms cpu, 4-\u003e6-\u003e2 MB, 5 MB goal, 8 P\ngc 5 @0.014s 5%: 0.021+0.16+0.002 ms clock, 0.17+0.098/0.028/0.001+0.016 ms cpu, 4-\u003e5-\u003e1 MB, 5 MB goal, 8 P\ngc 6 @0.014s 7%: 0.025+1.6+0.003 ms clock, 0.20+0.061/2.9/1.5+0.025 ms cpu, 4-\u003e6-\u003e2 MB, 5 MB goal, 8 P\ngc 7 @0.016s 7%: 0.019+1.0+0.002 ms clock, 0.15+0.053/1.0/0.018+0.017 ms cpu, 4-\u003e6-\u003e2 MB, 5 MB goal, 8 P\ngc 8 @0.017s 7%: 0.029+0.17+0.002 ms clock, 0.23+0.037/0.10/0.063+0.022 ms cpu, 4-\u003e4-\u003e0 MB, 5 MB goal, 8 P\ngc 9 @0.018s 7%: 0.019+0.23+0.002 ms clock, 0.15+0.040/0.16/0.023+0.018 ms cpu, 4-\u003e5-\u003e1 MB, 5 MB goal, 8 P\ngc 10 @0.018s 7%: 0.022+0.23+0.003 ms clock, 0.17+0.061/0.13/0.006+0.024 ms cpu, 4-\u003e6-\u003e2 MB, 5 MB goal, 8 P\ngc 11 @0.018s 7%: 0.019+0.11+0.001 ms clock, 0.15+0.033/0.051/0.013+0.015 ms cpu, 4-\u003e5-\u003e1 MB, 5 MB goal, 8 P\ngc 12 @0.019s 7%: 0.018+0.19+0.001 ms clock, 0.14+0.035/0.10/0.018+0.014 ms cpu, 4-\u003e5-\u003e1 MB, 5 MB goal, 8 P\ngc 13 @0.019s 7%: 0.018+0.35+0.002 ms clock, 0.15+0.21/0.054/0.013+0.016 ms cpu, 4-\u003e5-\u003e1 MB, 5 MB goal, 8 P\ngc 14 @0.019s 8%: 0.024+0.27+0.002 ms clock, 0.19+0.022/0.13/0.014+0.017 ms cpu, 4-\u003e5-\u003e1 MB, 5 MB goal, 8 P\ngc 15 @0.020s 8%: 0.019+0.42+0.038 ms clock, 0.15+0.060/0.28/0.007+0.31 ms cpu, 4-\u003e17-\u003e13 MB, 5 MB goal, 8 P\ngc 16 @0.021s 8%: 0.018+0.53+0.060 ms clock, 0.14+0.045/0.39/0.005+0.48 ms cpu, 21-\u003e28-\u003e7 MB, 26 MB goal, 8 P\ngc 17 @0.021s 10%: 0.020+0.91+0.64 ms clock, 0.16+0.050/0.36/0.027+5.1 ms cpu, 12-\u003e16-\u003e4 MB, 14 MB goal, 8 P\ngc 18 @0.023s 10%: 0.020+0.55+0.002 ms clock, 0.16+0.053/0.50/0.081+0.023 ms cpu, 7-\u003e9-\u003e2 MB, 8 MB goal, 8 P\n```\n\n字段含义由下表所示：\n\n|字段|含义|\n|:--|:--|\n|gc 2|第二个 GC 周期|\n|0.006|程序开始后的 0.006 秒|\n|2%|该 GC 周期中 CPU 的使用率|\n|0.006|标记开始时， STW 所花费的时间（wall clock）|\n|4.5|标记过程中，并发标记所花费的时间（wall clock）|\n|0.058|标记终止时， STW 所花费的时间（wall clock）|\n|0.048|标记开始时， STW 所花费的时间（cpu time）|\n|0.070|标记过程中，标记辅助所花费的时间（cpu time）|\n|0.027|标记过程中，并发标记所花费的时间（cpu time）|\n|3.6|标记过程中，GC 空闲的时间（cpu time）|\n|0.47|标记终止时， STW 所花费的时间（cpu time）|\n|4|标记开始时，堆的大小的实际值|\n|5|标记结束时，堆的大小的实际值|\n|1|标记结束时，标记为存活的对象大小|\n|5|标记结束时，堆的大小的预测值|\n|8|P 的数量|\n\n### 2. Go tool trace\n\n```\npackage main\n\nimport (\n    \"os\"\n    \"runtime/trace\"\n)\n\nfunc main() {\n    f, _ := os.Create(\"trace.out\")\n    defer f.Close()\n    trace.Start(f)\n    defer trace.Stop()\n    for n := 1; n \u003c 100000; n++ {\n        _ = make([]byte, 1\u003c\u003c20)\n    }\n}\n```\n\n```\n$ go run main.go\n$ go tool trace trace.out\n```\n\n打开浏览器后，可以看到如下统计：\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226004606.png)\n\n点击 View trace，可以查看当时的 trace 情况\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226004617.png)\n\n\n点击 Minimum mutator utilization，可以查看到赋值器 mutator （用户程序）对 CPU 的利用率 74.1%，接近 100%则代表没有针对 GC 的优化空间了\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226004625.png)\n\n### 3. Debug. ReadGCStats\n\n```\npackage main\n\nimport (\n    \"fmt\"\n    \"runtime/debug\"\n    \"time\"\n)\n\nfunc printGCStats() {\n    t := time.NewTicker(time.Second)\n    s := debug.GCStats{}\n    for {\n        select {\n        case \u003c-t.C:\n            debug.ReadGCStats(\u0026s)\n            fmt.Printf(\"gc %d last@%v, PauseTotal %v\\n\", s.NumGC, s.LastGC, s.PauseTotal)\n        }\n    }\n}\nfunc main() {\n    go printGCStats()\n    for n := 1; n \u003c 100000; n++ {\n        _ = make([]byte, 1\u003c\u003c20)\n    }\n}\n```\n\n```\n$ go run main.go\n\ngc 3392 last@2022-05-04 19:22:52.877293 +0800 CST, PauseTotal 117.524907ms\ngc 6591 last@2022-05-04 19:22:53.876837 +0800 CST, PauseTotal 253.254996ms\ngc 10028 last@2022-05-04 19:22:54.87674 +0800 CST, PauseTotal 376.981595ms\ngc 13447 last@2022-05-04 19:22:55.87689 +0800 CST, PauseTotal 511.420111ms\ngc 16938 last@2022-05-04 19:22:56.876955 +0800 CST, PauseTotal 649.293449ms\ngc 20350 last@2022-05-04 19:22:57.876756 +0800 CST, PauseTotal 788.003014ms\n```\n\n字段含义由下表所示：\n\n|字段|含义|\n|:--|:--|\n|NumGC|GC 总次数|\n|LastGC|上次 GC 时间|\n|PauseTotal|STW 总耗时|\n\n### 4. Runtime. ReadMemStats\n\n```\npackage main\n\nimport (\n    \"fmt\"\n    \"runtime\"\n    \"time\"\n)\n\nfunc printMemStats() {\n    t := time.NewTicker(time.Second)\n    s := runtime.MemStats{}\n    for {\n        select {\n        case \u003c-t.C:\n            runtime.ReadMemStats(\u0026s)\n            fmt.Printf(\"gc %d last@%v, heap_object_num: %v, heap_alloc: %vMB, next_heap_size: %vMB\\n\",\n                s.NumGC, time.Unix(int64(time.Duration(s.LastGC).Seconds()), 0), s.HeapObjects, s.HeapAlloc/(1\u003c\u003c20), s.NextGC/(1\u003c\u003c20))\n        }\n    }\n}\nfunc main() {\n    go printMemStats()\n    fmt.Println(1 \u003c\u003c 20)\n    for n := 1; n \u003c 100000; n++ {\n        _ = make([]byte, 1\u003c\u003c20)\n    }\n}\n\n```\n\n```\n$ go run main.go\n\ngc 2978 last@2022-05-04 19:38:04 +0800 CST, heap_object_num: 391, heap_alloc: 20MB, next_heap_size: 28MB\ngc 5817 last@2022-05-04 19:38:05 +0800 CST, heap_object_num: 370, heap_alloc: 4MB, next_heap_size: 4MB\ngc 9415 last@2022-05-04 19:38:06 +0800 CST, heap_object_num: 392, heap_alloc: 7MB, next_heap_size: 8MB\ngc 11429 last@2022-05-04 19:38:07 +0800 CST, heap_object_num: 339, heap_alloc: 4MB, next_heap_size: 5MB\ngc 14706 last@2022-05-04 19:38:08 +0800 CST, heap_object_num: 436, heap_alloc: 6MB, next_heap_size: 8MB\ngc 18253 last@2022-05-04 19:38:09 +0800 CST, heap_object_num: 375, heap_alloc: 4MB, next_heap_size: 6M\n```\n\n\n\n字段含义由下表所示：\n\n|字段|含义|\n|:--|:--|\n|NumGC|GC 总次数|\n|LastGC|上次 GC 时间|\n|HeapObjects|堆中已经分配的对象总数，GC 内存回收后 HeapObjects 取值相应减小|\n|HeapAlloc|堆中已经分配给对象的字节数，GC 内存回收后 HeapAlloc 取值相应减小|\n|NextGC|下次 GC 目标堆的大小|\n","lastmodified":"2024-03-02T12:01:53.846210423Z","tags":["GO/八股文"]},"/GO/%E5%85%AB%E8%82%A1%E6%96%87/%E5%B9%B6%E5%8F%91":{"title":"并发","content":"\t\n\n# **go 语言怎么支持的并发请求**\n\n\n``Go`` 中有 goroutine，所以可以采用多协程来解决并发问题。Accept 连接后，将连接丢给 goroutine 处理后续的读写操作。在开发者看到的这个 goroutine 中业务逻辑是同步的，也不用考虑 IO 是否阻塞。\n\n Golang 的协程通信有哪些方式\n\n1）共享内存\n\n- 共享内存是指多个协程直接访问共享变量的方式，这种方式不需要显式地进行通信，但需要考虑并发访问时的竞态问题，需要使用互斥锁等机制来确保同步和一致性。\n\n2）通道\n\n- 通道是 Go 语言中一个重要的并发原语，它是一种线程安全的、带缓冲的 FIFO 队列。通道支持阻塞式读写，可以用来在不同的协程之间传递数据，也可以用来进行同步操作。通道在多个协程之间传递数据时，会自动进行同步，不需要程序员显式地进行加锁和解锁操作。\n\n3）选择器\n\n- 选择器是 Go 语言中的一种控制结构，可以同时监听多个通道的操作，并选择其中一个可以进行操作的通道。选择器可以用来实现非阻塞的通信操作，避免了因等待某个通道操作而导致的阻塞。选择器通常与通道配合使用，用于多个协程之间的协作和同步。\n\n4）条件变量（Cond）\n\n- 条件变量用于在协程之间进行复杂的通信和协调。在 Go 中，可以使用 `sync` 包中的 `Cond` 类型来实现条件变量。它通常与互斥锁一起使用，以便协程可以在特定条件下等待或被唤醒。\n\n5）原子操作（Atomic Operations）\n\n- Go 语言提供了 `sync/atomic` 包，用于执行原子操作，这些操作通常用于共享资源的更新，以避免竞态条件。原子操作可以用于对变量的读取、写入、加法等操作，而不需要额外的锁定。\n\n总之，Go 协程之间的通信是非常重要的，不同的应用场景需要选择不同的通信方式，以确保程序的正确性和性能。共享内存通常用于需要高性能的并发场景，但需要注意线程安全和同步问题；通道是一种简单、安全、高效的通信方式，适用于大多数并发场景；选择器则适用于多通道协作和同步的场景。\n\n\n\n\n# Go 常用的并发模型？\n\n并发模型说的是系统中的线程如何协作完成并发任务，不同的并发模型，线程以不同的方式进行**通信**和协作。\n\n## 线程间通信方式\n\n线程间通信方式有两种：共享内存和消息传递，无论是哪种通信模型，线程或者协程最终都会从内存中获取数据，所以更为准确的说法是直接共享内存、发送消息的方式来同步信息\n\n### **共享内存**\n\n**抽象层级**：抽象层级低，当我们遇到对资源进行更细粒度的控制或者对性能有极高要求的场景才应该考虑抽象层级更低的方法\n\n**耦合**：高，线程需要在读取或者写入数据时先获取保护该资源的互斥锁\n\n**线程竞争**：需要加锁，才能避免线程竞争和数据冲突\n\n### **发送消息**\n\n**抽象层级**：抽象层级高，提供了更良好的封装和与领域更相关和契合的设计，比如 Go 语言中的 `Channel` 就提供了 Goroutine 之间用于传递信息的方式，它在内部实现时就广泛用到了共享内存和锁，通过对两者进行的组合提供了更高级的同步机制\n\n**耦合**：低，生产消费者模型\n\n**线程竞争**：保证同一时间只有一个活跃的线程能够访问数据，channel 维护所有被该 chanel 阻塞的协程，保证有资源的时候只唤醒一个协程，从而避免竞争\n\nGo 语言中实现了两种并发模型，一种是共享内存并发模型，另一种则是 CSP 模型。\n\n## 共享内存并发模型\n\n通过直接共享内存 + 锁的方式同步信息，传统多线程并发\n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226005141.png)\n\n## CSP 并发模型\n\n通过发送消息的方式来同步信息，Go 语言推荐使用的_通信顺序进程_（communicating sequential processes）并发模型，通过 goroutine 和 channel 来实现\n\n- `goroutine` 是 Go 语言中并发的执行单位，可以理解为”线程“\n- `channel` 是 Go 语言中各个并发结构体 (`goroutine`)之前的通信机制。通俗的讲，就是各个 `goroutine` 之间通信的”管道“，类似于 Linux 中的管道\n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226005155.png)\n\n\n# Go 为啥使用 CSP 模型来实现并发?\n\nGo 语言使用 CSP（Communicating Sequential Processes，通信顺序进程）模型来实现并发，这是由 Go 语言设计者选择的一种并发模型，有以下几个重要的原因：\n\n1. **简单性和清晰性**：CSP 模型提供了一种清晰且直观的方式来表达并发程序。它基于协程之间的通信来进行协作，通过通道（channel）进行消息传递，使得并发程序的结构和逻辑更加简单和可读。\n2. **避免共享状态**：CSP 模型强调避免共享状态，而是通过通信共享数据。共享状态是许多并发程序中的错误和难点来源之一，而 CSP 模型可以减少竞态条件（race condition）等问题的出现。\n3. **安全性**：Go 的 CSP 模型通过通道提供了一种安全的并发机制。通道的发送和接收操作都是原子的，不需要额外的锁定，因此减少了程序中出现的锁定问题，如死锁和竞态条件。\n4. **可扩展性**：CSP 模型可以轻松扩展到大量的协程，因为通道和协程的创建成本相对较低。这使得 Go 非常适合构建高并发的系统，如 Web 服务器、分布式系统和网络服务。\n5. **编译器和运行时支持**：Go 编译器和运行时系统针对 CSP 模型进行了优化。Go 的并发原语在语言级别得到支持，而不是通过库的方式实现，这使得并发编程更加容易。\n\n总之，Go 选择 CSP 模型是为了提供一种简单、安全、高效和可扩展的并发编程模型，以便开发者能够更轻松地构建并发程序，同时避免共享状态和典型的并发问题。这使得 Go 成为了一个流行的选择，特别适用于需要高度并发性能的应用程序和系统。\n\n\n# 有没有什么线程安全的办法？\n\n在 Go 语言中，线程安全一般指协程安全，因为 Go 一般使用协程进行调度；而 Go 中为了保证其协程安全，有以下几种机制：\n\n1、互斥锁：在 Go 的标准库中有 sync 包，sync. Mutex 就是解决并发冲突导致的安全性问题的一种方式。\n\n2、读写锁：是在互斥锁上的进一步升级版本，主要为了解决并发多写少读、少写多读两种高并发的情况\n\n3、如果不是需要强制使用同一个对象，那么也可以采用创建对象副本的方式，每个协程独占一个对象，相互之间不关联，但是这显然不符合我们的要求。\n\n综上，使用互斥锁或者读写锁就能很好的解决问题。\n\n\n\n# select 可以用于什么\n\nGo 的通道有两种操作方式，一种是带 range 子句的 for 语句，另一种则是 select 语句，它是专门为了操作通道而存在的。这里主要介绍 select 的用法。\n\nSelect 的语法如下：\n\n```\nselect {\n   case \u003c-ch1 :\n     statement(s)   \n   case ch2 \u003c- 1 :\n      statement(s)\n    …\n   default : /* 可选 */\n      statement(s)\n}\n```\n\n这里要注意：\n\n- 每个 case 都必须是一个通信。由于 select 语句是专为通道设计的，所以每个 case 表达式中都只能包含操作通道的表达式，比如接收表达式。\n- 如果有多个 case 都可以运行，select 会随机公平地选出一个执行，其他不会执行。\n- 如果多个 case 都不能运行，若有 default 子句，则执行该语句，反之，select 将阻塞，直到某个 case 可以运行。\n- 所有 channel 表达式都会被求值。\n- Select 机制⽤来处理异步 IO 问题。\n- Select 机制最⼤的⼀条限制就是每个 case 语句⾥必须是⼀个 IO 操作。\n\n**实例**\n\n```\npackage main\n\nimport (\n    \"fmt\"\n    \"math/rand\"\n)\n\nfunc main() {\n    // 准备好几个通道。\n    intChannels := [5]chan int{\n        make(chan int, 1),\n        make(chan int, 1),\n        make(chan int, 1),\n        make(chan int, 1),\n        make(chan int, 1)，\n    }\n    // 随机选择一个通道，并向它发送元素值。\n    index := rand.Intn(5)\n    fmt.Printf(\"The index: %d\", index)\n    intChannels[index] \u003c- index\n    // 哪一个通道中有可取的元素值，哪个对应的分支就会被执行。\n    select {\n        case \u003c-intChannels[0]:\n            fmt.Println(\"The first candidate case is selected.\")\n        case \u003c-intChannels[1]:\n            fmt.Println(\"The second candidate case is selected.\")\n        case elem := \u003c-intChannels[2]:\n            fmt.Printf(\"The third candidate case is selected. The element is %d.\", elem)\n        default:\n            fmt.Println(\"No candidate case is selected!\")\n    }\n}\n```\n\n## **select 死锁**  \nSelect 使用不当会发生死锁。如果通道没有数据发送，但 select 中有存在接收通道数据的语句，将发生死锁。\n\n```\nfunc main() {  \n        ch := make(chan string)\n        select {\n            case \u003c-ch:\n        }\n}\n/*\nfatal error: all goroutines are asleep - deadlock!\ngoroutine 1 [chan receive]:\nmain.main()\n/workspace/src/test.go:5 +0x52\nexit status 2\n*/\n//可以添加 default 语句来避免产生死锁。\n```\n\n## **空 select{}**\n\n对于空的 select 语句，程序会被阻塞，确切的说是当前协程被阻塞，同时 **Go 自带死锁检测机制，当发现当前协程再也没有机会被唤醒时，则会发生 panic**。所以上述程序会 panic。\n\n\n```\nfunc main() {  \n        select {}\n}\n\n/*\nfatal error: all goroutines are asleep - deadlock!\ngoroutine 1 [select (no cases)]:\nmain.main()\n\t/workspace/src/test.go:3 +0x20\nexit status 2\n*/\n```\n\n## **select 和 for 结合使用**\n\nSelect 语句只能对其中的每一个 case 表达式各求值一次。所以，如果想连续或定时地操作其中的通道的话，就需要通过在 for 语句中嵌入 select 语句的方式实现。\n\n```\nfunc main() {\n    tick := time.Tick(time.Second)\n    for {\n        select {\n            case t := \u003c-tick:\n                fmt.Println(t)\n                break\n            }\n    }\n    fmt.Println(\"end\")\n}\n```\n\n你会发现 break 只跳出了 select，无法跳出 for。解决办法有两种：  \n### **使用 goto 跳出循环**\n\n```\nfunc main() {\n    tick := time.Tick(time.Second)\n    for {\n        select {\n            case t := \u003c-tick:\n                fmt.Println(t)\n                //跳到指定位置\n                goto END\n            }\n        }\nEND:\n        fmt.Println(\"end\")\n    }\n```\n\n### **使用标签**\n\n```\nfunc main() {\n    tick := time.Tick(time.Second)\n//这是标签\nFOREND:\n    for {\n        select {\n            case t := \u003c-tick:\n                fmt.Println(t)\n                //跳出FOREND标签\n                break ForEnd\n            }\n        }\nEND:\n        fmt.Println(\"end\")\n    }\n```\n\n## **select 实现超时机制**  \n\n\n主要使用的 time. After 实现超时控制。\n\n```\nfunc main() {\n    ch := make(chan int)\n    quit := make(chan bool)\n\n    go func() {\n        for {\n            select {\n                case num := \u003c-ch:  //如果有数据，下面打印。但是有可能ch一直没数据\n                 fmt.Println(\"num = \", num)\n                case \u003c-time.After(3 * time.Second): //上面的ch如果一直没数据会阻塞，那么select也会检测其他case条件，检测到后3秒超时\n                 fmt.Println(\"超时\")\n                 quit \u003c- true  //写入\n            }\n        }\n\n    }()\n\n    for i := 0; i \u003c 5; i++ {\n        ch \u003c- i\n        time.Sleep(time.Second)\n    }\n    \u003c-quit //这里暂时阻塞，直到可读\n    fmt.Println(\"程序结束\")\n}\n```\n\n执行后，可以观察到：依次打印出 0-4，几秒过后打印出“超时”和“程序结束”，打印结果如下：\n\n```\nnum =  0\nnum =  1\nnum =  2\nnum =  3\nnum =  4\n超时\n程序结束\n```\n\n# Select 底层原理\n\nselect 的底层原理：[Go select使用与底层原理](https://juejin.cn/post/7123037385419407374?searchId=20230920141239DA74937FA19C8E97461E#heading-2) \n\n\n1. 每一个 case 对应的 channl 都会被封装到一个结构体中；\n2. 当第一次执行到 select 时，会锁住所有的 channl 并且，打乱 case 结构体的顺序；\n3. 按照打乱的顺序遍历，如果有就绪的信号，就直接走对应 case 的代码段，之后跳出 select；\n4. 如果没有就绪的代码段，但是有 default 字段，那就走 default 的代码段，之后跳出 select；\n5. 如果没有 default，那就将当前 goroutine 加入所有 channl 的对应等待队列；\n6. 当某一个等待队列就绪时，再次锁住所有的 channl，遍历一遍，将所有等待队列中的 goroutine 取出，之后执行就绪的代码段，跳出select。\n\n## 数据结构\n\n每一个 case 对应的数据结构如下：\n\n```\ntype scase struct {\n    c           *hchan         // chan\n    elem        unsafe.Pointer // 读或者写的缓冲区地址\n    kind        uint16   //case语句的类型，是default、传值写数据(channel \u003c-) 还是  取值读数据(\u003c- channel)\n    pc          uintptr // race pc (for race detector / msan)\n    releasetime int64\n}\n```\n\n\n\n# Go 有哪些并发同步原语？\n\nGo 是一门以并发编程见长的语言，它提供了一系列的同步原语方便开发者使用\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226005223.png)\n## 原子操作\n\nMutex、RWMutex 等并发原语的底层实现是通过 atomic 包中的一些原子操作来实现的，原子操作是最基础的并发原语. Go atomic 包是最轻量级的锁（也称无锁结构），可以在**不形成临界区和创建互斥量的情况下完成并发安全的值替换操作**，不过这个包只支持 int 32/int 64/uint 32/uint 64/uintptr 这几种数据类型的一些基础操作（增减、交换、载入、存储等）\n\n### 概念\n\n原子操作仅会由一个独立的 CPU 指令代表和完成。原子操作是无锁的，常常直接通过 CPU 指令直接实现。事实上，其它同步技术的实现常常依赖于原子操作。\n\n### 使用场景\n\n当我们想要对**某个变量**并发安全的修改，除了使用官方提供的 `mutex`，还可以使用 sync/atomic 包的原子操作，它能够保证对变量的读取或修改期间不被其他的协程所影响。\n\nAtomic 包提供的原子操作能够确保任一时刻只有一个 goroutine 对变量进行操作，善用 atomic 能够避免程序中出现大量的锁操作。\n\n\n```\npackage main\n\nimport (\n    \"fmt\"\n    \"sync/atomic\"\n)\n\nvar opts int64 = 0\n\nfunc main() {\n    add(\u0026opts, 3)\n    load(\u0026opts)\n    compareAndSwap(\u0026opts, 3, 4)\n    swap(\u0026opts, 5)\n    store(\u0026opts, 6)\n}\n\nfunc add(addr *int64, delta int64) {\n    atomic.AddInt64(addr, delta) //加操作\n    fmt.Println(\"add opts: \", *addr)\n}\n\nfunc load(addr *int64) {\n    fmt.Println(\"load opts: \", atomic.LoadInt64(\u0026opts))\n}\n\nfunc compareAndSwap(addr *int64, oldValue int64, newValue int64) {\n    if atomic.CompareAndSwapInt64(addr, oldValue, newValue) {\n        fmt.Println(\"cas opts: \", *addr)\n        return\n    }\n}\n\nfunc swap(addr *int64, newValue int64) {\n    atomic.SwapInt64(addr, newValue)\n    fmt.Println(\"swap opts: \", *addr)\n}\n\nfunc store(addr *int64, newValue int64) {\n    atomic.StoreInt64(addr, newValue)\n    fmt.Println(\"store opts: \", *addr)\n}\n```\n\n\n\n### 常见操作\n\n- 增减 Add\n- 载入 Load\n- 比较并交换 CompareAndSwap\n- 交换 Swap\n- 存储 Store\n\nAtomic 操作的对象是一个地址，你需要把可寻址的变量的地址作为参数传递给方法，而不是把变量的值传递给方法\n\n下面将分别介绍这些操作：\n\n#### **增减操作**\n\n此类操作的前缀为 `Add`\n\n```\nfunc AddInt32(addr *int32, delta int32) (new int32)\n\nfunc AddInt64(addr *int64, delta int64) (new int64)\n\nfunc AddUint32(addr *uint32, delta uint32) (new uint32)\n\nfunc AddUint64(addr *uint64, delta uint64) (new uint64)\n\nfunc AddUintptr(addr *uintptr, delta uintptr) (new uintptr)\n```\n\n需要注意的是，第一个参数必须是指针类型的值，通过指针变量可以获取被操作数在内存中的地址，从而施加特殊的 CPU 指令，确保同一时间只有一个 goroutine 能够进行操作。\n\n使用举例：\n\n```\nfunc add(addr *int64, delta int64) {\n    atomic.AddInt64(addr, delta) //加操作\n    fmt.Println(\"add opts: \", *addr)\n}\n```\n\n#### **载入操作**\n\n此类操作的前缀为 `Load`\n\n```\nfunc LoadInt32(addr *int32) (val int32)\n\nfunc LoadInt64(addr *int64) (val int64)\n\nfunc LoadPointer(addr *unsafe.Pointer) (val unsafe.Pointer)\n\nfunc LoadUint32(addr *uint32) (val uint32)\n\nfunc LoadUint64(addr *uint64) (val uint64)\n\nfunc LoadUintptr(addr *uintptr) (val uintptr)\n\n// 特殊类型： Value类型，常用于配置变更\nfunc (v *Value) Load() (x interface{}) {}\n```\n\n载入操作能够保证原子的读变量的值，当读取的时候，任何其他 CPU 操作都无法对该变量进行读写，其实现机制受到底层硬件的支持。\n\n使用示例:\n\n```\nfunc load(addr *int64) {\n    fmt.Println(\"load opts: \", atomic.LoadInt64(\u0026opts))\n}\n```\n\n#### **比较并交换**\n\n此类操作的前缀为 `CompareAndSwap`, 该操作简称 CAS，可以用来实现乐观锁\n\n```\nfunc CompareAndSwapInt32(addr *int32, old, new int32) (swapped bool)\n\nfunc CompareAndSwapInt64(addr *int64, old, new int64) (swapped bool)\n\nfunc CompareAndSwapPointer(addr *unsafe.Pointer, old, new unsafe.Pointer) (swapped bool)\n\nfunc CompareAndSwapUint32(addr *uint32, old, new uint32) (swapped bool)\n\nfunc CompareAndSwapUint64(addr *uint64, old, new uint64) (swapped bool)\n\nfunc CompareAndSwapUintptr(addr *uintptr, old, new uintptr) (swapped bool)\n```\n\n该操作在进行交换前首先确保变量的值未被更改，即仍然保持参数 `old` 所记录的值，满足此前提下才进行交换操作。CAS 的做法类似操作数据库时常见的乐观锁机制。\n\n需要注意的是，当有大量的 goroutine 对变量进行读写操作时，可能导致 CAS 操作无法成功，这时可以利用 for 循环多次尝试。\n\n使用示例：\n\n```\nfunc compareAndSwap(addr *int64, oldValue int64, newValue int64) {\n    if atomic.CompareAndSwapInt64(addr, oldValue, newValue) {\n        fmt.Println(\"cas opts: \", *addr)\n        return\n    }\n}\n```\n\n#### **交换**\n\n此类操作的前缀为 `Swap`：\n\n```\nfunc SwapInt32(addr *int32, new int32) (old int32)\n\nfunc SwapInt64(addr *int64, new int64) (old int64)\n\nfunc SwapPointer(addr *unsafe.Pointer, new unsafe.Pointer) (old unsafe.Pointer)\n\nfunc SwapUint32(addr *uint32, new uint32) (old uint32)\n\nfunc SwapUint64(addr *uint64, new uint64) (old uint64)\n\nfunc SwapUintptr(addr *uintptr, new uintptr) (old uintptr)\n```\n\n相对于 CAS，明显此类操作更为暴力直接，**并不管变量的旧值是否被改变，直接赋予新值然后返回背替换的值**。\n\n```\nfunc swap(addr *int64, newValue int64) {\n    atomic.SwapInt64(addr, newValue)\n    fmt.Println(\"swap opts: \", *addr)\n}\n```\n\n#### **存储**\n\n此类操作的前缀为 `Store`：\n\n```\nfunc StoreInt32(addr *int32, val int32)\n\nfunc StoreInt64(addr *int64, val int64)\n\nfunc StorePointer(addr *unsafe.Pointer, val unsafe.Pointer)\n\nfunc StoreUint32(addr *uint32, val uint32)\n\nfunc StoreUint64(addr *uint64, val uint64)\n\nfunc StoreUintptr(addr *uintptr, val uintptr)\n\n// 特殊类型： Value类型，常用于配置变更\nfunc (v *Value) Store(x interface{})\n```\n\n此类操作确保了写变量的原子性，避免其他操作读到了修改变量过程中的脏数据。\n\n```\nfunc store(addr *int64, newValue int64) {\n    atomic.StoreInt64(addr, newValue)\n    fmt.Println(\"store opts: \", *addr)\n}\n```\n\n### Go 原子操作和锁的区别？\n\n- 原子操作由底层硬件支持，而锁是基于原子操作+信号量完成的。若实现相同的功能，前者通常会更有效率\n- 原子操作是单个指令的互斥操作；互斥锁/读写锁是一种数据结构，可以完成临界区（多个指令）的互斥操作，扩大原子操作的范围\n- 原子操作是无锁操作，属于乐观锁；说起锁的时候，一般属于悲观锁\n- 原子操作存在于各个指令/语言层级，比如“机器指令层级的原子操作”，“汇编指令层级的原子操作”，“Go 语言层级的原子操作”等。\n- 锁也存在于各个指令/语言层级中，比如“机器指令层级的锁”，“汇编指令层级的锁”，“Go 语言层级的锁”等\n\n\n## Channel\n\n[Channel](GO/八股文/Channel.md)\n\n`channel` 管道，高级同步原语，goroutine 之间通信的桥梁\n\n使用场景：消息队列、数据传递、信号通知、任务编排、锁\n\n```\npackage main\n\nimport (\n    \"fmt\"\n    \"time\"\n)\n\nfunc main() {\n    c := make(chan struct{}, 1)\n    for i := 0; i \u003c 10; i++ {\n        go func() {\n            c \u003c- struct{}{}\n            time.Sleep(1 * time.Second)\n            fmt.Println(\"通过ch访问临界区\")\n            \u003c-c\n        }()\n    }\n    for {\n    }\n}\n```\n\n\n\n## 基本并发原语\n\nGo 语言在 `sync` 包中提供了用于同步的一些基本原语，这些基本原语提供了较为基础的同步功能，但是它们是一种相对原始的同步机制，在多数情况下，我们都应该使用抽象层级更高的 Channel 实现同步。\n\n常见的并发原语如下：`sync.Mutex`、`sync.RWMutex`、`sync.WaitGroup`、`sync.Cond`、`sync.Once`、`sync.Pool`、`sync.Context`\n\n### **sync. Mutex**\n\n[Mutex和RWMutex](GO/八股文/Mutex和RWMutex.md)\n\n`sync.Mutex` （互斥锁） 可以限制对临界资源的访问，保证只有一个 goroutine 访问共享资源\n\n使用场景：大量读写，比如多个 goroutine 并发更新同一个资源，像计数器\n\n```\npackage main\n\nimport (\n    \"fmt\"\n    \"sync\"\n)\n\nfunc main() {\n    // 封装好的计数器\n    var counter Counter\n    var wg sync.WaitGroup\n    var gNum = 1000\n    wg.Add(gNum)\n    // 启动10个goroutine\n    for i := 0; i \u003c gNum; i++ {\n        go func() {\n            defer wg.Done()\n            counter.Incr() // 受到锁保护的方法\n        }()\n    }\n    wg.Wait()\n    fmt.Println(counter.Count())\n}\n\n// 线程安全的计数器类型\ntype Counter struct {\n    mu    sync.Mutex\n    count uint64\n}\n\n// 加1的方法，内部使用互斥锁保护\nfunc (c *Counter) Incr() {\n    c.mu.Lock()\n    c.count++\n    c.mu.Unlock()\n}\n\n// 得到计数器的值，也需要锁保护\nfunc (c *Counter) Count() uint64 {\n    c.mu.Lock()\n    defer c.mu.Unlock()\n    return c.count\n}\n```\n\n### sync. RWMutex\n\n[Mutex和RWMutex](GO/八股文/Mutex和RWMutex.md)\n\n`sync.RWMutex` （读写锁） 可以限制对临界资源的访问，保证只有一个 goroutine 写共享资源，可以有多个 goroutine 读共享资源\n\n使用场景：大量并发读，少量并发写，有强烈的性能要求\n\n```\npackage main\n\nimport (\n    \"fmt\"\n    \"sync\"\n    \"time\"\n)\n\nfunc main() {\n    // 封装好的计数器\n    var counter Counter\n    var gNum = 1000\n    // 启动10个goroutine\n    for i := 0; i \u003c gNum; i++ {\n        go func() {\n            counter.Count() // 受到锁保护的方法\n        }()\n    }\n    for { // 一个writer\n        counter.Incr() // 计数器写操作\n        fmt.Println(\"incr\")\n        time.Sleep(time.Second)\n    }\n}\n\n// 线程安全的计数器类型\ntype Counter struct {\n    mu    sync.RWMutex\n    count uint64\n}\n\n// 加1的方法，内部使用互斥锁保护\nfunc (c *Counter) Incr() {\n    c.mu.Lock()\n    c.count++\n    c.mu.Unlock()\n}\n\n// 得到计数器的值，也需要锁保护\nfunc (c *Counter) Count() uint64 {\n    c.mu.RLock()\n    defer c.mu.RUnlock()\n    return c.count\n}\n```\n\n### **sync. WaitGroup**\n\n\n`sync.WaitGroup` 可以等待一组 Goroutine 的返回\n\n\n```\n// A WaitGroup must not be copied after first use.\ntype WaitGroup struct {\n noCopy noCopy\n state1 [3]uint32\n}\n```\n\n#### 底层数据结构\n\n其中 `noCopy` 是 golang 源码中检测禁止拷贝的技术。如果程序中有 WaitGroup 的赋值行为，使用 `go vet` 检查程序时，就会发现有报错。但需要注意的是，noCopy 不会影响程序正常的编译和运行。\n\n`state 1` 主要是存储着状态和信号量，状态维护了 2 个计数器，一个是请求计数器 counter ，另外一个是等待计数器 waiter（已调用 `WaitGroup. Wait` 的 goroutine 的个数）\n\n当数组的首地址是处于一个 `8` 字节对齐的位置上时，那么就将这个数组的前 `8` 个字节作为 `64` 位值使用表示状态，后 `4` 个字节作为 `32` 位值表示信号量 (`semaphore`)；同理如果首地址没有处于 `8` 字节对齐的位置上时，那么就将前 `4` 个字节作为 `semaphore`，后 `8` 个字节作为 `64` 位数值。\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226005747.png)\n\n\n#### 使用场景\n\n并发等待，任务编排，一个比较常见的使用场景是批量发出 RPC 或者 HTTP 请求\n#### 使用方法\n\n在 WaitGroup 里主要有 3 个方法：\n\n- `WaitGroup.Add ()`：可以添加或减少请求的 goroutine 数量，*`Add (n)` 将会导致 `counter += n`*\n- `WaitGroup.Done ()`：相当于 Add (-1)，`Done ()` 将导致 `counter -=1`，请求计数器 counter 为 0 时通过信号量调用 `runtime_Semrelease` 唤醒 waiter 线程\n- `WaitGroup.Wait ()`：会将 `waiter++`，同时通过信号量调用 `runtime_Semacquire (semap)` 阻塞当前 goroutine\n\n```\nfunc main() {\n    var wg sync.WaitGroup\n    for i := 1; i \u003c= 5; i++ {\n        wg.Add(1)\n        go func() {\n            defer wg.Done()\n            println(\"hello\")\n        }()\n    }\n\n    wg.Wait()\n}\n```\n\n\n#### WaitGroup 的坑\n\n1. Add 一个负数\n\n\u003e 如果计数器的值小于 0 会直接 panic\n\n2. Add 在 Wait 之后调用\n\n\u003e 比如一些子协程开头调用 Add 结束调用 Wait，这些 Wait 无法阻塞子协程。正确做法是在开启子协程之前先 Add 特定的值。\n\n3. 未置为 0 就重用\n\n\u003e WaitGroup 可以完成一次编排任务，计数值降为 0 后可以继续被其他任务所用，但是不要在还没使用完的时候就用于其他任务，这样由于带着计数值，很可能出问题。\n\n4. 复制 waitgroup\n\n\u003e WaitGroup 有 nocopy 字段，不能被复制。也意味着 WaitGroup 不能作为函数的参数。\n\n#### 深入理解 sync. Waitgroup\n\n[https://juejin.cn/post/7181812988461252667](https://juejin.cn/post/7181812988461252667) \n\n\n`WaitGroup` 内部**通过一个计数器来统计有多少协程被等待**。\n\n* 这个计数器的值在我们启动 goroutine 之前先写入（使用 `Add` 方法），\n* 然后在 goroutine 结束的时候，将这个计数器减 1（使用 `Done` 方法）。\n* 除此之外，在启动这些 goroutine 的协程中，会调用 `Wait` 来进行等待，在 `Wait` 调用的地方会阻塞，直到 `WaitGroup` 内部的计数器减到 0。 **也就实现了等待一组 goroutine 的目的**\n\n### **sync. Cond**\n\n`sync.Cond` 可以让一组的 Goroutine 都在满足特定条件时被唤醒, `Go` 标准库提供了 `Cond` 原语\n\n\n\n```\ntype Cond struct {\n    noCopy noCopy\n\n    // L is held while observing or changing the condition\n    L Locker\n\n    notify  notifyList\n    checker copyChecker\n}\n\ntype notifyList struct {\n    wait   uint32\n    notify uint32\n    lock   uintptr // key field of the mutex\n    head   unsafe.Pointer\n    tail   unsafe.Pointer\n}\n```\n\n#### 底层数据结构\n\n主要有 `4` 个字段：\n\n- `nocopy` ： golang 源码中检测禁止拷贝的技术。如果程序中有 WaitGroup 的赋值行为，使用 `go vet` 检查程序时，就会发现有报错，但需要注意的是，noCopy 不会影响程序正常的编译和运行\n- `checker`：用于禁止运行期间发生拷贝，双重检查 (`Double check`)\n- `L`：可以传入一个读写锁或互斥锁，当修改条件或者调用 `Wait` 方法时需要加锁\n- `notify`：通知链表，调用 `Wait ()` 方法的 `Goroutine` 会放到这个链表中，从这里获取需被唤醒的 Goroutine 列表\n#### 使用场景\n\n利用等待 / 通知机制实现阻塞或者唤醒\n\n#### 使用方法\n\n在 Cond 里主要有 3 个方法：\n\n- `sync.NewCond (l Locker)`: 新建一个 sync. Cond 变量，注意该函数需要一个 Locker 作为必填参数，这是因为在 `cond.Wait ()` 中底层会涉及到 Locker 的锁操作\n- `Cond.Wait ()`: 阻塞等待被唤醒，调用 Wait 函数前**需要先加锁**；并且由于 Wait 函数被唤醒时存在虚假唤醒等情况，导致唤醒后发现，条件依旧不成立，因此需要使用 for 语句来循环地进行等待，直到条件成立为止\n- `Cond.Signal ()`: 只唤醒一个最先 Wait 的 goroutine，可以不用加锁\n- `Cond.Broadcast ()`: 唤醒所有 Wait 的 goroutine，可以不用加锁\n\n```\npackage main\n\nimport (\n    \"fmt\"\n    \"sync\"\n    \"sync/atomic\"\n    \"time\"\n)\n\n\n\nvar status int64\n\n  \n\nfunc TestCond(t *testing.T) {\n\n    c := sync.NewCond(\u0026sync.Mutex{})\n\n    for i := 0; i \u003c 10; i++ {\n\n        go listen(c)\n\n    }\n\n    time.Sleep(1 * time.Second)\n\n    go broadcast(c)\n\n    time.Sleep(1 * time.Second)\n\n}\n\n  \n\nfunc broadcast(c *sync.Cond) {\n\n    // 原子操作\n\n    atomic.StoreInt64(\u0026status, 1)\n\n    c.Broadcast()\n\n}\n\n  \n\nfunc listen(c *sync.Cond) {\n\n    c.L.Lock()\n\n    fmt.Println(\"wait\")\n\n    c.Wait()\n\n     // Wait 内部会先调用 c.L.Unlock()，来先释放锁，如果调用方不先加锁的话，会报错\n\n    fmt.Println(\"listen\")\n\n    c.L.Unlock()\n\n}\n```\n\n### **sync. Once**\n\n#### **什么是** sync. Once\n\nOnce 可以用来执行且仅仅执行一次动作，常常用于单例对象的初始化场景。\n\nOnce 常常用来初始化单例资源，或者并发访问只需初始化⼀次的共享资源，或者在测试的时候初始化⼀次测试资源。\n\n\n\n**源码**\n\n```\ntype Once struct {\n\tm    Mutex\n\tdone uint32\n}\n\nfunc (o *Once) Do(f func()) {\n\tif atomic.LoadUint32(\u0026o.done) == 1 {\n\t\treturn\n\t}\n\to.m.Lock()\n\tdefer o.m.Unlock()\n\tif o.done == 0 {\n\t\tdefer atomic.StoreUint32(\u0026o.done, 1)\n\t\tf()\n\t}\n}\n```\n\n\n\n`sync.Once` 可以保证在 Go 程序运行期间的某段代码只会执行一次\n\n使用场景：常常用于单例对象的初始化场景\n\n```\npackage main\n\nimport (\n    \"fmt\"\n    \"sync\"\n)\n\nfunc main() {\n    o := \u0026sync.Once{}\n    for i := 0; i \u003c 10; i++ {\n        o.Do(func() {\n            fmt.Println(\"only once\")\n        })\n    }\n}\n```\n\n### **sync. Pool**\n\n\n对于很多需要重复分配、回收内存的地方，sync. Pool 是一个很好的选择。频繁地分配、回收内存会给 GC 带来一定的负担，严重的时候会引起 CPU 的毛刺，而**sync. Pool 可以将暂时不用的对象缓存起来，待下次需要的时候直接使用，不用再次经过内存分配，复用对象的内存**，减轻 GC 的压力，提升系统的性能。\n\n`sync.Pool` 是 sync 包下的一个组件，可以作为保存临时取还对象的一个“池子”。个人觉得它的名字有一定的误导性，因为 Pool 里装的对象可以被无通知地被回收，可能 `sync.Cache` 是一个更合适的名字。\n\n[sync.Pool底层原理](https://zhuanlan.zhihu.com/p/399150710) \n\n[# 深度解密 Go 语言之 sync.Pool](https://zhuanlan.zhihu.com/p/133638023)\n\n#### 使用场景\n\n对于很多需要重复分配、回收内存的地方，`sync.Pool` 是一个很好的选择。频繁地分配、回收内存会给 GC 带来一定的负担，严重的时候会引起 CPU 的毛刺，而 `sync.Pool` 可以将暂时不用的对象缓存起来，待下次需要的时候直接使用，不用再次经过内存分配，复用对象的内存，减轻 GC 的压力，提升系统的性能。\n\n对象池化， TCP 连接池、数据库连接池、Worker Pool\n\n#### 使用方法\n\n首先，`sync.Pool` 是协程安全的，这对于使用者来说是极其方便的。使用前，设置好对象的 `New` 函数，用于在 `Pool` 里没有缓存的对象时，创建一个。之后，在程序的任何地方、任何时候仅通过 `Get()`、`Put()` 方法就可以取、还对象了。\n\n首先来看一个简单的例子：\n\n```text\npackage main\nimport (\n    \"fmt\"\n    \"sync\"\n)\n\nvar pool *sync.Pool\n\ntype Person struct {\n    Name string\n}\n\nfunc initPool() {\n    pool = \u0026sync.Pool {\n        New: func()interface{} {\n            fmt.Println(\"Creating a new Person\")\n            return new(Person)\n        },\n    }\n}\n\nfunc main() {\n    initPool()\n\n    p := pool.Get().(*Person)\n    fmt.Println(\"首次从 pool 里获取：\", p)\n\n    p.Name = \"first\"\n    fmt.Printf(\"设置 p.Name = %s\\n\", p.Name)\n\n    pool.Put(p)\n\n    fmt.Println(\"Pool 里已有一个对象：\u0026{first}，调用 Get: \", pool.Get().(*Person))\n    fmt.Println(\"Pool 没有对象了，调用 Get: \", pool.Get().(*Person))\n}\n```\n\n运行结果：\n\n```text\nCreating a new Person\n首次从 pool 里获取： \u0026{}\n设置 p.Name = first\nPool 里已有一个对象：\u0026{first}，Get:  \u0026{first}\nCreating a new Person\nPool 没有对象了，Get:  \u0026{}\n```\n\n\n### **sync. Map**\n\n\n[Map 和Sync.map](GO/八股文/Map%20和Sync.map.md)\n\n`sync.Map` 线程安全的 map\n\n使用场景：map 并发读写\n\n```\npackage main\n\nimport (\n    \"fmt\"\n    \"sync\"\n)\n\nfunc main() {\n    var scene sync.Map\n    // 将键值对保存到sync.Map\n    scene.Store(\"1\", 1)\n    scene.Store(\"2\", 2)\n    scene.Store(\"3\", 3)\n    // 从sync.Map中根据键取值\n    fmt.Println(scene.Load(\"1\"))\n    // 根据键删除对应的键值对\n    scene.Delete(\"1\")\n    // 遍历所有sync.Map中的键值对\n    scene.Range(func(k, v interface{}) bool {\n        fmt.Println(\"iterate:\", k, v)\n        return true\n    })\n}\n```\n\n#### **sync. Context**\n\n[Context](GO/八股文/Context.md)\n\n`sync.Context` 可以进行上下文信息传递、提供超时和取消机制、控制子 goroutine 的执行\n\n使用场景：取消一个 goroutine 的执行\n\n```\npackage main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"time\"\n)\n\nfunc main() {\n    ctx, cancel := context.WithCancel(context.Background())\n    go func() {\n        defer func() {\n            fmt.Println(\"goroutine exit\")\n        }()\n        for {\n            select {\n            case \u003c-ctx.Done():\n                fmt.Println(\"receive cancel signal!\")\n                return\n            default:\n                fmt.Println(\"default\")\n                time.Sleep(time.Second)\n            }\n        }\n    }()\n    time.Sleep(time.Second)\n    cancel()\n    time.Sleep(2 * time.Second)\n}\n```\n\n## 扩展并发原语\n\n### **ErrGroup**\n\n`errgroup` 可以在一组 Goroutine 中提供了同步、错误传播以及上下文取消的功能\n\n如果协程中 panic 依然会\n\n使用场景：只要一个 goroutine 出错我们就不再等其他 goroutine 了，减少资源浪费，并且返回错误\n\n```\npackage main\n\nimport (\n    \"fmt\"\n    \"net/http\"\n\n    \"golang.org/x/sync/errgroup\"\n)\n\nfunc main() {\n    var g errgroup.Group\n    var urls = []string{\n        \"http://www.baidu.com/\",\n        \"https://www.sina.com.cn/\",\n    }\n    for i := range urls {\n        url := urls[i]\n        g.Go(func() error {\n            resp, err := http.Get(url)\n            if err == nil {\n                resp.Body.Close()\n            }\n            return err\n        })\n    }\n    err := g.Wait()\n    if err == nil {\n        fmt.Println(\"Successfully fetched all URLs.\")\n    } else {\n        fmt.Println(\"fetched error:\", err.Error())\n    }\n}\n```\n\n### **Semaphore**\n\n`Semaphore` 带权重的信号量，控制多个 goroutine 同时访问资源\n\n使用场景：控制 goroutine 的阻塞和唤醒\n\n```\npackage main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"log\"\n    \"runtime\"\n    \"time\"\n\n    \"golang.org/x/sync/semaphore\"\n)\n\nvar (\n    maxWorkers = runtime.GOMAXPROCS(0)\n    sema       = semaphore.NewWeighted(int64(maxWorkers)) //信号量\n    task       = make([]int, maxWorkers*4)\n\n// 任务数，是worker的四\n)\n\nfunc main() {\n    ctx := context.Background()\n    for i := range task {\n        // 如果没有worker可用，会阻塞在这里，直到某个worker被释放\n        if err := sema.Acquire(ctx, 1); err != nil {\n            break\n        }\n        // 启动worker goroutine\n        go func(i int) {\n            defer sema.Release(1)\n            time.Sleep(100 * time.Millisecond) // 模拟一个耗时操作\n            task[i] = i + 1\n        }(i)\n    }\n    // 请求所有的worker,这样能确保前面的worker都执行完\n    if err := sema.Acquire(ctx, int64(maxWorkers)); err != nil {\n        log.Printf(\"获取所有的worker失败: %v\", err)\n    }\n    fmt.Println(maxWorkers, task)\n}\n```\n\n### **SingleFlight**\n\n用于抑制对下游的重复请求\n\n使用场景：访问缓存、数据库等场景，缓存过期时只有一个请求去更新数据库\n\n```\npackage main\n\nimport (\n    \"fmt\"\n    \"sync\"\n    \"sync/atomic\"\n    \"time\"\n\n    \"golang.org/x/sync/singleflight\"\n)\n\n// 模拟从数据库读取\nfunc getArticle(id int) (article string, err error) {\n    // 假设这里会对数据库进行调用, 模拟不同并发下耗时不同\n    atomic.AddInt32(\u0026count, 1)\n    time.Sleep(time.Duration(count) * time.Millisecond)\n\n    return fmt.Sprintf(\"article: %d\", id), nil\n}\n\n// 模拟优先读缓存，缓存不存在读取数据库，并且只有一个请求读取数据库，其它请求等待\nfunc singleflightGetArticle(sg *singleflight.Group, id int) (string, error) {\n    v, err, _ := sg.Do(fmt.Sprintf(\"%d\", id), func() (interface{}, error) {\n        return getArticle(id)\n    })\n\n    return v.(string), err\n}\n\nvar count int32\n\nfunc main() {\n    time.AfterFunc(1*time.Second, func() {\n        atomic.AddInt32(\u0026count, -count)\n    })\n\n    var (\n        wg  sync.WaitGroup\n        now = time.Now()\n        n   = 1000\n        sg  = \u0026singleflight.Group{}\n    )\n\n    for i := 0; i \u003c n; i++ {\n        wg.Add(1)\n        go func() {\n            res, _ := singleflightGetArticle(sg, 1)\n            // res, _ := getArticle(1)\n            if res != \"article: 1\" {\n                panic(\"err\")\n            }\n            wg.Done()\n        }()\n    }\n\n    wg.Wait()\n    fmt.Printf(\"同时发起 %d 次请求，耗时: %s\", n, time.Since(now))\n}\n```\n\n\n# Go 有哪些方式安全读写共享变量？\n\n|方法|并发原语|备注|\n|---|---|---|\n|不要修改变量|sync. Once|不要去写变量，变量只初始化一次|\n|只允许一个 goroutine 访问变量|Channel|不要通过共享变量来通信，通过通信 (channel)来共享变量|\n|允许多个 goroutine 访问变量，但是同一时间只允许一个 goroutine 访问|sync. Mutex、sync. RWMutex、原子操作|实现锁机制，同时只有一个线程能拿到|\n\n#  Go 如何排查数据竞争问题？\n\n## 概念\n\n只要有两个以上的 goroutine 并发访问同一变量，且至少其中的一个是写操作的时候就会发生数据竞争；全是读的情况下是不存在数据竞争的。\n\n## 排查方式\n\n```\npackage main\n\nimport \"fmt\"\n\nfunc main() {\n    i := 0\n\n    go func() {\n        i++ // write i\n    }()\n\n    fmt.Println(i) // read i\n}\n```\n\n`go 命令行`有个参数`race`可以帮助检测代码中的数据竞争\n\n```\n$ go run -race main.go\n\nWARNING: DATA RACE\nWrite at 0x00c0000ba008 by goroutine 7:\nexit status 66\n```\n\n\n\n\n\n# Go 语言怎么做的连接复用\n\nGo 的 netpoll 是怎么实现的像阻塞 read 一样去使用底层的非阻塞 read\n\n[Golang的IO多路复用的netpoll模型](https://www.cnblogs.com/luozhiyun/p/14390824.html) \n\nGo 语言中 IO 多路复用使用 netpoll 模型\nNetpoll 本质上是对 I/O 多路复用技术的封装，所以自然也是和 epoll 一样脱离不了下面几步：\n\n1. Netpoll 创建及其初始化；\n2. 向 netpoll 中加入待监控的任务；\n3. 从 netpoll 获取触发的事件；\n在 go 中对 epoll 提供的三个函数进行了封装\n\n```\nfunc netpollinit()\nfunc netpollopen(fd uintptr, pd *pollDesc) int32\nfunc netpoll(delay int64) gList\n```\n\n\nNetpollinit 函数负责初始化 netpoll；\nNetpollopen 负责监听文件描述符上的事件；\nNetpoll 会阻塞等待返回一组已经准备就绪的 Goroutine；\n\n\n\n\n#  Data Race 问题怎么解决？能不能不加锁解决这个问题？\n\n![image-20230724164303002](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticimage-20230724164303002.png)\n\n#  runtime 提供常见的方法\n\n1. **Gosched ()**：让当前线程让出 cpu 以让其它线程运行，它不会挂起当前线程，因此当前线程未来会继续执行。\n2. **NumCPU ()**：返回当前系统的 CPU 核数量。\n3. **GOMAXPROCS ()**：设置最大的可同时使用的 CPU 核数。  \n    \n\t1. 通过 runtime. GOMAXPROCS 函数，应用程序可以设置运行时系统中的 P 最大数量。注意，如果在运行期间设置该值的话，会引起“Stop the World”。所以，应在应用程序最早期调用，并且最好是在运行 Go 程序之前设置好操作程序的环境变量 GOMAXPROCS，而不是在程序中调用 runtime. GOMAXPROCS 不能作为函数的参数。\n\t2. 无论我们传递给函数的整数值是什么值，运行时系统的 P 最大值总会在 1~256 之间。\n\t3. Go 1.8 后，默认让程序运行在多个核上，可以不用设置了。\n\t4. Go 1.8 前，还是要设置一下，可以更高效的利用 cpu。\n4. **Goexit ()**：退出当前 goroutine（但是 defer 语句会照常执行）。 \n5. **NumGoroutine**：返回正在执行和排队的任务总数。  \n    \n\t1. Runtime. NumGoroutine 函数在被调用后，会返回系统中的处于特定状态的 Goroutine 的数量。这里的特定状态是指 GrunnableGruningGsyscallGwaition。处于这些状态的 Goroutine 即被看做是活跃的或者说正在被调度。\n\t2. 注意：垃圾回收所在 Goroutine 的状态也处于这个范围内的话，也会被纳入该计数器。 \n6. **GOOS**：查看目标操作系统。很多时候，我们会根据平台的不同实现不同的操作，就可以用 GOOS 来查看自己所在的操作系统。\n7. **runtime. GC**：会让运行时系统进行一次强制性的垃圾收集。  \n    强制的垃圾回收：不管怎样，都要进行的垃圾回收。非强制的垃圾回收：只会在一定条件下进行的垃圾回收（即运行时，系统自上次垃圾回收之后新申请的堆内存的单元（也成为单元增量）达到指定的数值）。\n8. **GOROOT ()**：获取 goroot 目录。\n9. **runtime. LockOSThread 和 runtime. UnlockOSThread 函数**：前者调用会使调用他的 Goroutine 与当前运行它的 M 锁定到一起，后者调用会解除这样的锁定。\n\n","lastmodified":"2024-03-02T12:01:53.846210423Z","tags":["GO/八股文"]},"/GO/%E5%85%AB%E8%82%A1%E6%96%87/Context":{"title":"Context","content":"\n# 参考\n\n\n[Golang context 实现原理]( https://mp.weixin.qq.com/s?__biz=MzkxMjQzMjA0OQ==\u0026mid=2247483677\u0026idx=1\u0026sn=d1c0e52b1fd31932867ec9b1d00f4ec2\u0026chksm=c10c4fc3f67bc6d590141040342153004ea4e420d83f4e2b2afc068e8bb904778b02b5be3f97\u0026scene=178\u0026cur_album_id=2709593649634033668#rd )\n\n[go 之 Context 基本使用]( https://www.cnblogs.com/huyiCloud/p/16120294.html )\n\n\n# 前言\n\n\n\ncontext 是 golang 中的经典工具\n\n*  主要在异步场景中用于实现并发协调以及对 goroutine 的生命周期控制. \n* 除此之外，context 还兼有一定的数据存储能力. \n* 本着知其然知其所以然的精神，本文和大家一起深入 context 源码一探究竟，较为细节地对其实现原理进行梳理.\n\n\n\n# 为啥使用 Context \n\n比如以下这个例子，一旦主协程关闭`done channel`，那么子协程就可以退出了，这样就实现了主协程通知子协程的需求\n```\n  \nfunc main() {\n    // 数据通道\n    messages := make(chan int, 10)\n    // 信号通道\n    done := make(chan bool)\n\n    defer close(messages)\n    // consumer\n    go func() {\n        // 每隔一秒执行一次，定时器\n        ticker := time.NewTicker(1 * time.Second)\n        for _ = range ticker.C {\n            select {\n            // 若关闭了通道则 执行下面的代码\n            case \u003c-done:\n                fmt.Println(\"child process interrupt...\")\n                return\n            default:\n                fmt.Printf(\"send message: %d\\n\", \u003c-messages)\n            }\n        }\n    }()\n\n    // producer\n    for i := 0; i \u003c 10; i++ {\n        messages \u003c- i\n    }\n    time.Sleep(5 * time.Second)\n    // 关闭通道, 退出上面的匿名函数\n    close(done)\n    time.Sleep(1 * time.Second)\n    fmt.Println(\"main process exit!\")\n}\n```\n\n假如主协程中有多个任务1, 2, …m，主协程对这些任务有超时控制。如果还是使用`done channel`的用法 ，那么使用`done channel`的方式将会变得非常繁琐且混乱\n\n\n\n我们需要一种优雅的方案来实现这样一种机制：\n\n- **上层任务取消后，所有的下层任务都会被取消；**\n- **中间某一层的任务取消后，只会将当前任务的下层任务取消，而不会影响上层的任务以及同级任务**。\n\n这个时候`context`就派上用场了\n\n\n# Context 的使用\n注意: 这两种方式是创建根context，不具备任何功能，需要用到with系列函数来实现具体功能`\n\n## 根 Context\n\n- context.Backgroud()\n\t- 是上下文的默认值，所有其他的上下文都应该从它衍生（Derived）出来, ,一般情况下我们用这个\n- context.TODO()\n\t-  应该只在不确定应该使用哪种上下文时使用；\n\n\n## With 系列函数\n\n\n###  context.withCancel() 取消控制\n就可以使用withCancel来衍生一个context传递到不同的goroutine中，当我想让这些goroutine停止运行，就可以调用cancel来进行取消\n\n```\n// 案例一\n\n/*  \n\t代码逻辑:\n    我们使用withCancel创建一个基于Background的ctx，然后启动一个讲话程序，\n    每隔1s说一话，main函数在10s后执行cancel，那么speak检测到取消信号就会退出。\n*/\n\npackage main\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"time\"\n)\n\n// context.Background()函数创建根上下文，返回父context和cancel函数\nfunc NewWithCancel() (context.Context, context.CancelFunc) {\n\treturn context.WithCancel(context.Background())\n\n}\n\n//  业务逻辑\nfunc Speak(ctx context.Context) {\n\tfor range time.Tick(time.Second) {\n\t\tselect {\n\t\tcase \u003c-ctx.Done():\n\t\t\tfmt.Println(\"关闭线程...\")\n\t\t\tfmt.Println(ctx.Err())\n\t\tdefault:\n\t\t\tfmt.Println(\"hahahhaa\")\n\t\t}\n\t}\n}\n\nfunc main() {\n        // 创建父context和cancel函数\n\tctx, cancel := NewWithCancel()\n\n        // 使用协程来启动业务逻辑\n\tgo Speak(ctx)\n\n\ttime.Sleep(10 * time.Second)\n\n        // 取消的信号，结束Speak函数的运行\n\tcancel()\n\n\ttime.Sleep(1 * time.Second)\n\n}\n```\n\n\n```\n  \n// 案例二\n\n/*\n代码逻辑: \n1. 利用根Context创建一个父Context，使用父Context创建一个协程，\n2. 利用上面的父Context再创建一个子Context，使用该子Context创建一个协程\n3. 一段时间后，调用父Context的cancel函数，会发现父Context的协程和子Context的协程都收到了信号，被结束了\n\n*/\npackage main\n \nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"time\"\n)\n \nfunc main() {\n\t// 父context(利用根context得到)\n\tctx, cancel := context.WithCancel(context.Background())\n \n\t// 父context的子协程\n\tgo watch1(ctx)\n \n\t// 子context，注意：这里虽然也返回了cancel的函数对象，但是未使用\n\tvalueCtx, _ := context.WithCancel(ctx)\n\t// 子context的子协程\n\tgo watch2(valueCtx)\n \n\tfmt.Println(\"现在开始等待3秒,time=\", time.Now().Unix())\n\ttime.Sleep(3 * time.Second)\n \n\t// 调用cancel()\n\tfmt.Println(\"等待3秒结束,调用cancel()函数\")\n\tcancel()\n \n\t// 再等待5秒看输出，可以发现父context的子协程和子context的子协程都会被结束掉\n\ttime.Sleep(5 * time.Second)\n\tfmt.Println(\"最终结束,time=\", time.Now().Unix())\n}\n \n// 父context的协程\nfunc watch1(ctx context.Context) {\n\tfor {\n\t\tselect {\n\t\tcase \u003c-ctx.Done(): //取出值即说明是结束信号\n\t\t\tfmt.Println(\"收到信号，父context的协程退出,time=\", time.Now().Unix())\n\t\t\treturn\n\t\tdefault:\n\t\t\tfmt.Println(\"父context的协程监控中,time=\", time.Now().Unix())\n\t\t\ttime.Sleep(1 * time.Second)\n\t\t}\n\t}\n}\n \n// 子context的协程\nfunc watch2(ctx context.Context) {\n\tfor {\n\t\tselect {\n\t\tcase \u003c-ctx.Done(): //取出值即说明是结束信号\n\t\t\tfmt.Println(\"收到信号，子context的协程退出,time=\", time.Now().Unix())\n\t\t\treturn\n\t\tdefault:\n\t\t\tfmt.Println(\"子context的协程监控中,time=\", time.Now().Unix())\n\t\t\ttime.Sleep(1 * time.Second)\n\t\t}\n\t}\n}\n```\n\n###  context.WithTimeout 超时控制\n\n\n`withTimeout`或者`withDeadline`来做超时控制，当一次请求到达我们设置的超时时间，就会及时取消，不在往下执行。`withTimeout`和`withDeadline`作用是一样的，就是传递的时间参数不同而已，他们都会通过传入的时间来自动取消`Context`，这里要注意的是他们都会返回一个`cancelFunc`方法，通过调用这个方法可以达到提前进行取消\n\n```\n  \n// 案例一\n\npackage main\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"time\"\n)\n\n// 创建一个带超时context， 三秒后退出执行\nfunc NewContextWithTimeout() (context.Context, context.CancelFunc) {\n\treturn context.WithTimeout(context.Background(), 3*time.Second)\n}\n\n// 处理程序\nfunc HttpHandler() {\n\tctx, cancel := NewContextWithTimeout()\n\tdefer cancel()\n\tdeal(ctx)\n\n}\n\n// 业务逻辑代码\nfunc deal(ctx context.Context) {\n\tfor i := 0; i \u003c 10; i++ {\n\t\ttime.Sleep(1 * time.Second)\n\t\tselect {\n\t\tcase \u003c-ctx.Done():\n\t\t\tfmt.Println(ctx.Err())\n\t\t\treturn\n\t\tdefault:\n\t\t\tfmt.Printf(\"deal time is %d\\n\", i)\n\t\t}\n\t}\n}\nfunc main() {\n\tHttpHandler()\n}\n```\n\n```\n// 案例二\n\npackage main\n \nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"time\"\n)\n \nfunc main() {\n\t// 创建一个子节点的context,3秒后自动超时\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second*3)\n \n\tgo watch(ctx, \"监控1\")\n\tgo watch(ctx, \"监控2\")\n \n\tfmt.Println(\"现在开始等待8秒,time=\", time.Now().Unix())\n\ttime.Sleep(8 * time.Second)\n \n\tfmt.Println(\"等待8秒结束,准备调用cancel()函数，发现两个子协程已经结束了，time=\", time.Now().Unix())\n\tcancel()\n}\n \n// 单独的监控协程\nfunc watch(ctx context.Context, name string) {\n\tfor {\n\t\tselect {\n\t\tcase \u003c-ctx.Done():\n\t\t\tfmt.Println(name, \"收到信号，监控退出,time=\", time.Now().Unix())\n\t\t\treturn\n\t\tdefault:\n\t\t\tfmt.Println(name, \"goroutine监控中,time=\", time.Now().Unix())\n\t\t\ttime.Sleep(1 * time.Second)\n\t\t}\n\t}\n}\n```\n\n\n### ##### context.WithValue() 携带数据 `[谨慎使用]`\n\n日常在业务开发中都希望能有一个`trace_id`能串联所有的日志，这就需要我们打印日志时能够获取到这个`trace_id`，在`python`中我们可以用`gevent.local`来传递，在`java`中我们可以用`ThreadLocal`来传递，在`Go`语言中我们就可以使用`Context`来传递，通过使用`WithValue`来创建一个携带`trace_id`的`context`，然后不断透传下去，打印日志时输出即可\n\n\n```\n/*\n我们基于context.Background创建一个携带trace_id的ctx，然后通过context树一起传递，\n从中派生的任何context都会获取此值，我们最后打印日志的时候就可以从ctx中取值输出到日志中。\n目前一些RPC框架都是支持了Context，所以trace_id的向下传递就更方便了\n*/\npackage main\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/google/uuid\"\n)\n\ntype MyKEY string\n\nconst (\n\tKEY MyKEY = \"trace_id\"\n)\n\n// 返回一个UUID\nfunc NewRequestID1() MyKEY {\n\treturn MyKEY(strings.Replace(uuid.New().String(), \"-\", \"\", -1))\n\n}\n\n// 创建一个携带trace_id 的ctx\nfunc NewContextWithTraceID() context.Context {\n\tctx := context.WithValue(context.Background(), KEY, NewRequestID1())\n\treturn ctx\n}\n\n// 打印值\nfunc PrintLog(ctx context.Context, message string) {\n\tfmt.Printf(\"%s|info|trace_id=%s|%s\", time.Now().Format(\"2006-01-02 15:04:05\"), GetContextValue1(ctx, KEY), message)\n}\n\n// 获取设置的key对应的值,并断言\nfunc GetContextValue1(ctx context.Context, k MyKEY) MyKEY {\n\tv, ok := ctx.Value(k).(MyKEY)\n\tfmt.Println(\"打印k:\" + k)\n\tfmt.Printf(\"打印v: %v\\n\", v)\n\tif !ok {\n\t\treturn \"\"\n\t}\n\treturn v\n}\n\nfunc ProcessEnter(ctx context.Context) {\n\tPrintLog(ctx, \"Golang\")\n}\n\nfunc main() {\n\tProcessEnter(NewContextWithTraceID())\n}\n```\n\n- 不建议使用 context 值传递关键参数，关键参数应该显示的声明出来\n- 因为携带value也是key value，避免context多个包使用带来的冲突,建议使用内置类型\n- context 传递的数据 key value 都是 interface，所以类型断言时别忘了保证程序的健壮性\n\n\n\n#  应用场景\n\n- `RPC调用`\n    \n- `PipeLine`\n    \n- `超时请求`\n    \n- `HTTP服务器的request互相传递数据\n\n\n注意：\n\n1. 不要将 Context 塞到结构体里。直接将 Context 类型作为函数的第一参数，而且一般都命名为 ctx。\n2. 不要向函数传入一个 nil 的 context，如果你实在不知道传什么，标准库给你准备好了一个 context：todo。\n3. 不要把本应该作为函数参数的类型塞到 context 中，context 存储的应该是一些共同的数据。例如：登陆的 session、cookie 等。\n4. 同一个 context 可能会被传递到多个 goroutine，别担心，context 是并发安全的\n\n\n# 核心数据结构\n\n## context.Context\n\n![图片](https://mmbiz.qpic.cn/mmbiz_png/3ic3aBqT2ibZvfwRgTAXo1RdShVNkHZHalqnGibXKxgD9owqhL6ZPBtpQxADvrGa5qKXvibs1Pib5we53dy1iaabuv0w/640?wx_fmt=png\u0026wxfrom=5\u0026wx_lazy=1\u0026wx_co=1)\n\ncontext数据结构\n\n```\ntype Context interface {\n    Deadline() (deadline time.Time, ok bool)\n    Done() \u003c-chan struct{}\n    Err() error\n    Value(key any) any\n}\n```\n\nContext 为 interface，定义了四个核心 api：\n\n-  Deadline：返回 context 的过期时间；也就是完成工作的截止日期；如果没有设定期限，将返回ok == false\n    \n-  Done：返回 context 中的 channel；当绑定当前context的任务被取消时，将返回一个关闭的channel；如果当前context不会被取消，将返回nil\n    \n-  Err：返回错误； \n\t- 如果 Done 返回的 channel 没有关闭，将返回 nil;如果 Done 返回的 channel 已经关闭，将返回非空的值表示任务结束的原因\n\t- 如果是 context 被取消，Err 将返回 Canceled；如果是 context 超时，Err 将返回 DeadlineExceeded\n    Err() error\n\t    \n-  Value：返回 context 中的对应 key 的值.\n    \n\n## 标准 error\n\n```\nvar Canceled = errors.New(\"context canceled\")\n\nvar DeadlineExceeded error = deadlineExceededError{}\n\ntype deadlineExceededError struct{}\n\nfunc (deadlineExceededError) Error() string   { return \"context deadline exceeded\" }\nfunc (deadlineExceededError) Timeout() bool   { return true }\nfunc (deadlineExceededError) Temporary() bool { return true\n```\n\n- • Canceled：context 被 cancel 时会报此错误；\n    \n- • DeadlineExceeded：context 超时时会报此错误.\n    \n\n#  emptyCtx\n\n##  类的实现\n\n```\ntype emptyCtx int\n\nfunc (*emptyCtx) Deadline() (deadline time.Time, ok bool) {\n    return\n}\n\nfunc (*emptyCtx) Done() \u003c-chan struct{} {\n    return nil\n}\n\nfunc (*emptyCtx) Err() error {\n    return nil\n}\n\nfunc (*emptyCtx) Value(key any) any {\n    return \n}\n```\n\n- emptyCtx 是一个空的 context，本质上类型为一个整型；\n    \n-  Deadline 方法会返回一个公元元年时间以及 false 的 flag，标识当前 context 不存在过期时间；\n    \n-  Done 方法返回一个 nil 值，用户无论往 nil 中写入或者读取数据，均会陷入阻塞；\n    \n-  Err 方法返回的错误永远为 nil；\n    \n-  Value 方法返回的 value 同样永远为 nil.\n    \n\n##  context.Background() \u0026 context.TODO()\n\n```\nvar (\n    background = new(emptyCtx)\n    todo       = new(emptyCtx)\n)\n\nfunc Background() Context {\n    return background\n}\n\nfunc TODO() Context {\n    return todo\n}\n```\n\n我们所常用的 context.Background() 和 context.TODO() 方法返回的均是 emptyCtx 类型的一个实例.\n\n#  cancelCtx\n\n##  cancelCtx 数据结构\n\n![图片](https://mmbiz.qpic.cn/mmbiz_png/3ic3aBqT2ibZvfwRgTAXo1RdShVNkHZHal10nWicjtGfpuhrAe1eXPFNmJMUgYctII58yAtkGM3m7FcnbDniaUyWuQ/640?wx_fmt=png\u0026wxfrom=5\u0026wx_lazy=1\u0026wx_co=1)\n\ncancelCtx数据结构\n\n```\ntype cancelCtx struct {\n    Context\n   \n    mu       sync.Mutex            // protects following fields\n    done     atomic.Value          // of chan struct{}, created lazily, closed by first cancel call\n    children map[canceler]struct{} // set to nil by the first cancel call\n    err      error                 // set to non-nil by the first cancel call\n}\n\ntype canceler interface {\n    cancel(removeFromParent bool, err error)\n    Done() \u003c-chan struct{}\n}\n```\n\n-  embed 了一个 context 作为其父 context. 可见，cancelCtx 必然为某个 context 的子 context；\n    \n- Mu 内置了一把锁，用以协调并发场景下的资源获取；\n    \n-  done：实际类型为 chan struct{}，即用以反映 cancelCtx 生命周期的通道；**c.done 是“懒汉式”创建**，只有调用了 Done() 方法的时候才会被创建。再次说明，函数返回的是**一个只读的 channel，而且没有地方向这个 channel 里面写数据**。所以，直接调用读这个 channel，协程会被 block 住。一般通过搭配 select 来使用。一旦关闭，就会立即读出零值。\n    \n-  children：一个 set，指向 cancelCtx 的所有子 context；\n    \n-  err：记录了当前 cancelCtx 的错误. 必然为某个 context 的子 context；\n    \n## Deadline 方法\n\ncancelCtx 未实现该方法，仅是 embed 了一个带有 Deadline 方法的 Context interface，因此倘若直接调用会报错.\n\n##  Done 方法\n\n![图片](https://mmbiz.qpic.cn/mmbiz_png/3ic3aBqT2ibZvfwRgTAXo1RdShVNkHZHal2PYOJJPIf6FMVCSqzVoFFnMvHIQuALvRg3CfutoztqKHaT3OdrnXcA/640?wx_fmt=png\u0026wxfrom=5\u0026wx_lazy=1\u0026wx_co=1)\n\ncancelCtx.Done\n\n\n.done 是“懒汉式”创建**，只有调用了 Done () 方法的时候才会被创建。再次说明，函数返回的是**一个只读的 channel，而且没有地方向这个 channel 里面写数据**。所以，直接调用读这个 channel，协程会被 block 住。一般通过搭配 select 来使用。\n\n```\nfunc (c *cancelCtx) Done() \u003c-chan struct{} {\n    d := c.done.Load()\n    if d != nil {\n        return d.(chan struct{})\n    }\n    c.mu.Lock()\n    defer c.mu.Unlock()\n    d = c.done.Load()\n    if d == nil {\n        d = make(chan struct{})\n        c.done.Store(d)\n    }\n    return d.(chan struct{})\n}\n```\n\n- 基于 atomic 包，读取 cancelCtx 中的 chan；倘若已存在，则直接返回；\n    \n- 加锁后，在此检查 chan 是否存在，若存在则返回；（double check）\n    \n- 初始化 chan 存储到 aotmic.Value 当中，并返回.（懒加载机制）\n    \n\n##  Err 方法\n\n```\nfunc (c *cancelCtx) Err() error {\n    c.mu.Lock()\n    err := c.err\n    c.mu.Unlock()\n    return err\n}\n```\n\n- • 加锁；\n    \n- • 读取 cancelCtx.err；\n    \n- • 解锁；\n    \n- • 返回结果.\n    \n\n## Value 方法\n\n```\nfunc (c *cancelCtx) Value(key any) any {\n    if key == \u0026cancelCtxKey {\n        return c\n    }\n    return value(c.Context, key)\n}\n```\n\n- • 倘若 key 特定值 \u0026cancelCtxKey，则返回 cancelCtx 自身的指针；\n    \n- • 否则遵循 valueCtx 的思路取值返回\n    \n\n## context.WithCancel()\n\n### context.WithCancel()\n\n```\nfunc WithCancel(parent Context) (ctx Context, cancel CancelFunc) {\n    if parent == nil {\n        panic(\"cannot create context from nil parent\")\n    }\n    c := newCancelCtx(parent)\n    propagateCancel(parent, \u0026c)\n    return \u0026c, func() { c.cancel(true, Canceled) }\n}\n\nfunc newCancelCtx(parent Context) cancelCtx {\n    return cancelCtx{Context: parent}\n}\n```\n\n- • 校验父 context 非空；\n    \n- • 注入父 context 构造好一个新的 cancelCtx；\n    \n- • 在 propagateCancel 方法内启动一个守护协程，以保证父 context 终止时，该 cancelCtx 也会被终止；\n    \n- • 将 cancelCtx 返回，连带返回一个用以终止该 cancelCtx 的闭包函数.\n    \n\n这是一个暴露给用户的方法，传入一个父 Context（这通常是一个 `background`，作为根节点），返回新建的 context，**新 context 的 done channel 是新建的（前文讲过）。**\n\n当 WithCancel 函数返回的 CancelFunc 被调用或者是父节点的 done channel 被关闭（父节点的 CancelFunc 被调用），此 context（子节点） 的 done channel 也会被关闭。\n\n注意传给 WithCancel 方法的参数，前者是 true，也就是说取消的时候，需要将自己从父节点里删除。第二个参数则是一个固定的取消错误类型：\n\n\n    \n\n###  propagateCancel\n\n![图片](https://mmbiz.qpic.cn/mmbiz_png/3ic3aBqT2ibZvfwRgTAXo1RdShVNkHZHaliaDlicS0KjfkKRoflkGOImE2xamdv9H3AQuZUgib0ib78dticA5ic0S8f6RA/640?wx_fmt=png\u0026wxfrom=5\u0026wx_lazy=1\u0026wx_co=1)\n\n\n\n这个方法的作用就是向上寻找可以“挂靠”的“可取消”的 context，并且“挂靠”上去。这样，调用上层 cancel 方法的时候，由上层的协程来管理对子 context 的取消。如果没有父 context ，就自己新建一个携程\n\n\npropagate流程\n\n```\nfunc propagateCancel(parent Context, child canceler) {\n\t// 父节点是个空节点\n\tif parent.Done() == nil {\n\t\treturn // parent is never canceled\n\t}\n\t// 找到可以取消的父 context\n\tif p, ok := parentCancelCtx(parent); ok {\n\t\tp.mu.Lock()\n\t\tif p.err != nil {\n\t\t\t// 父节点已经被取消了，本节点（子节点）也要取消\n\t\t\tchild.cancel(false, p.err)\n\t\t} else {\n\t\t\t// 父节点未取消\n\t\t\tif p.children == nil {\n\t\t\t\tp.children = make(map[canceler]struct{})\n\t\t\t}\n\t\t\t// \"挂到\"父节点上\n\t\t\tp.children[child] = struct{}{}\n\t\t}\n\t\tp.mu.Unlock()\n\t} else {\n\t\t// 如果没有找到可取消的父 context。新启动一个协程监控父节点或子节点取消信号\n\t\tgo func() {\n\t\t\tselect {\n\t\t\tcase \u003c-parent.Done():\n\t\t\t\tchild.cancel(false, parent.Err())\n\t\t\tcase \u003c-child.Done():\n\t\t\t}\n\t\t}()\n\t}\n}\n```\n\npropagateCancel 方法顾名思义，用以传递父子 context 之间的 cancel 事件：\n\n- 倘若 parent 是不会被 cancel 的类型（如 emptyCtx），则直接返回；\n    \n-  倘若 parent 已经被 cancel，则直接终止子 context，并以 parent 的 err 作为子 context 的 err；\n    \n-  假如 parent 是 cancelCtx 的类型，则加锁，并将子 context 添加到 parent 的 children map 当中；\n    \n-  假如 parent 不是 cancelCtx 类型，但又存在 cancel 的能力（比如用户自定义实现的 context），则启动一个协程，通过多路复用的方式监控 parent 状态，倘若其终止，则同时终止子 context，并透传 parent 的 err.\n    \n\n- • 倘若 parent 的 channel 已关闭或者是不会被 cancel 的类型，则返回 false；\n    \n- • 倘若以特定的 cancelCtxKey 从 parent 中取值，取得的 value 是 parent 本身，则返回 true. （基于 cancelCtxKey 为 key 取值时返回 cancelCtx 自身，是 cancelCtx 特有的协议）.\n    \n\n### cancelCtx.cancel\n\n![图片](https://mmbiz.qpic.cn/mmbiz_png/3ic3aBqT2ibZvfwRgTAXo1RdShVNkHZHalkvwNxYrbVJsn2LorIG3ibESumuwIUTo8wEkWXf7sclgVYd33uQx0ticA/640?wx_fmt=png\u0026wxfrom=5\u0026wx_lazy=1\u0026wx_co=1)\n\n\n\n`cancel()` 方法的功能就是关闭 channel：c.done；递归地取消它的所有子节点；从父节点从删除自己。达到的效果是通过关闭 channel，将取消信号传递给了它的所有子节点。Goroutine 接收到取消信号的方式就是 select 语句中的 `读 c.done` 被选中\n\n```\nfunc (c *cancelCtx) cancel(removeFromParent bool, err error) {\n    // 必须要传 err\n\tif err == nil {\n\t\tpanic(\"context: internal error: missing cancel error\")\n\t}\n\tc.mu.Lock()\n\tif c.err != nil {\n\t\tc.mu.Unlock()\n\t\treturn // 已经被其他协程取消\n\t}\n\t// 给 err 字段赋值\n\tc.err = err\n\t// 关闭 channel，通知其他协程\n\tif c.done == nil {\n\t\tc.done = closedchan\n\t} else {\n\t\tclose(c.done)\n\t}\n\t\n\t// 遍历它的所有子节点\n\tfor child := range c.children {\n\t    // 递归地取消所有子节点\n\t\tchild.cancel(false, err)\n\t}\n\t// 将子节点置空\n\tc.children = nil\n\tc.mu.Unlock()\n\n\tif removeFromParent {\n\t    // 从父节点中移除自己 \n\t\tremoveChild(c.Context, c)\n\t}\n}\n```\n\n- • cancelCtx.cancel 方法有两个入参，第一个 removeFromParent 是一个 bool 值，表示当前 context 是否需要从父 context 的 children set 中删除；第二个 err 则是 cancel 后需要展示的错误；\n    \n- • 进入方法主体，首先校验传入的 err 是否为空，若为空则 panic；\n    \n- • 加锁；\n    \n- • 校验 cancelCtx 自带的 err 是否已经非空，若非空说明已被 cancel，则解锁返回；\n    \n- • 将传入的 err 赋给 cancelCtx.err；\n    \n- • 处理 cancelCtx 的 channel，若 channel 此前未初始化，则直接注入一个 closedChan，否则关闭该 channel；\n    \n- • 遍历当前 cancelCtx 的 children set，依次将 children context 都进行 cancel；\n    \n- • 解锁.\n    \n- • 根据传入的 removeFromParent flag 判断是否需要手动把 cancelCtx 从 parent 的 children set 中移除.\n    \n\n走进 removeChild 方法中，观察如何将 cancelCtx 从 parent 的 children set 中移除：\n\n```\nfunc removeChild(parent Context, child canceler) {\n    p, ok := parentCancelCtx(parent)\n    if !ok {\n        return\n    }\n    p.mu.Lock()\n    if p.children != nil {\n        delete(p.children, child)\n    }\n    p.mu.Unlock()\n}\n```\n\n- • 如果 parent 不是 cancelCtx，直接返回（因为只有 cancelCtx 才有 children set） \n    \n- • 加锁；\n    \n- • 从 parent 的 children set 中删除对应 child\n    \n- • 解锁返回.\n    \n\n# timerCtx\n\n##  类\n\n![图片](https://mmbiz.qpic.cn/mmbiz_png/3ic3aBqT2ibZvfwRgTAXo1RdShVNkHZHal41XDibicmYv3qXYlDp6gMDA0mCB9f3h1BDsUqwpBIPEVwBQAVTadIE0A/640?wx_fmt=png\u0026wxfrom=5\u0026wx_lazy=1\u0026wx_co=1)\n\ntimerCtx数据结构\n\n```\ntype timerCtx struct {\n    cancelCtx\n    timer *time.Timer // Under cancelCtx.mu.\n\n    deadline time.Time\n}\n```\n\ntimerCtx 在 cancelCtx 基础上又做了一层封装，除了继承 cancelCtx 的能力之外，新增了一个 time.Timer 用于定时终止 context；另外新增了一个 deadline 字段用于字段 timerCtx 的过期时间.\n\n##  timerCtx.Deadline()\n\n```\nfunc (c *timerCtx) Deadline() (deadline time.Time, ok bool) {\n    return c.deadline, true\n}\n```\n\ncontext.Context interface 下的 Deadline api 仅在 timerCtx 中有效，由于展示其过期时间.\n\n##  timerCtx.cancel\n\n```\nfunc (c *timerCtx) cancel(removeFromParent bool, err error) {\n    c.cancelCtx.cancel(false, err)\n    if removeFromParent {\n        removeChild(c.cancelCtx.Context, c)\n    }\n    c.mu.Lock()\n    if c.timer != nil {\n        c.timer.Stop()\n        c.timer = nil\n    }\n    c.mu.Unlock()\n}\n```\n\n- • 复用继承的 cancelCtx 的 cancel 能力，进行 cancel 处理；\n    \n- • 判断是否需要手动从 parent 的 children set 中移除，若是则进行处理\n    \n- • 加锁；\n    \n- • 停止 time.Timer\n    \n- • 解锁返回.\n    \n\n##  context.WithTimeout \u0026 context.WithDeadline\n\n```\nfunc WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc) {\n    return WithDeadline(parent, time.Now().Add(timeout))\n}\n```\n\ncontext.WithTimeout 方法用于构造一个 timerCtx，本质上会调用 context.WithDeadline 方法：\n\n```\nfunc WithDeadline(parent Context, d time.Time) (Context, CancelFunc) {\n    if parent == nil {\n        panic(\"cannot create context from nil parent\")\n    }\n    if cur, ok := parent.Deadline(); ok \u0026\u0026 cur.Before(d) {\n        // The current deadline is already sooner than the new one.\n        return WithCancel(parent)\n    }\n    c := \u0026timerCtx{\n        cancelCtx: newCancelCtx(parent),\n        deadline:  d,\n    }\n    propagateCancel(parent, c)\n    dur := time.Until(d)\n    if dur \u003c= 0 {\n        c.cancel(true, DeadlineExceeded) // deadline has already passed\n        return c, func() { c.cancel(false, Canceled) }\n    }\n    c.mu.Lock()\n    defer c.mu.Unlock()\n    if c.err == nil {\n        c.timer = time.AfterFunc(dur, func() {\n            c.cancel(true, DeadlineExceeded)\n        })\n    }\n    return c, func() { c.cancel(true, Canceled) }\n}\n```\n\n- • 校验 parent context 非空；\n    \n- • 校验 parent 的过期时间是否早于自己，若是，则构造一个 cancelCtx 返回即可；\n    \n- • 构造出一个新的 timerCtx；\n    \n- • 启动守护方法，同步 parent 的 cancel 事件到子 context；\n    \n- • 判断过期时间是否已到，若是，直接 cancel timerCtx，并返回 DeadlineExceeded 的错误；\n    \n- • 加锁；\n    \n- • 启动 time.Timer，设定一个延时时间，即达到过期时间后会终止该 timerCtx，并返回 DeadlineExceeded 的错误；\n    \n- • 解锁；\n    \n- • 返回 timerCtx，已经一个封装了 cancel 逻辑的闭包 cancel 函数.\n    \n\n#  valueCtx\n\n## 类\n\n![图片](https://mmbiz.qpic.cn/mmbiz_png/3ic3aBqT2ibZvfwRgTAXo1RdShVNkHZHalIVWfu4T9C1icgjPVgm72em5XEmkWMWcNeiatmNGGBerBtkcJ27XHCoVQ/640?wx_fmt=png\u0026wxfrom=5\u0026wx_lazy=1\u0026wx_co=1)\n\nvalueCtx数据结构\n\n```\ntype valueCtx struct {\n    Context\n    key, val any\n}\n```\n\n- • valueCtx 同样继承了一个 parent context；\n    \n- • 一个 valueCtx 中仅有一组 kv 对.\n    \n\n##  valueCtx.Value()\n\n![图片](https://mmbiz.qpic.cn/mmbiz_png/3ic3aBqT2ibZvfwRgTAXo1RdShVNkHZHal2tHrS8XW75EIQC6BbgHbQchXplMw7nviagAUOhDKBGHQMqqYogcwZpg/640?wx_fmt=png\u0026wxfrom=5\u0026wx_lazy=1\u0026wx_co=1)\n\nvalueCtx.Value\n\n```\nfunc (c *valueCtx) Value(key any) any {\n    if c.key == key {\n        return c.val\n    }\n    return value(c.Context, key)\n}\n```\n\n- • 假如当前 valueCtx 的 key 等于用户传入的 key，则直接返回其 value；\n    \n- • 假如不等，则从 parent context 中依次向上寻找.\n    \n\n```\nfunc value(c Context, key any) any {\n    for {\n        switch ctx := c.(type) {\n        case *valueCtx:\n            if key == ctx.key {\n                return ctx.val\n            }\n            c = ctx.Context\n        case *cancelCtx:\n            if key == \u0026cancelCtxKey {\n                return c\n            }\n            c = ctx.Context\n        case *timerCtx:\n            if key == \u0026cancelCtxKey {\n                return \u0026ctx.cancelCtx\n            }\n            c = ctx.Context\n        case *emptyCtx:\n            return nil\n        default:\n            return c.Value(key)\n        }\n    }\n}\n```\n\n- • 启动一个 for 循环，由下而上，由子及父，依次对 key 进行匹配；\n    \n- • 其中 cancelCtx、timerCtx、emptyCtx 类型会有特殊的处理方式；\n    \n- • 找到匹配的 key，则将该组 value 进行返回.\n    \n\n##  valueCtx 用法小结\n\n阅读源码可以看出，valueCtx 不适合视为存储介质，存放大量的 kv 数据，原因有三：\n\n- • 一个 valueCtx 实例只能存一个 kv 对，因此 n 个 kv 对会嵌套 n 个 valueCtx，造成空间浪费；\n    \n- • 基于 k 寻找 v 的过程是线性的，时间复杂度 O(N)；\n    \n- • 不支持基于 k 的去重，相同 k 可能重复存在，并基于起点的不同，返回不同的 v. 由此得知，valueContext 的定位类似于请求头，只适合存放少量作用域较大的全局 meta 数据.\n    \n\n## context.WithValue()\n\n```\nfunc WithValue(parent Context, key, val any) Context {\n    if parent == nil {\n        panic(\"cannot create context from nil parent\")\n    }\n    if key == nil {\n        panic(\"nil key\")\n    }\n    if !reflectlite.TypeOf(key).Comparable() {\n        panic(\"key is not comparable\")\n    }\n    return \u0026valueCtx{parent, key, val}\n}\n```\n\n- • 倘若 parent context 为空，panic；\n    \n- • 倘若 key 为空 panic；\n    \n- • 倘若 key 的类型不可比较，panic；\n    \n- • 包括 parent context 以及 kv 对，返回一个新的 valueCtx.\n\n\n\n\n通过层层传递 Context ，最终形成这样一棵树：\n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240227175739.png)\n\n\n和链表有点像，只是它的方向相反：Context 指向它的父节点，链表则指向下一个节点。通过 WithValue 函数，可以创建层层的 valueCtx，存储 goroutine 间可以共享的变量。\n\n\n取值的过程，实际上是一个递归查找的过程：\n\n```golang\nfunc (c *valueCtx) Value(key interface{}) interface{} {\n\tif c.key == key {\n\t\treturn c.val\n\t}\n\treturn c.Context.Value(key)\n}\n```\n\n它会顺着链路一直往上找，比较当前节点的 key 是否是要找的 key，如果是，则直接返回 value。否则，一直顺着 context 往前，最终找到根节点（一般是 emptyCtx），直接返回一个 nil。所以用 Value 方法的时候要判断结果是否为 nil。","lastmodified":"2024-03-02T12:01:53.846210423Z","tags":[]},"/GO/%E5%85%AB%E8%82%A1%E6%96%87/Golang%E5%9F%BA%E7%A1%80":{"title":"Golang基础","content":"\n\n\n# init 和 main 函数相关特点\n\n## init 函数 （没有输入参数、返回值）的主要作用\n\n- 初始化不能采用初始化表达式初始化的变量。\n- 程序运行前的注册。\n- 实现sync.Once功能。\n- 其他\n## init 顺序\n\n1. 在同一个 package 中，可以多个文件中定义 init 方法\n2. 在同一个 go 文件中，可以重复定义 init 方法\n3. 在同一个 package 中，不同文件中的 init 方法的执行按照文件名先后执行各个文件中的 init 方法\n4. 在同一个文件中的多个 init 方法，按照在代码中编写的顺序依次执行不同的 init 方法\n5. 对于不同的 package，如果不相互依赖的话，按照 main 包中 import 的顺序调用其包中的 init() 函数\n6. 如果 package 存在依赖，调用顺序为最后被依赖的最先被初始化，例如：导入顺序 main –\u003e A –\u003e B –\u003e C，则初始化顺序为 C –\u003e B –\u003e A –\u003e main，一次执行对应的 init 方法。\n\n所有 init 函数都在同⼀个 goroutine 内执行。\n所有 init 函数结束后才会执行 main.main 函数\n\n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticimage.png)\n\n\n# Go 的数据结构的零值是什么?\n\n- 所有整型类型：0\n\n- 浮点类型：0.0\n\n- 布尔类型：false\n\n- 字符串类型：””\n\n- 指针、interface、切片（slice）、channel、map、function ：nil\n\nGo的零值初始是递归的，即**数组、结构体等类型的零值初始化就是对其组成元素逐一进行零值初始化**。\n\n# byte和rune有什么区别\n\nrune和byte在go语言中都是字符类型，且都是别名类型\n\n* byte 型本质上是 uint8类型的别名，代表了 ASCII 码的一个字符\n\n* rune 型本质上是 int32型的别名，代表一个 UTF-8 字符\n\n# Go struct 能不能比较\n\n需要具体情况具体分析，如果struct中含有不能被比较的字段类型，就不能被比较。\n\n如果struct中所有的字段类型都支持比较，那么就可以被比较。\n\n* 不可被比较的类型：\n\t- slice，因为slice是引用类型，除非是和nil比较\n\t- map，和slice同理，如果要比较两个map只能通过循环遍历实现\n\t- 函数类型\n\n其他的类型都可以比较。\n\n还有两点值得注意：\n\n- 结构体之间只能比较它们是否相等，而不能比较它们的大小\n- 只有所有属性都相等而且属性顺序都一致的结构体才能进行比较\n\n# Go 语言如何初始化变量\n\n```\nvar a int=10  \nvar a=10  \na:=10\n```\n\n\n\n# Go import 的三种方式\n\n**一、加下划线：**\n\nimport 下划线（如：_ “github.com/go-sql-driver/mysql”）\n\n作用：**使用[import _ 包路径]只是引用该包，仅仅是为了调用init()函数，所以无法通过包名来调用包中的其他函数**。\n\n**二、加点(.)：**\n\nimport和引用的包名之间加点（.）操作的含义就是这个包导入之后在调用这个包的函数时，可以省略前缀的包名。\n\n**三、别名：**\n\n别名操作顾名思义可以把包命名成另一个用起来容易记忆的名字。\n\n# 与其他语言相比，使用 Go 有什么好处？\n\n- 与其他作为学术实验开始的语⾔不同，Go 代码的设计是务实的。每个功能和语法决策都旨在让程序员的⽣活更轻松。\n- Golang 针对并发进行了优化，并且在规模上运行良好。\n- 由于单⼀的标准代码格式，Golang 通常被认为比其他语⾔更具可读性。\n- ⾃动垃圾收集明显比Java 或 Python 更有效，因为它与程序同时执行。\n\n# 听说 go 有什么什么的缺陷，你怎么看\n* 缺少框架；\n* go 语言通过函数和预期的调用代码简单地返回错误，容易丢失错误发生的范围； \n* go语言的软件包管理没有办法制定特定版本的依赖库。\n\n# Golang的常量取地址\n\nGo 语⾔中，**常量⽆法寻址, 是不能进⾏取指针操作的**\n\n```\nconst i = 100  \n  \nvar j = 123  \n  \nfunc main() {  \n\tfmt.Println(\u0026j, j)   \n\tfmt.Println(\u0026i, i)  //panic  \n} //Go语⾔中，常量⽆法寻址, 是不能进⾏取指针操作的\n```\n\n# Golang 的字符串拼接\n\n\n```\nA. str := 'abc' + '123'  \nB. str := \"abc\" + \"123\"  \nC. str ：= '123' + \"abc\"  \nD. fmt.Sprintf(\"abc%d\", 123)\n\n答案：B、D\n```\n\n\n# string 和 []byte 如何取舍\n\nstring 擅长的场景：\n\n- 需要字符串比较的场景；\n- 不需要nil字符串的场景；\n\n[]byte擅长的场景：\n\n- 修改字符串的场景，尤其是修改粒度为1个字节；\n- 函数返回值，需要用nil表示含义的场景；\n- 需要切片操作的场景；\n\n# 使用过哪些 Golang 的 String 类库\n\n**strings. Builder**\n\n`Go` 语言提供了一个专门操作字符串的库 `strings`，可以用于字符串查找、替换、比较等。\n\n使用 `strings.Builder` 可以进行字符串拼接，提供了 `writeString` 方法拼接字符串，使用方式如下：\n\n\n```\nvar builder strings.Builder\nbuilder.WriteString(\"asong\")\nbuilder.String()\n```\n\n`strings.builder` 的实现原理很简单，结构如下：\n\n```\ntype Builder struct {\n    addr *Builder // of receiver, to detect copies by value\n    buf  []byte // 1\n}\n```\n\n`addr` 字段主要是做 `copycheck`，`buf` 字段是一个 `byte` 类型的切片，这个就是用来存放字符串内容的，提供的 `writeString()` 方法就是向切片 `buf` 中追加数据：\n\n```\nfunc (b *Builder) WriteString(s string) (int, error) {\n b.copyCheck()\n b.buf = append(b.buf, s...)\n return len(s), nil\n}\n```\n\n提供的 `String` 方法就是将 `[]byte` 转换为 `string` 类型，这里为了避免内存拷贝的问题，使用了强制转换来避免内存拷贝：\n\n```\nfunc (b *Builder) String() string {\n return *(*string)(unsafe.Pointer(\u0026b.buf))\n}\n```\n\n**bytes. Buffer**\n\n因为 `string` 类型底层就是一个 `byte` 数组，所以我们就可以 `Go` 语言的 `bytes.Buffer` 进行字符串拼接。`bytes.Buffer` 是一个一个缓冲 `byte` 类型的缓冲器，这个缓冲器里存放着都是 `byte`。使用方式如下：\n\n```\nbuf := new(bytes.Buffer)\nbuf.WriteString(\"asong\")\nbuf.String()\n```\n\n`bytes.buffer` 底层也是一个 `[]byte` 切片，结构体如下：\n\n```\ntype Buffer struct {\n buf      []byte // contents are the bytes buf[off : len(buf)]\n off      int    // read at \u0026buf[off], write at \u0026buf[len(buf)]\n lastRead readOp // last read operation, so that Unread* can work correctly.\n}\n```\n\n因为 `bytes.Buffer` 可以持续向 `Buffer` 尾部写入数据，从 `Buffer` 头部读取数据，所以 `off` 字段用来记录读取位置，再利用切片的 `cap` 特性来知道写入位置，这个不是本次的重点，重点看一下 `WriteString` 方法是如何拼接字符串的：\n\n```\nfunc (b *Buffer) WriteString(s string) (n int, err error) {\n b.lastRead = opInvalid\n m, ok := b.tryGrowByReslice(len(s))\n if !ok {\n  m = b.grow(len(s))\n }\n return copy(b.buf[m:], s), nil\n}\n```\n\n切片在创建时并不会申请内存块，只有在往里写数据时才会申请，首次申请的大小即为写入数据的大小。如果写入的数据小于 64 字节，则按 64 字节申请。采用 `动态扩展slice` 的机制，字符串追加采用 `copy` 的方式将追加的部分拷贝到尾部，copy 是内置的拷贝函数，可以减少内存分配。\n\n但是在将 `[]byte` 转换为 `string` 类型依旧使用了标准类型，所以会发生内存分配：\n\n```\nfunc (b *Buffer) String() string {\n if b == nil {\n  // Special case, useful in debugging.\n  return \"\u003cnil\u003e\"\n }\n return string(b.buf[b.off:])\n}\n```\n\n\n# 字符串转成 byte 数组，会发生内存拷贝吗\n\n**字符串转成切片，会产生拷贝。严格来说，只要是发生类型强转都会发生内存拷贝**\n\nhttps://mp.weixin.qq.com/s?__biz=MzkxNTU5MjE0MQ==\u0026mid=2247492748\u0026idx=1\u0026sn=1b836dbf9ce2e660080d28878f57476c\u0026source=41#wechat_redirect\n\n# 翻转含有中文、数字、英文字母的字符串\n\n- `rune` 关键字，从 golang 源码中看出，它是 int32的别名（-2^31 ~ 2^31-1），比起 byte（-128～127），**可表示更多的字符**。\n    \n- 由于rune可表示的范围更大，所以能处理一切字符，当然也包括**中文字符**。在平时计算中文字符，可用rune。\n    \n- **因此将`字符串`转为`rune的切片`，再进行翻转，完美解决**\n\nhttps://mp.weixin.qq.com/s?__biz=MzkxNTU5MjE0MQ==\u0026mid=2247492747\u0026idx=1\u0026sn=2c2e3331053fe3baf9e842ddbd795f20\u0026source=41#wechat_redirect\n\n# json 包变量不加 tag 会怎么样？\n\n- 如果变量 `首字母小写`，则为 `private`。无论如何 `不能转`，因为取不到 `反射信息`。\n    \n- 如果变量`首字母大写`，则为`public`。\n\n\t- `不加tag`，可以正常转为`json`里的字段，`json`内字段名跟结构体内字段`原名一致`。\n\t    \n\t- `加了tag`，从`struct`转`json`的时候，`json`的字段名就是`tag`里的字段名，原字段名已经没用。\n\nhttps://mp.weixin.qq.com/s?__biz=MzkxNTU5MjE0MQ==\u0026mid=2247492753\u0026idx=1\u0026sn=50f47249103f79fd404c180cb9e2c926\u0026source=41#wechat_redirect\n\n# reflect（反射包）如何获取字段 tag？为什么 json 包不能导出私有变量的 tag？\n\nhttps://mp.weixin.qq.com/s?__biz=MzkxNTU5MjE0MQ==\u0026mid=2247492754\u0026idx=1\u0026sn=9fb4360da097c81fe733ba48d3aca8a7\u0026source=41#wechat_redirect\n\n# 昨天那个在 for 循环里 append 元素的同事，今天还在么？\n\nhttps://mp.weixin.qq.com/s?__biz=MzkxNTU5MjE0MQ==\u0026mid=2247492759\u0026idx=1\u0026sn=d91070aef6e10d92a7a094d1e99f45ee\u0026source=41#wechat_redirect\n\n# Golang 语言的自增，自减操作\n\nGolang 语言没++i、–i，只有 i++、i–-。\n\n# Printf()、Sprintf()、Fprintf()函数的区别用法是什么\n\n都是把格式好的字符串输出，只是输出的目标不一样。\n\n* Printf()，是把格式字符串**输出到标准输出**（一般是屏幕，可以重定向）。Printf() 是和标准输出文件 (stdout) 关联的，Fprintf 则没有这个限制。\n* Sprintf()，是把格式字符串**输出到指定字符串中**，所以参数比 printf 多一个 char*。那就是目标字符串地址。\n* Fprintf()，是把格式字符串**输出到指定文件设备中**，所以参数比 printf 多一个文件指针 FILE*。主要用于文件操作。Fprintf() 是格式化输出到一个 stream，通常是到文件。\n\n# Go 语言中 cap 函数可以作用于哪些内容？\n\n- array 返回数组的元素个数；\n\n- slice 返回 slice 的最⼤容量；\n\n- channel 返回 channel 的容量；\n\n# Golang 语言的引用类型有什么?\n\nGo语言中的引用类型有\n\n- func（函数类型）\n\n- interface（接口类型）\n\n- slice（切片类型）\n\n- map（字典类型）\n\n- channel（管道类型）\n\n- 指针类型\n\n# 通过指针变量  **p** 访问其成员变量 name，有哪几种方式？\n\nA. p.name\n\nB. (\u0026p).name\n\nC. (*p).name\n\nD. p-\u003ename\n\n**答案：A、C**\n\n# for select 时，如果通道已经关闭会怎么样？如果只有⼀个 case 呢？\n\n- for 循环 `select` 时，如果其中一个 case 通道已经关闭，则每次都会执行到这个 case。\n    \n- 如果select里边只有一个case，而这个case被关闭了，则会出现死循环。\n\nhttps://mp.weixin.qq.com/s?__biz=MzkxNTU5MjE0MQ==\u0026mid=2247492758\u0026idx=1\u0026sn=fb81bf91986b7c42f1ac2b8fb75f74a6\u0026source=41#wechat_redirect\n# Golang 的 bool 类型的赋值\n\n\n```\nA. b = true  \nB. b = 1  \nC. b = bool(1)  \nD. b = (1 == 2)  \n  \n赋值正确的是A,D。   \n首先B选项，int类型不能由bool类型来表示。  \n其次C选项，bool()不能转化int类型。int和float可以相互转化\n```\n\n\n# 空结构体占不占内存空间？ 为什么使用空结构体？\n\n空结构体是没有内存大小的结构体。  \n通过 unsafe.Sizeof() 可以查看空结构体的宽度，代码如下：\n\n\n```\nvar s struct{}\nfmt.Println(unsafe.Sizeof(s)) // prints 0\n```\n\n\n准确的来说，空结构体有一个特殊起点： `zerobase` 变量。`zerobase`是一个占用 8 个字节的`uintptr`全局变量。每次定义 `struct {}` 类型的变量，编译器只是把`zerobase`变量的地址给出去。也就是说空结构体的变量的内存地址都是一样的。  \n空结构体的使用场景主要有三种：\n\n- 实现方法接收者：在业务场景下，**我们需要将方法组合起来，代表其是一个 ”分组“ 的**，便于后续拓展和维护。\n- 实现集合类型：在** Go 语言的标准库中并没有提供集合（Set）的相关实现，因此一般在代码中我们图方便，会直接用 map 来替代：`type Set map[string]struct{}`**。\n- 实现空通道：在 Go channel 的使用场景中，**常常会遇到通知型 channel，其不需要发送任何数据，只是用于协调 Goroutine 的运行，用于流转各类状态或是控制并发情况**。\n\n# 空结构体的使用场景\n\n空结构体（empty struct）是在 Go 语言中一个特殊的概念，它没有任何字段。在 Go 中，它通常被称为匿名结构体或零宽度结构体。尽管它没有字段，但它在某些情况下仍然有其用途，以下是一些常见的空结构体的使用场景：\n\n1. **占位符**：空结构体可以用作占位符，用于表示某个数据结构或数据集合的存在而不实际存储任何数据。这在某些数据结构的实现中非常有用，特别是在要实现某种数据结构的集合或映射时，但并不需要存储实际的值。 \n\n```\ngoCopy code// 表示集合中是否包含某个元素的映射\nset := make(map[string]struct{})\nset[\"apple\"] = struct{}{}\n```\n\n2. **信号量**：空结构体可以用作信号量，用于控制并发操作。通过向通道发送或接收空结构体，可以实现信号的传递和同步。 \n\n```\ngoCopy code// 用通道作为信号量\nsemaphore := make(chan struct{}, 5) // 控制并发数为5\ngo func() {\n    semaphore \u003c- struct{}{} // 获取信号量\n    defer func() { \u003c-semaphore }() // 释放信号量\n    // 执行并发操作\n}()\n```\n\n1. **强调结构**：有时，空结构体可用于强调某个结构的重要性或存在。它可以用作结构体的标签，表示关注该结构的存在而不是其内容。 \n   \n```\ngoCopy code// 表示一篇文章的元信息，不包含实际内容\ntype Article struct {\n    Title       string\n    Author      string\n    PublishedAt time.Time\n    Metadata    struct{} // 空结构体强调元信息的存在\n}\n```\n\n1. **JSON 序列化**：在处理 JSON 数据时，有时需要表示一个空对象。可以使用空结构体来表示 JSON 中的空对象（`{}`）。\n\n```\ngoCopy code// 表示一个空的JSON对象\nemptyJSON := struct{}{}\njsonBytes, _ := json.Marshal(emptyJSON)\nfmt.Println(string(jsonBytes)) // 输出: {}\n```\n\n\n尽管空结构体没有字段，但它在上述情况下提供了一种轻量级的方式来实现特定的需求，而无需分配额外的内存或定义具体的数据结构。这使得它成为 Go 中的一种有用工具，可以在编写清晰、高效和易于理解的代码时派上用场。\n\n**struct 的特点**\n\n- 用来自定义复杂数据结构\n- Struct 里面可以包含多个字段（属性）\n- Struct 类型可以定义方法，注意和函数的区分\n- Struct 类型是值类型\n- Struct 类型可以嵌套\n- GO 语言没有 class 类型，只有 struct 类型\n\n**特殊之处**\n\n- 结构体是用户单独定义的类型，不能和其他类型进行强制转换\n- Golang 中的 struct 没有构造函数，一般可以使用工厂模式来解决这个问题\n- 我们可以为 struct 中的每个字段，写上一个 tag。这个 tag 可以通过反射的机制获取到，最常用的场景就是 json 序列化和反序列化。\n- 结构体中字段可以没有名字，即匿名字段\n\n\n# Go 的面向对象特性\n\n**接口**\n\n接口使用 interface 关键字声明，**任何实现接口定义方法的类都可以实例化该接口**，接口和实现类之间没有任何依赖\n\n你可以实现一个新的类当做 Sayer 来使用，而不需要依赖 Sayer 接口，也可以为已有的类创建一个新的接口，而不需要修改任何已有的代码，和其他静态语言相比，这可以算是 golang 的特色了吧\n\n```\ntype Sayer interface {\n Say(message string)\n SayHi()\n}\n```\n\n**继承**\n\n**继承使用组合的方式实现**\n\n```\ntype Animal struct {\n Name string\n}\n\nfunc (a *Animal) Say(message string) {\n    fmt.Printf(\"Animal[%v] say: %v\n\", a.Name, message)\n}\n\ntype Dog struct {\n Animal\n}\n```\n\n\nDog 将继承 Animal 的 Say 方法，以及其成员 Name\n\n**覆盖**\n\n子类可以重新实现父类的方法\n\n\n```\n// override Animal.Say\nfunc (d *Dog) Say(message string) {\n    fmt.Printf(\"Dog[%v] say: %v\n\", d.Name, message)\n}\n```\n\nDog.Say 将覆盖 Animal.Say\n\n**多态**\n\n接口可以用任何实现该接口的指针来实例化\n\n\n```\nvar sayer Sayer\n\nsayer = \u0026Dog{Animal{Name: \"Yoda\"}}\nsayer.Say(\"hello world\")\n```\n\n\n但是不支持父类指针指向子类，下面这种写法是不允许的\n\n\n\n```\nvar animal *Animal\nanimal = \u0026Dog{Animal{Name: \"Yoda\"}}\n```\n\n\n同样子类继承的父类的方法引用的父类的其他方法也没有多态特性\n\n\n```\nfunc (a *Animal) Say(message string) {\n    fmt.Printf(\"Animal[%v] say: %v\n\", a.Name, message)\n}\n\nfunc (a *Animal) SayHi() {\n    a.Say(\"Hi\")\n}\n\nfunc (d *Dog) Say(message string) {\n    fmt.Printf(\"Dog[%v] say: %v\n\", d.Name, message)\n}\n\nfunc main() {\n var sayer Sayer\n\n    sayer = \u0026Dog{Animal{Name: \"Yoda\"}}\n    sayer.Say(\"hello world\") // Dog[Yoda] say: hello world\n    sayer.SayHi() // Animal[Yoda] say: Hi\n    }\n```\n\n上面这段代码中，**子类 Dog 没有实现 SayHi 方法，调用的是从父类 Animal.SayHi，而 Animal.SayHi 调用的是 Animal.Say 而不是Dog.Say，这一点和其他面向对象语言有所区别**，需要特别注意，但是可以用下面的方式来实现类似的功能，以提高代码的复用性\n\n```\nfunc SayHi(s Sayer) {\n    s.Say(\"Hi\")\n}\n\ntype Cat struct {\n Animal\n}\n\nfunc (c *Cat) Say(message string) {\n    fmt.Printf(\"Cat[%v] say: %v\n\", c.Name, message)\n}\n\nfunc (c *Cat) SayHi() {\n SayHi(c)\n}\n\nfunc main() {\n var sayer Sayer\n\n    sayer = \u0026Cat{Animal{Name: \"Jerry\"}}\n    sayer.Say(\"hello world\") // Cat[Jerry] say: hello world\n    sayer.SayHi() // Cat[Jerry] say: Hi\n}\n```\n\n# Go 语言中 ,下面哪个关于指针的说法是错误的?\n\n- 指针不能进行算术运算 \n- 指针可以比较\n- 指针可以是nil\n- 指针可以指向任何类型\n\n指针在 Go 语言中只能指向相同类型的结构体或者基本类型。例如，一个 int 类型的变量，只能指向 int 类型的指针。如果尝试将一个不同类型的指针赋给一个变量，将会导致编译错误。\n\n# Go 语言的接口类型是如何实现的？\n\n在Go语言中，接口类型是通过类型嵌入（embedding的方式实现的。**每个实现了接口的类型的结构体中都有一个隐含的成员，该成员是指向接口类型的指针**。通过这种方式，接口实现了对类型的约束和定义。\n\n具体来说，当一个类型实现了某个接口的所有方法后，该类型就被认为是实现了该接口。在结构体中，可以通过嵌入接口类型的方式来实现接口方法。在实现接口方法时，方法的签名需要与接口定义中的方法签名保持一致。\n\n\n# Go 结构体内嵌后的命名冲突\n\n```\npackage main\n\nimport (\n\t\"fmt\"\n)\n\ntype A struct {\n\ta int\n}\n\ntype B struct {\n\ta int\n}\n\ntype C struct {\n\tA\n\tB\n}\n\nfunc main() {\n\tc := \u0026C{}\n\tc.A.a = 1\n\tfmt.Println(c)\n}\n// 输出 \u0026{{1} {0}}\n```\n\n第 7 行和第 11 行分别定义了两个拥有 a int 字段的结构体。\n第 15 行的结构体嵌入了 A 和 B 的结构体。\n第 21 行实例化 C 结构体。\n第 22 行按常规的方法，访问嵌入结构体 A 中的 a 字段，并赋值1。\n第 23 行可以正常输出实例化 C 结构体。\n接着，将第 22 行修改为如下代码：\n\n```\nfunc main(){\n\tc:=\u0026C{}\n    c.a=1\n    fmt.Println(c)\n}\n```\n\n![img](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticimg.png)\n\n此时再编译运行，编译器报错：\n\n.main. Go:22:3:ambiguousselectorc. A\n\n编译器告知 C 的选择器 a 引起歧义，也就是说，编译器无法决定将 1 赋给 C 中的 A 还是 B 里的字段 a。使用c.a 引发二义性的问题一般应该由程序员逐级完整写出避免错误。\n\n在使用内嵌结构体时，Go 语言的编译器会非常智能地提醒我们可能发生的歧义和错误。\n\n**解决：可以通过：c.A.a 或者c.B.a 都可以正确得到对应的值\n\n\n# 关于 switch 语句，下⾯说法正确的有?\n\nA. 条件表达式必须为常量或者整数；\n\nB. 单个case中，可以出现多个结果选项；\n\nC. 需要⽤break来明确退出⼀个case；\n\nD. 只有在case中明确添加fallthrough关键字，才会继续执⾏紧跟的下⼀个case；\n\n**答案B、D**\n\n# Go 编程语言中 switch 语句的语法\n\n```\nswitch var1 {\n    case val1:\n        ...\n    case val2:\n        ...\n    default:\n        .\n}\n\nswitch{\n    case 1,2,3,4:\n    default:\n} //case可以有多个数据\n\n```\n变量 var1 可以是任何类型，而 val1 和 val2 则可以是同类型的任意值。类型不被局限于常量或整数，但必须是相同的类型；或者最终结果为相同类型的表达式。\n\n# Go 关键字 fallthrough 有什么作用\n\nFallthrough 关键字只能用在 switch 中。且只能在每个 case 分支中最后一行出现，**作用是如果这个 case 分支被执行，将会继续执行下一个 case 分支，而且不会去判断下一个分支的 case 条件是否成立。**\n\n```\npackage main  \n  \nimport \"fmt\"  \n  \nfunc main() {  \n\tswitch \"a\" {  \n\tcase \"a\":  \n\t\tfmt.Println(\"匹配a\")  \n\t\tfallthrough  \n\tcase \"b\":  \n\t\tfmt.Println(\"a成功了，也执行b分支\")  \n\tcase \"c\":  \n\t\tfmt.Println(\"a成功了，c分支会执行吗？\")  \n\tdefault:  \n\t\tfmt.Println(\"默认执行\")  \n\t}  \n}  \n/*  \n\t匹配a  \n    a成功了，也执行b分支  \n*/\n```\n\n\n# copy 是操作符还是内置函数\n\nGolang中copy是内置函数。\n\n# Go 两个接口之间可以存在什么关系？\n\n**如果两个接口有相同的方法列表，那么他们就是等价的，可以相互赋值**。如果接口 A的方法列表是接口B的方法列表的自己，那么接口B可以赋值给接口A。接口查询是否成功，要在运行期才能够确定。\n\n\n# Golang 的返回值命名\n\n![image-20230724165455977](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticimage-20230724165455977.png)\n\n# Golang 的 iota 如何使用？\n\n![image-20230724165708801](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticimage-20230724165708801.png)\n\n1. iota在const关键字出现时被重置为0\n2. const声明块中每新增一行iota值自增1\n3. **第一个常量必须指定一个表达式，后续的常量如果没有表达式，则继承上面的表达式**\n\n# 数组之间如何进行比较？\n\n![image-20230724170030544](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticimage-20230724170030544.png)\n\n# for range 的注意点和坑\n\n**第一个说法**\n\n1.迭代变量。Python中for in 可以直接的到value，但Go的for range 迭代变量有两个，**第一个是元素在迭代集合中的序号值key（从0开始），第二个值才是元素值value**。\n\n2.针对字符串。在Go中对字符串运用for range操作，**每次返回的是一个码点，而不是一个字节**。Go编译器不会为[]byte进行额外的内存分配，而是直接使用string的底层数据。\n\n3.对map类型内元素的迭代顺序是随机的。要想有序迭代map内的元素，我们需要额外的数据结构支持，**比如使用一个切片来有序保存map内元素的key值**。\n\n4.针对切片类型复制之后，如果原切片扩容增加新元素。迭代复制后的切片并不会输出扩容新增元素。这是因为range表达式中的切片实际上是原切片的副本。\n\n5.迭代变量是重用的。类似PHP语言中的i=0；如果其他循环中使用相同的迭代变量，需要重新初始化i。\n\n6.for range使用时，k,v值已经赋值好了，不会因为for循环的改变而改变\n\n```\npackage main\n\nimport (\n\t\"fmt\"\n)\n\nfunc main() {\n\tx := []string{\"a\", \"b\", \"c\"}\n\tfor v := range x {\n\t\tfmt.Println(v)\n\t}\n}\n//输出 0 1 2\n```\n\n\n\n\n**第二个说法**\n\n应该是一个for循环中作用域的问题\n\n\n```\nsrc := []int{1, 2, 3, 4, 5}\nvar dst2 []*inv\nfor _, v := range src {\n    dst2 = append(dst2, \u0026v)\n    // fmt.println(\u0026v)\n}\n\nfor _, p := range dst2 {\n    fmt.Print(*p)\n}\n// 输出\n// 5555\n```\n\n为什么呢, 因为 for-range 中 循环变量的作用域的规则限制  \n假如取消append()后一行的注释，可以发现循环中v的变量内存地址是一样的，也可以解释为for range相当于\n\n\n```\nvar i int\nfor j := 0; j \u003c len(src); j++ {\n    i = src[j]\n    dst2 = append(dst2, \u0026i)\n}\n```\n\n\n而不是我们想象中的\n\n```\nfor j := 0; j \u003c len(src); j++ {\n    dst2 = append(dst2, \u0026src[j])\n}\n```\n\n\n如果要在for range中实现，我们可以改写为\n\n\n```\nsrc := []int{1, 2, 3, 4, 5}\nvar dst2 []*int\nfor _, v := range src {\n    new_v := v\n    dst2 = append(dst2, \u0026new_v)\n    // fmt.println(\u0026new_v)\n}\n\nfor _, p := range dst2 {\n    fmt.Print(*p)\n}\n```\n\n# Golang 的断言\n\nGo中的所有程序都实现了`interface{}`的接口，这意味着，所有的类型如`string`,`int`,`int64`甚至是自定义的`struct`类型都就此拥有了`interface{}`的接口.那么在一个数据通过`func funcName(interface{})`的方式传进来的时候，也就意味着这个参数被自动的转为interface{}的类型。\n\n如以下的代码：\n\n\n\n```\nfunc funcName(a interface{}) string {\n\treturn string(a)\n}\n```\n\n\n编译器将会返回：`cannot convert a (type interface{}) to type string: need type assertion`\n\n此时，意味着整个转化的过程需要类型断言。类型断言有以下几种形式：\n\n直接断言使用\n\n\n```\nvar a interface{}\nfmt.Println(\"Where are you,Jonny?\", a.(string))\n```\n\n但是如果断言失败一般会导致panic的发生。所以为了防止panic的发生，我们需要在断言前进行一定的判断\n\n\n```\nvalue, ok := a.(string)\n```\n\n\n如果断言失败，那么ok的值将会是false,但是如果断言成功ok的值将会是true,同时value将会得到所期待的正确的值。示例：\n\n\n```\nvalue, ok := a.(string)\nif !ok {\n    fmt.Println(\"It's not ok for type string\")\n    return\n}\nfmt.Println(\"The value is \", value)\n```\n\n\n另外也可以配合switch语句进行判断：\n\n```\nvar t interface{}\nt = functionOfSomeType()\nswitch t := t.(type) {\ndefault:\n    fmt.Printf(\"unexpected type %T\", t)       // %T prints whatever type t has    break\ncase bool:\n    fmt.Printf(\"boolean %t\\n\", t)             // t has type bool    break\ncase int:\n    fmt.Printf(\"integer %d\\n\", t)             // t has type int    break\ncase *bool:\n    fmt.Printf(\"pointer to boolean %t\\n\", *t) // t has type *bool    break\ncase *int:\n    fmt.Printf(\"pointer to integer %d\\n\", *t) // t has type *int    break\n}\n```\n\n\n\n# 如何在运行时检查变量类型？\n\n**类型开关是在运行时检查变量类型的最佳方式**。类型开关按类型而不是值来评估变量。每个 Switch ⾄少包含⼀个 case，⽤作条件语句，和⼀个 default，如果没有⼀个 case 为真，则执行。\n\n```\nfunc classifier(items ...interface{}) {\n    for i, x := range items {\n        switch x.(type) {\n        case bool:\n            fmt.Printf(\"Param #%d is a bool\\n\", i)\n        case float64:\n            fmt.Printf(\"Param #%d is a float64\\n\", i)\n        case int, int64:\n            fmt.Printf(\"Param #%d is a int\\n\", i)\n        case nil:\n            fmt.Printf(\"Param #%d is a nil\\n\", i)\n        case string:\n            fmt.Printf(\"Param #%d is a string\\n\", i)\n        default:\n            fmt.Printf(\"Param #%d is unknown\\n\", i)\n        }\n    }\n}\n```\n\n\n\n# 精通 Golang 项目依赖 Go modules\n\nhttps://www.topgoer.cn/docs/golangxiuyang/golangxiuyang-1cmee13oek1e8\n\n# Go string 的底层实现\n\n源码包src/runTime/string.go.stringStruct定义了string的数据结构\n\n\n```\nType stringStruct struct{\n\tstr unsafe.Pointer // 字符串的首地址\n \tlen int // 字符串的长度\n}\n```\n\n声明：\n\n如下代码所示，可以声明一个string变量赋予初值\n\n```\nvar str string\nstr = \"Hello world\"\n```\n\n字符串构建过程是根据字符串构建stringStruct，再转化成string。转换的源码如下：\n\n\n```\nfunc gostringnocopy(str *byte) string{       //根据字符串地址构建string\n       ss := stringStruct{str:unsafe.Pointer(str),len:findnull(str)}  // 先构造 stringStruct\n       s := *(*string)(unsafe.Pointer(\u0026ss))   //再将stringStruct 转换成string\n       return s\n}\n```\n\n# Go 语言的 panic 如何恢复\n\nrecover 可以中止 panic 造成的程序崩溃，或者说平息运行时恐慌，recover 函数不需要任何参数，并且会返回一个空接口类型的值。**需要注意的是 recover 只能在 defer 中发挥作用，在其他作用域中调用不会发挥作用**。编译器会将 recover 转换成 runtime.gorecover，该函数的实现逻辑是如果当前 goroutine 没有调用 panic，那么该函数会直接返回 nil，当前 goroutine 调用 panic 后，会先调用 runtime.gopaic 函数 runtime.gopaic 会从 runtime.  _defer 结构体中取出程序计数器 pc 和栈指针 sp，再调用 runtime.recovery 函数来恢复程序，runtime.recovery 会根据传入的 pc 和 sp 跳转回 runtime.deferproc，编译器自动生成的代码会发现 runtime.deferproc 的返回值不为 0，这时会调回 runtime.deferreturn 并恢复到正常的执行流程。总的来说恢复流程就是通过程序计数器来回跳转。\n\n# Go 如何避免 panic\n\n首先明确panic定义：go把真正的异常叫做 panic，是指出现重大错误，比如数组越界之类的编程BUG或者是那些需要人工介入才能修复的问题，比如程序启动时加载资源出错等等。  \n几个容易出现panic的点:\n\n- 函数返回值或参数为指针类型，nil, 未初始化结构体，此时调用容易出现panic，可加 != nil 进行判断\n- 数组切片越界\n- 如果我们关闭未初始化的通道，重复关闭通道，向已经关闭的通道中发送数据，这三种情况也会引发 panic，导致程序崩溃\n- 如果我们直接操作未初始化的映射（map），也会引发 panic，导致程序崩溃\n- 另外，操作映射可能会遇到的更为严重的一个问题是，同时对同一个映射并发读写，它会触发 runtime.throw，不像 panic 可以使用 recover 捕获。所以，我们在对同一个映射并发读写时，一定要使用锁。\n- 如果类型断言使用不当，比如我们不接收布尔值的话，类型断言失败也会引发 panic，导致程序崩溃。\n- 如果很多时候不可避免地出现了panic, 记得使用 defer/recover\n\n\n# defer 的几个坑\n\n```\nfunc main() {\n    fmt.Println(test())\n}\n\nfunc test() error {\n    var err error\n    defer func() {\n       if r := recover(); r != nil {\n          err = errors.New(fmt.Sprintf(\"%s\", r))\n       }\n    }()\n    raisePanic()\n    return err\n}\n\nfunc raisePanic() {\n    panic(\"发生了错误\")\n}\n```\n为什么输出****?\n\n\n```\npackage main\n\nimport (\n    \"fmt\"\n)\n\nfunc main()  {\n\n    defer func() {\n       if err := recover(); err != nil{\n           fmt.Println(err)\n       }else {\n           fmt.Println(\"fatal\")\n       }\n    }()\n\n    defer func() {\n        panic(\"defer panic\")\n    }()\n\n    panic(\"panic\")\n}\n```\n\n**结果**\n```\ndefer panic\n```\n\n\n**分析**\n\n**panic仅有最后一个可以被revover捕获**。\n\n触发`panic(\"panic\")`后defer顺序出栈执行，第一个被执行的defer中 会有`panic(\"defer panic\")`异常语句，这个异常将会覆盖掉main中的异常`panic(\"panic\")`，最后这个异常被第二个执行的defer捕获到。\n\n```\npackage main\n\nimport \"fmt\"\n\nfunc function(index int, value int) int {\n\n    fmt.Println(index)\n\n    return index\n}\n\nfunc main() {\n    defer function(1, function(3, 0))\n    defer function(2, function(4, 0))\n}\n```\n\n这里，有4个函数，他们的index序号分别为1，2，3，4。\n\n那么这4个函数的先后执行顺序是什么呢？这里面有两个defer， 所以defer一共会压栈两次，先进栈1，后进栈2。 那么在压栈function1的时候，需要连同函数地址、函数形参一同进栈，那么为了得到function1的第二个参数的结果，所以就需要先执行function3将第二个参数算出，那么function3就被第一个执行。同理压栈function2，就需要执行function4算出function2第二个参数的值。然后函数结束，先出栈fuction2、再出栈function1.\n\n所以顺序如下：\n\n- defer压栈function1，压栈函数地址、形参1、形参2(调用function3) –\u003e 打印3\n- defer压栈function2，压栈函数地址、形参1、形参2(调用function4) –\u003e 打印4\n- defer出栈function2, 调用function2 –\u003e 打印2\n- defer 出栈 function1, 调用 function1–\u003e 打印1\n```\n3\n4\n2\n1\n```\n\n**\n\n# **Go**程序中的包是什么？\n\n包(pkg)是 Go 工作区中包含 Go 源⽂件或其他包的目录。源文件中的每个函数、变量和类型都存储在链接包中。每个 Go 源文件都属于⼀个包，该包在文件顶部使⽤以下命令声明：\n\n```\npackage \u003cpackagename\u003e\n```\n\n您可以使⽤以下⽅法导⼊和导出包以重⽤导出的函数或类型：\n\n```\nimport \u003cpackagename\u003e\n```\n\nGolang 的标准包是 fmt，其中包含格式化和打印功能，如 Println().\n\n# Go 实现不重启热部署\n\n根据系统的 SIGHUP 信号量，以此信号量触发进程重启，达到热更新的效果。\n\n热部署我们需要考虑几个能力：\n\n- 新进程启动成功，老进程不会有资源残留\n- 新进程初始化的过程中，服务不会中断\n- 新进程初始化失败，老进程仍然继续工作\n- 同一时间，只能有一个更新动作执行\n\n监听信号量的方法的环境是在 类 UNIX 系统中，在现在的 UNIX 内核中，允许多个进程同时监听一个端口。在收到 SIGHUP 信号量时，先 fork 出一个新的进程监听端口，同时等待旧进程处理完已经进来的连接，最后杀掉旧进程。\n\n我基于这个思路，实现了一段示例代码，仓库地址：[https://github.com/guowei-gong/tablefilp-example，](https://github.com/guowei-gong/tablefilp-example%EF%BC%8C)  如果你希望动手来加深印象可以打开看看。\n\n# Go 中的指针强转\n\n在 **Golang 中无法使用指针类型对指针进行强制转换**\n\n![image-20220501142757244](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticimage-20220501142757244.png)\n\n但可以借助 `unsafe` 包中的 `unsafe.Pointer` 转换\n\n![image-20220501142724715](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticimage-20220501142724715.png)\n\n在 `src/unsafe.go` 中可以看到指针类型说明\n\n```\n// ArbitraryType 与 IntegerType 在此只用于文档描述，实际并不 unsafe 包中的一部分\n// 表示任意 go 的表达式\ntype ArbitraryType int\n\n// 表示任意 integer 类型\ntype IntegerType int\n\ntype Pointer *ArbitraryType\n```\n\n对于指针类型 `Pointer` 强调以下四种操作\n\n- 指向任意类型的指针都可以被转化成 Pointer\n- Pointer 可以转化成指向任意类型的指针\n- uintptr 可以转化成 Pointer\n- Pointer 可以转化成 uintptr\n\n\u003e uintptr 在 `src/builtin/builtin.go` 中定义\n\n其后描述了六种指针转换的情形\n\n其一：*_Conversion of a _T1 to Pointer to *T2__\n\n转换条件：\n\n- T2 的数据类型不大于 T1\n- T1、T2 的内存模型相同\n\n因此对于 `*int` 不能强制转换 `*float64` 可以变化为 `*int` -\u003e `unsafe.Pointer` -\u003e `*float64` 的过程\n\n# Go 支持什么形式的类型转换？将整数转换为浮点数。\n\nGo 支持显式类型转换以满足其严格的类型要求。\n\n```\ni := 55 //int\nj := 67.8 //float64\nsum := i + int(j)//j is converted to int\n```\n\n# Golang 语言中== 的使用\n\n```\npackage main\n\nfunc main() {\n\tvar x interface{}\n\tvar y interface{} = []int{3, 5}\n\t_ = x == x //输出true\n\t_ = x == y //interface{}比较的是动态类型和动态值，输出false\n\t_ = y == y //panic,切片不可比较\n}\n```\n\n\n\n# Go 语言实现小根堆\n \n```\npackage main\n\nimport (\n\t\"container/heap\"\n\t\"fmt\"\n)\n\ntype MinHeap []int\n\nfunc (h MinHeap) Len() int           { return len(h) }\nfunc (h MinHeap) Less(i, j int) bool { return h[i] \u003c h[j] }\nfunc (h MinHeap) Swap(i, j int)      { h[i], h[j] = h[j], h[i] }\n\nfunc (h *MinHeap) Push(x interface{}) {\n\t*h = append(*h, x.(int))\n}\n\nfunc (h *MinHeap) Pop() interface{} {\n\told := *h\n\tn := len(old)\n\tx := old[n-1]\n\t*h = old[:n-1]\n\treturn x\n}\n\nfunc main() {\n\th := \u0026MinHeap{2, 1, 5, 3, 4}\n\theap.Init(h)\n\tfmt.Println(\"堆中最小的元素是：\", (*h)[0])\n\theap.Push(h, 0)\n\tfmt.Println(\"插入后最小的元素是：\", (*h)[0])\n\tmin := heap.Pop(h).(int)\n\tfmt.Println(\"弹出最小的元素是：\", min)\n}\n```\n\n#  Go 怎么实现 func 的自定义参数\n\n在 golang中，type 可以定义任何自定义的类型\n\nfunc 也是可以作为类型自定义的，type myFunc func(int) int，意思是自定义了一个叫 myFunc 的函数类型，这个函数的签名必须符合输入为 int，输出为 int。\n\ngolang通过type定义函数类型  \n通过 type 可以定义函数类型，格式如下\n\n```\ntype typeName func(arguments) retType\n```\n\n函数类型也是一种类型，故可以将其定义为函数入参，在 go 语言中函数名可以看做是函数类型的常量，所以我们可以直接将函数名作为参数传入的函数中。\n\n```\npackage main\n\nimport \"fmt\"\n\nfunc add(a, b int) int {\n\treturn a + b\n}\n\n//sub作为函数名可以看成是 op 类型的常量\nfunc sub(a, b int) int {\n\treturn a - b\n}\n\n//定义函数类型 op\ntype op func(a, b int) int\n\n//形参指定传入参数为函数类型op\nfunc Oper(fu op, a, b int) int {\n\treturn fu(a, b)\n}\n\nfunc main() {\n\t//在go语言中函数名可以看做是函数类型的常量，所以我们可以直接将函数名作为参数传入的函数中。\n\taa := Oper(add, 1, 2)\n\tfmt.Println(aa)\n\tbb := Oper(sub, 1, 2)\n\tfmt.Println(bb)\n}\n```\n\n# 为什么 go 的变量申请类型是为了什么？\n\n在 Go 编程语言中，数据类型用于声明函数和变量。  \n数据类型的出现是为了把数据分成所需内存大小不同的数据，编程的时候需要用大数据的时候才需要申请大内存，就可以充分利用内存。\n\n# Go 的闭包语法\n\ngo语言的闭包可以理解为一个引用外部变量的匿名函数，Go语言中闭包是引用了自由变量的函数，被引用的自由变量和函数一同存在，即使已经离开了自由变量的环境也不会被释放或者删除，在闭包中可以继续使用这个自由变量，因此，简单的说：  \n`函数 + 引用环境 = 闭包`  \n同一个函数与不同引用环境组合，可以形成不同的实例，如下图：  \n![img](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticimg.jpg)  \n一个函数类型就像结构体一样，可以被实例化，函数本身不存储任何信息，只有与引用环境结合后形成的闭包才具有“记忆性”，函数是编译期静态的概念，而闭包是运行期动态的概念。\n\n# Go 语言中 int 占几个字节\n\nGo语言中的int的大小是和操作系统位数相关的，如果是32位操作系统，int类型的大小就是4字节; 如果是64位操作系统，int类型的大小就是8个字节\n\n# Golang 程序启动过程\n\n[Go程序启动过程](https://juejin.cn/post/6942509882281033764) \n\n[Golang 程序启动过程](https://juejin.cn/post/7035633561805783070) \n\n# Golang 开发新手常犯的50个错误\n\n[https://blog.csdn.net/gezhonglei2007/article/details/52237582](https://blog.csdn.net/gezhonglei2007/article/details/52237582) \n\n\n# go基础语法50问\n https://juejin.cn/post/7160639446612705316 \n\n\n# Go 程序的基本结构？\n\n![img](https://blog-1314857283.cos.ap-shanghai.myqcloud.com/images/202308281927218.png)\n\n# Go 有哪些关键字？\n\n![img](https://blog-1314857283.cos.ap-shanghai.myqcloud.com/images/202308281929906.png)\n\n# Go 有哪些数据类型？\n\n![img](https://blog-1314857283.cos.ap-shanghai.myqcloud.com/images/202308281929278.png)\n\n# Go 方法与函数的区别？\n\n![image-20230828192956848](https://blog-1314857283.cos.ap-shanghai.myqcloud.com/images/202308281929899.png)\n\n# Go 方法值接收者和指针接收者的区别?\n\n* 如果方法的接收者是指针类型，无论调用者是对象还是对象指针，**修改的都是对象本身，会影响调用者**；\n\n* 如果方法的接收者是值类型，无论调用者是对象还是对象指针，**修改的都是对象的副本，不影响调用者**；\n\n```\npackage main\n\nimport \"fmt\"\n\ntype Person struct {\n\tage int\n}\n\n// 如果实现了接收者是指针类型的方法，会隐含地也实现了接收者是值类型的IncrAge1方法。\n// 会修改age的值\nfunc (p *Person) IncrAge1() {\n\tp.age += 1\n}\n\n// 如果实现了接收者是值类型的方法，会隐含地也实现了接收者是指针类型的IncrAge2方法。\n// 不会修改age的值\nfunc (p Person) IncrAge2() {\n\tp.age += 1\n}\n\n// 如果实现了接收者是值类型的方法，会隐含地也实现了接收者是指针类型的GetAge方法。\nfunc (p Person) GetAge() int {\n\treturn p.age\n}\n\nfunc main() {\n\t// p1 是值类型\n\tp := Person{age: 10}\n\n\t// 值类型 调用接收者是指针类型的方法\n\tp.IncrAge1()\n\tfmt.Println(p.GetAge())\n\t// 值类型 调用接收者是值类型的方法\n\tp.IncrAge2()\n\tfmt.Println(p.GetAge())\n\n\t// ----------------------\n\n\t// p2 是指针类型\n\tp2 := \u0026Person{age: 20}\n\n\t// 指针类型 调用接收者是指针类型的方法\n\tp2.IncrAge1()\n\tfmt.Println(p2.GetAge())\n\t// 指针类型 调用接收者是值类型的方法\n\tp2.IncrAge2()\n\tfmt.Println(p2.GetAge())\n}\n/*\n11\n11\n21\n21\n*/\n```\n\n上述代码中：\n\n实现了接收者是指针类型的 IncrAge 1 函数，不管调用者是值类型还是指针类型，都可以调用 IncrAge 1 方法，并且它的 age 值都改变了。\n\n实现了接收者是指针类型的 IncrAge 2 函数，不管调用者是值类型还是指针类型，都可以调用 IncrAge 2 方法，并且它的 age 值都没有被改变。\n\n通常我们使用**指针类型作为方法的接收者的理由**：\n\n- 使用指针类型能够修改调用者的值。\n- 使用指针类型可以避免在每次调用方法时复制该值，在值的类型为大型结构体时，这样做会更加高效。\n\n# Go 函数返回局部变量的指针是否安全?\n\n一般来说，局部变量会在函数返回后被销毁，因此被返回的引用就成为了”无所指”的引用，程序会进入未知状态。\n\n但这在 Go 中是安全的，**Go 编译器将会对每个局部变量进行逃逸分析。如果发现局部变量的作用域超出该函数，则不会将内存分配在栈上，而是分配在堆上**，因为他们不在栈区，即使释放函数，其内容也不会受影响。\n\n```\npackage main\n\nimport \"fmt\"\n\nfunc add(x, y int) *int {\n\tres := 0\n\tres = x + y\n\treturn \u0026res\n}\n\nfunc main() {\n\tfmt.Println(add(1, 2))\n}\n```\n\n这个例子中，函数 `add` 局部变量 `res` 发生了逃逸。Res 作为返回值，在 main 函数中继续使用，因此 res 指向的内存不能够分配在栈上，随着函数结束而回收，只能分配在堆上。\n\n编译时可以借助选项 `-gcflags=-m`，查看变量逃逸的情况\n\n```\n./main.go:6:2: res escapes to heap:\n./main.go:6:2:   flow: ~r2 = \u0026res:\n./main.go:6:2:     from \u0026res (address-of) at ./main.go:8:9\n./main.go:6:2:     from return \u0026res (return) at ./main.go:8:2\n./main.go:6:2: moved to heap: res\n./main.go:12:13: ... argument does not escape\n0xc0000ae008\n```\n\n`res escapes to heap` 即表示 `res` 逃逸到堆上了。\n\n# Go 函数参数传递到底是值传递还是引用传递？\n\n先说下结论：\n\n**Go 语言中所有的传参都是值传递（传值），都是一个副本，一个拷贝。**\n\n**参数如果是非引用类型（int、string、struct 等这些），这样就在函数中就无法修改原内容数据；如果是引用类型（指针、map、slice、chan 等这些），这样就可以修改原内容数据。**\n\n**是否可以修改原内容数据，和传值、传引用没有必然的关系。在 C++中，传引用肯定是可以修改原内容数据的，在 Go 语言里，虽然只有传值，但是我们也可以修改原内容数据，因为参数是引用类型**\n\n**引用类型和引用传递是 2 个概念，切记**！！！\n\n**什么是值传递？**\n\n将实参的值传递给形参，形**参是实参的一份拷贝，实参和形参的内存地址不同**。函数内对形参值内容的修改，是否会影响实参的值内容，取决于参数是否是引用类型\n\n**什么是引用传递？**\n\n**将实参的地址传递给形参，函数内对形参值内容的修改**，将会影响实参的值内容。Go 语言是没有引用传递的，在 C++中，函数参数的传递方式有引用传递。\n\n**例子：**\n\n```\npackage main\n\nimport \"fmt\"\n\nfunc main() {\n    m := make(map[string]int)\n    m[\"age\"] = 8\n\n    fmt.Printf(\"原始map的内存地址是：%p\\n\", \u0026m)\n    modifyMap(m)\n    fmt.Printf(\"改动后的值是: %v\\n\", m)\n}\n\nfunc modifyMap(m map[string]int) {\n    fmt.Printf(\"函数里接收到map的内存地址是：%p\\n\", \u0026m)\n    m[\"age\"] = 9\n}\n/*\n原始map的内存地址是：0xc00000e028\n函数里接收到map的内存地址是：0xc00000e038\n改动后的值是: map[age:9]\n通过make函数创建的map变量本质是一个hmap类型的指针*hmap，所以函数内对形参的修改，会修改原内容数据(channel也如此)\n*/\n```\n\n# Go defer 关键字的实现原理？\n\n**定义**：\n\nDefer 能够让我们推迟执行某些函数调用，**推迟到当前函数返回前才实际执行**。Defer 与 panic 和 recover 结合，形成了 Go 语言风格的异常与捕获机制。\n\n**使用场景**：\n\nDefer 语句经常被用于处理成对的操作，如文件句柄关闭、连接关闭、释放锁\n\n**优点：**\n\n方便开发者使用\n\n**缺点：**\n\n有性能损耗\n\n**实现原理**：\n\nGo 1.14 中编译器会将 defer 函数直接插入到函数的尾部，无需链表和栈上参数拷贝，性能大幅提升。把 defer 函数在当前函数内展开并直接调用，这种方式被称为 open coded defer\n\n源代码：\n\n```\nfunc A(i int) {\n    defer A1(i, 2*i)\n    if(i \u003e 1) {\n        defer A2(\"Hello\", \"eggo\")\n    }\n    // code to do something\n    return\n}\nfunc A1(a,b int) {\n    //......\n}\nfunc A2(m,n string) {\n    //......\n}\n```\n\n编译后（伪代码）：\n\n```\nfunc A(i int) {\n        // code to do something\n    if(i \u003e 1){\n       A2(\"Hello\", \"eggo\")\n    }\n    A1(i, 2*i)\n    return\n}\n```\n\n**代码示例**：\n\n1、函数退出前，按照先进后出的顺序，执行 defer 函数\n\n```\npackage main\n\nimport \"fmt\"\n\n// defer：延迟函数执行，先进后出\nfunc main() {\n    defer fmt.Println(\"defer1\")\n    defer fmt.Println(\"defer2\")\n    defer fmt.Println(\"defer3\")\n    defer fmt.Println(\"defer4\")\n    fmt.Println(\"11111\")\n}\n\n// 11111\n// defer4\n// defer3\n// defer2\n// defer1\n```\n\n2、panic 后的 defer 函数不会被执行（遇到 panic，如果没有捕获错误，函数会立刻终止）\n\n```\npackage main\n\nimport \"fmt\"\n\n// panic后的defer函数不会被执行\nfunc main() {\n    defer fmt.Println(\"panic before\")\n    panic(\"发生panic\")\n    defer func() {\n        fmt.Println(\"panic after\")\n    }()\n}\n\n// panic before\n// panic: 发生panic\n```\n\n3、panic 没有被 recover 时，抛出的 panic 到当前 goroutine 最上层函数时，最上层程序直接异常终止\n\n```\npackage main\n\nimport \"fmt\"\n\nfunc F() {\n    defer func() {\n        fmt.Println(\"b\")\n    }()\n    panic(\"a\")\n}\n\n// 子函数抛出的panic没有recover时，上层函数时，程序直接异常终止\nfunc main() {\n    defer func() {\n        fmt.Println(\"c\")\n    }()\n    F()\n    fmt.Println(\"继续执行\")\n}\n\n// b\n// c\n// panic: a\n```\n\n4、panic 有被 recover 时，当前 goroutine 最上层函数正常执行\n\n```\npackage main\n\nimport \"fmt\"\n\nfunc F() {\n    defer func() {\n        if err := recover(); err != nil {\n            fmt.Println(\"捕获异常:\", err)\n        }\n        fmt.Println(\"b\")\n    }()\n    panic(\"a\")\n}\n\nfunc main() {\n    defer func() {\n        fmt.Println(\"c\")\n    }()\n    F()\n    fmt.Println(\"继续执行\")\n}\n\n// 捕获异常: a\n// b\n// 继续执行\n// c\n```\n\n\n```\npackage main\n\nimport \"fmt\"\n\nfunc main() {\n\n\tdefer func() {\n\t\tif v := recover();v == 11 {\n\t\t\tfmt.Println(\"v:\",v)\n\t\t}\n\t\tfmt.Printf(\"defer1...\")\n\t\t}()\n\n\tdefer func() {\n\t\tfmt.Printf(\"defer2...\")\n\t}()\n\n\tarray := [2]int{1,2}\n\tfmt.Println(\"array: \",array[1])\n\tpanic(11)\n}\n//array:  2\n//defer2...\n//v:  11   \n//defer1...\n```\n\n5. 执行过程是: 保存返回值 (若有)–\u003e执行 defer（若有）–\u003e执行 ret 跳转\n\n```\nfunc foo() (ret int) {\n    defer func() {\n        ret++\n    }()\n\n    return 0\n}\n```\n\n6. 延迟函数的参数在 defer 语句出现时就已经确定下来了\n\n```\nfunc a() {\n    i := 0\n    defer fmt.Println(i)\n    i++\n    return\n}\n```\n\n**注意：**\n\n执行顺序应该为 panic、defer、recover\n\n- 发生 panic 的函数并不会立刻返回，而是先层层函数执行 defer，再返回。如果有办法将 panic 捕获到 panic，就正常处理（若是外部函数捕获到，则外部函数只执行 defer），如果没有没有捕获，程序直接异常终止。\n- Go 语言提供了 recover 内置函数。前面提到，一旦 panic 逻辑就会走到 defer（defer 必须在 panic 的前面！)。调用 recover 函数将会捕获到当前的 panic，被捕获到的 panic 就不会向上传递了\n- 在 panic 发生时，在前面的 defer 中通过 recover 捕获这个 panic，转化为错误通过返回值告诉方法调用者。\n\n# Go 内置函数 make 和 new 的区别？\n\n首先纠正下 make 和 new 是内置函数，不是关键字\n\n变量初始化，一般包括 2 步，变量声明 + 变量内存分配，var 关键字就是用来声明变量的，new 和 make 函数主要是用来分配内存的\n\nVar 声明**值类型**的变量时，系统会**默认为他分配内存空间**，并赋该类型的**零值**\n\n比如布尔、数字、字符串、结构体\n\n如果**指针类型**或者**引用类型**的变量，系统**不会为它分配内存**，默认就是 `nil`。此时如果你想 `直接使用，那么系统会抛异常`，必须进行内存分配后，才能使用。\n\nNew 和 make 两个内置函数，主要用来分配内存空间，有了内存，变量就能使用了，主要有以下 2 点区别：\n\n**使用场景区别：**\n\nMake 只能用来分配及初始化类型为 slice、map、chan 的数据。\n\nNew 可以分配任意类型的数据，并且置零。\n\n**返回值区别：**\n\nMake 函数原型如下，返回的是 slice、map、chan 类型本身\n\n这 3 种类型是引用类型，就没有必要返回他们的指针\n\n```\nfunc make(t Type, size ...IntegerType) Type\n```\n\nNew 函数原型如下，返回一个指向该类型内存地址的指针\n\n\n```\ntype slice struct {\n    array unsafe.Pointer\n    len   int\n    cap   int\n}\n```\n\n\n# Make 函数底层实现\n\n```\nfunc makeslice(et *_type, len, cap int) unsafe.Pointer {\n\tmem, overflow := math.MulUintptr(et.size, uintptr(cap))\n\tif overflow || mem \u003e maxAlloc || len \u003c 0 || len \u003e cap {\n\t\t// NOTE: Produce a 'len out of range' error instead of a\n\t\t// 'cap out of range' error when someone does make([]T, bignumber).\n\t\t// 'cap out of range' is true too, but since the cap is only being\n\t\t// supplied implicitly, saying len is clearer.\n\t\t// See golang.org/issue/4085.\n\t\tmem, overflow := math.MulUintptr(et.size, uintptr(len))\n\t\tif overflow || mem \u003e maxAlloc || len \u003c 0 {\n\t\t\tpanicmakeslicelen()\n\t\t}\n\t\tpanicmakeslicecap()\n\t}\n\n\treturn mallocgc(mem, et, true)\n}\n```\n\n函数功能：\n\n- 检查切片占用的内存空间是否溢出。\n- 调用 `mallocgc` 在堆上申请一片连续的内存。\n\n检查内存空间这里是根据切片容量进行计算的，**根据当前切片元素的大小与切片容量的乘积得出当前内存空间的大小**，检查溢出的条件：\n\n- 内存空间大小溢出了\n- 申请的内存空间大于最大可分配的内存\n- 传入的 `len` 小于 `0`，`cap` 的大小只小于 `len","lastmodified":"2024-03-02T12:01:53.846210423Z","tags":["GO/八股文"]},"/GO/%E5%85%AB%E8%82%A1%E6%96%87/Map-%E5%92%8CSync.map":{"title":"Map","content":"\n# 参考\n\n[Golang map 实现原理](https://mp.weixin.qq.com/s?__biz=MzkxMjQzMjA0OQ==\u0026mid=2247483868\u0026idx=1\u0026sn=6e954af8e5e98ec0a9d9fc5c8ceb9072\u0026chksm=c10c4f02f67bc614ff40a152a848508aa1631008eb5a600006c7552915d187179c08d4adf8d7\u0026scene=178\u0026cur_album_id=2709593649634033668#rd)\n[Golang sync.Map 实现原理](https://mp.weixin.qq.com/s?__biz=MzkxMjQzMjA0OQ==\u0026mid=2247483821\u0026idx=1\u0026sn=f45e9e2b4c4cb7edaa57d904e3bf7bd7\u0026chksm=c10c4f73f67bc6655e7e7c9f808a318b1c74e76782824df18843f4c31e39ce512819d6abe156\u0026scene=178\u0026cur_album_id=2709593649634033668#rd)\n\n\n\n# Map 概述\n\nmap 又称字典，是一种常用的数据结构，核心特征包含下述三点：\n\n（1）存储基于 key-value 对映射的模式；\n\n（2）基于 key 维度实现存储数据的去重；\n\n（3）读、写、删操作控制，时间复杂度 O(1).\n\n\n# Map 初始化 \n\nGolang 中，对 map 的初始化分为以下几种方式：\n\n```\n\n\nmyMap1 := make(map[int]int,2)\n//通过 make 关键字进行初始化，同时指定 map 预分配的容量.\n\nmyMap2 := make(map[int]int)\n//通过 make 关键字进行初始化，不显式声明容量，因此默认容量 为 0.\n\nmyMap3 :=map[int]int{\n  1:2,\n  3:4,\n}\n```\n\n\n# Map 的 key 可以是哪些类型？可以嵌套 map 吗？\n\n* **Map key 必须是可比较的类型**，\n\t* 语言规范中定义了可比较的类型：boolean, numeric, string, pointer, channel, interface,以及仅包含这些类型的 struct 和 array 。\n\t* 不能作为 map key 的类型有：slice，map, function。\n\n* 可以嵌套 map。\n\n# Map 读\n\n * 第一种方式是直接读，倘若 key 存在，则获取到对应的 val，倘若 key 不存在或者 map 未初始化，会返回 val 类型的零值作为兜底\n \n```\nv1 := myMap[10]\n```\n\n * 第二种方式是读的同时添加一个 bool 类型的 flag 标识是否读取成功. 倘若 ok == false，**说明读取失败， key 不存在，或者 map 未初始化.**\n\n\n```\nv2,ok := myMap[10]\n```\n\n* 如果 map 没有初始化,取值得到零值 \n\n```\npackage main\n\nimport \"fmt\"\n\nfunc main() {\n    var myMap map[string]int // 未初始化的 map\n    value := myMap[\"some_key\"] // 尝试获取一个键的值\n\n    fmt.Println(value)\n}\n//panic: assignment to entry in nil map\n```\n\n\n# Map 的查询复杂度\n\n**空间复杂度**:\n由于溢出桶数量超过 hash 桶数量时会触发缩容，所以最坏的情况是数据被集中在一条链上，hash 表基本是空的，这时空间浪费 O (n)。  \n最好的情况下，数据均匀散列在 hash 表上，没有元素溢出，这时最好的空间复杂度就是扩散因子决定了，当前 go 的扩散因子由全局变量决定，即 loadFactorNum/loadFactorDen = 6.5。即平均每个 hash 桶被分配到 6.5 个元素以上时，开始扩容。所以最小的空间浪费是 (8-6.5)/8 = 0.1875，即 O (0.1875n)\n\n结论：go map 的空间复杂度（指除去正常存储元素所需空间之外的空间浪费）是 O (0.1875 n) ~ O (n)之间。  \n​ 具体细节：[https://blog.csdn.net/dongjijiaoxiangqu/article/details/109643025](https://blog.csdn.net/dongjijiaoxiangqu/article/details/109643025) \n\n**时间复杂度**：\n\nGo 采用的 hash 算法应是很成熟的算法，极端情况暂不考虑。所以综合情况下 go map 的时间复杂度应为 O(1)\n\n# Map 写\n\n\n```\nmyMap[5] = 6\n```\n倘若 map 未初始化，直接执行写操作会导致 panic： \n\n\n```\nconst plainError string\npanic(plainError(\"assignment to entry in nil map\"))\n```\n\n# Map 删除\n\n```\ndelete(myMap,5)\n\n```\n执行 delete 方法时，倘若 key 存在，则会从 map 中将对应的 key-value 对删除；倘若 key 不存在或 map 未初始化，则方法直接结束，不会产生显式提示.\n\n# Map 遍历\n\n\n遍历分为下面两种方式：\n\n```\nfor k,v := range myMap{\n// ...\n}\n```\n\n基于 k,v 依次承接 map 中的 key-value 对；\n\n```\nfor k := range myMap{  \n// ...\n}\n```\n\n基于 k 依次承接 map 中的 key，不关注 val 的取值.\n\n需要注意的是，在执行 map 遍历操作时，**获取的 key-value 对并没有一个固定的顺序，因此前后两次遍历顺序可能存在差异**.\n\n\n#  map 的底层实现原理？\n\n\nmap 又称为 hash map，在算法上基于 hash 实现 key 的映射和寻址；在数据结构上基于桶数组实现 key-value 对的存储.\n\n以一组 key-value 对写入 map 的流程为例进行简述：\n\n（1）通过哈希方法取得 key 的 hash 值；\n\n（2）hash 值对桶数组长度取模，确定其所属的桶；\n\n（3）在桶中插入 key-value 对.\n\n\n## Hash\n\n\nhash 译作散列，是一种将任意长度的输入压缩到某一固定长度的输出摘要的过程\n\n* （1）hash 的可重入性：相同的 key，必然产生相同的 hash 值；\n* （2）hash 的离散性：只要两个 key 不相同，不论其相似度的高低，产生的 hash 值会在整个输出域内均匀地离散化；\n* （3）hash 的单向性：企图通过 hash 值反向映射回 key 是无迹可寻的.\n* （4）hash 冲突：由于输入域（key）无穷大，输出域（hash 值）有限，因此必然存在不同 key 映射到相同 hash 值的情况，称之为 hash 冲突.\n\n## 桶数组 \n\nmap 中，会通过长度为 2 的整数次幂的桶数组进行 key-value 对的存储：\n\n（1）每个桶固定可以存放 8 个 key-value 对；\n\n（2）倘若超过 8 个 key-value 对打到桶数组的同一个索引当中，此时会通过创建桶链表的方式来化解这一问题.\n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226212728.png)\n\n##  map 冲突的解决方式？\n\n比较常用的 Hash 冲突解决方案有链地址法和开放寻址法：\n\n**链地址法**\n\n当哈希冲突发生时，创建新**单元**，并将新单元添加到冲突单元所在链表的尾部. 在 Go 中将命中同一个桶的元素通过链表的形式进行链接，因此很便于动态扩展\n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226213338.png)\n\n\n**开放寻址法**\n\n当哈希冲突发生时，从发生冲突的那个**单元**起，按照一定的次序，从哈希表中寻找一个空闲的单元，然后把发生冲突的元素存入到该单元。**开放寻址法需要的表长度要大于等于所需要存放的元素数量**\n\n开放寻址法有多种方式：**线性探测法、平方探测法、随机探测法和双重哈希法**。这里以线性探测法来帮助读者理解开放寻址法思想\n\n\n\n**两种解决方案比较**\n\n| 方法    | 优点                                              |\n|-------|-------------------------------------------------|\n| 拉链法   | 简单常用；无需预先为元素分配内存.                               |\n| 开放寻址法 | 无需额外的指针用于链接元素；内存地址完全连续，可以基于局部性原理，充分利用 CPU 高速缓存. |\n\n\n**总结**\n\n**GO 中 实际上结合了拉链法和开放寻址法两种思路**. 以 map 的插入写流程为例，进行思路阐述：\n\n- （1）桶数组中的每个桶，严格意义上是一个单向桶链表，以桶为节点进行串联；\n\n- （2）每个桶固定可以存放 8 个 key-value 对；\n\n- （3）当 key 命中一个桶时，首先根据开放寻址法，在桶的 8 个位置中寻找空位进行插入；\n\n- （4）倘若桶的 8 个位置都已被占满，则基于桶的溢出桶指针，找到下一个桶，重复第（3）步；\n\n- （5）倘若遍历到链表尾部，仍未找到空位，则基于拉链法，在桶链表尾部续接新桶，并插入 key-value 对.\n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226213553.png)\n\n\n## 扩容\n\nmap 扩容机制的核心点包括：\n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226221432.png)\n\n\n- （1）扩容分为增量扩容和等量扩容；\n\t-  **双倍扩容**：新建一个 buckets 数组，**新的 buckets 大小是原来的 2 倍**，然后旧 buckets 数据搬迁到新的 buckets。该方法我们称之为**双倍扩容**\n\t- 等量扩容：**并不扩大容量**，buckets 数量维持不变，**重新做一遍类似双倍扩容的搬迁动作，把松散的键值对重新排列一次**，使得同一个 bucket 中的 key 排列地更紧密，节省空间，提高 bucket 利用率，进而保证更快的存取。该方法我们称之为等量扩容。\n\n- （2）当桶内 key-value 总数/桶数组长度 \u003e 6.5 时发生增量扩容，桶数组长度增长为原值的两倍；\n\n- （3）当桶内溢出桶数量大于等于 2^B 时( B 为桶数组长度的指数，B 最大取 15)，发生等量扩容，桶的长度保持为原值；\n\n- （4）采用渐进扩容的方式，当桶被实际操作到时，由使用者负责完成数据迁移，避免因为一次性的全量数据迁移引发性能抖动.\n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226214126.png)\n\n\n## **hmap 结构体**\n\nGo 中的 map 是一个应用，占用 8 个字节，指向 hmap 结构体\n\n源码包中 `src/runtime/map.go` 定义了 hmap 的数据结构：\n\nHmap 包含若干个结构为 bmap 的数组，每个 bmap 底层都采用链表结构，bmap 通常叫其 bucket\n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240225233011.png)\n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226214237.png)\n\n\n\n```\n// A header for a Go map.\ntype hmap struct {\n    count     int \n    // 代表哈希表中的元素个数，调用len(map)时，返回的就是该字段值。\n    flags     uint8 \n    // 状态标志（是否处于正在写入的状态等）\n    B         uint8  \n    // buckets（桶）的对数\n    // 如果B=5，则buckets数组的长度 = 2^B=32，意味着有32个桶\n    noverflow uint16 \n    // 溢出桶的数量\n    hash0     uint32 \n    // 生成hash的随机数种子\n    buckets    unsafe.Pointer \n    // 指向buckets数组的指针，数组大小为2^B，如果元素个数为0，它为nil。\n    oldbuckets unsafe.Pointer \n    // 如果发生扩容，oldbuckets是指向老的buckets数组的指针，老的buckets数组大小是新的buckets的1/2;非扩容状态下，它为nil。\n    nevacuate  uintptr        \n    // 表示扩容进度，小于此地址的buckets代表已搬迁完成。\n    extra *mapextra \n    // 存储溢出桶，这个字段是为了优化GC扫描而设计的，下面详细介绍\n }\n```\n\n- （1）count：map 中的 key-value 总数；\n\n- （2）flags：map 状态标识，可以标识出 map 是否被 goroutine 并发读写；\n\n- （3）B：桶数组长度的指数，桶数组长度为 2^B；\n\n- （4）noverflow：map 中溢出桶的数量；\n\n- （5）hash0：hash 随机因子，生成 key 的 hash 值时会使用到；\n\n- （6）buckets：桶数组；\n\n- （7）oldbuckets：扩容过程中老的桶数组；\n\n- （8）nevacuate：扩容时的进度标识，index 小于 nevacuate 的桶都已经由老桶转移到新桶中；\n\n- （9）extra：预申请的溢出桶.\n\n## **bmap 结构体**\n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226214340.png)\n\n\n`bmap` 就是我们常说的“桶”，一个桶里面会最多装 8 个 key，\n\n* 这些 key 之所以会落入同一个桶，是因为它们经过哈希计算后，**哈希结果的低 B 位是相同的**，\n* 在桶内，又会根据 key 计算出来的 hash 值的高 8 位来决定 key 到底落入桶内的哪个位置（一个桶内最多有 8 个位置)。\n\n```\n// A bucket for a Go map.\ntype bmap struct {\n    tophash [bucketCnt]uint8        \n    // len为8的数组\n    // 用来快速定位key是否在这个bmap中\n    // 一个桶最多8个槽位，如果key所在的tophash值在tophash中，则代表该key在这个桶中\n}\n```\n\n\n上面 bmap 结构是静态结构，在编译过程中 `runtime.bmap` 会拓展成以下结构体：\n\n\n```\ntype bmap struct{\n    tophash [8]uint8\n    keys [8]keytype \n    // keytype 由编译器编译时候确定\n    values [8]elemtype \n    // elemtype 由编译器编译时候确定\n    overflow uintptr \n    // overflow指向下一个bmap，overflow是uintptr而不是*bmap类型，保证bmap完全不含指针，是为了减少gc，溢出桶存储到extra字段中\n}\n```\n\n\n* Tophash 就是用于实现快速定位 key 的位置，在实现过程中**会使用 key 的 hash 值的高 8 位作为 tophash 值**，存放在 bmap 的 tophash 字段中\n\n* Tophash 字段不仅存储 key 哈希值的高 8 位，**还会存储一些状态值，用来表明当前桶单元状态，这些状态值都是小于 minTopHash** 的\n\n* 为了避免 key 哈希值的高 8 位值和这些状态值相等，产生混淆情况，**所以当 key 哈希值高 8 位若小于 minTopHash 时候，自动将其值加上 minTopHash 作为该 key 的 tophash**。桶单元的状态值如下：\n\n```\nemptyRest      = 0 // 表明此桶单元为空，且更高索引的单元也是空\nemptyOne       = 1 // 表明此桶单元为空\nevacuatedX     = 2 // 用于表示扩容迁移到新桶前半段区间\nevacuatedY     = 3 // 用于表示扩容迁移到新桶后半段区间\nevacuatedEmpty = 4 // 用于表示此单元已迁移\nminTopHash     = 5 // key的tophash值与桶状态值分割线值，小于此值的一定代表着桶单元的状态，大于此值的一定是key对应的tophash值\n\nfunc tophash(hash uintptr) uint8 {\n    top := uint8(hash \u003e\u003e (goarch.PtrSize*8 - 8))\n    if top \u003c minTopHash {\n        top += minTopHash\n    }\n    return top\n}\n```\n\n\n**总结**\n\nBmap（bucket）内存数据结构可视化如下:\n\n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240225233151.png)\n\n\n## **mapextra 结构体**\n\n当 map 的 key 和 value 都不是指针类型时候，bmap 将完全不包含指针，那么 gc 时候就不用扫描 bmap。Bmap 指向溢出桶的字段 overflow 是 uintptr 类型，为了防止这些 overflow 桶被 gc 掉，所以需要 mapextra. Overflow 将它保存起来。如果 bmap 的 overflow 是 bmap 类型，那么 gc 扫描的是一个个拉链表，效率明显不如直接扫描一段内存 (hmap. Mapextra. Overflow)\n\n```\ntype mapextra struct {\n    overflow    *[]*bmap\n    // overflow 包含的是 hmap.buckets 的 overflow 的 buckets\n    oldoverflow *[]*bma\n   // oldoverflow 包含扩容时 hmap.oldbuckets 的 overflow 的 bucket\n    nextOverflow *bmap \n     // 指向空闲的 overflow bucket 的指针\n}\n```\n\n**在 map 初始化时，倘若容量过大，会提前申请好一批溢出桶**，以供后续使用，这部分溢出桶存放在 hmap.mapextra 当中：\n\n（1）mapextra.overflow：供桶数组 buckets 使用的溢出桶；\n\n（2）mapextra.oldoverFlow: 扩容流程中，供老桶数组 oldBuckets 使用的溢出桶；\n\n（3）mapextra.nextOverflow：下一个可用的溢出桶.\n\n\n## Map 的负载因子为什么是 6.5？\n\n**什么是负载因子?**\n\n**负载因子（load factor），用于衡量当前哈希表中空间占用率的核心指标**，也就是每个 bucket 桶存储的平均元素个数。\n\n| 负载因子 = 哈希表存储的元素个数/桶个 |\n| ---- |\n\n另外负载因子**与扩容、迁移**等重新散列（rehash）行为有直接关系：\n\n- 在程序运行时，会不断地进行插入、删除等，会导致 bucket 不均，内存利用率低，需要迁移。\n- 在程序运行时，出现负载因子过大，需要做扩容，解决 bucket 过大的问题。\n\n负载因子是哈希表中的一个重要指标，在各种版本的哈希表实现中都有类似的东西，主要目的是**为了平衡 buckets 的存储空间大小和查找元素时的性能高低**。\n\n在接触各种哈希表时都可以关注一下，做不同的对比，看看各家的考量。\n\n**为什么是 6.5?**\n\n为什么 Go 语言中哈希表的负载因子是 6.5，为什么不是 8 ，也不是 1。这里面有可靠的数据支撑吗？\n\n**测试报告**\n\n实际上这是 Go 官方的经过认真的测试得出的数字，一起来看看官方的这份测试报告。\n\n报告中共包含 4 个关键指标，如下：\n\n|loadFactor|%overflow|bytes/entry|hitprobe|missprobe|\n|:--|:--|:--|:--|:--|\n|4.00|2.13|20.77|3.00|4.00|\n|4.50|4.05|17.30|3.25|4.50|\n|5.00|6.85|14.77|3.50|5.00|\n|5.50|10.55|12.94|3.75|5.50|\n|6.00|15.27|11.67|4.00|6.00|\n|6.50|20.90|10.79|4.25|6.50|\n|7.00|27.14|10.15|4.50|7.00|\n|7.50|34.03|9.73|4.75|7.50|\n|8.00|41.10|9.40|5.00|8.00|\n\n- LoadFactor：负载因子，也有叫装载因子。\n- %overflow：溢出率，有溢出 bukcet 的百分比。\n- Bytes/entry：平均每对 key/value 的开销字节数.\n- Hitprobe：查找一个存在的 key 时，要查找的平均个数。\n- Missprobe：查找一个不存在的 key 时，要查找的平均个数。\n\n**选择数值**\n\nGo 官方发现：**装载因子越大，填入的元素越多，空间利用率就越高，但发生哈希冲突的几率就变大。反之，装载因子越小，填入的元素越少，冲突发生的几率减小，但空间浪费也会变得更多，而且还会提高扩容操作的次数**\n\n根据这份测试结果和讨论，Go 官方取了一个相对适中的值，把 Go 中的 map 的负载因子硬编码为 6.5，这就是 6.5 的选择缘由。\n\n这意味着在 Go 语言中，**当 map 存储的元素个数大于或等于 6.5 * 桶个数时，就会触发扩容行为**。\n\n\n## 构造流程\n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226215050.png)\n\n创建 map 时，实际上会调用 runtime/map.go 文件中的 makemap 方法，下面对源码展开分析：\n\n\n```\nfunc makemap(t *maptype, hint int, h *hmap) *hmap {\n    mem, overflow := math.MulUintptr(uintptr(hint), t.bucket.size)\n    if overflow || mem \u003e maxAlloc {\n        hint = 0\n    }\n\n\n    if h == nil {\n        h = new(hmap)\n    }\n    h.hash0 = fastrand()\n\n\n    B := uint8(0)\n    for overLoadFactor(hint, B) {\n        B++\n    }\n    h.B = B\n\n\n    if h.B != 0 {\n        var nextOverflow *bmap\n        h.buckets, nextOverflow = makeBucketArray(t, h.B, nil)\n        if nextOverflow != nil {\n            h.extra = new(mapextra)\n            h.extra.nextOverflow = nextOverflow\n        }\n    }\n\n\n    return \n```\n- （1）hint 为 map 拟分配的容量；在分配前，会提前对拟分配的内存大小进行判断，倘若超限，会将 hint 置为零；\n\n- （2）通过 new 方法初始化 hmap；\n\n- （3）调用 fastrand，构造 hash 因子：hmap.hash0；\n\n- （4）大致上基于 log2(B) \u003e= hint 的思路，计算桶数组的容量 B；\n\t- overLoadFactor   中实现\n\t- 倘若 map 预分配容量小于等于 8，B 取 0，桶的个数为 1；\n\t- 保证 map 预分配容量小于等于桶数组长度 * 6.5.\n\n- （5）调用 makeBucketArray 方法，初始化桶数组 hmap.buckets\n\t- makeBucketArray 方法会进行桶数组的初始化，并根据桶的数量决定是否需要提前作溢出桶的初始化.\n\n- （6）倘若 map 容量较大，会提前申请一批溢出桶 hmap.extra.\n\n## 读流程 \n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226215347.png)\n\nmap 读流程主要分为以下几步：\n\n（1）根据 key 取 hash 值；\n\n（2）根据 hash 值对桶数组取模，确定所在的桶；\n\n（3）沿着桶链表依次遍历各个桶内的 key-value 对；\n\n（4）命中相同的 key，则返回 value；倘若 key 不存在，则返回零值.\n\nmap 读操作最终会走进 runtime/map.go 的 mapaccess 方法中，下面开始阅读源码\n\n```\nfunc mapaccess1(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer {\n    if h == nil || h.count == 0 {\n        return unsafe.Pointer(\u0026zeroVal[0])\n    }\n    if h.flags\u0026hashWriting != 0 {\n        fatal(\"concurrent map read and map write\")\n    }\n    hash := t.hasher(key, uintptr(h.hash0))\n    m := bucketMask(h.B)\n    b := (*bmap)(add(h.buckets, (hash\u0026m)*uintptr(t.bucketsize)))\n    if c := h.oldbuckets; c != nil {\n        if !h.sameSizeGrow() {\n            m \u003e\u003e= 1\n        }\n        oldb := (*bmap)(add(c, (hash\u0026m)*uintptr(t.bucketsize)))\n        if !evacuated(oldb) {\n            b = oldb\n        }\n    }\n    top := tophash(hash)\nbucketloop:\n    for ; b != nil; b = b.overflow(t) {\n        for i := uintptr(0); i \u003c bucketCnt; i++ {\n            if b.tophash[i] != top {\n                if b.tophash[i] == emptyRest {\n                    break bucketloop\n                }\n                continue\n            }\n            k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize))\n            if t.indirectkey() {\n                k = *((*unsafe.Pointer)(k))\n            }\n            if t.key.equal(key, k) {\n                e := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize))\n                if t.indirectelem() {\n                    e = *((*unsafe.Pointer)(e))\n                }\n                return e\n            }\n        }\n    }\n    return unsafe.Pointer(\u0026zeroVal[0])\n}\n\n\nfunc (h *hmap) sameSizeGrow() bool {\n    return h.flags\u0026sameSizeGrow != 0\n}\n\n\nfunc evacuated(b *bmap) bool {\n    h := b.tophash[0]\n    return h \u003e emptyOne \u0026\u0026 h \u003c minTopHash\n}\n```\n\n（1）倘若 map 未初始化，或此时存在 key-value 对数量为 0，直接返回零值；\n\n（2）倘若发现存在其他 goroutine 在写 map，直接抛出并发读写的 fatal error；其中，并发写标记，位于 hmap.flags 的第 3 个 bit 位；\n\n（3）通过 maptype.hasher() 方法计算得到 key 的 hash 值，并对桶数组长度取模，取得对应的桶. 关于 hash 方法的内部实现，golang 并未暴露.\n\n* 其中，bucketMast 方法会根据 B 求得桶数组长度 - 1 的值，用于后续的 \u0026 运算，实现取模的效果：\n\n（4）在取桶时，会关注当前 map 是否处于扩容的流程，倘若是的话，需要在老的桶数组 oldBuckets 中取桶，通过 evacuated 方法判断桶数据是已迁到新桶还是仍存留在老桶，倘若仍在老桶，需要取老桶进行遍历.\n\n* 在取老桶前，会先判断 map 的扩容流程是否是增量扩容，倘若是的话，说明老桶数组的长度是新桶数组的一半，需要将桶长度值 m 除以 2.\n\n（5）取 key hash 值的高 8 位值 top. 倘若该值 \u003c 5，会累加 5，以避开 0 ~ 4 的取值. 因为这几个值会用于枚举，具有一些特殊的含义.\n\n（6）开启两层 for 循环进行遍历流程，外层基于桶链表，依次遍历首个桶和后续的每个溢出桶，内层依次遍历一个桶内的 key-value 对.\n\n* 内存遍历时，首先查询高 8 位的 tophash 值，看是否和 key 的 top 值匹配.\n\n* 倘若不匹配且当前位置 tophash 值为 0，说明桶的后续位置都未放入过元素，当前 key 在 map 中不存在，可以直接打破循环，返回零值.\n\n\n* 倘若找到了相等的 key，则通过地址偏移的方式取到 value 并返回.\n\n其中 dataOffset 为一个桶中 tophash 数组所占用的空间大小.\n\n## 写流程 \n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226215900.png)\n\nmap 写流程主要分为以下几步：\n\n（1）根据 key 取 hash 值；\n\n（2）根据 hash 值对桶数组取模，确定所在的桶；\n\n（3）倘若 map 处于扩容，则迁移命中的桶，帮助推进渐进式扩容；\n\n（4）沿着桶链表依次遍历各个桶内的 key-value 对；\n\n（5）倘若命中相同的 key，则对 value 中进行更新；\n\n（6）倘若 key 不存在，则插入 key-value 对；\n\n（7）倘若发现 map 达成扩容条件，则会开启扩容模式，并重新返回第（2）步.\n\n```\nfunc mapassign(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer {\n    if h == nil {\n        panic(plainError(\"assignment to entry in nil map\"))\n    }\n    if h.flags\u0026hashWriting != 0 {\n        fatal(\"concurrent map writes\")\n    }\n    hash := t.hasher(key, uintptr(h.hash0))\n\n\n    h.flags ^= hashWriting\n\n\n    if h.buckets == nil {\n        h.buckets = newobject(t.bucket) \n    }\n\n\nagain:\n    bucket := hash \u0026 bucketMask(h.B)\n    if h.growing() {\n        growWork(t, h, bucket)\n    }\n    b := (*bmap)(add(h.buckets, bucket*uintptr(t.bucketsize)))\n    top := tophash(hash)\n\n\n    var inserti *uint8\n    var insertk unsafe.Pointer\n    var elem unsafe.Pointer\nbucketloop:\n    for {\n        for i := uintptr(0); i \u003c bucketCnt; i++ {\n            if b.tophash[i] != top {\n                if isEmpty(b.tophash[i]) \u0026\u0026 inserti == nil {\n                    inserti = \u0026b.tophash[i]\n                    insertk = add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize))\n                    elem = add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize))\n                }\n                if b.tophash[i] == emptyRest {\n                    break bucketloop\n                }\n                continue\n            }\n            k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize))\n            if t.indirectkey() {\n                k = *((*unsafe.Pointer)(k))\n            }\n            if !t.key.equal(key, k) {\n                continue\n            }\n            if t.needkeyupdate() {\n                typedmemmove(t.key, k, key)\n            }\n            elem = add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize))\n            goto done\n        }\n        ovf := b.overflow(t)\n        if ovf == nil {\n            break\n        }\n        b = ovf\n    }\n\n\n    if !h.growing() \u0026\u0026 (overLoadFactor(h.count+1, h.B) || tooManyOverflowBuckets(h.noverflow, h.B)) {\n        hashGrow(t, h)\n        goto again \n    }\n\n\n    if inserti == nil {\n        newb := h.newoverflow(t, b)\n        inserti = \u0026newb.tophash[0]\n        insertk = add(unsafe.Pointer(newb), dataOffset)\n        elem = add(insertk, bucketCnt*uintptr(t.keysize))\n    }\n\n\n    if t.indirectkey() {\n        kmem := newobject(t.key)\n        *(*unsafe.Pointer)(insertk) = kmem\n        insertk = kmem\n    }\n    if t.indirectelem() {\n        vmem := newobject(t.elem)\n        *(*unsafe.Pointer)(elem) = vmem\n    }\n    typedmemmove(t.key, insertk, key)\n    *inserti = top\n    h.count++\n\n\n\n\ndone:\n    if h.flags\u0026hashWriting == 0 {\n        fatal(\"concurrent map writes\")\n    }\n    h.flags \u0026^= hashWriting\n    if t.indirectelem() {\n        elem = *((*unsafe.Pointer)(elem))\n    }\n    return \n}\n```\n（1）写操作时，倘若 map 未初始化，直接 panic；\n\n（2）倘若其他 goroutine 在进行写或删操作，抛出并发写 fatal error；\n\n（3）通过 maptype.hasher() 方法求得 key 对应的 hash 值；\n\n（4）通过异或位运算，将 map.flags 的第 3 个 bit 位置为 1，添加写标记；\n\n（5）倘若 map 的桶数组 buckets 未空，则对其进行初始化；\n\n（6）找到当前 key 对应的桶索引 bucket；\n\n（7）倘若发现当前 map 正处于扩容过程，则帮助其渐进扩容，具体内容在第 9 节中再作展开；\n\n（8）从 map 的桶数组 buckets 出发，结合桶索引和桶容量大小，进行地址偏移，获得对应桶 b；\n\n（9）取得 key 的高 8 位 tophash：\n\n（10）提前声明好的三个指针，用于指向存放 key-value 的空槽:\n\n```\ninserti：tophash 拟插入位置；\n\ninsertk：key 拟插入位置 ；\n\nelem：val 拟插入位置；\n```\n\n（11）开启两层 for 循环，外层沿着桶链表依次遍历，内层依次遍历桶内的 key-value 对：\n\n(12）倘若 key 的 tophash 和当前位置 tophash 不同，则会尝试将 inserti、insertk elem 调整指向首个空位，用于后续的插入操作.\n\n* 倘若发现当前位置 tophash 标识为 emtpyRest（0），则说明当前桶链表后续位置都未空，无需继续遍历，直接 break 遍历流程即可.\n\n* 倘若桶中某个位置的 tophash 标识为 emptyOne（1），说明当前位置未放入元素，倘若为 emptyRest（0），说明包括当前位置在内，此后的位置都为空.\n\n（13）倘若找到了相等的 key，则执行更新操作，并且直接跳转到方法的 done 标志位处，进行收尾处理\n\n（14）倘若没找到相等的 key，会在执行插入操作前，判断 map 是否需要开启扩容模式. 这部分内容在第 9 节中作展开.\n\n倘若需要扩容，会在开启扩容模式后，跳转回 again 标志位，重新开始桶的定位以及遍历流程.\n\n（15）倘若遍历完桶链表，都没有为当前待插入的 key-value 对找到空位，则会创建一个新的溢出桶，挂载在桶链表的尾部，并将 inserti、insertk、elem 指向溢出桶的首个空位：\n\n创建溢出桶时：\n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226220556.png)\n\n- I 倘若 hmap.extra 中还有剩余可用的溢出桶，则直接获取 hmap.extra.nextOverflow，并将 nextOverflow 调整指向下一个空闲可用的溢出桶；\n\n- II 倘若 hmap 已经没有空闲溢出桶了，则创建一个新的溢出桶.\n\n- III hmap 的溢出桶数量 hmap.noverflow 累加 1；\n\n- IV 将新获得的溢出桶添加到原桶链表的尾部；\n\n- V 返回溢出桶.\n\n（16）将 tophash、key、value 插入到取得空位中，并且将 map 的 key-value 对计数器 count 值加 1；\n\n（17）收尾环节，再次校验是否有其他协程并发写，倘若有，则抛 fatal error. 将 hmap.flags 中的写标记抹去，然后退出方法.\n\n\n## 删除流程\n\n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226220742.png)\n\n\nmap 删楚 kv 对流程主要分为以下几步：\n\n（1）根据 key 取 hash 值；\n\n（2）根据 hash 值对桶数组取模，确定所在的桶；\n\n（3）倘若 map 处于扩容，则迁移命中的桶，帮助推进渐进式扩容；\n\n（4）沿着桶链表依次遍历各个桶内的 key-value 对；\n\n（5）倘若命中相同的 key，删除对应的 key-value 对；并将当前位置的 tophash 置为 emptyOne，表示为空；\n\n（6）倘若当前位置为末位，或者下一个位置的 tophash 为 emptyRest，则沿当前位置向前遍历，将毗邻的 emptyOne 统一更新为 emptyRest.\n\nmap 删操作最终会走进 runtime/map.go 的 mapdelete 方法中，下面开始阅读源码：\n\n```\nfunc mapdelete(t *maptype, h *hmap, key unsafe.Pointer) {\n    if h == nil || h.count == 0 {\n        return\n    }\n    if h.flags\u0026hashWriting != 0 {\n        fatal(\"concurrent map writes\")\n    }\n\n\n    hash := t.hasher(key, uintptr(h.hash0))\n\n\n    h.flags ^= hashWriting\n\n\n    bucket := hash \u0026 bucketMask(h.B)\n    if h.growing() {\n        growWork(t, h, bucket)\n    }\n    b := (*bmap)(add(h.buckets, bucket*uintptr(t.bucketsize)))\n    bOrig := b\n    top := tophash(hash)\nsearch:\n    for ; b != nil; b = b.overflow(t) {\n        for i := uintptr(0); i \u003c bucketCnt; i++ {\n            if b.tophash[i] != top {\n                if b.tophash[i] == emptyRest {\n                    break search\n                }\n                continue\n            }\n            k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize))\n            k2 := k\n            if t.indirectkey() {\n                k2 = *((*unsafe.Pointer)(k2))\n            }\n            if !t.key.equal(key, k2) {\n                continue\n            }\n            // Only clear key if there are pointers in it.\n            if t.indirectkey() {\n                *(*unsafe.Pointer)(k) = nil\n            } else if t.key.ptrdata != 0 {\n                memclrHasPointers(k, t.key.size)\n            }\n            e := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize))\n            if t.indirectelem() {\n                *(*unsafe.Pointer)(e) = nil\n            } else if t.elem.ptrdata != 0 {\n                memclrHasPointers(e, t.elem.size)\n            } else {\n                memclrNoHeapPointers(e, t.elem.size)\n            }\n            b.tophash[i] = emptyOne\n            if i == bucketCnt-1 {\n                if b.overflow(t) != nil \u0026\u0026 b.overflow(t).tophash[0] != emptyRest {\n                    goto notLast\n                }\n            } else {\n                if b.tophash[i+1] != emptyRest {\n                    goto notLast\n                }\n            }\n            for {\n                b.tophash[i] = emptyRest\n                if i == 0 {\n                    if b == bOrig {\n                        break\n                    }\n                    c := b\n                    for b = bOrig; b.overflow(t) != c; b = b.overflow(t) {\n                    }\n                    i = bucketCnt - 1\n                } else {\n                    i--\n                }\n                if b.tophash[i] != emptyOne {\n                    break\n                }\n            }\n        notLast:\n            h.count--\n            if h.count == 0 {\n                h.hash0 = fastrand()\n            }\n            break search\n        }\n    }\n\n\n    if h.flags\u0026hashWriting == 0 {\n        fatal(\"concurrent map writes\")\n    }\n    h.flags \u0026^= hashWritin\n```\n\n（1）倘若 map 未初始化或者内部 key-value 对数量为 0，删除时不会报错，直接返回；\n\n（2）倘若存在其他 goroutine 在进行写或删操作，抛出并发写的 fatal error；\n\n（3）通过 maptype.hasher() 方法求得 key 对应的 hash 值；\n\n（4）通过异或位运算，将 map.flags 的第 3 个 bit 位置为 1，添加写标记；\n\n（5）找到当前 key 对应的桶索引 bucket；\n\n（6）倘若发现当前 map 正处于扩容过程，则帮助其渐进扩容\n\n（7）从 map 的桶数组 buckets 出发，结合桶索引和桶容量大小，进行地址偏移，获得对应桶 b，并赋值给 bOrg\n\n（8）取得 key 的高 8 位 tophash：\n\n（9）开启两层 for 循环，外层沿着桶链表依次遍历，内层依次遍历桶内的 key-value 对\n\n（10）遍历时，倘若发现当前位置 tophash 值为 emptyRest，则直接结束遍历流程：\n\n（11）倘若 key 不相等，则继续遍历：\n\n（12）倘若 key 相等，则删除对应的 key-value 对，并且将当前位置的 tophash 置为 emptyOne：\n\n（13）倘若当前位置不位于最后一个桶的最后一个位置，或者当前位置的后置位 tophash 不为 emptyRest，则无需向前遍历更新 tophash 标识，直接跳转到 notLast 位置即可；\n\n（14）向前遍历，将沿途的空位（ tophash 为 emptyOne ）的 tophash 都更新为 emptySet.\n\n（15）倘若成功从 map 中删除了一组 key-value 对，则将 hmap 的计数器 count 值减 1. 倘若 map 中的元素全都被删除完了，会为 map 更换一个新的随机因子 hash0.\n\n（16）收尾环节，再次校验是否有其他协程并发写，倘若有，则抛 fatal error. 将 hmap.flags 中的写标记抹去，然后退出方法.\n\n\n## 遍历流程 \n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226221021.png)\n\nMap 的遍历流程首先会走进 runtime/map.go 的 mapiterinit() 方法当中，初始化用于遍历的迭代器 hiter；接着会调用 runtime/map.go 的 mapiternext() 方法开启遍历流程.\n\n**迭代器数据结构**\n\n```\ntype hiter struct {\n    key         unsafe.Pointer \n    elem        unsafe.Pointer \n    t           *maptype\n    h           *hmap\n    buckets     unsafe.Pointer \n    bptr        *bmap         \n    overflow    *[]*bmap      \n    oldoverflow *[]*bmap      \n    startBucket uintptr       \n    offset      uint8         \n    wrapped     bool         \n    B           uint8\n    i           uint8\n    bucket      uintptr\n    checkBucket uintptr\n}\n```\n\nhiter 是遍历 map 时用于存放临时数据的迭代器：\n\n（1）key：指向遍历得到 key 的指针；\n\n（2）value：指向遍历得到 value 的指针；\n\n（3）t：map 类型，包含了 key、value 类型大小等信息；\n\n（4）h：map 的指针；\n\n（5）buckets：map 的桶数组；\n\n（6）bptr：当前遍历到的桶；\n\n（7）overflow：新老桶数组对应的溢出桶；\n\n（8）startBucket：遍历起始位置的桶索引；\n\n（9）offset：遍历起始位置的 key-value 对索引；\n\n（10）wrapped：遍历是否穿越桶数组尾端回到头部了；\n\n（11）B：桶数组的长度指数；\n\n（12）i：当前遍历到的 key-value 对在桶中的索引；\n\n（13）bucket：当前遍历到的桶；\n\n（14）checkBucket：因为扩容流程的存在，需要额外检查的桶.\n\n\nmap 遍历流程开始时，首先会走进 runtime/map.go 的 mapiterinit() 方法当中，此时会对创建 map 迭代器 hiter，并且通过取随机数的方式，决定遍历的起始桶号，以及起始 key-value 对索引号.\n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226221137.png)\n\n\n1）遍历时发现其他 goroutine 在并发写，直接抛出 fatal error：\n\n（2）开启最外圈的循环，依次遍历桶数组中的每个桶链表，通过 next 和 goto next 关键字实现循环代码块；\n\n（3）倘若已经遍历完所有的桶，重新回到起始桶为止，则直接结束方法；\n\n（4）倘若 map 处于扩容流程，取桶时兼容新老桶数组的逻辑. 倘若桶处于旧桶数组且未完成迁移，需要将 checkBucket 置为当前的桶号；\n\n5）遍历的桶号加 1，倘若来到桶数组末尾，则将桶号置为 0. 将 key-value 对的遍历索引 i 置为 0.\n\n（6）依次遍历各个桶中每个 key-value 对：\n\n（7）倘若遍历到的桶属于旧桶数组未迁移完成的桶，需要按照其在新桶中的顺序完成遍历. 比如，增量扩容流程中，旧桶中的 key-value 对最终应该被分散迁移到新桶数组的 x、y 两个区域，则此时遍历时，哪怕 key-value 对仍存留在旧桶中未完成迁移，遍历时也应该严格按照其在新桶数组中的顺序来执行.\n\n\n（8）执行 mapaccessK 方法，基于读流程方法获取 key-value 对，通过迭代 hiter 的 key、value 指针进行接收，用于对用户的遍历操作进行响应：\n\n\n\n## 扩容流程 \n\n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226221610.png)\n\n\n###  扩容类型\n\n（1）增量扩容\n\n表现：扩容后，桶数组的长度增长为原长度的 2 倍；\n\n目的：降低每个桶中 key-value 对的数量，优化 map 操作的时间复杂度.\n\n（2）等量扩容\n\n表现：扩容后，桶数组的长度和之前保持一致；但是溢出桶的数量会下降.\n\n目的：提高桶主体结构的数据填充率，减少溢出桶数量，避免发生内存泄漏\n\n### 何时扩容\n（1）只有 map 的写流程可能开启扩容模式；\n\n（2）写 map 新插入 key-value 对之前，会发起是否需要扩容的逻辑判断：\n\n（3）根据 hmap 的 oldbuckets 是否空，可以判断 map 此前是否已开启扩容模式：\n\n（4）倘若此前未进入扩容模式，且 map 中 key-value 对的数量超过 8 个，且大于桶数组长度的 6.5 倍，则进入增量扩容：\n\n（5）倘若溢出桶的数量大于 2^B 个（即桶数组的长度；B 大于 15 时取15），则进入等量扩容：\n\n###  如何开启扩容模式\n\n\n开启扩容模式的方法位于 runtime/map.go 的 hashGrow 方法中：\n\n```\nfunc hashGrow(t *maptype, h *hmap) {\n    bigger := uint8(1)\n    if !overLoadFactor(h.count+1, h.B) {\n        bigger = 0\n        h.flags |= sameSizeGrow\n    }\n    oldbuckets := h.buckets\n    newbuckets, nextOverflow := makeBucketArray(t, h.B+bigger, nil)\n\n\n\n\n    flags := h.flags \u0026^ (iterator | oldIterator)\n    if h.flags\u0026iterator != 0 {\n        flags |= oldIterator\n    }\n    // commit the grow (atomic wrt gc)\n    h.B += bigger\n    h.flags = flags\n    h.oldbuckets = oldbuckets\n    h.buckets = newbuckets\n    h.nevacuate = 0\n    h.noverflow = 0\n\n\n    if h.extra != nil \u0026\u0026 h.extra.overflow != nil {\n        // Promote current overflow buckets to the old generation.\n        if h.extra.oldoverflow != nil {\n            throw(\"oldoverflow is not nil\")\n        }\n        h.extra.oldoverflow = h.extra.overflow\n        h.extra.overflow = nil\n    }\n    if nextOverflow != nil {\n        if h.extra == nil {\n            h.extra = new(mapextra)\n        }\n        h.extra.nextOverflow = nextOverflow\n    }\n```\n\n（1）倘若是增量扩容，bigger 值取 1；倘若是等量扩容，bigger 值取 0，并将 hmap.flags 的第 4 个 bit 位置为 1，标识当前处于等量扩容流程\n（2）将原桶数组赋值给 oldBuckets，并创建新的桶数组和一批新的溢出桶.\n\n此处会通过变量 bigger，实现不同扩容模式下，新桶数组长度的区别处理.\n（3）更新 hmap 的桶数组长度指数 B，flag 标识，并将新、老桶数组赋值给 hmap.oldBuckets 和 hmap.buckets；扩容迁移进度 hmap.nevacuate 标记为 0；新桶数组的溢出桶数量 hmap.noverflow 置为 0.\n\n（4）将原本存量可用的溢出桶赋给 hmap.extra.oldoverflow；倘若存在下一个可用的溢出桶，赋给 hmap.extra.nextOverflow.\n\n### 扩容迁移规则 \n\n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226222118.png)\n\n（1）在等量扩容中，**新桶数组长度与原桶数组相同**；\n\n（2）key-value 对在新桶数组和老桶数组的中的索引号保持一致；\n\n（3）在增量扩容中，**新桶数组长度为原桶数组的两倍**；\n\n（4）把新桶数组中桶号对应于老桶数组的区域称为 x 区域，新扩展的区域称为 y 区域.\n\n（5）实际上，一个 key 属于哪个桶，取决于其 hash 值对桶数组长度取模得到的结果，因此依赖于其低位的 hash 值结果.；\n\n（6）在增量扩容流程中，新桶数组的长度会扩展一位，假定 key 原本从属的桶号为 i，则在新桶数组中从属的桶号只可能是 i （x 区域）或者 i + 老桶数组长度（y 区域）；\n\n（7）当 key 低位 hash 值向左扩展一位的 bit 位为 0，则应该迁往 x 区域的 i 位置；倘若该 bit 位为 1，应该迁往 y 区域对应的 i + 老桶数组长度的位置.\n\n###  渐进式扩容\n\n\nmap 采用的是**渐进扩容**的方式，避免因为一次性的全量数据迁移引发性能抖动.\n\n当每次触发写、删操作时，会为处于扩容流程中的 map 完成两组桶的数据迁移：\n\n**（1）一组桶是当前写、删操作所命中的桶；**\n\n**（2）另一组桶是，当前未迁移的桶中，索引最小的那个桶.**\n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226222153.png)\n\n\n数据迁移的逻辑位于 runtime/map.go 的 evacuate 方法当中：\n\n```\nfunc evacuate(t *maptype, h *hmap, oldbucket uintptr) {\n    // 入参中，oldbucket 为当前要迁移的桶在旧桶数组中的索引\n    // 获取到待迁移桶的内存地址 b\n    b := (*bmap)(add(h.oldbuckets, oldbucket*uintptr(t.bucketsize)))\n    // 获取到旧桶数组的容量 newbit\n    newbit := h.noldbuckets()\n    // evacuated 方法判断出桶 b 是否已经迁移过了，未迁移过，才进入此 if 分支进行迁移处理\n    if !evacuated(b) {\n        // 通过一个二元数组 xy 指向当前桶可能迁移到的目的桶\n        // x = xy[0]，代表新桶数组中索引和旧桶数组一致的桶\n        // y = xy[1]，代表新桶数组中，索引为原索引加上旧桶容量的桶，只在增量扩容中会使用到\n        var xy [2]evacDst\n        x := \u0026xy[0]\n        x.b = (*bmap)(add(h.buckets, oldbucket*uintptr(t.bucketsize)))\n        x.k = add(unsafe.Pointer(x.b), dataOffset)\n        x.e = add(x.k, bucketCnt*uintptr(t.keysize))\n\n\n        // 只有进入增量扩容的分支，才需要对 y 进行初始化\n        if !h.sameSizeGrow() {\n            // Only calculate y pointers if we're growing bigger.\n            // Otherwise GC can see bad pointers.\n            y := \u0026xy[1]\n            y.b = (*bmap)(add(h.buckets, (oldbucket+newbit)*uintptr(t.bucketsize)))\n            y.k = add(unsafe.Pointer(y.b), dataOffset)\n            y.e = add(y.k, bucketCnt*uintptr(t.keysize))\n        }\n\n\n        // 外层 for 循环，遍历桶 b 和对应的溢出桶\n        for ; b != nil; b = b.overflow(t) {\n            // k,e 分别记录遍历桶时，当前的 key 和 value 的指针\n            k := add(unsafe.Pointer(b), dataOffset)\n            e := add(k, bucketCnt*uintptr(t.keysize))\n            // 遍历桶内的 key-value 对\n            for i := 0; i \u003c bucketCnt; i, k, e = i+1, add(k, uintptr(t.keysize)), add(e, uintptr(t.elemsize)) {\n                top := b.tophash[i]\n                if isEmpty(top) {\n                    b.tophash[i] = evacuatedEmpty\n                    continue\n                }\n                if top \u003c minTopHash {\n                    throw(\"bad map state\")\n                }\n                k2 := k\n                if t.indirectkey() {\n                    k2 = *((*unsafe.Pointer)(k2))\n                }\n                var useY uint8\n                if !h.sameSizeGrow() {\n                    // Compute hash to make our evacuation decision (whether we need\n                    // to send this key/elem to bucket x or bucket y).\n                    hash := t.hasher(k2, uintptr(h.hash0))\n                    if hash\u0026newbit != 0 {\n                       useY = 1\n                    }\n                }\n                b.tophash[i] = evacuatedX + useY // evacuatedX + 1 == evacuatedY\n                dst := \u0026xy[useY]                 // evacuation destination\n                if dst.i == bucketCnt {\n                    dst.b = h.newoverflow(t, dst.b)\n                    dst.i = 0\n                    dst.k = add(unsafe.Pointer(dst.b), dataOffset)\n                    dst.e = add(dst.k, bucketCnt*uintptr(t.keysize))\n                }\n                dst.b.tophash[dst.i\u0026(bucketCnt-1)] = top // mask dst.i as an optimization, to avoid a bounds check\n                if t.indirectkey() {\n                    *(*unsafe.Pointer)(dst.k) = k2 // copy pointer\n                } else {\n                    typedmemmove(t.key, dst.k, k) // copy elem\n                }\n                if t.indirectelem() {\n                    *(*unsafe.Pointer)(dst.e) = *(*unsafe.Pointer)(e)\n                } else {\n                    typedmemmove(t.elem, dst.e, e)\n                }\n                dst.i++\n                dst.k = add(dst.k, uintptr(t.keysize))\n                dst.e = add(dst.e, uintptr(t.elemsize))\n            }\n        }\n        // Unlink the overflow buckets \u0026 clear key/elem to help GC.\n        if h.flags\u0026oldIterator == 0 \u0026\u0026 t.bucket.ptrdata != 0 {\n            b := add(h.oldbuckets, oldbucket*uintptr(t.bucketsize))\n            // Preserve b.tophash because the evacuation\n            // state is maintained there.\n            ptr := add(b, dataOffset)\n            n := uintptr(t.bucketsize) - dataOffset\n            memclrHasPointers(ptr, n)\n        }\n    }\n\n\n    if oldbucket == h.nevacuate {\n        advanceEvacuationMark(h, t, newbit)\n    }\n}\n\n\nfunc (h *hmap) noldbuckets() uintptr {\n    oldB := h.B\n    if !h.sameSizeGrow() {\n        oldB--\n    }\n    return bucketShift(oldB)\n```\n\n（1）从老桶数组中获取到待迁移的桶 b；\n\n（2）获取到老桶数组的长度 newbit；\n\n（3）倘若当前桶已经完成了迁移，则无需处理；\n\n（4）创建一个二元数组 xy，分别承载 x 区域和 y 区域（含义定义见 9.4 小节）中的新桶位置，用于接受来自老桶数组的迁移数组；只有在增量扩容的流程中，才存在 y 区域，因此才需要对 xy 中的 y 进行定义；\n\n（5）开启两层 for 循环，外层遍历桶链表，内层遍历每个桶中的 key-value 对：\n\n（6）取每个位置的 tophash 值进行判断，倘若当前是个空位，则将当前位置 tophash 值置为 evacuatedEmpty，开始遍历下一个位置：\n\n（7）基于 9.4 的规则，寻找到迁移的目的桶；\n\n其中目的桶的类型定义如下：\n\n```\ntype evacDst struct {\n    b *bmap          // current destination bucket\n    i int            // key/elem index into b\n    k unsafe.Pointer // pointer to current key storage\n    e unsafe.Pointer // pointer to current elem storage\n}\n```\n\nI evacDst.b：目的地的所在桶；\n\nII evacDst.i：即将入桶的 key-value 对在桶中的索引；\n\nIII evacDst.k：入桶 key 的存储指针；\n\nIV evacDst.e：入桶 value 的存储指针.\n\n\n（8）将 key-value 对迁移到目的桶中，并且更新目的桶结构内几个指针的指向：\n\n（9）倘若当前迁移的桶是旧桶数组未迁移的桶中索引最小的一个，则 hmap.nevacuate 累加 1.\n\n倘若已经迁移完所有的旧桶，则会确保 hmap.flags 中，等量扩容的标识位被置为 0.\n\n\n#  map 遍历为什么是无序的？\n\n使用 range 多次遍历 map 时输出的 key 和 value 的顺序可能不同。这是 Go 语言的设计者们**有意为之**，旨在提示开发者们，Go 底层实现并不保证 map 遍历顺序稳定，请大家不要依赖 range 遍历结果顺序\n\n主要原因有 2 点：\n\n- Map 在遍历时，并不是从固定的 0 号 bucket 开始遍历的，每次遍历，都会从一个**随机值序号的 bucket**，再从其中**随机的 cell**开始遍历\n- Map 遍历时，是按序遍历 bucket，同时按需遍历 bucket 中和其 overflow bucket 中的 cell。但是 map 在扩容后，会发生 key 的搬迁，这造成原来落在一个 bucket 中的 key，搬迁后，有可能会落到其他 bucket 中了，从这个角度看，遍历 map 的结果就不可能是按照原来的顺序了\n\nMap 本身是无序的，且遍历时顺序还会被随机化，如果想顺序遍历 map，需要对 map key 先排序，再按照 key 的顺序遍历 map。\n\n```\nfunc TestMapRange(t *testing.T) {\n    m := map[int]string{1: \"a\", 2: \"b\", 3: \"c\"}\n    t.Log(\"first range:\")\n    for i, v := range m {\n        t.Logf(\"m[%v]=%v \", i, v)\n    }\n    t.Log(\"\\nsecond range:\")\n    for i, v := range m {\n        t.Logf(\"m[%v]=%v \", i, v)\n    }\n\n    // 实现有序遍历\n    var sl []int\n    // 把 key 单独取出放到切片\n    for k := range m {\n        sl = append(sl, k)\n    }\n    // 排序切片\n    sort.Ints(sl)\n    // 以切片中的 key 顺序遍历 map 就是有序的了\n    for _, k := range sl {\n        t.Log(k, m[k])\n    }\n}\n```\n\n# map 为什么是非线程安全的？\n\nMap 默认是并发不安全的，同时对 map 进行并发读写时，程序会 panic，原因如下：\n\nGo 官方在经过了长时间的讨论后，认为 Go map 更应适配典型使用场景（不需要从多个 goroutine 中进行安全访问），而不是为了小部分情况（并发访问），导致大部分程序付出加锁代价（性能），决定了不支持。\n\n场景: 2 个协程同时读和写，以下程序会出现致命错误：fatal error: concurrent map writes\n\n```\npackage main\n\nimport (\n    \"fmt\"\n    \"time\"\n)\n\nfunc main() {\n    s := make(map[int]int)\n    for i := 0; i \u003c 100; i++ {\n        go func(i int) {\n            s[i] = i\n        }(i)\n    }\n    for i := 0; i \u003c 100; i++ {\n        go func(i int) {\n            fmt.Printf(\"map第%d个元素值是%d\\n\", i, s[i])\n        }(i)\n    }\n    time.Sleep(1 * time.Second)\n}\n```\n\n如果想实现 map 线程安全，有两种方式：\n\n方式一：使用读写锁 `map` + `sync.RWMutex`\n\n```\npackage main\n\nimport (\n    \"fmt\"\n    \"sync\"\n    \"time\"\n)\n\nfunc main() {\n    var lock sync.RWMutex\n    s := make(map[int]int)\n    for i := 0; i \u003c 100; i++ {\n        go func(i int) {\n            lock.Lock()\n            s[i] = i\n            lock.Unlock()\n        }(i)\n    }\n    for i := 0; i \u003c 100; i++ {\n        go func(i int) {\n            lock.RLock()\n            fmt.Printf(\"map第%d个元素值是%d\\n\", i, s[i])\n            lock.RUnlock()\n        }(i)\n    }\n    time.Sleep(1 * time.Second)\n}\n\n```\n\n方式二：使用 Go 提供的 `sync.Map`\n\n```\npackage main\n\nimport (\n    \"fmt\"\n    \"sync\"\n    \"time\"\n)\n\nfunc main() {\n    var m sync.Map\n    for i := 0; i \u003c 100; i++ {\n        go func(i int) {\n            m.Store(i, i)\n        }(i)\n    }\n    for i := 0; i \u003c 100; i++ {\n        go func(i int) {\n            v, ok := m.Load(i)\n            fmt.Printf(\"Load: %v, %v\\n\", v, ok)\n        }(i)\n    }\n    time.Sleep(1 * time.Second)\n}\n```\n\n\n\n\n\n\n\n\n# Map 怎么知道自己处于竞争状态？是 Go 编码实现的还是底层硬件实现的？\n\n* 代码实现的，在查找、赋值、遍历、删除的过程中**都会检测写标志 flags，一旦发现写标志置位 (等于 1)，抛出 fatal error，无法使用 recover 进行恢复。\n\n* 赋值和删除函数载检测完标志是复位状态 (等于 0)之后，先将写标志位置位，才会进行之后的操作。\n\n# Map 的 panic 能被 recover 掉吗？了解 panic 和 recover 的机制？\n\n\n**抛出 fatal error，无法使用 recover 进行恢复**\n\n```\nfunc main() {\n    defer errorHandler()\n    m := map[string]int{}\n\n    go func() {\n        for {\n            m[\"x\"] = 1\n        }\n    }()\n    for {\n        _ = m[\"x\"]\n    }\n}\n\nfunc errorHandler() {\n    if r := recover(); r != nil {\n        fmt.Println(r)\n    }\n}//不能\n```\n\nMap 由于不是线程安全的，所以在遇到并发读写的时候会抛出 concurrent map read and map write 异常，从而使程序直接退出。\n\n```\nfunc mapaccess1_faststr(t *maptype, h *hmap, ky string) unsafe.Pointer {\n    ...\n    if h.flags\u0026hashWriting != 0 {\n        throw(\"concurrent map read and map write\")\n    }\n    ...\n｝\n```\n\n这里的 throw 和上面一样，最终会调用到 exit 执行退出。\n\n# Go 中两个 map 对象如何比较\n\n使用 reflect. DeepEqual 这个函数进行比较。使用 reflect. DeepEqual 有一点注意：由于使用了反射，所以有性能的损失。如果你多做一些测试，那么你会发现 reflect. DeepEqual 会比 == 慢 100 倍以上。\n\n# Map 的优缺点以及改进?\n\n**优点**：\n\n1. Map 类似其他语言中的哈希表或字典，以 key-value 形式存储数据\n\n2. Key 必须是支持==或!=比较运算的类型，不可以是函数、map 或 slice\n\n3. Map 通过 key 查找 value 比线性搜索快很多。\n\n4. Map 使用 make ()创建，支持:=这种简写方式\n\n5. 超出容量时会自动扩容，\n\n6. 当键值对不存在时自动添加，使用 delete ()删除某键值对\n\n**缺点：**\n\n并发中的 map 不是安全的\n\n# Sync. Map 怎么使用\n\n```\npackage main\n\nimport (\n    \"fmt\"\n    \"sync\"\n)\n\nfunc main() {\n    var scene sync.Map\n    // 将键值对保存到sync.Map\n    scene.Store(\"1\", 1)\n    scene.Store(\"2\", 2)\n    scene.Store(\"3\", 3)\n    // 从sync.Map中根据键取值\n    fmt.Println(scene.Load(\"1\"))\n    // 根据键删除对应的键值对\n    scene.Delete(\"1\")\n    // 遍历所有sync.Map中的键值对\n    scene.Range(func(k, v interface{}) bool {\n        fmt.Println(\"iterate:\", k, v)\n        return true\n    })\n}\n```\n\n\n# Sync. Map 底层实现原理 \n\n\n## Sync. Map\n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226223137.png)\n\n\n```\ntype Map struct {\n    mu Mutex\n    read atomic.Value \n    dirty map[any]*entry\n    misses int\n}\n```\n\nsync.Map 主类中包含以下核心字段：\n\n- read：无锁化的只读 map，实际类型为 readOnly，2.3 小节会进一步介绍；\n    \n- dirty：加锁处理的读写 map；\n    \n- misses：记录访问 read 的失效次数，累计达到阈值时，会进行 read map/dirty map 的更新轮换；\n    \n- mu：一把互斥锁，实现 dirty 和 misses 的并发管理.\n\n\n可见，sync.Map 的特点是冗余了两份 map：read map 和 dirty map，后续的所介绍的交互流程也和这两个 map 息息相关，基本可以归结为两条主线\n\n* 主线一：首先基于无锁操作访问 read map；倘若 read map 不存在该 key，则加锁并使用 dirty map 兜底；\n\n* 主线二：read map 和 dirty map 之间会交替轮换更新\n\n## Entry \n\n```\ntype entry struct {\n    p unsafe.Pointer \n}\n```\n\nkv 对中的 value，统一采用 unsafe.Pointer 的形式进行存储，通过 entry.p 的指针进行链接.\n\nentry.p 的指向分为三种情况：\n\n* I 存活态：正常指向元素；\n\n* II 软删除态：指向 nil；\n\n* III 硬删除态：指向固定的全局变量 expunged.\n\n```\nvar expunged = unsafe.Pointer(new(any))\n```\n\n\u003e  * 存活态很好理解，即 key-entry 对仍未删除； \n\u003e  \n\u003e * nil 态表示软删除，read map 和 dirty map 底层的 map 结构仍存在 key-entry 对，但在逻辑上该 key-entry 对已经被删除，因此无法被用户查询到；  \n    * expunged 态表示硬删除，dirty map 中已不存在该 key-entry 对.\n\n\n##  readOnly \n\n```\ntype readOnly struct {\n    m       map[any]*entry\n    amended bool // true if the dirty map contains some key not in m.\n}\n```\n\nsync.Map 中的只读 map：read 内部包含两个成员属性：\n\n- m：真正意义上的 read map，实现从 key 到 entry 的映射；\n    \n- amended：标识 read map 中的 key-entry 对是否存在缺失，需要通过 dirty map 兜底.\n\n\n## 读流程 \n\n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226223946.png)\n\n### sync.Map.Load()\n\n```\nfunc (m *Map) Load(key any) (value any, ok bool) {\n    read, _ := m.read.Load().(readOnly)\n    e, ok := read.m[key]\n    if !ok \u0026\u0026 read.amended {\n        m.mu.Lock()\n        read, _ = m.read.Load().(readOnly)\n        e, ok = read.m[key]\n        if !ok \u0026\u0026 read.amended {\n            e, ok = m.dirty[key]\n            m.missLocked()\n        }\n        m.mu.Unlock()\n    }\n    if !ok {\n        return nil, false\n    }\n    return e.load()\n}\n```\n\n- 查看 read map 中是否存在 key-entry 对，若存在，则直接读取 entry 返回；\n    \n- 倘若第一轮 read map 查询 miss，且 read map 不全，则需要加锁 double check；\n    \n- 第二轮 read map 查询仍 miss（加锁后），且 read map 不全，则查询 dirty map 兜底；\n    \n-  查询操作涉及到与 dirty map 的交互，misses 加一；\n    \n-  解锁，返回查得的结果.\n\n\n### entry.load()\n\n\n```\nfunc (e *entry) load() (value any, ok bool) {\n    p := atomic.LoadPointer(\u0026e.p)\n    if p == nil || p == expunged {\n        return nil, false\n    }\n    return *(*any)(p), true\n}\n```\n\n-  sync.Map 中，kv 对的 value 是基于 entry 指针封装的形式；\n    \n-  从 map 取得 entry 后，最终需要调用 entry.load 方法读取指针指向的内容；\n    \n- 倘若 entry 的指针状态为 nil 或者 expunged，说明 key-entry 对已被删除，则返回 nil；\n    \n-  倘若 entry 未被删除，则读取指针内容，并且转为 any 的形式进行返回.\n### ## sync.Map.missLocked()\n\n```\nfunc (m *Map) missLocked() {\n    m.misses++\n    if m.misses \u003c len(m.dirty) {\n        return\n    }\n    m.read.Store(readOnly{m: m.dirty})\n    m.dirty = nil\n    m.misses = 0\n}\n```\n\n-  在读流程中，倘若未命中 read map，且由于 read map 内容存在缺失需要和 dirty map 交互时，会走进 missLocked 流程；\n    \n-  在 missLocked 流程中，首先 misses 计数器累加 1；\n    \n-  倘若 miss 次数小于 dirty map 中存在的 key-entry 对数量，直接返回即可；\n    \n-  倘若 miss 次数大于等于 dirty map 中存在的 key-entry 对数量，则使用 dirty map 覆盖 read map，并将 read map 的 amended flag 置为 false；\n    \n-  新的 dirty map 置为 nil，misses 计数器清零.\n\n##  写流程\n\n![图片](https://mmbiz.qpic.cn/mmbiz_png/3ic3aBqT2ibZsUuTG80xphH43Ht3WJG36CEl8AXCYgWOicSKtS6hNVcTzjJwoG6VrEqImiahxnV3aeImfEyNh9IsqQ/640?wx_fmt=png\u0026wxfrom=5\u0026wx_lazy=1\u0026wx_co=1)\n\nsync.Map 写流程\n\n### sync.Map.Store()\n\n```\nfunc (m *Map) Store(key, value any) {\n    read, _ := m.read.Load().(readOnly)\n    if e, ok := read.m[key]; ok \u0026\u0026 e.tryStore(\u0026value) {\n        return\n    }\n\n\n    m.mu.Lock()\n    read, _ = m.read.Load().(readOnly)\n    if e, ok := read.m[key]; ok {\n        if e.unexpungeLocked() {\n            m.dirty[key] = e\n        }\n        e.storeLocked(\u0026value)\n    } else if e, ok := m.dirty[key]; ok {\n        e.storeLocked(\u0026value)\n    } else {\n        if !read.amended {\n            m.dirtyLocked()\n            m.read.Store(readOnly{m: read.m, amended: true})\n        }\n        m.dirty[key] = newEntry(value)\n    }\n    m.mu.Unlock()\n}\n\n\nfunc (e *entry) storeLocked(i *any) {\n    atomic.StorePointer(\u0026e.p, unsafe.Pointe\n}\n```\n\n（1）倘若 read map 存在拟写入的 key，且 entry 不为 expunged 状态，说明这次操作属于更新而非插入，直接基于 CAS 操作进行 entry 值的更新，并直接返回（存活态或者软删除，直接覆盖更新）；\n\n（2）倘若未命中（1）的分支，则需要加锁 double check；\n\n（3）倘若第二轮检查中发现 read map 或者 dirty map 中存在 key-entry 对，则直接将 entry 更新为新值即可（存活态或者软删除，直接覆盖更新）；\n\n（4）在第（3）步中，如果发现 read map 中该 key-entry 为 expunged 态，需要在 dirty map 先补齐 key-entry 对，再更新 entry 值（从硬删除中恢复，然后覆盖更新）；\n\n（5）倘若 read map 和 dirty map 均不存在，则在 dirty map 中插入新 key-entry 对，并且保证 read map 的 amended flag 为 true.（插入）\n\n（6）第（5）步的分支中，倘若发现 dirty map 未初始化，需要前置执行 dirtyLocked 流程；\n\n（7）解锁返回.  \n\n下面补充介绍 Store() 方法中涉及到的几个子方法.\n\n### entry.tryStore()\n\n```\nfunc (m *Map) Store(key, value any) {\n    read, _ := m.read.Load().(readOnly)\n    if e, ok := read.m[key]; ok \u0026\u0026 e.tryStore(\u0026value) {\n        return\n    }\n\n\n    m.mu.Lock()\n   // ...\n}\n\n\nfunc (e *entry) tryStore(i *any) bool {\n    for {\n        p := atomic.LoadPointer(\u0026e.p)\n        if p == expunged {\n            return false\n        }\n        if atomic.CompareAndSwapPointer(\u0026e.p, p, unsafe.Pointer(i)) {\n            return true\n        }\n    }\n}\n```\n\n- • 在写流程中，倘若发现 read map 中已存在对应的 key-entry 对，则会对调用 tryStore 方法尝试进行更新；\n    \n- • 倘若 entry 为 expunged 态，说明已被硬删除，dirty 中缺失该项数据，因此 tryStore 执行失败，回归主干流程；\n    \n- • 倘若 entry 非 expunged 态，则直接执行 CAS 操作完成值的更新即可.\n    \n\n### entry.unexpungeLocked()\n\n```\nfunc (m *Map) Store(key, value any) {\n    // ...\n    m.mu.Lock()\n    read, _ = m.read.Load().(readOnly)\n    if e, ok := read.m[key]; ok {\n        if e.unexpungeLocked() {\n            m.dirty[key] = e\n        }\n        e.storeLocked(\u0026value)\n    } \n    // ...\n}\n\n\nfunc (e *entry) unexpungeLocked() (wasExpunged bool) {\n    return atomic.CompareAndSwapPointer(\u0026e.p, expunged, nil)\n}\n```\n\n- • 在写流程加锁 double check 的过程中，倘若发现 read map 中存在对应的 key-entry 对，会执行该方法；\n    \n- • 倘若 key-entry 为硬删除 expunged 态，该方法会基于 CAS 操作将其更新为软删除 nil 态，然后进一步在 dirty map 中补齐该 key-entry 对，实现从硬删除到软删除的恢复.\n    \n\n### entry.storeLocked()\n\n```\nfunc (m *Map) Store(key, value any) {\n    // ...\n    m.mu.Lock()\n    read, _ = m.read.Load().(readOnly)\n    if e, ok := read.m[key]; ok {\n       // ...\n        e.storeLocked(\u0026value)\n    } else if e, ok := m.dirty[key]; ok {\n        e.storeLocked(\u0026value)\n    } \n    // ...\n}\n\n\nfunc (e *entry) storeLocked(i *any) {\n    atomic.StorePointer(\u0026e.p, unsafe.Pointer)\n}\n```\n\n写流程中，倘若 read map 或者 dirty map 存在对应 key-entry，最终会通过原子操作，将新值的指针存储到 entry.p 当中.\n\n### sync.Map.dirtyLocked()\n\n![图片](https://mmbiz.qpic.cn/mmbiz_png/3ic3aBqT2ibZsUuTG80xphH43Ht3WJG36CcuBUenRpJGmoHvuTdQTX4BwgLVEAhjgTBomODX1LBibuibqd6VkaOcVQ/640?wx_fmt=png\u0026wxfrom=5\u0026wx_lazy=1\u0026wx_co=1)\n\ndirtyLock 方法\n\n```\nfunc (m *Map) dirtyLocked() {\n    if m.dirty != nil {\n        return\n    }\n\n\n    read, _ := m.read.Load().(readOnly)\n    m.dirty = make(map[any]*entry, len(read.m))\n    for k, e := range read.m {\n        if !e.tryExpungeLocked() {\n            m.dirty[k] = e\n        }\n    }\n}\n\n\nfunc (e *entry) tryExpungeLocked() (isExpunged bool) {\n    p := atomic.LoadPointer(\u0026e.p)\n    for p == nil {\n        if atomic.CompareAndSwapPointer(\u0026e.p, nil, expunged) {\n            return true\n        }\n        p = atomic.LoadPointer(\u0026e.p)\n    }\n    return p == expunged\n}\n```\n\n- • 在写流程中，倘若需要将 key-entry 插入到兜底的 dirty map 中，并且此时 dirty map 为空（从未写入过数据或者刚发生过 missLocked），会进入 dirtyLocked 流程；\n    \n- • 此时会遍历一轮 read map ，将未删除的 key-entry 对拷贝到 dirty map 当中；\n    \n- • 在遍历时，还会将 read map 中软删除 nil 态的 entry 更新为硬删除 expunged 态，因为在此流程中，不会将其拷贝到 dirty map.\n    \n\n## 删流程\n\n![图片](https://mmbiz.qpic.cn/mmbiz_png/3ic3aBqT2ibZsUuTG80xphH43Ht3WJG36CRAuibb73ia2hJuBkpQNNiaowGY9HPic4MX2YPresfrfndXdIj6bTLIKblw/640?wx_fmt=png\u0026wxfrom=5\u0026wx_lazy=1\u0026wx_co=1)\n\nDelete流程\n\n### sync.Map.Delete()\n\n```\nfunc (m *Map) Delete(key any) {\n    m.LoadAndDelete(key)\n}\n\n\nfunc (m *Map) LoadAndDelete(key any) (value any, loaded bool) {\n    read, _ := m.read.Load().(readOnly)\n    e, ok := read.m[key]\n    if !ok \u0026\u0026 read.amended {\n        m.mu.Lock()\n        read, _ = m.read.Load().(readOnly)\n        e, ok = read.m[key]\n        if !ok \u0026\u0026 read.amended {\n            e, ok = m.dirty[key]\n            delete(m.dirty, key)\n            m.missLocked()\n        }\n        m.mu.Unlock()\n    }\n    if ok {\n        return e.delete()\n    }\n    return nil, false\n}\n```\n\n（1）倘若 read map 中存在 key，则直接基于 cas 操作将其删除；\n\n（2）倘若read map 不存在 key，且 read map 有缺失（amended flag 为 true），则加锁 dou check；\n\n（3）倘若加锁 double check 时，read map 仍不存在 key 且 read map 有缺失，则从 dirty map 中取元素，并且将 key-entry 对从 dirty map 中物理删除；\n\n（4）走入步骤（3），删操作需要和 dirty map 交互，需要走进 3.3 小节介绍的 missLocked 流程；\n\n（5）解锁；\n\n（6）倘若从 read map 或 dirty map 中获取到了 key 对应的 entry，则走入 entry.delete() 方法逻辑删除 entry；\n\n（7）倘若 read map 和 dirty map 中均不存在 key，返回 false 标识删除失败.  \n\n### entry.delete()\n\n```\nfunc (e *entry) delete() (value any, ok bool) {\n    for {\n        p := atomic.LoadPointer(\u0026e.p)\n        if p == nil || p == expunged {\n            return nil, false\n        }\n        if atomic.CompareAndSwapPointer(\u0026e.p, p, nil) {\n            return *(*any)(p), true\n        }\n    }\n}\n```\n\n- • 该方法是 entry 的逻辑删除方法；\n    \n- • 倘若 entry 此前已被删除，则直接返回 false 标识删除失败；\n    \n- • 倘若 entry 当前仍存在，则通过 CAS 将 entry.p 指向 nil，标识其已进入软删除状态.\n    \n\n##  遍历流程\n\n![图片](https://mmbiz.qpic.cn/mmbiz_png/3ic3aBqT2ibZsUuTG80xphH43Ht3WJG36CkgF4rrYRgJjyxJMZG87pW5bN1sGWwmgm1jZLrnuCXL9UJZ5dUs5YHw/640?wx_fmt=png\u0026wxfrom=5\u0026wx_lazy=1\u0026wx_co=1)\n\n遍历流程\n\n```\nfunc (m *Map) Range(f func(key, value any) bool) {\n    read, _ := m.read.Load().(readOnly)\n    if read.amended {\n        m.mu.Lock()\n        read, _ = m.read.Load().(readOnly)\n        if read.amended {\n            read = readOnly{m: m.dirty}\n            m.read.Store(read)\n            m.dirty = nil\n            m.misses = 0\n        }\n        m.mu.Unlock()\n    }\n\n\n    for k, e := range read.m {\n        v, ok := e.load()\n        if !ok {\n            continue\n        }\n        if !f(k, v) {\n            break\n        }\n    }\n}\n```\n\n- （1）在遍历过程中，倘若发现 read map 数据不全（amended flag 为 true），会额外加一次锁，并使用 dirty map 覆盖 read map；\n    \n- （2）遍历 read map（通过步骤（1）保证 read map 有全量数据），执行用户传入的回调函数，倘若某次回调时返回值为 false，则会终止全流程.\n    \n\n## 总结\n\n### entry 的 expunged 态\n\n**思考问题：**\n\n为什么需要使用 expunged 态来区分软硬删除呢？仅用 nil 一种状态来标识删除不可以吗？\n\n**回答：**\n\n首先需要明确，无论是软删除(nil)还是硬删除(expunged),都表示在逻辑意义上 key-entry 对已经从 sync.Map 中删除，nil 和 expunged 的区别在于：\n\n• 软删除态（nil）：read map 和 dirty map 在物理上仍保有该 key-entry 对，因此倘若此时需要对该 entry 执行写操作，可以直接 CAS 操作；\n\n• 硬删除态（expunged）：dirty map 中已经没有该 key-entry 对，倘若执行写操作，必须加锁（dirty map 必须含有全量 key-entry 对数据）.\n\n![图片](https://mmbiz.qpic.cn/mmbiz_png/3ic3aBqT2ibZsUuTG80xphH43Ht3WJG36CAxye1O5PX8pnubKpT3wDbURickVwsYzqgWaBJ5GM07ms57giaiaiaM2n6g/640?wx_fmt=png\u0026wxfrom=5\u0026wx_lazy=1\u0026wx_co=1)\n\n复用 nil 态软删除的数据\n\n设计 expunged 和 nil 两种状态的原因，就是为了优化在 dirtyLocked 前，针对同一个 key 先删后写的场景. 通过 expunged 态额外标识出 dirty map 中是否仍具有指向该 entry 的能力，这样能够实现对一部分 nil 态 key-entry 对的解放，能够基于 CAS 完成这部分内容写入操作而无需加锁.\n\n### read map 和 dirty map 的数据流转\n\nsync.Map 由两个 map 构成：\n\n- • read map：访问时全程无锁；\n    \n- • dirty map：是兜底的读写 map，访问时需要加锁.\n    \n\n之所以这样处理，是希望能根据对读、删、更新、写操作频次的探测，来实时动态地调整操作方式，希望在读、更新、删频次较高时，更多地采用 CAS 的方式无锁化地完成操作；在写操作频次较高时，则直接了当地采用加锁操作完成.\n\n因此， sync.Map 本质上采取了一种以空间换时间 + 动态调整策略的设计思路，下面对两个 map 间的数据流转过程进行详细介绍：\n\n#### 两个 map\n\n![图片](https://mmbiz.qpic.cn/mmbiz_png/3ic3aBqT2ibZsUuTG80xphH43Ht3WJG36CIlk7IHD6tdMsFJ1DWggymJ72FEPEOLF5y6vWufWfILfeq27KSXFguw/640?wx_fmt=png\u0026wxfrom=5\u0026wx_lazy=1\u0026wx_co=1)\n\nread map\u0026 dirty map\n\n- • 总体思想，希望能多用 read map，少用 dirty map，因为操作前者无锁，后者需要加锁；\n    \n- • 除了 expunged 态的 entry 之外，read map 的内容为 dirty map 的子集；\n    \n\n####  dirty map -\u003e read map\n\n![图片](https://mmbiz.qpic.cn/mmbiz_png/3ic3aBqT2ibZsUuTG80xphH43Ht3WJG36CPMHoHZqRHibmVmXkCy09LefxEkmwS2w9MVWqHkzOxKtTgmDupA4mcibQ/640?wx_fmt=png\u0026wxfrom=5\u0026wx_lazy=1\u0026wx_co=1)\n\ndirty map 覆写 read map\n\n- • 记录读/删流程中，通过 misses 记录访问 read map miss 由 dirty 兜底处理的次数，当 miss 次数达到阈值，则进入 missLocked 流程，进行新老 read/dirty 替换流程；此时将老 dirty 作为新 read，新 dirty map 则暂时为空，直到 dirtyLocked 流程完成对 dirty 的初始化；\n    \n\n####  read map -\u003e dirty map\n\n![图片](https://mmbiz.qpic.cn/mmbiz_png/3ic3aBqT2ibZsUuTG80xphH43Ht3WJG36CibxGwWWlfByvgeV1gjpbfpCvUYq1HHjMeyZckzLQh97zR2GkjDgCdXQ/640?wx_fmt=png\u0026wxfrom=5\u0026wx_lazy=1\u0026wx_co=1)\n\n遍历 read map 填充 dirty map  \n\n- • 发生 dirtyLocked 的前置条件：I dirty 暂时为空（此前没有写操作或者近期进行过 missLocked 流程）；II 接下来一次写操作访问 read 时 miss，需要由 dirty 兜底；\n    \n- • 在 dirtyLocked 流程中，需要对 read 内的元素进行状态更新，因此需要遍历，是一个线性时间复杂度的过程，可能存在性能抖动；\n    \n- • dirtyLocked 遍历中，会将 read 中未被删除的元素（非 nil 非 expunged）拷贝到 dirty 中；会将 read 中所有此前被删的元素统一置为 expunged 态.\n\n\n\n\n# Go map 和 sync. Map 谁的性能好，为什么？\n\nGo 语言的 `sync. Map` 支持并发读写，采取了 “空间换时间” 的机制，冗余了两个数据结构，分别是：read 和 dirty\n\n```\ntype Map struct {\n   mu Mutex\n   read atomic.Value // readOnly\n   dirty map[interface{}]*entry\n   misses int\n}\n```\n\n**对比原始 map：**\n\n和原始 map+RWLock 的实现并发的方式相比，减少了加锁对性能的影响。它做了一些优化：可以无锁访问 read map，而且会优先操作 read map，倘若只操作 read map 就可以满足要求，那就不用去操作 write map (dirty)，所以在某些特定场景中它发生锁竞争的频率会远远小于 map+RWLock 的实现方式\n\n**优点：**\n\n适合读多写少的场景\n\n**缺点：**\n\n写多的场景，会导致 read map 缓存失效，需要加锁，冲突变多，性能急剧下降","lastmodified":"2024-03-02T12:01:53.846210423Z","tags":["GO/八股文"]},"/GO/%E5%85%AB%E8%82%A1%E6%96%87/Slice":{"title":"Slice","content":"\n# 参考\n\n\n[你真的了解go语言中的切片吗](https://mp.weixin.qq.com/s?__biz=MzkxMjQzMjA0OQ==\u0026mid=2247484378\u0026idx=1\u0026sn=3d2d4a0055a96c8c76e620371bfec7f7\u0026chksm=c10c4d04f67bc412295034c5ad5a28bb11ffcd4d8fd2d8846e3bdb48d4137ecf6637557d9be4\u0026scene=178\u0026cur_album_id=2709593649634033668#rd) \n\n\n# 基本介绍\ngo 语言中的切片对标于其他编程语言中通俗意义上的“数组”. **切片中的元素存放在一块内存地址连续的区域**，使用索引可以快速检索到指定位置的元素；切片长度和容量是可变的，在使用过程中可以根据需要进行扩容.\n\n\n# Go slice 的底层实现原理?\n\n切片是基于数组实现的，它的底层是数组，可以理解为对底层数组的抽象。\n\n源码包中 src/runtime/slice. Go 定义了 slice 的数据结构：\n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226175632.png)\n\n\n```\ntype slice struct {\n\t// 指向起点的地址\n    array unsafe.Pointer\n    // 切片长度\n    len   int\n    // 切片容量\n    cap   int\n}\n```\n\nSlice 占用 24 个字节\n\n- Array: 指向底层数组的指针，占用 8 个字节\n\n- Len: 切片的长度，占用 8 个字节\n\n- Cap: 切片的容量，cap 总是大于等于 len 的，占用 8 个字节\n\nSlice 有 4 种初始化方式\n\n```\n// 初始化方式1：直接声明\nvar slice1 []int\n\n// 初始化方式2：使用字面量\nslice2 := []int{1, 2, 3, 4}\n\n// 初始化方式3：使用make创建slice\nslice3 := make([]int, 3, 5)         \n\n// 初始化方式4: 从切片或数组“截取”\nslcie4 := arr[1:3]\n```\n\n通过一个简单程序，看下 slice 初始化调用的底层函数\n\n```\npackage main\n\nimport \"fmt\"\n\nfunc main() {\n    slice := make([]int, 0)\n    slice = append(slice, 1)\n    fmt.Println(slice, len(slice), cap(slice))\n}\n```\n\n通过 `go tool compile -S test.go | grep CALL` 得到汇编代码\n\n```\n0x0042 00066 (test.go:6)        CALL    runtime.makeslice(SB)\n0x006d 00109 (test.go:7)        CALL    runtime.growslice(SB)\n0x00a4 00164 (test.go:8)        CALL    runtime.convTslice(SB)\n0x00c0 00192 (test.go:8)        CALL    runtime.convT64(SB)\n0x00d8 00216 (test.go:8)        CALL    runtime.convT64(SB)\n0x0166 00358 ($GOROOT/src/fmt/print.go:274)     CALL    fmt.Fprintln(SB)\n0x0180 00384 (test.go:5)        CALL    runtime.morestack_noctxt(SB)\n0x0079 00121 (\u003cautogenerated\u003e:1)        CALL    runtime.efaceeq(SB)\n0x00a0 00160 (\u003cautogenerated\u003e:1)        CALL    runtime.morestack_noctxt(SB)\n```\n\n初始化 slice 调用的是 **runtime. Makeslice，makeslice 函数的工作主要就是计算 slice 所需内存大小，然后调用 mallocgc 进行内存的分配**\n\n所需内存大小 = 切片中元素大小 * 切片的容量\n\n```\nfunc makeslice(et *_type, len, cap int) unsafe.Pointer {\n    // 根据 cap 结合每个元素的大小，计算出消耗的总容量\n    mem, overflow := math.MulUintptr(et.size, uintptr(cap))\n    if overflow || mem \u003e maxAlloc || len \u003c 0 || len \u003e cap {\n        // 倘若容量超限，len 取负值或者 len 超过 cap，直接 panic\n        mem, overflow := math.MulUintptr(et.size, uintptr(len))\n        if overflow || mem \u003e maxAlloc || len \u003c 0 {\n            panicmakeslicelen()\n        }\n        panicmakeslicecap()\n    }\n    // 走 mallocgc 进行内存分配以及切片初始化\n    return mallocgc(mem, et, true)\n}\n```\n\n\n# Slice 切片的截取\n\n```\n x := make([]int, 2, 10)\n _ = x[6:10]\n _ = x[6:]\n _ = x[2:]\n\n//_ = x[6:] 这⼀⾏会发⽣panic, 截取符号 [i:j]，\n//如果 j 省略，默认是原切⽚或者数组的⻓度，x 的⻓度是 2，⼩于起始下标 6 ，所以 panic\n```\n\n可以修改 slice 下标的方式，进行 slice 内容的截取，形如 s[a: b] 的格式，其中 a b 代表切片的索引 index，左闭右开，比如 s[a: b] 对应的范围是 [a,b)，代表的是取切片 slice index = a ~ index = b-1 范围的内容.\n\n此外，这里我聊到的 a 和 b 是可以缺省的：\n\n- 如果 a 缺省不填则默认取 0 ，则代表从切片起始位置开始截取. 比如 s[:b] 等价于 s[0:b]\n    \n-  如果 b 缺省不填，则默认取 len(s)，则代表末尾截取到切片长度 len 的终点，比如 s[a:] 等价于 s[a:len(s)]\n    \n- •a 和 b 均缺省也是可以的，则代表截取整个切片长度的范围，比如 s[:] 等价于 s[0:len(s)\n\n对切片 slice 执行截取操作时，本质上是一次引用传递操作，因为不论如何截取，**底层复用的都是同一块内存空间中的数据**，只不过，截取动作会创建出一个新的 slice header 实例\n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226180202.png)\n\n\n# Slice 元素追加\n\n通过 append 操作，可以在 slice 末尾，额外新增一个元素. 需要注意，这里的末尾指的是针对 slice 的长度 len 而言. **这个过程中倘若发现 slice 的剩余容量已经不足了，则会对 slice 进行扩容**.\n\n# Slice 扩容\n\n\n**版本 1.18 之前**\n扩容会发生在 slice append 的时候，当 slice 的 cap 不足以容纳新元素，就会进行扩容，扩容规则如下\n\n- 如果原有 slice 长度小于 1024，那么每次就扩容为原来的 2 倍\n- 如果原 slice 长度大于等于 1024，那么每次扩容就扩为原来的 1.25 倍\n\n**1.18 +**\n\n切片的扩容流程源码位于 runtime/slice.go 文件的 growslice 方法当中，其中核心步骤如下：\n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226204620.png)\n\n\n- 倘若扩容后预期的新容量小于原切片的容量，则 panic\n    \n- 倘若切片元素大小为 0（元素类型为 struct{}），则直接复用一个全局的 zerobase 实例，直接返回\n    \n- 倘若预期的新容量超过老容量的两倍，则直接采用预期的新容量\n    \n- 倘若老容量小于 256，则直接采用老容量的2倍作为新容量\n    \n- 倘若老容量已经大于等于 256，则在老容量的基础上扩容 1/4 的比例并且累加上 192 的数值，持续这样处理，直到得到的新容量已经大于等于预期的新容量为止\n    \n-  结合 mallocgc 流程中，对内存分配单元 mspan 的等级制度，推算得到实际需要申请的内存空间大小\n    \n- 调用 mallocgc，对新切片进行内存初始化\n    \n- 调用 memmove 方法，将老切片中的内容拷贝到新切片中\n    \n-  返回扩容后的新切片 \n```\nfunc growslice(et *_type, old slice, cap int) slice {\n    //... \n    if cap \u003c old.cap {\n        panic(errorString(\"growslice: cap out of range\"))\n    }\n\n\n    if et.size == 0 {\n        // 倘若元素大小为 0，则无需分配空间直接返回\n        return slice{unsafe.Pointer(\u0026zerobase), old.len, cap}\n    }\n\n\n    // 计算扩容后数组的容量\n    newcap := old.cap\n    // 取原容量两倍的容量数值\n    doublecap := newcap + newcap\n    // 倘若新的容量大于原容量的两倍，直接取新容量作为数组扩容后的容量\n    if cap \u003e doublecap {\n        newcap = cap\n    } else {\n        const threshold = 256\n        // 倘若原容量小于 256，则扩容后新容量为原容量的两倍\n        if old.cap \u003c threshold {\n            newcap = doublecap\n        } else {\n            // 在原容量的基础上，对原容量 * 5/4 并且加上 192\n            // 循环执行上述操作，直到扩容后的容量已经大于等于预期的新容量为止\n            for 0 \u003c newcap \u0026\u0026 newcap \u003c cap {             \n                newcap += (newcap + 3*threshold) / 4\n            }\n            // 倘若数值越界了，则取预期的新容量 cap 封顶\n            if newcap \u003c= 0 {\n                newcap = cap\n            }\n        }\n    }\n\n\n    var overflow bool\n    var lenmem, newlenmem, capmem uintptr\n    // 基于容量，确定新数组容器所需要的内存空间大小 capmem\n    switch {\n    // 倘若数组元素的大小为 1，则新容量大小为 1 * newcap.\n    // 同时会针对 span class 进行取整\n    case et.size == 1:\n        lenmem = uintptr(old.len)\n        newlenmem = uintptr(cap)\n        capmem = roundupsize(uintptr(newcap))\n        overflow = uintptr(newcap) \u003e maxAlloc\n        newcap = int(capmem)\n    // 倘若数组元素为指针类型，则根据指针占用空间结合元素个数计算空间大小\n    // 并会针对 span class 进行取整\n    case et.size == goarch.PtrSize:\n        lenmem = uintptr(old.len) * goarch.PtrSize\n        newlenmem = uintptr(cap) * goarch.PtrSize\n        capmem = roundupsize(uintptr(newcap) * goarch.PtrSize)\n        overflow = uintptr(newcap) \u003e maxAlloc/goarch.PtrSize\n        newcap = int(capmem / goarch.PtrSize)\n    // 倘若元素大小为 2 的指数，则直接通过位运算进行空间大小的计算   \n    case isPowerOfTwo(et.size):\n        var shift uintptr\n        if goarch.PtrSize == 8 {\n            // Mask shift for better code generation.\n            shift = uintptr(sys.Ctz64(uint64(et.size))) \u0026 63\n        } else {\n            shift = uintptr(sys.Ctz32(uint32(et.size))) \u0026 31\n        }\n        lenmem = uintptr(old.len) \u003c\u003c shift\n        newlenmem = uintptr(cap) \u003c\u003c shift\n        capmem = roundupsize(uintptr(newcap) \u003c\u003c shift)\n        overflow = uintptr(newcap) \u003e (maxAlloc \u003e\u003e shift)\n        newcap = int(capmem \u003e\u003e shift)\n    // 兜底分支：根据元素大小乘以元素个数\n    // 再针对 span class 进行取整     \n    default:\n        lenmem = uintptr(old.len) * et.size\n        newlenmem = uintptr(cap) * et.size\n        capmem, overflow = math.MulUintptr(et.size, uintptr(newcap))\n        capmem = roundupsize(capmem)\n        newcap = int(capmem / et.size)\n    }\n\n\n\n\n    // 进行实际的切片初始化操作\n    var p unsafe.Pointer\n    // 非指针类型\n    if et.ptrdata == 0 {\n        p = mallocgc(capmem, nil, false)\n        // ...\n    } else {\n        // 指针类型\n        p = mallocgc(capmem, et, true)\n        // ...\n    }\n    // 将切片的内容拷贝到扩容后的位置 p \n    memmove(p, old.array, lenmem)\n    return slice{p, old.len, newcap}\n}\n```\n\n\n# Slice 元素删除\n\n从切片中删除元素的实现思路，本质上和切片内容截取的思路是一致的.\n\n需要删除 slice 中间的某个元素，**操作思路则是采用内容截取加上元素追加的复合操作**，可以先截取待删除元素的左侧部分内容，然后在此基础上追加上待删除元素后侧部分的内容：\n\n```func Test_slice(t *testing.T){\n    s := []int{0,1,2,3,4}\n    // 删除 index = 2 的元素\n    s = append(s[:2],s[3:]...)\n    // s: [0,1,3,4], len: 4, cap: 5\n    t.Logf(\"s: %v, len: %d, cap: %d\", s, len(s), cap(s))\n}\n```\n\n\nGo 语言删除切片元素的方法：  \n1、指定删除位置，如【index := 1】;  \n2、查看删除位置之前的元素和之后的元素;  \n3、将删除点前后的元素连接起来即可。  \nGo 语言并没有对删除切片元素提供专用的语法或者接口，需要使用切片本身的特性来删除元素。  \n示例代码如下：\n\n```\nstr := []string{\"a\",\"b\",\"c\"}\n// step 1\nindex := 1\n// step 2\nfmt.Println(str[:index], str[index+1])\n// step 3\nstr = append(str[:index], str[index+1]...)\n// res\nfmt.Println(str)\n```\n\n\n# Slice 切片拷贝 \n\nslice 的拷贝可以分为简单拷贝和完整拷贝两种类型.\n\n\n* 简单拷贝，只需要对切片的字面量进行赋值传递即可，这样相当于创建出了一个新的 slice header 实例，但是其中的指针 array、容量 cap 和长度 len 仍和老的 slice header 实例相同.\n\n```\nfunc Test_slice(t *testing.T) {\n    s := []int{0, 1, 2, 3, 4}\n    s1 := s\n    t.Logf(\"address of s: %p, address of s1: %p\", s, s1)\n}\n```\n* slice 的完整复制，指的是会创建出一个和 slice 容量大小相等的独立的内存区域，并将原 slice 中的元素一一拷贝到新空间中.\n```\nfunc Test_slice(t *testing.T) {\n    s := []int{0, 1, 2, 3, 4}\n    s1 := make([]int, len(s))\n    copy(s1, s)\n    t.Logf(\"s: %v, s1: %v\", s, s1)\n    t.Logf(\"address of s: %p, address of s1: %p\", s, s1)\n}\n```\n\n# Go array 和 slice 的区别？\n\n**1）数组长度不同**\n\n数组初始化必须指定长度，并且长度就是固定的\n\n切片的长度是不固定的，可以追加元素，在追加时可能使切片的容量增大\n\n**2）函数传参不同**\n\n数组是值类型，将一个数组赋值给另一个数组时，传递的是一份深拷贝，函数传参操作都会复制整个数组数据，会占用额外的内存，函数内对数组元素值的**修改**，不会修改原数组内容。\n\n切片是引用类型，将一个切片赋值给另一个切片时，传递的是一份浅拷贝，函数传参操作不会拷贝整个切片，只会复制 len 和 cap，底层共用同一个数组，不会占用额外的内存，函数内对数组元素值的**修改**，会修改原数组内容。\n\n**3）计算数组长度方式不同**\n\n数组需要遍历计算数组长度，时间复杂度为 O (n)\n\n切片底层包含 len 字段，可以通过 len ()计算切片长度，时间复杂度为 O (1)\n\n# Go slice 深拷贝和浅拷贝\n\n深拷贝：拷贝的是数据本身，创造一个新对象，新创建的对象与原对象不共享内存，新创建的对象在内存中开辟一个新的内存地址，新对象值修改时不会影响原对象值\n\n实现深拷贝的方式：\n\n1. Copy (slice 2, slice 1)\n2. 遍历 append 赋值\n\n```\nfunc main() {\n    slice1 := []int{1, 2, 3, 4, 5}\n    slice2 := make([]int, 5, 5)\n    fmt.Printf(\"slice1: %v, %p\\n\", slice1, slice1)\n    copy(slice2, slice1)\n    fmt.Printf(\"slice2: %v, %p\\n\", slice2, slice2)\n    slice3 := make([]int, 0, 5)\n    for _, v := range slice1 {\n        slice3 = append(slice3, v)\n    }\n    fmt.Printf(\"slice3: %v, %p\\n\", slice3, slice3)\n}\n\nslice1: [1 2 3 4 5], 0xc0000b0030\nslice2: [1 2 3 4 5], 0xc0000b0060\nslice3: [1 2 3 4 5], 0xc0000b0090\n```\n\n浅拷贝：拷贝的是数据地址，只复制指向的对象的指针，此时新对象和老对象指向的内存地址是一样的，新对象值修改时老对象也会变化\n\n实现浅拷贝的方式：\n\n引用类型的变量，**默认赋值操作就是浅拷贝**\n\n```\nfunc main() {\n    slice1 := []int{1, 2, 3, 4, 5}\n    fmt.Printf(\"slice1: %v, %p\\n\", slice1, slice1)\n    slice2 := slice1\n    fmt.Printf(\"slice2: %v, %p\\n\", slice2, slice2)\n}\n\nslice1: [1 2 3 4 5], 0xc00001a120\nslice2: [1 2 3 4 5], 0xc00001a120\n```\n\n\n\n\n# Go slice 为什么不是线程安全的？\n\n**先看下线程安全的定义**：\n\n多个线程访问同一个对象时，调用这个对象的行为都可以获得正确的结果，那么这个对象就是线程安全的。\n\n若有多个线程同时执行写操作，一般都需要考虑线程同步，否则的话就可能影响线程安全。\n\n**再看 Go 语言实现线程安全常用的几种方式**：\n\n1. 互斥锁\n2. 读写锁\n3. 原子操作\n4. Sync. Once\n5. Sync. Atomic\n6. Channel\n\nSlice 底层结构并没有使用加锁等方式，不支持并发读写，所以并不是线程安全的，使用多个 goroutine 对类型为 slice 的变量进行操作，每次输出的值大概率都不会一样，与预期值不一致; **slice 在并发执行中不会报错，但是数据会丢失**\n\n```\n/**\n* 切片非并发安全\n* 多次执行，每次得到的结果都不一样\n* 可以考虑使用 channel 本身的特性 (阻塞) 来实现安全的并发读写\n */\nfunc TestSliceConcurrencySafe(t *testing.T) {\n a := make([]int, 0)\n var wg sync.WaitGroup\n for i := 0; i \u003c 10000; i++ {\n  wg.Add(1)\n  go func(i int) {\n   a = append(a, i)\n   wg.Done()\n  }(i)\n }\n wg.Wait()\n t.Log(len(a)) \n // not equal 10000\n}\n```\n\n\n# nil 切片和空切片指向的地址一样？\n\n```\nfunc main() {\n    var s1 []int\n    s2 := make([]int, 0)\n    s3 := make([]int, 0)\n    data1 := (*reflect.SliceHeader)(unsafe.Pointer(\u0026s1)).Data\n    data2 := (*reflect.SliceHeader)(unsafe.Pointer(\u0026s2)).Data\n    data3 := (*reflect.SliceHeader)(unsafe.Pointer(\u0026s3)).Data\n\n    fmt.Printf(\"s1 data:%+v\\n\", data1)\n    fmt.Printf(\"s2 data:%+v\\n\", data2)\n    fmt.Printf(\"s3 data:%+v\\n\", data3)\n\n    fmt.Printf(\"s1:s2=\u003e%t\\n\", data1 == data2)\n    fmt.Printf(\"s2:s3=\u003e%t\\n\", data2 == data3)\n}\n\n//输出\ns1 data:0\ns2 data:824634859200\ns3 data:824634859200\ns1:s2=\u003efalse\ns2:s3=\u003etrue\n```\n\n**Nil 切片和空切片指向的地址不一样**。\n\n**Nil 切片引用数组指针地址为 0（无指向任何实际地址）**\n\n**空切片的引用数组指针地址是有的，且固定为一个值。**\n\n```\n//切片的数据结构\ntype SliceHeader struct {\n    Data uintptr //引用数组指针地址\n    Len  int\n    Cap  int\n}\n```\n\n**Nil 切片和空切片最大的区别在于指向的数组引用地址是不一样的**\n\n# 拷贝大切片一定比小切片代价大吗？\n\n并不是，所有切片的大小相同；三个字段（一个 uintptr，两个 int）。切片中的第一个字段是指向切片底层数组的指针，这是切片的存储空间，第二个字段是切片的长度，第三个字段是容量。将一个 slice 变量分配给另一个变量只会复制三个机器字。所**以拷贝大切片跟小切片的代价应该是一样的**。\n\nSliceHeader 是切片在 go 的底层结构。\n\n```\ntype SliceHeader struct {\n    Data uintptr\n    Len  int\n    Cap  int\n}\n```\n\n大切片跟小切片的区别无非就是 Len 和 Cap 的值比小切片的这两个值大一些，如果发生拷贝，本质上就是拷贝上面的三个字段。\n\n# json 库对 nil slice 和空 slice 的处理是一致的吗？\n\nJson 库对 nil slice 和空 slice 的处理是不一致的，\n\n因为 nil slice 只是声明了 slice，却没有给实例化的对象。\n\n```\n\tvar f1 []string\n    f2 := make([]string, 0)\n    json1, _ := json.Marshal(Person{f1})\n    json2, _ := json.Marshal(Person{f2})\n    fmt.Printf(\"%s\\n\", string(json1))\n    fmt.Printf(\"%s\\n\", string(json2))\n\n//输出\n{\"Friends\":null}\n{\"Friends\":[]}\n```\n\n**Json 库对 nil slice 编码为 null, json 库对空 slice 编码为[]。**\n\n\n\n\n# 扩容前后的 Slice 是否相同?\n\n情况一：**原数组还有容量可以扩容（实际容量没有填充完），这种情况下，扩容以后的数组还是指向原来的数组**，对一个切片的操作可能影响多个指针指向相同地址的 slice。\n\n情况二：**原来数组的容量已经达到了最大值，再想扩容，go 默认会先开一片内存区域，把原来的值拷贝过来，然后再执行 append ()操作**。这种情况丝毫不影响原数组。要复制一个 slice，最好使用 copy 函数。\n\n![image-20230906170544338](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticimage-20230906170544338.png)\n\n**输出：**\n\n```\n函数内s=[1,2]\n主函数内s=[1]\n```\n\n# 使用值为 nil 的 slice、map 会发生啥\n\n**允许对值为 nil 的 slice 添加元素，但对值为 nil 的 map 添加元素，则会造成运行时 panic**。\n\n\n```\n// map 错误示例  \nfunc main () {  \n    var m map[string]int  \n    m[\"one\"] = 1  // error: panic: assignment to entry in nil map  \n    // m := make (map[string]int)// map 的正确声明，分配了实际的内存  \n}      \n  \n// slice 正确示例  \nfunc main () {  \n var s []int  \n s = append (s, 1)  \n}\n```\n\n如果先使用 `make()`,那么可以使用 `m[\"one\"]=1`,因为分配了内存。\n\n# slice 分配在堆上还是栈上\n\n**有可能分配到栈上，也有可能分配到栈上。当开辟切片空间较大时，会逃逸到堆上**。\n\n通过命令 `go build -gcflags \"-m -l\" xxx.go` 观察 golang 是如何进行逃逸分析的\n\n```\n// map 错误示例\nfunc main() {\n    var m map[string]int\n    m[\"one\"] = 1  // error: panic: assignment to entry in nil map\n    // m := make(map[string]int)// map 的正确声明，分配了实际的内存\n}    \n\n// slice 正确示例\nfunc main() {\n var s []int\n s = append(s, 1)\n}\n```\n\n\n# Go 中如果 new 一个切片会怎么样\n\n\n**new ([]int) 之后的 list 是⼀个未设置⻓度的  * []int 类型的指针不能对未设置⻓度的指针执⾏ append 操作。**\n\n![image-20230724165822059](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticimage-20230724165822059.png)\n\n```\npackage main\n\nimport \"fmt\"\n\nfunc main() {\n\tlist := new([]int)\n\t// 编译错误\n\t// new([]int) 之后的 list 是⼀个未设置⻓度的 *[]int 类型的指针\n\t// 不能对未设置⻓度的指针执⾏ append 操作。\n\t*list = append(*list, 1)\n\tfmt.Println(*list)\n\ts1 := []int{1, 2, 3}\n\ts2 := []int{4, 5}\n\t// 编译错误，s2需要展开\n\ts1 = append(s1, s2...)\n\tfmt.Println(s1)\n}//正确写法\n```\n\n# 整型切片如何初始化？\n\n```\n//数组初始化\narr1 := [3]int{1, 2, 3}\narr2 := [...]int{1, 2, 3}\narr3 := [3]int{0:3,1:4}\n```\n\n# 数组怎么转集合 ?\n\n可以使用数组的索引作为 map 的 key，数组的值作为 map 的值。\n\n\n```\n//数组初始化\narr1 := [3]int{1, 2, 3}\narr2 := [...]int{1, 2, 3}\narr3 := [3]int{0:3,1:4}\n```\n\n# 数组是如何实现根据下标随机访问数组元素的吗？\n\n例如： a := [10]int{0}\n\n- 计算机给数组 a，分配了一组连续的内存空间。\n- 比如内存块的首地址为 base_address=1000。\n- 当计算给每个内存单元分配一个地址，计算机通过地址来访问数据。当计算机需要访问数组的某个元素的时候，会通过一个寻址公式来计算存储的内存地址。\n\n# 一个函数传参一个 slice，先 append 再赋值和另一个函数先赋值再 append，哪个会发生变化？\n\n\n```\npackage main\n\nimport \"fmt\"\n\nfunc BeforeAppend(s []int) []int {\n\ts = append(s, 1)\n\ts = []int{1, 2, 3}\n\treturn s\n}\n\nfunc AfterAppend(s []int) []int {\n\ts = []int{1, 2, 3}\n\ts = append(s, 1)\n\treturn s\n}\n\nfunc main() {\n\ts := make([]int, 0)\n\tfmt.Println(BeforeAppend(s))\n\tfmt.Println(AfterAppend(s))\n}\n```\n\n\n","lastmodified":"2024-03-02T12:01:53.846210423Z","tags":["GO/八股文"]},"/GO/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B9%B6%E5%8F%91%E5%8E%9F%E8%AF%AD/%E9%98%9F%E5%88%97%E6%A0%85%E6%A0%8F%E5%92%8CSTM":{"title":"队列、栅栏和STM","content":"","lastmodified":"2024-03-02T12:01:53.85021041Z","tags":[]},"/GO/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B9%B6%E5%8F%91%E5%8E%9F%E8%AF%AD/Leader%E9%80%89%E4%B8%BE%E4%BA%92%E6%96%A5%E9%94%81%E5%92%8C%E8%AF%BB%E5%86%99%E9%94%81":{"title":"Leader选举互斥锁和读写锁","content":"","lastmodified":"2024-03-02T12:01:53.85021041Z","tags":[]},"/GO/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C/atomic":{"title":"atomic","content":"","lastmodified":"2024-03-02T12:01:53.85021041Z","tags":[]},"/GO/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E5%9F%BA%E7%A1%80%E5%B9%B6%E5%8F%91%E5%8E%9F%E8%AF%AD/Cond":{"title":"Cond","content":"","lastmodified":"2024-03-02T12:01:53.85021041Z","tags":[]},"/GO/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E5%9F%BA%E7%A1%80%E5%B9%B6%E5%8F%91%E5%8E%9F%E8%AF%AD/Context":{"title":"Context","content":"","lastmodified":"2024-03-02T12:01:53.85021041Z","tags":[]},"/GO/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E5%9F%BA%E7%A1%80%E5%B9%B6%E5%8F%91%E5%8E%9F%E8%AF%AD/Mutex":{"title":"Mutex","content":"","lastmodified":"2024-03-02T12:01:53.85021041Z","tags":[]},"/GO/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E5%9F%BA%E7%A1%80%E5%B9%B6%E5%8F%91%E5%8E%9F%E8%AF%AD/Once":{"title":"Once","content":"","lastmodified":"2024-03-02T12:01:53.85021041Z","tags":[]},"/GO/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E5%9F%BA%E7%A1%80%E5%B9%B6%E5%8F%91%E5%8E%9F%E8%AF%AD/Pool":{"title":"Pool","content":"","lastmodified":"2024-03-02T12:01:53.85021041Z","tags":[]},"/GO/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E5%9F%BA%E7%A1%80%E5%B9%B6%E5%8F%91%E5%8E%9F%E8%AF%AD/RWMutex":{"title":"RWMutex","content":"","lastmodified":"2024-03-02T12:01:53.85021041Z","tags":[]},"/GO/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E5%9F%BA%E7%A1%80%E5%B9%B6%E5%8F%91%E5%8E%9F%E8%AF%AD/WaitGroup":{"title":"WaitGroup","content":"","lastmodified":"2024-03-02T12:01:53.85021041Z","tags":[]},"/GO/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E5%9F%BA%E7%A1%80%E5%B9%B6%E5%8F%91%E5%8E%9F%E8%AF%AD/map":{"title":"map","content":"","lastmodified":"2024-03-02T12:01:53.85021041Z","tags":[]},"/GO/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E5%BC%80%E7%AF%87%E8%AF%8D":{"title":"开篇词","content":"\n参考 https://time.geekbang.org/column/article/294849\n\n# 为啥选择 Go\n\n* Go 的简单高效\n* 并发编程的便利性\n* GO 生态圈微服务框架的发展\n\n# 学习 Go 并发编程的困难\n\n* 无从下手\n* 最优解选择困难\n* 并发任务编排困难\n* 程序 panic 或者死锁排查困难\n* 负责并发问题处理困难 \n\n#  提升 GO 并发编程能力\n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240107213310.png)\n## 知识主线\n* 基础并发原语\n\t* [Mutex](GO/并发编程/基础并发原语/Mutex.md) \n\t* [RWMutex](GO/并发编程/基础并发原语/RWMutex.md) \n\t* [WaitGroup](GO/并发编程/基础并发原语/WaitGroup.md) \n\t* [Cond](GO/并发编程/基础并发原语/Cond.md) \n\t* [Once](GO/并发编程/基础并发原语/Once.md) \n\t* [map](GO/并发编程/基础并发原语/map.md) \n\t* [Pool](GO/并发编程/基础并发原语/Pool.md) \n\t* [Context](GO/并发编程/基础并发原语/Context.md) \n* 原子操作 \n\t* [atomic](GO/并发编程/原子操作/atomic.md) \n* Channel \n\t* [channel](GO/并发编程/Channel/channel.md) \n* 扩展并发原语\n\t* [Semaphore-信号量](GO/并发编程/扩展并发原语/Semaphore-信号量.md) \n\t* [SingleFlight 和 CyclicBarrier-请求合并和循环栅栏](GO/并发编程/扩展并发原语/SingleFlight%20和%20CyclicBarrier-请求合并和循环栅栏.md) \n* 分布式并发原语\n\t* [Leader选举互斥锁和读写锁](GO/并发编程/分布式并发原语/Leader选举互斥锁和读写锁.md) \n\t* [队列、栅栏和STM](GO/并发编程/分布式并发原语/队列、栅栏和STM.md) \n\n## 学习主线\n\n* 基础用法 \n\t* Go 中有一个大的方向，就是任务编排用 Channel，共享资源保护用传统并发原语。\n* 实现原理 \n* 易错场景 \n* 知名项目中的 bug \n\n## 掌握武器 \n\n* 建立丰富的并发原语库\n* 熟系每一种并发原语的实现机制和适用场景\n* 创造自己需要的并发原语","lastmodified":"2024-03-02T12:01:53.85021041Z","tags":[]},"/GO/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E6%89%A9%E5%B1%95%E5%B9%B6%E5%8F%91%E5%8E%9F%E8%AF%AD/%E5%88%86%E7%BB%84%E6%93%8D%E4%BD%9C":{"title":"分组操作","content":"","lastmodified":"2024-03-02T12:01:53.85021041Z","tags":[]},"/GO/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E6%89%A9%E5%B1%95%E5%B9%B6%E5%8F%91%E5%8E%9F%E8%AF%AD/Semaphore-%E4%BF%A1%E5%8F%B7%E9%87%8F":{"title":"Semaphore-信号量","content":"","lastmodified":"2024-03-02T12:01:53.85021041Z","tags":[]},"/GO/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E6%89%A9%E5%B1%95%E5%B9%B6%E5%8F%91%E5%8E%9F%E8%AF%AD/SingleFlight-%E5%92%8C-CyclicBarrier-%E8%AF%B7%E6%B1%82%E5%90%88%E5%B9%B6%E5%92%8C%E5%BE%AA%E7%8E%AF%E6%A0%85%E6%A0%8F":{"title":"SingleFlight 和 CyclicBarrier-请求合并和循环栅栏","content":"","lastmodified":"2024-03-02T12:01:53.85021041Z","tags":[]},"/GO/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/Channel/channel":{"title":"channel","content":"","lastmodified":"2024-03-02T12:01:53.85021041Z","tags":[]},"/Java/Spring/Spring-cloud/spring-cloud-alibaba":{"title":"spring cloud alibaba","content":"* 官网  [spring cloud alibaba ](https://sca.aliyun.com/zh-cn/)\n* ","lastmodified":"2024-03-02T12:01:53.85021041Z","tags":[]},"/Java/netty/%E4%BC%A0%E8%BE%93%E5%92%8CChannel":{"title":"传输和Channel","content":"在某些时候，你需要支撑比预期多很多的并发连接。如果你随后尝试从阻塞传输切换到非阻塞传输，那么你可能会因为这两种网络 API 的截然不同而遇到问题。\n\n**Netty 为它所有的传输实现提供了一个通用 API，这使得这种转换比你直接使用 JDK 所能够达到的简单得多。**\n\n# 传输方式\n\n- OIO\n    \n- NIO\n    \n- AIO\n    \n\n  \n\n# Channel\n\n传输 API 的核心是 interface Channel，它被用于所有的 I/O 操作\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-670.png)\n\n- 每个 Channel 都将会被分配一个 ChannelPipeline 和 ChannelConfig。\n    \n    - ChannelConfig 包含了该 Channel 的所有配置设置，并且支持热更新。由于特定的传输可能 具有独特的设置，所以它可能会实现一个 ChannelConfig 的子类型。\n        \n- 由于 Channel 是独一无二的，所以为了保证顺序将 Channel 声明为 java.lang.Comparable 的一个子接口\n    \n- ChannelPipeline **持有所有将应用于入站和出站数据以及事件的 ChannelHandler实例**，这些 ChannelHandler 实现了应用程序用于处理状态变化以及数据处理的逻辑\n    \n    - ChannelHandler 的典型用途包括：\n        \n        -  将数据从一种格式转换为另一种格式；\n            \n        -  提供异常的通知；\n            \n        -  提供 Channel 变为活动的或者非活动的通知；\n            \n        -  提供当 Channel 注册到 EventLoop 或者从 EventLoop 注销时的通知；\n            \n        -  提供有关用户自定义事件的通知。\n            \n- 也可以利用 Channel 的其他方法\n    \n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-668.png)\n\nNetty 的 **Channel 实现是线程安全的.**\n\n# NIO\n\n  \n\nNIO 提供了一个所有 I/O 操作的全异步的实现。\n\n选择器背后的基本概念是充当一个注册表，在那里你将可以请求在 Channel 的状态发生变化时得到通知。可能的状态变化有：\n\n-  新的 Channel 已被接受并且就绪；\n    \n-  Channel 连接已经完成；\n    \n-  Channel 有已经就绪的可供读取的数据；\n    \n-  Channel 可用于写数据。\n    \n\n**选择器运行在一个检查状态变化并对其做出相应响应的线程上，在应用程序对状态的改变做出响应之后，选择器将会被重置**，并将重复这个过程\n\n的常量值代表了由class java.nio.channels.SelectionKey定义的位模式。这些位模式可以组合起来定义一组应用程序正在请求通知的状态变化集。\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-669.png)\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-667.png)\n\n# 零拷贝\n\n零拷贝（zero-copy）是一种目前只有在使用 NIO 和 Epoll 传输时才可使用的特性**。它使你可以快速 高效地将数据从文件系统移动到网络接口，而不需要将其从内核空间复制到用户空间，**其在像 FTP 或者 HTTP 这样的协议中可以显著地提升性能。但是，并不是所有的操作系统都支持这一特性。特别地，它对于实现了数据加密或者压缩的文件系统是不可用的——只能传输文件的原始内容。","lastmodified":"2024-03-02T12:01:53.85021041Z","tags":[]},"/Java/netty/%E7%BC%96%E8%A7%A3%E7%A0%81%E5%99%A8":{"title":"编解码器","content":"每个网络应用程序都必须定义如何解析在\n\n- **两个节点之间来回传输的原始字节**\n    \n- **其和目标应用程序的数据格式做相互转换**\n    \n\n  \n\n- 编码器是将消息转换为适合于传输的格式（最有可能的就是字节流）；\n    \n- 而对应的解码器则是将网络字节流转换回应用程序的消息格式\n    \n\n  \n\n# 解码器\n\n因为解码器是负责将入站数据从一种格式转换到另一种格式的，所以知道 Netty 的解码器实现了 **ChannelInboundHandler** 也不会让你感到意外。\n\n我们将研究 Netty 所提供的解码器类，并提供关于何时以及如何使用它们的具 体示例。这些类覆盖了两个不同的用例：\n\n- 将字节解码为消息——**ByteToMessageDecoder 和 ReplayingDecoder；**\n    \n- 将一种消息类型解码为另一种——**MessageToMessageDecoder**\n    \n\n  \n\n## ByteToMessageDecoder\n\n将字节解码为消息（或者另一个字节序列）是一项如此常见的任务，以至于 Netty 为它提供了一个抽象的基类：ByteToMessageDecoder\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-750.png)\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-745.png)\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-748.png)\n\n虽然 ByteToMessageDecoder 使得可以很简单地实现这种模式，但是你可能会发现，**在调用 readInt()方法前不得不验证所输入的 ByteBuf 是否具有足够的数据有点繁琐**。在下一节中，\n\n我们将讨论 ReplayingDecoder，它是一个特殊的解码器，以少量的开销消除了这个步骤\n\n  \n\n## ReplayingDecoder\n\nReplayingDecoder扩展了ByteToMessageDecoder类（如代码清单 10-1 所示），使得我们不必调用 readableBytes()方法，它通过使用一个自定义的ByteBuf实现 ，\n\nReplayingDecoderByteBuf，包装传入的ByteBuf实现了这一点，其将在内部执行该调用\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-750.png)\n\n- ByteBuf中提取的int将会被添加到List中。**如果没有足够的字节可用，这个readInt()方法的实现将会抛出一个Error**\n    \n- 并不是所有的 ByteBuf 操作都被支持，如果调用了一个不被支持的方法，将会抛出一个 UnsupportedOperationException；\n    \n- ReplayingDecoder 稍慢于 ByteToMessageDecoder。\n    \n\n  \n\n## MessageToMessageDecoder\n\n```Go\npublic abstract class MessageToMessageDecoder\u003cI\u003e extends ChannelInboundHandlerAdapter\n```\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-750.png)\n\n  \n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-745.png)\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-745.png)\n\n## TooLongFrameException 类\n\n由于 Netty 是一个异步框架，所以需要在字节可以解码之前在内存中缓冲它们。因此，不能让解码器缓冲大量的数据以至于耗尽可用的内存.Netty 提供了TooLongFrameException 类，其将由解码器在帧超出指定的大小限制时抛出。\n\nByteToMessageDecoder 是如何使用 TooLongFrameException 来通知 ChannelPipeline 中的其他 ChannelHandler 发生了帧大小溢出的。\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-745.png)\n\n  \n\n# 编码器\n\n编码器实现了 ChannelOutboundHandler，并将出站数据从一种格式转换为另一种格式，\n\n-  将消息编码为字节；\n    \n-  将消息编码为消息 ①\n    \n\n我们将首先从抽象基类 MessageToByteEncoder 开始来对这些类进行考察。\n\n## MessageToByteEncoder\n\n使 用 MessageToByteEncoder 将消息转化为字节\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-744.png)\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-745.png)\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-743.png)\n\n## MessageToMessageEncoder\n\n数据将如何从一种消息编码为另一种\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-745.png)\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-745.png)\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-726.png)\n\n  \n\n  \n\n# 抽象的编解码\n\n们一直将解码器和编码器作为单独的实体讨论，但是你有时将会发现在同一个类中管理入站和出站数据和消息的转换是很有用的。\n\n这些类同时实现了 ChannelInboundHandler 和 ChannelOutboundHandler 接口。\n\n  \n\n## ByteToMessageCodec\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-728.png)\n\n## MessageToMessageCodec\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-727.png)\n\n## CombinedChannelDuplexHandler\n\n结合一个解码器和编码器可能会对可重用性造成影响。但是，有一 种方法既能够避免这种惩罚，又不会牺牲将一个解码器和一个编码器作为一个单独的单元部署所带来的便利性。CombinedChannelDuplexHandler 提供了这个解决方案\n\n```Go\npublic class CombinedChannelDuplexHandler \u003cI extends ChannelInboundHandler, O extends ChannelOutboundHandler\u003e\n```\n\n这个类充当了 ChannelInboundHandler 和 ChannelOutboundHandler（该类的类型 参数 I 和 O）的容器。\n\n通过提供分别继承了解码器类和编码器类的类型，我们可以实现一个编解码器，**而又不必直接扩展抽象的编解码器类**\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-745.png)\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-745.png)\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-745.png)","lastmodified":"2024-03-02T12:01:53.85021041Z","tags":[]},"/Java/netty/1.-%E6%A6%82%E5%BF%B5%E5%92%8C%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84":{"title":"1. 概念和体系结构","content":"# IO 模型\n\n[IO模型详解](https://jovbd87bon.feishu.cn/wiki/wikcnlmBPltNAH5jI0rrD6bpNWf)\n\n  \n\n  \n\n# Java 网络编程\n\n最早期的 Java API（java.net）只支持由本地系统套接字库提供的所谓的阻塞函数\n\n```Java\n//  创建一个新的 ServerSocket，用以 监听指定端口上的连接请求\nServerSocket serverSocket = new ServerSocket(portNumber); \n// 对accept 阻塞，知道创建一个\nSocket clientSocket = serverSocket.accept(); \nBufferedReader in = new BufferedReader(new InputStreamReader(clientSocket.getInputStream())); \nPrintWriter out = new PrintWriter(clientSocket.getOutputStream(), true); \nString request, response; \nwhile ((request = in.readLine()) != null) { \n    if (\"Done\".equals(request)) { \n        break; \n    } \n    response = processRequest(request); \n    out.println(response); \n} \n```\n\n  \n\n# Java Nio\n\n本地套接字库很早就提供了非阻塞调用， 其为网络资源的利用率提供了相当多的控制：\n\n- 可以使用 setsockopt()方法配置套接字，以便读/写调用在没有数据的时候立即返回， 也就是说，如果是一个阻塞调用应该已经被阻塞了① ；\n    \n- 可以使用操作系统的事件通知 API②注册一组非阻塞套接字，以确定它们中是否有任何的套接字已经有数据可供读写。\n    \n\nJava 对于非阻塞 I/O 的支持是在 2002 年引入的，位于 JDK 1.4 的 java.nio 包中\n\n  \n\n## 选择器\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-657.png)\n\nclass java.nio.channels.Selector 是 Java 的非阻塞 I/O 实现的关键。它使用了事件通知 API\n\n以确定在一组非阻塞套接字中有哪些已经就绪能够进 行 I/O 相关的操作。**因为可以在任何的时间检查任意**\n\n**的读操作或者写操作的完成状态，一个单一的线程便可以处理多个并发的连接。**\n\n与阻塞 I/O 模型相比，这种模型提供了更好的资源管理：\n\n- 使用较少的线程便可以处理许多连接，因此也减少了内存管理和上下文切换所带来开销；\n    \n- 当没有 I/O 操作需要处理的时候，线程也可以被用于其他任务。\n    \n\n  \n\n# Netty\n\n在网络编程领域，Netty是Java的卓越框架。 它驾驭了Java高级API的能力，并将其隐藏在一个易于使用的API之后。\n\nNetty 的关键特性\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-665.png)\n\n## Netty 的主要构件块\n\n- Channel；\n    \n- 回调；\n    \n- Future；\n    \n- 事件和 ChannelHandler。\n    \n\n这些构建块代表了不同类型的构造：资源、逻辑以及通知\n\n  \n\n### Channel\n\nChannel 是 Java NIO 的一个基本构造。\n\n\u003e 它代表一个到实体（如一个硬件设备、一个文件、一个网络套接字或者一个能够执行一个或者多个不同的I/O操作的程序组件）的开放连接，如读操作和写操作 ①\n\n**把 Channel 看作是传入（入站）或者传出（出站）数据的载体。因此，它可以被打开或者被关闭，连接或者断开连接。**\n\n### 回调\n\n一个回调其实就是一个方法，**一个指向已经被提供给另外一个方法的方法的引用**。\n\nNetty 在内部使用了回调来处理事件；当一个回调被触发时，相关的事件可以被一个 interface ChannelHandler 的实现处理。\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-663.png)\n\n当一个新的连接已经被建立时，ChannelHandler 的 channelActive()回调方法将会被调用，并将打印出一条信息。\n\n  \n\n### Future\n\nFuture 提供了另一种在操作完成时通知应用程序的方式。这个对象可以看作是一个异步操作的结果的占位符；它将在未来的某个时刻完成，并提供对其结果的访问\n\n- JDK 预置了 interface java.util.concurrent.Future，但是其所提供的实现，只 允许手动检查对应的操作是否已经完成，或者一直阻塞直到它完成。这是非常繁琐的，\n    \n- 所以 Netty 提供了它自己的实现——ChannelFuture，用于在执行异步操作的时候使用\n    \n\n  \n\n- ChannelFuture提供了几种额外的方法，这些方法使得我们能够注册一个或者多个 ChannelFutureListener实例。监听器的回调方法operationComplete()，将会在对应的操作完成时被调用\n    \n- 每个 Netty 的出站 I/O 操作都将返回一个 ChannelFuture；也就是说，它们都不会阻塞。正如我们前面所提到过的一样，Netty 完全是异步和事件驱动的\n    \n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-656.png)\n\n  \n\nChannel 回调的用法\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-662.png)\n\n### 事件和ChannelHandler\n\nNetty 使用不同的事件来通知我们状态的改变或者是操作的状态。这使得我们能够基于已经 =发生的事件来触发适当的动作。\n\nNetty 是一个网络编程框架，所以事件是按照它们与入站或出站数据流的相关性进行分类的。\n\n  \n\n可能由**入站**数据或者相关的状态更改而触发的事件包括：\n\n-  连接已被激活或者连接失活；\n    \n-  数据读取；\n    \n-  用户事件；\n    \n-  错误事件。\n    \n\n**出站事件**是未来将会触发的某个动作的操作结果，这些动作包括：\n\n-  打开或者关闭到远程节点的连接；\n    \n-  将数据写到或者冲刷到套接字。\n    \n\n每个事件都可以被分发给 ChannelHandler 类中的某个用户实现的方法。这是一个很好的将事件驱动范式直接转换为应用程序构件块的例子。\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-664.png)\n\n  \n\n## Netty 的组件和设计\n\n- 首先，它的基于 Java NIO 的异步的和事件驱动的实现，保证了高负载下应用程序 性能的最大化和可伸缩性。\n    \n- 其次，Netty 也包含了一组设计模式，将应用程序逻辑从网络层解耦，简化了开发过程，同时也最大限度地提高了可测试性、模块化以及代码的可重用性。\n    \n\n### Channel\n\nNetty 的 Channel 接 口所提供的 API，大大地降低了直接使用 Socket 类的复杂性。其基本的构造是 class Socket。\n\nChannel 也是拥有许多 预定义的、专门化实现的广泛类层次结构的根，下面是一个简短的部分清单：\n\n- EmbeddedChannel；\n    \n- LocalServerChannel；\n    \n- NioDatagramChannel；\n    \n- NioSctpChannel；\n    \n- NioSocketChannel。\n    \n\n### EventLoop\n\nEventLoop 定义了 Netty 的核心抽象，用于处理连接的生命周期中所发生的事件\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-659.png)\n\nChannel、EventLoop、Thread 以及 EventLoopGroup 之间的关系\n\n- 一个 EventLoopGroup 包含一个或者多个 EventLoop；\n    \n- 一个 EventLoop 在它的生命周期内只和一个 Thread 绑定；\n    \n- 所有由 EventLoop 处理的 I/O 事件都将在它专有的 Thread 上被处理；\n    \n- 一个 Channel 在它的生命周期内只注册于一个 EventLoop；\n    \n- 一个 EventLoop 可能会被分配给一个或多个 Channel。\n    \n\n### ChannelFuture\n\n- Netty 中所有的 I/O 操作都是异步的。因为一个操作可能不会立即返回，所以我们需要一种用于在之后的某个时间点确定其结果的方法。\n    \n- Netty 提供了 ChannelFuture 接口，其 addListener()方法注册了一个 ChannelFutureListener，以便在某个操作完成时（无论是否成功）得到通知。\n    \n\n### ChannelHandler\n\n- 从应用程序开发人员的角度来看，Netty 的主要组件是 ChannelHandler，它充当了所有处理入站和出站数据的应用程序逻辑的容器\n    \n- 事实上，ChannelHandler 可专 门用于几乎任何类型的动作，例如将数据从一种格式转换为另外一种格式，或者处理转换过程中所抛出的异常。\n    \n\n### ChannaelPipeline\n\n- ChannelPipeline 提供了 ChannelHandler 链的容器，并**定义了用于在该链上传播入站和出站事件**流的 API\n    \n- 当 Channel 被创建时，它会被自动地分配到它专属的 ChannelPipeline。\n    \n- ChannelHandler 安装到 ChannelPipeline 中的过程如下所示\n    \n    - 一个ChannelInitializer的实现被注册到了ServerBootstrap中 ① ；\n        \n    - 当 ChannelInitializer.initChannel()方法被调用时，ChannelInitializer将在 ChannelPipeline 中安装一组自定义的 ChannelHandler；\n        \n    - ChannelInitializer **将它自己从 ChannelPipeline 中移除**。\n        \n\n  \n\n从 ChannelHandler 派生的 ChannelInboundHandler 和 ChannelOutboundHandler 接口\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-661.png)\n\n  \n\n- 上面的接口使得事件流经 ChannelPipeline 是 ChannelHandler 的工作，它们是在应用程序的**初始化或者引导阶段被安装的**。\n    \n- 这些对象接收事件、执行它们所实现的处理逻辑，并将数据传递给链中的下一个 ChannelHandler。\n    \n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-658.png)\n\n- 它们的执行顺序是由它们被添加的顺序所决定的。实际上，被我们称为 ChannelPipeline 的是这些 ChannelHandler 的编排顺序\n    \n- 虽然 ChannelInboundHandle 和 ChannelOutboundHandle 都扩展自 ChannelHandler，但是 Netty 能区分 ChannelInboundHandler 实现和 ChannelOutboundHandler 实现，并确保数据只会在具有相同定向类型的两个 ChannelHandler 之间传递。\n    \n- 在 Netty 中，有**两种发送消息的方式。**\n    \n    - 你可以**直接写到 Channel** 中，会导致消息**从Channe-lPipeline 的尾端开始流动**\n        \n    - 也可以写到和 ChannelHandler相关联的**ChannelHandlerContext对象**中将导致消息从 **ChannelPipeline 中的下一个 ChannelHandler 开始流动。**\n        \n\n  \n\n#### 适配器\n\nNetty 以适配器类的形式提供了大量默认的 ChannelHandler 实现，\n\n- 其旨在简化应用程序处理逻辑的开发过程。\n    \n- 你已经看到了，ChannelPipeline中的每个ChannelHandler 将负责把事件转发到链中的下一个 ChannelHandler。这些适配器类（及它们的子类）将自动 执行这个操作，所以你可以只重写那些你想要特殊处理的方法和事件。\n    \n- 常用的适配器\n    \n    -  ChannelHandlerAdapter\n        \n    -  ChannelInboundHandlerAdapter\n        \n    -  ChannelOutboundHandlerAdapter\n        \n    -  ChannelDuplexHandler\n        \n\n  \n\n#### 编解码器\n\n- 通常来说，这些基类的名称将类似于 ByteToMessageDecoder 或 MessageToByteEncoder。\n    \n- 对于特殊的类型，你可能会发现类似于 ProtobufEncoder 和 ProtobufDecoder 这样的名称——预置的用来支持 Google 的 Protocol Buffers。\n    \n- 严格地说，其他的处理器也可以完成编码器和解码器的功能。但是，正如有用来简化ChannelHandler 的创建的适配器类一样，所有由 Netty 提供的编码器/解码器适配器类都实现 ChannelOutboundHandler 或者 ChannelInboundHandler 接口。\n    \n\n  \n\n#### SimpleChannelInboundHandler\n\n- 最常见的情况是，你的应用程序会利用一个 ChannelHandler 来接收解码消息，并对该数据应用业务逻辑。\n    \n- 要创建一个这样的 ChannelHandler,你只需要扩展基类 `SimpleChannelInboundHandler\u003cT\u003e`，其中 T 是你要处理的消息的 Java 类型 。\n    \n    - 在这种类型的 ChannelHandler 中，最重要的方法是 channelRead0(ChannelHandlerContext,T)**。除了要求不要阻塞当前的 I/O 线程之外**，其具体实现完全取决于你\n        \n\n### BootStrap\n\nNetty 的引导类为应用程序的网络层配置提供了容器，\n\n- 这涉及将一个进程绑定到某个指定的端口，ServerBootStrap\n    \n- 或者将一个进程连接到另一个运行在某个指定主机的指定端口上的进程,BootStrap\n    \n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-660.png)\n\n引导一个客户端只需要一个 EventLoopGroup，但是一个ServerBootstrap 则需要两个（也可以是同一个实例）。为什么呢？\n\n因为服务器需要两组不同的 Channel。\n\n- 第一组将只包含一个 ServerChannel，代表服务器自身的已绑定到某个本地端口的正在监听的套接字。\n    \n- 而第二组将包含所有已创建的用来处理传 入客户端连接（**对于每个服务器已经接受的连接都有一个**）的 Channel。\n    \n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-666.png)","lastmodified":"2024-03-02T12:01:53.85021041Z","tags":[]},"/Java/netty/BootStrap":{"title":"BootStrap","content":"\n简单来说，**引导一个应用程序是指对它进行配置，并使它运行起来的过程**—尽管该过程的具体细节可能并不如它的定义那样简单，尤其是对于一个网络应用程序来说\n\n  \n\nNetty处理引导的方式**使你的应用程序和网络层相隔离**，无论它是客户端还是服务器\n\n  \n\n# BootStrap类\n\n引导类的层次结构包括一个抽象的父类和两个具体的引导子类\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-699.png)\n\n相对于将具体的引导类分别看作用于服务器和客户端的引导来说，记住它们的本意是用来支撑不同的应用程序的功能的将有所裨益。\n\n- 服务器致力于使用一个父 Channel 来接受来自客户端的连接，并创建子 Channel 以用于它们之间的通信\n    \n- 而客户端将最可能只需要一个单独的、没有父 Channel 的 Channel 来用于所有的网络交互\n    \n\n  \n\n两种应用程序类型之间通用的引导步骤由 AbstractBootstrap 处理，而特定于客户端或者服务器的引导步骤则分别由 Bootstrap 或 ServerBootstrap 处理\n\n  \n\nAbstractBootstrap 类的完整声明是：\n\n```Go\npublic abstract class AbstractBootstrap \u003cB extends AbstractBootstrap\u003cB,C\u003e,C extends Channel\u003e\n```\n\n在这个签名中，子类型 B 是其父类型的一个类型参数，**因此可以返回到运行时实例的引用以支持方法的链式调用**\n\n其子类的声明如下：\n\n```Go\npublic class Bootstrap extends AbstractBootstrap\u003cBootstrap,Channel\u003e\n\npublic class ServerBootstrap extends AbstractBootstrap\u003cServerBootstrap,ServerChannel\u003e\n```\n\n  \n\n# 引导客户端和无连接协议\n\n**Bootstrap 类被用于客户端或者使用了无连接协议的应用程序中**\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-732.png)\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-708.png)\n\n## BootStrap\n\nBootstrap 类负责为客户端和使用无连接协议的应用程序创建 Channel\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-709.png)\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-734.png)\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-703.png)\n\n## Channel 和 EventLoopGroup 的兼容性\n\n你可以从包名以及与其相对应 的类名的前缀看到，对于 NIO 以及 OIO 传输两者来说，都有相关的 EventLoopGroup 和Channel 实现。\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-733.png)\n\n不能混用具有不同前缀的组件，如 NioEventLoopGroup 和 OioSocketChannel，会导致 IllegalStateException，\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-710.png)\n\n# 引导服务端\n\n  \n\n## ServerBootStrap\n\n  \n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-702.png)\n\n列出了一些bootStrap不存在的方法：childHandler()、 childAttr()和 childOption()。这些调用支持特别用于服务器应用程序的操作。具体来说， **ServerChannel 的实现负责创建子 Channel，这些子 Channel 代表了已被接受的连接。**负责引导 ServerChannel 的 ServerBootstrap 提供了这些方法，以简化将设置应用到已被接受的子 Channel 的 ChannelConfig 的任务\n\n- ServerBootstrap 在 bind()方法被调用时创建了一个 ServerChannel， 且该 ServerChannel 管理了多个子 Channel。\n    \n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-704.png)\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-700.png)\n\n  \n\n# 从Channel引导客户端\n\n我们都在引导的过程中调用了 handler()或者 childHandler()方法来添加单个的 ChannelHandler。\n\n通过在 ChannelPipeline 中将它们链接在一起来部署尽可能多的 ChannelHandler。\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-707.png)\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-706.png)\n\n  \n\n# 使用Netty的ChannelOption属性\n\n可以使用 option()方法来将 ChannelOption 应用到引\n\n在某些常用的属性和数据不可用时，Netty 提供了 AttributeMap 抽象（一个由 Channel 和引导类提供的集合）以及 `AttributeKey\u003cT\u003e`（一 个用于插入和获取属性值的泛型类）。\n\n使用这些工具，便可以安全地将任何类型的数据项与客户端和服务器 Channel（包含 ServerChannel 的子 Channel）相关联了。\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-705.png)\n\n# 引导DataGramChannel\n\nNetty 提供了各种 DatagramChannel 的实现。唯一区别就是，**不再调用 connect()方法，而是只调用 bind()方法**\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-701.png)\n\n# 关闭\n\n- 引导使你的应用程序启动并且运行起来，但是迟早你都需要优雅地将它关闭\n    \n- 最重要的是，你需要关闭 EventLoopGroup，它将处理任何挂起的事件和任务，并且随后释放所有活动的线程。\n    \n- 这就是调用 EventLoopGroup.shutdownGracefully()方法的作用。\n    \n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-729.png)","lastmodified":"2024-03-02T12:01:53.85021041Z","tags":[]},"/Java/netty/ByteBuf":{"title":"ByteBuf","content":"网络数据的基本单位总是字节。Java NIO 提供了 ByteBuffer 作为它的字节容器，但是这个类使用起来过于复杂，而且也有些繁琐。\n\nNetty 的 ByteBuffer 替代品是 ByteBuf，一个强大的实现，既解决了 JDK API 的局限性，又为网络应用程序的开发者提供了更好的 API。\n\n# ByteBuf 的优点\n\nNetty 的数据处理 API 通过两个组件暴露——abstract class ByteBuf 和 interface ByteBufHolder。\n\n下面是一些 ByteBuf API 的优点：\n\n 它可以被用户自定义的缓冲区类型扩展；\n\n 通过内置的复合缓冲区类型实现了透明的零拷贝；\n\n 容量可以按需增长（类似于 JDK 的 StringBuilder）；\n\n 在读和写这两种模式之间切换不需要调用 ByteBuffer 的 flip()方法；\n\n 读和写使用了不同的索引；\n\n 支持方法的链式调用；\n\n# ByteBuf 如何工作\n\n**ByteBuf 维护了两个不同的索引：一个用于读取，一个用于写入**。当你从 ByteBuf 读取时， 它的 readerIndex 将会被递增已经被读取的字节数。同样地，当你写入 ByteBuf 时，它的 writerIndex 也会被递增。\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-671.png)\n\nreaderIndex 达到 和 writerIndex 同样的值时, 试图读取超出该点的数据将会触发一个 IndexOutOfBoundsException。\n\n  \n\n# ByteBuf 的使用模式\n\n## 堆缓冲区\n\n最常用的 ByteBuf 模式是将数据存储在 **JVM 的堆空间**中，这种模式被称为**支撑数组** （backing array），它能在**没有使用池化的情况下提供快速的分配和释放**\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-673.png)\n\n## 直接缓冲区\n\nNIO 在 JDK 1.4 中引入的 ByteBuffer 类允许 JVM 实现通过本地调 用来分配内存。这主要是为了避**免在每次调用本地 I/O 操作之前（或者之后）将缓冲区的内容复 制到一个中间缓冲区（或者从中间缓冲区把内容复制到缓冲区）。**\n\n直接缓冲区的主要缺点是，相对于基于堆的缓冲区，**它们的分配和释放都较为昂贵。**\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-679.png)\n\n## 符合缓冲区\n\n它为**多个 ByteBuf 提供一个聚合视图。**在这里你可以根据需要添加或者删除 ByteBuf 实例，这是一个 JDK 的 ByteBuffer 实现完全缺失的特性。\n\nNetty 通过一个 ByteBuf 子类——**CompositeByteBuf——实现了这个模式**，它提供了一个将多个**缓冲区表示为单个合并缓冲区的虚拟表示**。\n\n为了举例说明，让我们考虑一下一个由两部分——头部和主体——组成的将通过 HTTP 协议 传输的消息。**这两部分由应用程序的不同模块产生，将会在消息被发送的时候组装**。该应用程序 可以选择为多个消息重用相同的消息主体。当这种情况发生时，对于每个消息都将会创建一个新的头部。\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-683.png)\n\n- 使用ByteBuffer 的符合缓冲区模式\n    \n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-684.png)\n\n- 使用 **CompositeByteBuf** 的复合缓冲区模式\n    \n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-684.png)\n\n- 访问 **CompositeByteBuf** 中的数据\n    \n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-687.png)\n\n  \n\n# 字节级操作\n\n## 随机访问索引\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-672.png)\n\n那些需要一个索引值参数的方法（的其中）之一来访问数据既不会改变readerIndex 也不会改变 writerIndex。\n\n  \n\n## 顺序访问索引\n\n虽然 ByteBuf 同时具有读索引和写索引，\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-677.png)\n\n## 可丢弃字节\n\n记为可丢弃字节的分段包含了已经被读过的字节。通过调用 discardReadBytes()方法，可以丢弃它们并回收空间\n\n  \n\n## 可读字节\n\nByteBuf 的可读字节分段存储了实际数据。新分配的、包装的或者复制的缓冲区的默认的\n\nreaderIndex 值为 0。任何名称以 read 或者 skip 开头的操作都将检索或者跳过位于当前\n\nreaderIndex 的数据，并且将它增加已读字节数。\n\n  \n\n## 可写字节\n\n可写字节分段是指一个拥有未定义内容的、写入就绪的内存区域。新分配的缓冲区的 writerIndex 的默认值为 0。任何名称以 write 开头的操作都将从当前的 writerIndex 处 开始写数据，并将它增加已经写入的字节数。如果写操作的目标也是 ByteBuf，并且没有指定源索引的值，则源缓冲区的 readerIndex 也同样会被增加相同的大小。这个调用如下所示：\n\nwriteBytes(ByteBuf dest);\n\n  \n\n## 读写操作\n\n正如我们所提到过的，有两种类别的读/写操作：\n\n get()和 set()操作，从给定的索引开始，并且保持索引不变；\n\n read()和 write()操作，从给定的索引开始，并且会根据已经访问过的字节数对索\n\n引进行调整\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-685.png)\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-675.png)\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-680.png)\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-686.png)\n\n## 其他操作\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-674.png)\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-681.png)\n\n  \n\n# ByteBufHolder\n\n- 除了实际的数据负载之外，我们还需要**存储各种属性值**。 为了处理这种常见的用例，Netty 提供了 ByteBufHolder\n    \n- ByteBufHolder 也为 Netty 的 高级特性提供了支持，如缓冲区池化，其中可以从池中借用 ByteBuf，并且在需要时自动释放\n    \n- ByteBufHolder 只有几种用于访问底层数据和引用计数的方法\n    \n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-676.png)\n\n  \n\n# ByteBuf分配\n\n## 按需分配ByteBufAllocator\n\n，Netty 通过 interface ByteBufAllocator 实现了 （ByteBuf 的）**池化**，它可以用来分配我们所描述过的任意类型的 ByteBuf 实例\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-682.png)\n\n可以通过 Channel（每个都可以有一个不同的 ByteBufAllocator 实例）或者绑定到 ChannelHandler 的 ChannelHandlerContext 获取一个到 ByteBufAllocator 的引用。\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-686.png)\n\nNetty提供了两种ByteBufAllocator的实现：PooledByteBufAllocator和UnpooledByteBufAllocator。\n\n- PooledByteBufAllocator，池化了ByteBuf的实例以提高性能并最大限度地减少内存碎片\n    \n- UnpooledByteBufAllocator，非池化ByteBuf实例，并且在每次它被调用时都会返回一个新的实例\n    \n\n**Netty默认使用了PooledByteBufAllocator**，但这可以很容易地通过ChannelConfig API或者在引导你的应用程序时指定一个不同的分配器来更改\n\n  \n\n## Unpooled 缓冲区\n\n你未能获取一个到 ByteBufAllocator 的引用。对于这种情况，Netty 提供了一个简单的称为 Unpooled 的工具类，它提供了静态的辅助方法来创建未池化的 ByteBuf 实例。\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-678.png)\n\n## ByteBufUtil\n\nByteBufUtil 提供了用于操作 ByteBuf 的静态的辅助方法。因为这个 API 是通用的，并\n\n且和池化无关，所以这些方法已然在分配类的外部实现\n\n  \n\n# 引用计数\n\nNetty 在第 4 版中为 ByteBuf 和 ByteBufHolder 引入了引用计数技术，它们都实现了 interface ReferenceCounted。\n\n它主要涉及跟踪到某个特定对象的活动引用的数量。一个 ReferenceCounted 实现的实例将通常以活动的引用计数为 1 作为开始。\n\n只要引用计数大于 0，就能保证对象不会被释放。当活动引用的数量减少到 0 时，该实例就会被释放\n\n引用计数对于池化实现（如 PooledByteBufAllocator）来说是至关重要的，它降低了内存分配的开销。","lastmodified":"2024-03-02T12:01:53.85021041Z","tags":[]},"/Java/netty/ChannelHandlerChannelPipelineChannelContext":{"title":"ChannelHandler、ChannelPipeline、ChannelContext","content":"当我们在本章中探讨 Netty 的数据流以及处理组件\n\n在 ChannelPipeline 中将 ChannelHandler 链接在一起以组织处理逻辑。我们将会研究涉及这些类的各种用例，以及一个重要的关系—ChannelHandlerContext\n\n  \n\n# ChannelHandler\n\n  \n\n## Channel 的生命周期\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-731.png)\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-731.png)\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-689.png)\n\n  \n\nChannelHandler的生命周期\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-731.png)\n\n  \n\nNetty定义了两个重要的ChannelHandler\n\n-  ChannelInboundHandler——处理入站数据以及各种状态变化；\n    \n-  ChannelOutboundHandler——处理出站数据并且允许拦截所有的操作。\n    \n\n  \n\n## ChannelInBoundHandler接口\n\nChannelInBoundHandler的生命周期方法。这些方法将会在数据被接收时或者与其对应的 Channel 状态发生改变时被调用。\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-721.png)\n\n当某个 ChannelInboundHandler 的实现重写 channelRead()方法时，它将负责显式地释放与池化的 ByteBuf 实例相关的内存。Netty 为此提供了一个实用方法 ReferenceCountUtil.release()\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-711.png)\n\n一个更加简单的方式是使用 SimpleChannelInboundHandler\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-722.png)\n\n由于 SimpleChannelInboundHandler 会自动释放资源，所以你不应该存储指向任何消 息的引用供将来使用\n\n## ChannelOutboundHandler\n\n出站操作和数据将由 ChannelOutboundHandler 处理。它的方法将被 Channel、ChannelPipeline 以及 ChannelHandlerContext 调用。\n\nChannelOutboundHandler 的一个强大的功能**是可以按需推迟操作或者事件**，这使得可以通过一些复杂的方法来处理请求。例如，如果到远程节点的写入被暂停了，那么你可以推迟冲刷操作并在稍后继续\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-714.png)\n\n  \n\n\u003e **ChannelPromise**与**ChannelFuture** ChannelOutboundHandler中的大部分方法都需要一个\n\u003e \n\u003e ChannelPromise参数，以便在操作完成时得到通知。ChannelPromise是ChannelFuture的一个\n\u003e \n\u003e 子类，其定义了一些可写的方法，如setSuccess()和setFailure()，从而使ChannelFuture不\n\u003e \n\u003e 可变\n\n  \n\n## 适配器\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-723.png)\n\n## 资源管理\n\n- 每当通过调用 ChannelInboundHandler.channelRead()或者 ChannelOutboundHandler.write()方法来处理数据时，你都需要确保没有任何的资源泄漏。\n    \n- Netty 使用引用计数来处理池化的 ByteBuf。所以在完全使用完某个ByteBuf 后，**调整其引用计数是很重要的**\n    \n\n  \n\nNetty提供了class ResourceLeakDetector①，它将对你应用程序的缓冲区分配做大约 1%的采样来检测内存泄露\n\nNetty的泄露级别\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-713.png)\n\n消费并释放入站消息\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-737.png)\n\n丢弃并释放出站消息\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-731.png)\n\n  \n\n# ChannelPipeline\n\n\u003e - ChannelPipeline 保存了与 Channel 相关联的 ChannelHandler；\n\u003e     \n\u003e - ChannelPipeline 可以根据需要，通过添加或者删除 ChannelHandler 来动态地修改；\n\u003e     \n\u003e - ChannelPipeline 有着丰富的 API 用以被调用，以响应入站和出站事件。\n\u003e     \n\n  \n\n- 每一个新创建的 Channel 都将会被分配一个新的 ChannelPipeline。这项关联是永久性的；\n    \n- Channel 既不能附加另外一个 ChannelPipeline，也不能分离其当前的\n    \n- 根据事件的起源，事件将会被 ChannelInboundHandler 或者 ChannelOutboundHandler处理，随后，通过调用 ChannelHandlerContext 实现，它将被转发给同一超类型的下一个 ChannelHandler\n    \n\n  \n\n\u003e ChannelHandlerContext使得ChannelHandler能够和它的ChannelPipeline以及其他的ChannelHandler 交互，\n\u003e \n\u003e - ChannelHandler 可以通知其所属的 ChannelPipeline 中的下一 个ChannelHandler，\n\u003e     \n\u003e - 甚至可以动态修改它所属的ChannelPipeline\n\u003e     \n\n  \n\n了一个典型的同时具有入站和出站 ChannelHandler 的 ChannelPipeline 的布 局，并且印证了我们之前的关于 ChannelPipeline 主要由一系列的 ChannelHandler 所组成的说法。\n\n  \n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-718.png)\n\n- ChannelPipeline 还提供了通过 ChannelPipeline 本身传播事件的方法。\n    \n    - 如果一个入站事件被触发，它将被从 ChannelPipeline 的头部开始一直被传播到 Channel Pipeline 的尾端\n        \n    - 一个出站 I/O 事件将从 ChannelPipeline 的最右边开始，然后向左传播。\n        \n- 在 ChannelPipeline 传播事件时，它会测试 ChannelPipeline 中的下一个 ChannelHandler 的类型是否和事件的运动方向相匹配。\n    \n    - 如果不匹配，ChannelPipeline 将跳过该ChannelHandler 并前进到下一个，直到它找到和该事件所期望的方向相匹配的为止。\n        \n\n  \n\n## 修改ChannelPipeline\n\nChannelHandler 可以通过添加、删除或者替换其他的 ChannelHandler 来实时地修改ChannelPipeline 的布局。\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-697.png)\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-749.png)\n\n  \n\n## ChannelHandler 的阻塞和执行\n\n- 通常 ChannelPipeline 中的每一个 ChannelHandler 都是通过它的 EventLoop（I/O 线程）来处 理传递给它的事件的。所以**至关重要的是不要阻塞这个线程**，因为这会对整体的 I/O 处理产生负面的影响。\n    \n- 但有时可能需要与那些使用阻塞 API 的遗留代码进行交互。对于这种情况，ChannelPipeline 有一些接受一个 EventExecutorGroup 的 add()方法。如果一个事件被传递给一个自定义的 EventExecutorGroup，它将被包含在这个 EventExecutorGroup 中的某个 **EventExecutor** 所处理，**从而被从该 Channel 本身的 EventLoop 中移除**。对于这种用例，Netty 提供了一个叫 DefaultEventExecutorGroup 的默认实现。\n    \n\n## 其他获取ChannelHandler的方法\n\n还有别的通过类型或者名称来访问 ChannelHandler 的方法\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-731.png)\n\n## 触发事件\n\n入站操作，用于通知 ChannelInboundHandler 在 ChannelPipeline 中所发生的事件\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-712.png)\n\nChannelPipeline API 的出站操作。\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-719.png)\n\n  \n\n# ChannelHandlerContext\n\n- ChannelHandlerContext 代表了 ChannelHandler 和 ChannelPipeline 之间的关联，每当有 ChannelHandler 添加到 ChannelPipeline 中时，都会创建 ChannelHandlerContext\n    \n- ChannelHandlerContext 的主要功能是管理它所关联的 ChannelHandler 和在 同一个 ChannelPipeline 中的其他 ChannelHandler 之间的交互\n    \n\n  \n\nChannelHandlerContext 有很多的方法，其中一些方法也存在于 Channel 和 ChannelPipeline 本身上，但是有一点重要的不同。\n\n- 如果调用 Channel 或者 ChannelPipeline 上的这些方法，它们将沿着整个 ChannelPipeline 进行传播\n    \n- 而调用位于 ChannelHandlerContext 上的相同方法，则将从当前所关联的 ChannelHandler 开始，并且**只会传播给位于该 ChannelPipeline 中的下一个能够处理该事件的 ChannelHandler**\n    \n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-698.png)\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-731.png)\n\n当使用 ChannelHandlerContext 的 API 的时候，请牢记以下两点：\n\n-  ChannelHandlerContext 和 ChannelHandler 之间的关联（绑定）是永远不会改变的，所以缓存对它的引用是安全的；\n    \n-  如同我们在本节开头所解释的一样，相对于其他类的同名方法，ChannelHandleContext 的方法将产生更短的事件流，应该尽可能地利用这个特性来获得最大的性能\n    \n\n## 使用\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-730.png)\n\n  \n\n### **ChannelHandlerContext** 访问 **Channel**\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-741.png)\n\n### 通过 **ChannelHandlerContext** 访问 **ChannelPipeline**\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-715.png)\n\n- 虽然被调用的 Channel 或 ChannelPipeline 上的 write()方法将**一直传播事件通过整个 ChannelPipeline**，\n    \n- 但是在 ChannelHandler 的级别上，事件从一个 ChannelHandler 到下一个 ChannelHandler 的移动是由ChannelHandlerContext 上的调用完成的\n    \n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-716.png)\n\n### 调用 **ChannelHandlerContext** 的 **write()**方法\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-731.png)\n\n消息将从下一个 ChannelHandler 开始流经 ChannelPipeline，绕过了所有前面的 ChannelHandler\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-736.png)\n\n### 可共享的ChannelHandler\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-738.png)\n\n  \n\n# 异常处理\n\n## 处理入站点异常\n\n- 如果在处理入站事件的过程中有异常被抛出，那么它将从它在 ChannelInboundHandler里被触发的那一点开始流经 ChannelPipeline\n    \n- 要想处理这种类型的入站异常，你需要在你的 ChannelInboundHandler 实现中重写下面的方法\n    \n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-742.png)\n\n- ChannelHandler.exceptionCaught()的默认实现是简单地将当前异常转发给 ChannelPipeline 中的下一个 ChannelHandler；\n    \n- 如果异常到达了 ChannelPipeline 的尾端，它将会被记录为未被处理；\n    \n- 要想定义自定义的处理逻辑，你需要重写 exceptionCaught()方法。然后你需要决定是否需要将该异常传播出去。\n    \n\n  \n\n## 处理出站异常\n\n用于处理出站操作中的正常完成以及异常的选项，都基于以下的通知机制。\n\n- 每个出站操作都将返回一个 ChannelFuture。注册到 ChannelFuture 的 ChannelFutureListener 将在操作完成时被通知该操作是成功了还是出错了\n    \n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-720.png)\n\n- 几乎所有的 ChannelOutboundHandler 上的方法都会传入一个 ChannelPromise 的实例。作为 ChannelFuture 的子类，ChannelPromise 也可以被分配用于异步通知的监听器。但是，ChannelPromise 还具有提供立即通知的可写方法：\n    \n    - ChannelPromise setSuccess();\n        \n    - ChannelPromise setFailure(Throwable cause)\n        \n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-690.png)","lastmodified":"2024-03-02T12:01:53.85021041Z","tags":[]},"/Java/netty/EventLoop-%E5%92%8C%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B":{"title":"EventLoop 和线程模型","content":"# 常见的线程模型\n\n基本的线程池化模式\n\n- 从池的空闲线程列表中选择一个 Thread，并且指派它去运行一个已提交的任务（一个 Runnable 的实现）；\n    \n- 当任务完成时，将该 Thread 返回给该列表，使其可被重用\n    \n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-717.png)\n\n虽然池化和重用线程相对于简单地为每个任务都创建和销毁线程是一种进步，但是它并不能消除由上下文切换所带来的开销\n\n# EventLoop\n\n运行任务来**处理在连接的生命周期内发生的事件是任何网络框架的基本功能**。与之相应的编程上的构造通常被称为**事件循环**—一个 Netty 使用了 interface io.netty.channel.EventLoop 来适配的术语。\n\n  \n\nNetty 的 EventLoop 是协同设计的一部分，它采用了两个基本的 API：并发和网络编程。\n\n- 首先，io.netty.util.concurrent 包构建在 JDK 的 java.util.concurrent 包上，用来提供线程执行器。\n    \n- 其次，io.netty.channel 包中的类，为了与 Channel 的事件进行交互，扩展了这些接口/类\n    \n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-691.png)\n\n线程的关系\n\n- 在这个模型中，一个 EventLoop 将由一个永远都不会改变的 Thread 驱动\n    \n- 同时任务 （Runnable 或者 Callable）可以直接提交给 EventLoop 实现，以立即执行或者调度执行。\n    \n- 根据配置和可用核心的不同，可能会创建多个 EventLoop 实例用以优化资源的使用，\n    \n- 并且单个 EventLoop 可能会被指派用于服务多个 Channel\n    \n- netty的EventLoop在继承了ScheduledExecutorService的同时，只定 义了一个方法，parent(),用于返回到当前EventLoopGroup的引用。\n    \n\n```Go\npublic interface EventLoop extends EventExecutor, EventLoopGroup { \n    @Override \n    EventLoopGroup parent(); \n}\n```\n\n  \n\n## Netty4 中的I/O和事件处理\n\nI/O 操作触发的事件将流经安装了一个或者多个 ChannelHandler 的 ChannelPipeline。**传播这些事件的方法调用可以随后被 ChannelHandler 所拦截，并且可以按需地处理事件**\n\n- 在Netty 4 中，所有的I/O操作和事件都由已经被分配给了EventLoop的那个Thread来处理\n    \n\n不同于 Netty 3 中所使用的模型\n\n  \n\n## Netty3 中的I/O操作\n\n在以前的版本中\n\n- 所使用的线程模型只保证了入站（之前称为上游）事件会在所谓的 I/O 线程（对应于 Netty 4 中的 EventLoop）中执行。\n    \n- 所有的出站（下游）事件都由调用线程处理，其可能是 I/O 线程也可能是别的线程\n    \n\n  \n\n已经被发现**是有问题的**， **因为需要在 ChannelHandler 中对出站事件进行仔细的同步。简而言之，不可能保证多个线程不会在同一时刻尝试访问出站事件**\n\n  \n\nNetty 4 中所采用的线程模型，通过在**同一个线程中处理某个给定的 EventLoop 中所产生的所有事件**，解决了这个问题。这提供了一个更加简单的执行体系架构，并且消除了在多个 ChannelHandler 中进行同步的需要（除了任何可能需要在多个 Channel 中共享的）\n\n  \n\n# 任务调度\n\n  \n\n偶尔，你将需要调度一个任务**以便稍后（延迟）执行或者周期性地执行**。例如，你可能想要注册一个在客户端已经**连接了 5 分钟之后触发的任务。**\n\n  \n\nJDK 的任务调度\n\n- 在 Java 5 之前，任务调度是建立在 java.util.Timer 类之上的，其使用了一个后台 Thread，并且具有与标准线程相同的限制。、\n    \n- 随后，JDK 提供了 java.util.concurrent 包，它定义了 interface ScheduledExecutorService。表 7-1 展示了 java.util.concurrent.Executors的相关工厂方法。\n    \n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-724.png)\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-746.png)\n\n  \n\n## EventLoop调度任务\n\nNetty 通 过 Channel 的 EventLoop 实现任务调度解决了这一问题\n\n  \n\n- 使用EventLoop调度任务\n    \n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-692.png)\n\n- 使用 **EventLoop** 调度周期性的任务\n    \n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-695.png)\n\n- 使用 **ScheduledFuture** 取消任务\n    \n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-725.png)\n\n  \n\n# 实现细节\n\n## 线程管理\n\nNetty线程模型的卓越性能取决于对于当前执行的Thread的身份的确定 ，**它是否是分配给当前Channel以及它的EventLoop的那一个线程，**\n\n- 如果（当前）调用线程正是支撑 EventLoop 的线程，那么所提交的代码块将会被（直接执行）\n    \n- 否则，EventLoop 将调度该任务以便稍后执行，**并将它放入到内部队列中**。当 EventLoop 下次处理它的事件时，它会执行队列中的那些任务/事件。这也就解释了任何的\n    \n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-696.png)\n\n  \n\n- 每个 EventLoop 都有它自已的任务队列，独立于任何其他的 EventLoop\n    \n- “永 远不要将一个长时间运行的任务放入到执行队列中，因为它将阻塞需要在同一线程上执行的任何其他任务。”如果必须要进行阻塞调用或者执行长时间运行的任务，我们建议使用一个专门的EventExecutor\n    \n\n## EventLoop线程的分配\n\n服务于 Channel 的 I/O 和事件的 EventLoop 包含在 EventLoopGroup 中。根据不同的传输实现，EventLoop 的创建和分配方式也不同\n\n#### 异步传输\n\n异步传输实现**只使用了少量的 EventLoop**（以及和它们相关联的 Thread），而且在当前的线程模型中，**它们可能会被多个 Channel 所共享**，这使得可以通过**尽可能少量的 Thread 来支撑大量的 Channel**，而不是每个 Channel 分配一个 Thread\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-693.png)\n\n- EventLoopGroup 负责为**每个新创建的 Channel 分配一个 EventLoop**。\n    \n    - 在当前实现中，使用顺序循环（round-robin）的方式进行分配以获取一个均衡的分布，并且相同的 **EventLoop可能会被分配给多个 Channel。**（这一点在将来的版本中可能会改变。）\n        \n- 一旦一个 Channel 被分配给一个 EventLoop，它将在它的整个生命周期中都使用这个 EventLoop（以及相关联的 Thread）\n    \n- EventLoop 的分配方式对 ThreadLocal 的使用的影响。因为一个EventLoop 通常会被用于支撑多个 Channel，所以对于所有相关联的 Channel 来说， ThreadLocal 都将是一样的\n    \n\n  \n\n#### 阻塞传输\n\n用于像 OIO（旧的阻塞 I/O）这样的其他传输的设计略有不同\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-694.png)\n\n这里每一个 Channel 都将被分配给一个 EventLoop（以及它的 Thread）。如果你开发的应用程序使用过 java.io 包中的阻塞 I/O 实现，你可能就遇到过这种模型\n\n但是，正如同之前一样，得到的保证是**每个 Channel 的 I/O 事件都将只会被一个 Thread** （用于支撑该 Channel 的 EventLoop 的那个 Thread）处理。","lastmodified":"2024-03-02T12:01:53.85021041Z","tags":[]},"/Obsidian/%E4%BD%BF%E7%94%A8quartz%E5%8F%91%E5%B8%83obsidian-vault":{"title":"使用quartz发布obsidian  vault","content":"","lastmodified":"2024-03-02T12:01:53.858210383Z","tags":[]},"/Obsidian/Front-Matter":{"title":"Front Matter","content":"\n\n使用 Front Matter 可以保存 note 待元数据，推荐使用 Hugo 的配置 [Front matter | Hugo (gohugo.io)](https://gohugo.io/content-management/front-matter/)\n\n","lastmodified":"2024-03-02T12:01:51.594217676Z","tags":["Obsidian"]},"/Obsidian/Obsidian-plugin":{"title":"Obsidian-plugin","content":"\n* [advanced-table](https://github.com/tgrosinger/advanced-tables-obsidian)\n* [banners](https://github.com/noatpad/obsidian-banners)\n* [calendar](https://github.com/liamcain/obsidian-calendar-plugin)\n* [commander](https://github.com/phibr0/obsidian-commander)\n* [dataview](https://github.com/blacksmithgu/obsidian-dataview)\n* [emoji-shortcodes](https://github.com/phibr0/obsidian-emoji-shortcodes)\n* [emoji-toolbar](https://github.com/oliveryh/obsidian-emoji-toolbar)\n* [excel-to-markdown-table](https://github.com/ganesshkumar/obsidian-excel-to-markdown-table)\n* [homepage](https://github.com/mirnovov/obsidian-homepage)\n* [hover-editor](https://github.com/nothingislost/obsidian-hover-editor)\n* [icon-folder)](https://github.com/FlorianWoelki/obsidian-icon-folder)\n* [icons](https://github.com/visini/obsidian-icons-plugin)\n* [image-toolkit](https://github.com/sissilab/obsidian-image-toolkit)\n* [minimal-settings](https://github.com/kepano/obsidian-minimal-settings)\n* [obsidian-git](https://github.com/denolehov/obsidian-git)\n* [recent-files](https://github.com/tgrosinger/recent-files-obsidian)\n* [settings-search](https://github.com/javalent/settings-search)\n* [style-settings](https://github.com/mgmeyers/obsidian-style-settings)\n* [tag-wrangler](https://github.com/pjeby/tag-wrangler)\n* [excalidraw](https://github.com/zsviczian/obsidian-excalidraw-plugin)","lastmodified":"2024-03-02T12:01:51.594217676Z","tags":["Obsidian"]},"/Obsidian/dataview":{"title":"dataview","content":"\n\n# 官方地址\n\n* [代码仓库](https://github.com/blacksmithgu/obsidian-dataview)\n* [文档地址](https://blacksmithgu.github.io/obsidian-dataview/)\n\n# 其他教程\n*  [Obsidian DataView 入门保姆级引导手册](https://zhuanlan.zhihu.com/p/614881764)\n\n# 元数据\n\n元数据是一系列的键值对,可以给笔记，可以给note,list item ,task 添加元数据\n\n## 如何添加元数据\n\n### Frontmatter\n\n* frontmatter 是markdown的一种扩展，可以使用yaml 来添加元数据\n\n```\n --- \n alias: \"document\" \n last-reviewed: 2021-08-17 \n thoughts: \n\t rating: 8 \n\t reviewable: false \n ---\n```\n\n###  inline fields\n* 使用方法为在文件的任意位置添加\n```text\n\nBasic Field:: Some random Value \n**Bold Field**:: Nice!\n  \n```\n\n* 如果你需要标注list itme 或者 task 需要使用中括号\n```\n- [ ] Send an mail to David about the deadline [due:: 2022-04-05].\n```\n\n\n# 另外还有隐含的元数据\n\n## page 中的元数据\n\n\n[# Metadata on Pages](https://blacksmithgu.github.io/obsidian-dataview/annotation/metadata-pages/)\n\n\n| Field Name       | Data Type      | Description                                                                                                                                                                   |\n|------------------|----------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| file.name        | Text           | The file name as seen in Obsidians sidebar.                                                                                                                                   |\n| file.folder      | Text           | The path of the folder this file belongs to.                                                                                                                                  |\n| file.path        | Text           | The full file path, including the files name.                                                                                                                                 |\n| file.ext         | Text           | The extension of the file type; generally md.                                                                                                                                 |\n| file.link        | Link           | A link to the file.                                                                                                                                                           |\n| file.size        | Number         | The size (in bytes) of the file.                                                                                                                                              |\n| file.ctime       | Date with Time | The date that the file was created.                                                                                                                                           |\n| file.cday        | Date           | The date that the file was created.                                                                                                                                           |\n| file.mtime       | Date with Time | The date that the file was last modified.                                                                                                                                     |\n| file.mday        | Date           | The date that the file was last modified.                                                                                                                                     |\n| file.tags        | List           | A list of all unique tags in the note. Subtags are broken down by each level, so #Tag/1/A will be stored in the list as [#Tag, #Tag/1, #Tag/1/A].                             |\n| file.etags       | List           | A list of all explicit tags in the note; unlike file.tags, does not break subtags down, i.e. [#Tag/1/A]                                                                       |\n| file.inlinks     | List           | A list of all incoming links to this file, meaning all files that contain a link to this file.                                                                                |\n| file.outlinks    | List           | A list of all outgoing links from this file, meaning all links the file contains.                                                                                             |\n| file.aliases     | List           | A list of all aliases for the note as defined via the YAML frontmatter.                                                                                                       |\n| file.tasks       | List           | A list of all tasks (I.e., \\| [ ] some task) in this file.                                                                                                                    |\n| file.lists       | List           | A list of all list elements in the file (including tasks); these elements are effectively tasks and can be rendered in task views.                                            |\n| file.frontmatter | List           | Contains the raw values of all frontmatter in form of key \\| value text values; mainly useful for checking raw frontmatter values or for dynamically listing frontmatter keys. |\n| file.day         | Date           | Only available if the file has a date inside its file name (of form yyyy-mm-dd or yyyymmdd), or has a Date field/inline field.                                                |\n| file.starred     | Boolean        | if this file has been starred via the Obsidian Core Plugin \"Starred Files\".                                                                                                   |\n\n\n## 列表和任务中的元数据\n\n[# Metadata on Tasks and Lists](https://blacksmithgu.github.io/obsidian-dataview/annotation/metadata-tasks/)\n\n| Field name     | Data Type | Description                                                                                                                                                                                                                                                                                               |\n|----------------|-----------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| status         | Text      | The completion status of this task, as determined by the character inside the [ ] brackets. Generally a space \" \" for incomplete tasks and a \"x\" for complete tasks, but allows for plugins which support alternative task statuses.                                                                      |\n| checked        | Boolean   | Whether or not this task status is empty, meaning it has a space in its [ ] brackets                                                                                                                                                                                                                      |\n| completed      | Boolean   | Whether or not this specific task has been completed; this does not consider the completionnon-completion of any child tasks. A task is explicitly considered \"completed\" if it has been marked with an 'x'. If you use a custom status, i.e. [-], checked will be true, whereas completed will be false. |\n| fullyCompleted | Boolean   | Whether or not this task and all of its subtasks are completed.                                                                                                                                                                                                                                           |\n| text           | Text      | The plain text of this task, including any metadata field annotations.                                                                                                                                                                                                                                    |\n| visual         | Text      | The text of this task, which is rendered by Dataview. It can be modified to render arbitary text.                                                                                                                                                                                                         |\n| line           | Number    | The line of the file this task shows up on.                                                                                                                                                                                                                                                               |\n| lineCount      | Number    | The number of Markdown lines that this task takes up.                                                                                                                                                                                                                                                     |\n| path           | Text      | The full path of the file this task is in. Equals to file.path for pages                                                                                                                                                                                                                                  |\n| section        | Link      | link to the section this task is contained in.                                                                                                                                                                                                                                                            |\n| tags           | List      | Any tags inside of the text task.                                                                                                                                                                                                                                                                         |\n| outlinks       | List      | Any links defined in this task.                                                                                                                                                                                                                                                                           |\n| link           | Link      | link to the closest linkable block near this task; useful for making links which go to the task.                                                                                                                                                                                                          |\n| children       | List      | ny subtasks or sublists of this task.                                                                                                                                                                                                                                                                     |\n| task           | Boolean   | If true, this is a task; otherwise, it is a regular list element.                                                                                                                                                                                                                                         |\n| annotated      | Boolean   | True if the task text contains any metadata fields, false otherwise.                                                                                                                                                                                                                                      |\n| parent         | Number    | The line number of the task above this task, if present; will be null if this is a root-level task.                                                                                                                                                                                                       |\n| blockId        | Text      | The block ID of this task / list element, if one has been defined with the ^blockId syntax; otherwise null.                                                                                                                                                                                               |\n\n\n# DQL\n\n比较类似于sql, 可是实现以下的功能\n\n- Choosing an **output format** of your output (the [Query Type](https://blacksmithgu.github.io/obsidian-dataview/queries/query-types/))\n- Fetch pages **from a certain [source](https://blacksmithgu.github.io/obsidian-dataview/reference/sources/)**, i.e. a tag, folder or link\n- **Filtering pages/data** by simple operations on fields, like comparison, existence checks, and so on\n- **Transforming fields** for displaying, i.e. with calculations or splitting up multi-value fields\n- **Sorting** results based on fields\n- **Grouping** results based on fields\n- **Limiting** your result count\n\n## 查询语法\n\n```text\n```dataview \n\t\u003cQUERY-TYPE\u003e \u003cfields\u003e \n\tFROM \u003csource\u003e \n\t\u003cDATA-COMMAND\u003e \u003cexpression\u003e \n\t\u003cDATA-COMMAND\u003e \u003cexpression\u003e \n\t...\n```\n```\t\n```\n\n\n## 输出类型\n\n* **TABLE**: A table of results with one row per result and one or many columns of **field data**.\n* **LIST**: A bullet point list of **pages** which match the query. You can output one field for each page alongside their file links.\n* **TASK**: An interactive task list of **tasks** that match the given query.\n* **CALENDAR**: A calendar view displaying each hit via a dot on its referred date.\n\n\n```text\nLists all pages in your vault as a bullet point list\n\t```dataview \n\tLIST \n\t```\n\t\nLists all tasks (completed or not) in your vault \n\t```dataview \n\tTASK \n\t```\n\t\nRenders a Calendar view where each page is represented as a dot on its creation date. \n\t```dataview \n\tCALENDAR file.cday \n\t```\n\t\nShows a table with all pages of your vault, their field value of due, the files' tags and an average of the values of multi-value field working-hours \n\t```dataview \n\tTABLE due, file.tags AS \"tags\", average(working-hours)\n\t ```\n\n```\n\n\n## 数据来源\n\n* tags\n* folders\n* note\n* lint\n\n```\nLists all pages inside the folder Books and its sub folders \n\t```dataview \n\tLIST FROM \"Books\" \n\t``` \n\t\nLists all pages that include the tag #status/open or #status/wip \n\t```dataview \n\tLIST FROM #status/open OR #status/wip \n\t``` \n\t\nLists all pages that have either the tag #assignment and are inside folder \"30 School\" (or its sub folders), or are inside folder \"30 School/32 Homeworks\" and are linked on the page School Dashboard Current To Dos \n\n\t```dataview \n\tLIST FROM (#assignment AND \"30 School\") OR (\"30 School/32 Homeworks\" AND outgoing([[School Dashboard Current To Dos]])) \n\t```\n\n```\n\n\n## Filter, sort, group or limit results\n\n* ***FROM** like explained [above](https://blacksmithgu.github.io/obsidian-dataview/queries/structure/#choose-your-source).\n*  **WHERE**: Filter notes based on information **inside** notes, the meta data fields.\n*  **SORT**: Sorts your results depending on a field and a direction.\n*  **GROUP BY**: Bundles up several results into one result row per group.\n*  **LIMIT**: Limits the result count of your query to the given number.\n*  **FLATTEN**: Splits up one result into multiple results based on a field or calculation.\n\n\n```\nLists all pages that have a metadata field `due` and where `due` is before today \n\n\t```dataview \n\tLIST WHERE due AND due \u003c date(today) \n\t``` \nLists the 10 most recently created pages in your vault that have the tag #status/open \n\t```dataview \n\tLIST FROM #status/open SORT file.ctime DESC LIMIT 10 \n\t``` \nLists the 10 oldest and incompleted tasks of your vault as an interactive task list, grouped by their containing file and sorted from oldest to newest file. \n\t```dataview \n\tTASK WHERE !completed SORT created ASC LIMIT 10 GROUP BY file.link SORT rows.file.ctime ASC \n\t```\n\n\n```","lastmodified":"2024-03-02T12:01:51.594217676Z","tags":["Obsidian"]},"/Obsidian/excalidraw":{"title":"excalidraw","content":"\n*  [代码仓库](https://github.com/zsviczian/obsidian-excalidraw-plugin)\n* note 中插入excalidraw 语法\n\n```\n![[excalidraw]]\n```","lastmodified":"2024-03-02T12:01:51.594217676Z","tags":["Obsidian"]},"/Obsidian/obsidian-overview":{"title":"obsidian overview","content":"\n# 主页内容\n\nobsidian 相关内容，包括插件\n\n\n# 结构\n\n","lastmodified":"2024-03-02T12:01:51.594217676Z","tags":["Obsidian"]},"/Obsidian/publish":{"title":"publish","content":"\n\n\n[obsidian 目前最完美的免费发布方案 渐进式教程 by oldwinter](https://publish.obsidian.md/chinesehelp/01+2021%E6%96%B0%E6%95%99%E7%A8%8B/obsidian+%E7%9B%AE%E5%89%8D%E6%9C%80%E5%AE%8C%E7%BE%8E%E7%9A%84%E5%85%8D%E8%B4%B9%E5%8F%91%E5%B8%83%E6%96%B9%E6%A1%88+%E6%B8%90%E8%BF%9B%E5%BC%8F%E6%95%99%E7%A8%8B+by+oldwinter#%E5%87%A0%E4%B8%AA%E5%8F%91%E5%B8%83%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94)","lastmodified":"2024-03-02T12:01:51.594217676Z","tags":["Obsidian"]},"/Obsidian/template":{"title":"template","content":"\n* *[模板的使用方法](https://publish.obsidian.md/help-zh/%E6%8F%92%E4%BB%B6/%E6%A8%A1%E6%9D%BF)\n* 默认存放的文件夹 `/template`\n\n","lastmodified":"2024-03-02T12:01:51.594217676Z","tags":["Obsidian"]},"/awesome/JavaGuide-%E7%9F%A5%E8%AF%86%E6%98%9F%E7%90%83%E4%BC%98%E8%B4%A8%E4%B8%BB%E9%A2%98%E6%B1%87%E6%80%BB":{"title":"JavaGuide 知识星球优质主题汇总","content":"为了避免这里成为知识杂货铺，我会对严格筛选入选的优质主题。  \n  \n更新日期：2023-06-11  \n  \n\n面试  \n  \n●[Java面试常见问题总结（2023最新版）](https://t.zsxq.com/0eRq7EJPy)  \n●[一位 HR 分享的求职建议](https://t.zsxq.com/0dSKX0jkK)  \n●[面试和简历上的一些大忌](https://t.zsxq.com/0eOgYt3qU)  \n●项目：  \n○[如何回答项目遇到什么困难，如何解决这类问题](https://t.zsxq.com/0dduy9CeQ)  \n○[项目太简单怎么办?](https://t.zsxq.com/0eV4BksDb)  \n○[商城项目到底能不能做？](https://t.zsxq.com/0eBcCNhbB)  \n  \n\n安抚心态  \n  \n如果你陷入精神内耗或者自我怀疑，不然看看下面这些内容：  \n  \n●[编程找工作现状 - 哔哩哔哩](https://t.zsxq.com/0edKnfcZW)  \n  \n\n技术资源  \n  \n学习路线：[Java 系统学习路线](https://t.zsxq.com/0dupYAEaq)  \n  \n总结 ：  \n  \n●[Java 后端开发常用的技术书籍+原创面试资料 PDF 版本](https://t.zsxq.com/0bWeUrBVq)  \n●[JavaGuide 网站总结的八股文合集  - 念神](https://t.zsxq.com/0biGG9UlX)  \n●[Java 后端常见知识点思维导图分享 - 吴不卷](https://t.zsxq.com/0bHk3wEDs)  \n  \n常用技术：  \n  \n●[SpringBoot 学习资源推荐](https://t.zsxq.com/0eEGBV1Md)  \n●[单测技术选型+学习资源推荐](https://t.zsxq.com/0d7jOz9Vm)  \n●[Redis 学习资源推荐](https://t.zsxq.com/0dwd4ONZ9)  \n●[Elasticsearch 学习资源推荐](https://t.zsxq.com/0dEWEThKR)  \n●[Kafka、RocketMQ、RabbitMQ 学习资源推荐](https://t.zsxq.com/0bEDFwgon)  \n●[分布式学习资源推荐（偏理论方向）](https://t.zsxq.com/0euwZ8uiP)  \n●[Git 学习资源推荐](https://t.zsxq.com/0bTheL01q)  \n●[《阿里开发者手册 - Redis 专题》PDF 文档](https://t.zsxq.com/0bEiLJIVW)  \n  \n\n代码质量  \n  \n●[24 个写出漂亮代码的小技巧](https://t.zsxq.com/0foGrZIc7)  \n●[程序员“起名”头痛根治指南](https://t.zsxq.com/0d8ODCefj)  \n●[5天带你读完《Effective Java》](https://t.zsxq.com/0dIkpk8AV)  \n●[提高代码质量的书籍和文章推荐](https://t.zsxq.com/0dWEHSiBW)  \n●[一个练习重构的开源教程](https://t.zsxq.com/0d221QNao)  \n●[分享3本对于提高代码质量有实际帮助的书籍](https://t.zsxq.com/0dFLaE2Lp)（《编写可读代码的艺术》、《Clean Code》、《The Clean Coder》）  \n  \n\n进阶攻略  \n  \n●[如何撰写一份令人赞叹的软件专利技术交底书？](https://articles.zsxq.com/id_2kdw0o0ovc44.html)  \n●[校招生如何参与开源项目？如何获得开源经历？](https://articles.zsxq.com/id_q0g14e71eqc3.html)  \n●[一些读书心得和看书做笔记的经验](https://t.zsxq.com/0cpx9pkIE)  \n●[一个关于提升学习能力和效率的视频](https://t.zsxq.com/0c2OboF1Q)（收益匪浅）  \n●[如何有效提升专注力？](https://t.zsxq.com/0eIuSBARU)  \n●[快速熟悉业务逻辑并付诸落地的建议 - 念神](https://t.zsxq.com/0cGu9HjPQ)  \n●[给初级 Java 工程师的一些学习建议 - 念神](https://t.zsxq.com/0ckNvT31a)  \n●[项目技术选型的建议](https://t.zsxq.com/0ciPGdBoZ)（听了一个技术选型分享之后的一些心得体会）  \n●[使用 Google 搜索的实用建议](https://t.zsxq.com/0c0K3zPRk)  \n●[不要把自己局限在技术上!](https://t.zsxq.com/0cdHCFWNw) （重视技术能力，但你的世界不能仅仅只有技术）  \n●[给一些想要换职业方向的朋友一些客观的建议](https://t.zsxq.com/0crTLD2hY)  \n●[如何做编程知识投资及减少知识失效的影响](https://t.zsxq.com/0ccagnzao) （感触很深的一篇文章，强烈推荐阅读）  \n●[碎片化知识可能会带来的坏处](https://t.zsxq.com/0cdfq7iR4)（碎片化知识泛滥的时代，应该注意其对自身的影响）  \n  \n\n开源项目  \n  \n●[一个简易版的IoC的轮子（球友自制，附笔记）](https://t.zsxq.com/0eCVtaUND)  \n●[Java 语言手写的一款简易版 Git（球友自制）](https://t.zsxq.com/0ekLd7XaX)  \n●[基于 SpringBoot 的国密前后端分离快速开发平台](https://t.zsxq.com/0b3wlSfjS)  \n●[《高并发的哲学原理》开源图书](https://t.zsxq.com/0bmQXO4bf)  \n●[zyplayer-doc：适合团队和个人使用的WIKI文档管理工具，同时还包含数据库文档、Api接口文档。](https://t.zsxq.com/0bcfjG15v)  \n●[《深入理解 Java 虚拟机》阅读笔记，基于第二版（目前最新版是第三版）](https://t.zsxq.com/0b1CDmh5H)  \n●[think：一款开源知识管理工具，支持创建知识库、多人协作、分享知识库、绘制思维导图、添加附加附件等功能](https://wx.zsxq.com/dweb2/index/group/48418884588288)  \n●[ip2region：高性能离线IP地址定位库，10微秒级别的查询效率，开箱即用，提供了多种主流编程语言（如 Go，Java，Python）的 xdb 数据生成和查询客户端 API。](https://t.zsxq.com/0b6BYX1rp)  \n●[novel：一套基于时下最新 Java 技术栈 Spring Boot 3 + Vue 3 开发的前后端分离学习型小说项目](https://t.zsxq.com/0b71m4luD)  \n●[lu-raft-kv：分布式 KV 存储轮子](https://t.zsxq.com/0baOCvT01)  \n●[MYDB：简易版数据库](https://t.zsxq.com/0b0d5pFHt)  \n●[mini-spring-cloud：手写的简化版的 Spring Cloud](https://t.zsxq.com/0bai0TuJX)  \n●[SurveyKing：号称功能最强大的调查问卷系统和考试系统](https://t.zsxq.com/0bJaH3GSP)  \n●[cs-self-learning：计算机自学指南](https://t.zsxq.com/0biDtoOF7)  \n●[upupor：小众但是功能强大的开源社区](https://t.zsxq.com/0bZrBeqMg)  \n●[Easy-Es： Elasticsearch 工具库](https://t.zsxq.com/0bWdejp6D)  \n  \n\n工具网站  \n  \n●[两个巨好用的 Linux 命令网站](https://t.zsxq.com/0eKkOJPDA)  \n●[GitHub Web IDE：直接通过多种在线 IDE 打开Github项目](https://t.zsxq.com/0eDXSZsBw)","lastmodified":"2024-03-02T12:01:53.86221037Z","tags":[]},"/elastic/KQL":{"title":"KQL","content":"\nKibana  Query Language\n\n\nhttps://juejin.cn/post/7003201901382598686\n\n\nhttps://www.elastic.co/guide/en/kibana/7.14/kuery-query.html#kuery-query\n\n\n","lastmodified":"2024-03-02T12:01:53.86221037Z","tags":[]},"/lua/%E7%94%A8Go%E5%AE%9E%E7%8E%B0Lua/%E5%89%8D%E8%A8%80":{"title":"前言","content":"\n# 参考资料\n\n*  *[自己动手实现Lua:虚拟机、编译器和标准库](https://weread.qq.com/web/bookDetail/40032ae07164852040038d3)\n* 《Programming in Lua, Fourth Edition》\n* 《Lua 5.3 Reference Manual》\n* 《The Evolution of Lua》\n* 《The Implementation of Lua 5.0》\n* 《A No-Frills Introduction to Lua 5.1 VM Instructions》\n* 《Lua 5.3 Bytecode Reference》\n\n\n\n# 关于 Lua 的语法\n\n* [lua基础](lua/lua基础.md)\n* [Lua高级](lua/Lua高级.md)\n\n\n# 参考代码\n\n* [自己动手实现Lua:虚拟机、编译器和标准库](https://weread.qq.com/web/bookDetail/40032ae07164852040038d3) 的随书代码 [luago-book](https://github.com/zxh0/luago-book)\n\n## 我的代码\n\n* [golua](https://github.com/googoo-s/golua)\n\n\n\n\n\n","lastmodified":"2024-03-02T12:01:53.86221037Z","tags":[]},"/lua/%E7%94%A8Go%E5%AE%9E%E7%8E%B0Lua/1.%E4%BA%8C%E8%BF%9B%E5%88%B6Chunk":{"title":"1.二进制Chunk","content":"\n# 什么是二进制 chunk\nLua 脚本并.不是直接被 Lua 解释器解释执行，而是类似 Java 语言那样，先由 Lua 编译器编译为字节码，然后再交给 Lua 虚拟机去执行\n\nLua 字节码需要一个载体，这个载体就是二进制 chunk，对 Java 虚拟机比较熟悉的读者可以把二进制 chunk 看作 Lua 版的 class 文件\n\n\n#  lunc 命令\n\n\nLuac 命令主要有两个用途：\n\n* 第一，作为编译器，把 Lua 源文件编译成二进制 chunk 文件：\n* 第二，作为反编译器，分析二进制 chunk，将信息输出到控制台\n\n\n```\n➜  will ~ luac\nC:\\Program Files (x86)\\Lua\\5.1\\luac.exe: no input files given\nusage: C:\\Program Files (x86)\\Lua\\5.1\\luac.exe [options] [filenames].\nAvailable options are:\n  -        process stdin\n  -l       list\n  -o name  output to file 'name' (default is \"luac.out\")\n  -p       parse only\n  -s       strip debug information\n  -v       show version information\n  --       stop handling options\n```\n\n## 编译 lua 源文件\n\n将一个或者多个文件名作为参数调用 luac 命令就可以编译指定的 Lua 源文件，如果编译成功，在当前目录下会出现 luac. Out 文件，里面的内容就是对应的二进制 chunk\n\n\n```\n$ luac hello_world.lua              # 生成luac.out\n$ luac -o hw.luac hello_world.lua   # 生成hw.luac\n$ luac -s hello_world.lua           # 不包含调试信息\n$ luac -p hello_world.lua           # 只进行语法检查\n```\n\n\n## Luac 的简单工作原理\n\n\nLua 编译器以函数为单位进行编译，每一个函数都会被 Lua 编译器编译为一个内部结构，这个结构叫作“原型”（Prototype）。原型主要包含 6 部分内容，分别是：\n\n* 函数基本信息（包括参数数量、局部变量数量等）\n* 字节码\n* 常量表\n* Upvalue 表\n* 调式信息\n* 子函数原型列表\n\n**函数原型是一种递归结构**，并且 Lua 源码中函数的嵌套关系会直接反映在编译后的原型里\n\n对于脚本，**Lua 编译器会自动为我们的脚本添加一个 main 函数**（后文称其为主函数），并且把整个程序都放进这个函数里，然后再以它为起点进行编译，那么自然就把整个程序都编译出来了\n\n\n综上所述，函数原型和二进制 chunk 的内部结构\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticPasted%20image%2020230805015642.png)\n\n\n## 反编译二进制 chunk \n\n\nLuc 命令兼具编译和反编译功能，使用“-l”选项可以将 luac 切换到反编译模式。正如 javap 命令是查看 class 文件的利器，luac 命令搭配“-l”选项则是查看二进制 chunk 的利器\n\n\n以前面编译出来的 hello_world. Luac 文件为例，其反编译输出如下。\n\n\n```\n$ luac -l hello_world.luac\n\nmain \u003chello_world.lua:0,0\u003e (4 instructions at 0x7fb4dbc030f0)\n0+ params, 2 slots, 1 upvalue, 0 locals, 2 constants, 0 functions\n\t1    [1]GETTABUP  0 0-1 ; _ENV \"print\"\n\t2    [1]LOADK      1-2       ; \"Hello, World! \"\n\t3    [1]CALL       0 2 1\n\t4    [1]RETURN     0 1\n```\n\n\n由于“Hello, World! ”程序只有一条打印语句，所以编译出来的二进制 chunk 里也只有一个主函数原型（没有子函数），因此反编译输出里也只有主函数信息\n\n\n多函数的 lua\n\n```\nfunction foo()\n\tfunction bar() end\nend\n```\n\n反编译结果，反编译输出中会依次包含 main、foo 和 bar 函数的信息，如下所示。\n\n\n```\n$ luac -l foo_bar.lua\n\nmain \u003cfoo_bar.lua:0,0\u003e (3 instructions at 0x7fc43fc02b20)\n0+ params, 2 slots, 1 upvalue, 0 locals, 1 constant, 1 function\n\t1  [4] CLOSURE    0 0     ; 0x7fc43fc02cc0\n\t2  [1] SETTABUP  0-1 0 ; _ENV \"foo\"\n\t3  [4] RETURN     0 1\n\nfunction \u003cfoo_bar.lua:1,4\u003e (3 instructions at 0x7fc43fc02cc0)\n0 params, 2 slots, 1 upvalue, 0 locals, 1 constant, 1 function\n\t1  [3] CLOSURE    0 0     ; 0x7fc43fc02e40\n\t2  [2] SETTABUP  0-1 0 ; _ENV \"bar\"\n\t3  [4] RETURN     0 1\n\nfunction \u003cfoo_bar.lua:2,3\u003e (1 instruction at 0x7fc43fc02e40)\n0 params, 2 slots, 0 upvalues, 0 locals, 0 constants, 0 functions\n\t1  [3] RETURN     0 1\n\n```\n\n\n反编译打印出的函数信息包含两个部分：\n\n* 前面两行是函数基本信息，\n\t* 第一行\n\t\t* 如果以 main 开头，说明这是编译器为我们生成的主函数，以 function 开头，说明这是一个普通函数\n\t\t* 接着是定义函数的源文件名和函数在文件里的**起止行号**（对于主函数，起止行号都是 0），然后是指令数量和函数地址。\n\t* 第二行依次给出\n\t\t* 函数的固定参数数量（如果有+号，表示这是一个 vararg 函数）\n\t\t* 运行函数所必要的寄存器数量\n\t\t* upvalue 数量\n\t\t* 局部变量数量\n\t\t* 常量数量\n\t\t* 子函数数量\n* 后面是指令列表。每一条都包含\n\t* 指令序号\n\t* 对应行号\n\t* 操作码 \n\t* 操作数\n\t* 分号后面是 luac 根据指令操作数生成的注释，以便于我们理解指令\n\n## 二进制 chunk 的格式\n\n和 Java 的 class 文件类似，Lua 的二进制 chunk 本质上也是一个字节流\n\n* 二进制 chunk 格式（包括 Lua 虚拟机指令）属于 Lua 虚拟机内部实现细节，并没有标准化，也没有任何官方文档对其进行说明，一切以 Lua 官方实现的源代码为准\n* **二进制 chunk 格式的设计没有考虑跨平台的需求**，使用超过一个字节表示的数据，必须要考虑大小端（Endianness）问题。\n\t* Lua 官方实现的做法比较简单：编译 Lua 脚本时，**直接按照本机的大小端方式**生成二进制 chunk 文件，当加载二进制 chunk 文件时，会探测被加载文件的大小端方式，如果和本机不匹配，就拒绝加载\n* 二进制 chunk 格式的设计也没有考虑不同 Lua 版本之间的兼容问题\n\t* 编译 Lua 脚本时，直接按照当时的 Lua 版本生成二进制 chunk 文件，当加载二进制 chunk 文件时，会检测被加载文件的版本号，如果和当前 Lua 版本不匹配，则拒绝加载\n* 二进制 chunk 格式并没有被刻意设计得很紧凑\n\t* lua 脚本预编译成二进制 chunk 的主要目的是为了获得更快的加载速度，所以这也不是什么大问题。\n\n### 数据类型 \n\n在讨论二进制 chunk 格式时，我们称这种被编码为一个或多个字节的信息单位为数据类型\n由于 Lua 官方实现是用 C 语言编写的，所以 **C 语言的一些数据类型（比如 size_t）会直接反映在二进制 chunk 的格式**里\n\n二进制 chunk 内部使用的数据类型大致可以分为**数字、字符串和列表**三种。\n\n\n#### 数字\n\n数字类型主要包括**字节、C 语言整型（后文简称 cint）、C 语言 size_t 类型（简称 size_t）、Lua 整数、Lua 浮点数**五种\n\n* 字节类型用来存放一些比较小的整数值，比如 Lua 版本号、函数的参数个数等；\n* cint 类型主要用来表示列表长度；\n* size_t 则主要用来表示长字符串长度；\n* Lua 整数和 Lua 浮点数则主要在常量表里出现，记录 Lua 脚本中出现的整数和浮点数字面量\n\n数字类型在二进制 chunk 里都按照固定长度存储。除字节类型外，其余四种数字类型都会占用多个字节，具体占用几个字节则会记录在头部里\n\nLua 官方实现（64 位平台）里对应的 C 语言类型、在本书中使用的 Go 语言类型，以及占用的字节数\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticPasted%20image%2020230805155327.png)\n\n\n#### 字符串\n\n字符串在二进制 chunk 里，其实就是一个**字节数组**。\n\n\n因为字符串长度是不固定的，所以需要把字节数组的长度也记录到二进制 chunk 里。**作为优化，字符串类型又可以进一步分为短字符串和长字符串两种，具体有三种情况**\n\n\n* 对于 NULL 字符串，只用 0 x 00 表示就可以了。\n* 对于长度小于等于 253（0 xFD）的字符串，**先使用一个字节记录长度+1**，然后是字节数组。\n* 对于长度大于等于 254（0 xFE）的字符串，**第一个字节是 0 xFF，后面跟一个 size_t 记录长度+1**，最后是字节数组。\n\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticPasted%20image%2020230805155714.png)\n\n\n#### 列表\n\n在二进制 chunk 内部，**指令表、常量表、子函数原型表等信息都是按照列表的方式存储的**。\n\n* 用一个 cint 类型记录列表长度，\n* 然后紧接着存储 n 个列表元素，\n* 至于列表元素如何存储那就要具体情况具体分析了\n\n### 总体结果\n\n总体而言，二进制 chunk 分为头部和主函数原型两部分\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticPasted%20image%2020230805015642.png)\n\n\n定义结构体 binaryChunk \n\n\n```\ntype binaryChunk struct {\n    // 头部\n    header\n    // 主函数upvalues 和闭包有关\n    sizeUpvalues byte\n    // 主函数原型\n    mainFunc *Prototype\n}\n```\n\n### 头部\n\n\n```\ntype header struct {\n\t// 签名，相对于Java的模式,主要起快速识别文件格式的作用\n\tsignature [4]byte\n\t// 版本号，记录二进制chunk文件所对应的Lua版本号\n\tversion byte\n\t// 格式号，如果和虚拟机本身的格式号不匹配，就拒绝加载该文件\n\tformat          byte\n\t// LUAC_DATA 格式号之后的6个字节在Lua官方实现里叫作LUAC_DATA。\n\t// 其中前两个字节是0x1993，这是Lua 1.0发布的年份；\n\t// 后四个字节依次是回车符（0x0D）、换行符（0x0A）、替换符（0x1A）和另一个换行符\n\t// 6个字节主要起进一步校验的作用。如果Lua虚拟机在加载二进制chunk时发现这6个字节和预期的不一样，就会认为文件已经损坏，拒绝加载\n\tluacData        [6]byte\n\t// 接下来的5个字节分别记录cint、size_t、Lua虚拟机指令、Lua整数和Lua浮点数这5种数据类型在二进制chunk里占用的字节数\n\tcintSize        byte\n\tsizetSize       byte\n\tinstructionSize byte\n\tluaIntegerSize  byte\n\tluaNumberSize   byte\n\t// LUAC_INT， n个字节存放Lua整数值0x5678，存储这个Lua整数的目的是为了检测二进制chunk的大小端方式\n\tluacInt         int64\n\t// LUAC_NUM，头部的最后n个字节存放Lua浮点数370.5，头部的最后n个字节存放Lua浮点数370.5\n\tluacNum         float64\n}\n```\n\n### 函数原型\n\n\n函数原型主要包含函数基本信息、指令表、常量表、upvalue 表、子函数原型表以及调试信息；\n\n* 基本信息\n\t* 源文件名、起止行号、固定参数个数、是否是 vararg 函数以及运行函数所必要的寄存器数量；\n\t* 调试信息又包括行号表、局部变量表以及 upvalue 名列表。\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticPasted%20image%2020230805162248.png)\n\n```\ntype Prototype struct {\n\t// 源文件名，只有在主函数原型里，该字段才真正有值，在其他嵌套的函数原型里，该字段存放空字符串\n\tSource string\n\t// Prototype,用于记录原型对应的函数在源文件中的起止行号。如果是普通的函数，起止行号都应该大于0；\n\t//  如果是主函数，则起止行号都是0\n\tLineDefined     uint32\n\tLastLineDefined uint32\n\t// 函数固定参数个数。这里的固定参数，是相对于变长参数（Vararg）而言的\n\tNumParams byte\n\t// 用来记录函数是否为Vararg函数，即是否有变长参数\n\tIsVararg byte\n\t// 记录的是寄存器数量。Lua编译器会在编译函数时将这个数量计算好，并以字节类型保存在函数原型\n\tMaxStackSize byte\n\t// 函数基本信息之后是指令表\n\tCode []uint32\n\t// 指令表之后是常量表。常量表用于存放Lua代码里出现的字面量，包括nil、布尔值、整数、浮点数和字符串五种。\n\t// 每个常量都以1字节tag开头，用来标识后续存储的是哪种类型的常量值。常量tag值,tag类型为TAG_NIL，TAG_BOOLEAN，，\n\tConstants []interface{}\n\t// Upvalues 占有两个字节\n\tUpvalues []Upvalue\n\t// 子函数原型表\n\tProtos []*Prototype\n\t// 行号表 子函数原型表之后是行号表，其中行号按cint类型存储。行号表中的行号和指令表中的指令一一对应\n\tLineInfo []uint32\n\t// 号表之后是局部变量表，用于记录局部变量名，\n\t// 表中每个元素都包含变量名（按字符串类型存储）和起止指令索引（按cint类型存储\n\tLocVars []LocVar\n\t// 数原型的最后一部分内容是Upvalue名列表。该列表中的元素（按字符串类型存储）\n\t// 和前面Upvalue表中的元素一一对应，分别记录每个Upvalue在源代码中的名字\n\tUpvalueNames []string\n}\n\ntype LocVar struct {\n\tVarName string\n\tStartPC uint32\n\tEndPC   uint32\n}\n\n\n// Upvalue 和闭包相关\ntype Upvalue struct {\n\tInstack byte\n\tInx     byte\n}\n\n// 常量类型\nconst (\n\tTAG_NIL       = 0x00\n\tTAG_BOOLEAN   = 0x01\n\tTAG_NUMBER    = 0x03\n\tTAG_INTEGER   = 0x13\n\tTAG_SHORT_STR = 0x04\n\tTAG_LONG_STR  = 0x14\n)\n\n```\n\n## 解析二进制 chunk\n\n在 `binary_chunk.go` 中定义了 chunk 的解析函数`Undump`\n\n```\nfunc Undump(data []byte) * Prototype {\n\treader := \u0026reader{data}\n\treader.checkHeader()\n\treader.readByte()\n\t\n\treader.readProto(\"\")\n}\n```\n\n解析 chunk 主要看 reader ，定义 ` binchunk/reader.go`\n\n\n```\npackage binchunk\n\nimport \"encoding/binary\"\nimport \"math\"\n\ntype reader struct {\n\tdata []byte\n}\n```\n\n### 读取基本数据类型\n\n定义了 7 种读取数据类型的方法\n\n\n```\n// readByte 从字节流里读取一个字节\nfunc (self *reader) readByte() byte \n// readUint32 使用小端方式从字节流里读取一个cint存储类型（占4个字节，映射为Go语言uint32类型）的整数\nfunc (self *reader) readUint32() uint32 \n// readUint64 使用小端方式从字节流里读取一个cint存储类型（占4个字节，映射为Go语言uint32类型）的整数\nfunc (self *reader) readUint64() uint64 \n// readLuaInteger 从字节流里读取一个Lua整数（占8个字节，映射为Go语言int64类型\nfunc (self *reader) readLuaInteger() int64 \n// readLuaNumber 从字节流里读取一个Lua浮点数（占8个字节，映射为Go语言float64类型）\nfunc (self *reader) readLuaNumber() float64 \n// readString()方法从字节流里读取字符串（映射为Go语言string类型）\nfunc (self *reader) readString() string \n// readBytes()方法从字节流里读取n个字节\nfunc (self *reader) readBytes(n uint) []byte \n\n```\n\n### 检查头部\n\nCheckHeader ()方法从字节流里读取并检查二进制 chunk 头部的各个字段，如果发现某个字段和期望不符，则调用 panic 函数终止加载\n\n\n### 读取函数原型\n\nReadProto ()方法从字节流里读取函数原型","lastmodified":"2024-03-02T12:01:53.86221037Z","tags":[]},"/lua/%E7%94%A8Go%E5%AE%9E%E7%8E%B0Lua/2.%E6%8C%87%E4%BB%A4%E9%9B%86":{"title":"2.指令集","content":"\n\n# 指令集介绍\n\n按照实现方式，虚拟机大致可以分为两类：\n\n* 基于栈（Stack Based）。 \n\t* Java 虚拟机、. NET CLR、Python 虚拟机，以及在第 2 章中提到过的 Ruby YARV 虚拟机都是基于栈的虚拟机；\n* 基于寄存器（Register Based）。\n\t* 以及本书讨论的 Lua 虚拟机则是基于寄存器的虚拟机\n\n\n如同真实机器有一套指令集（Instruction Set）一样，虚拟机也有自己的指令集：\n\n* 基于栈的虚拟机需要使用 PUSH 类指令往栈顶推入值，使用 POP 类指令从栈顶弹出值, 其他指令则是对栈顶值进行操作，因此**指令集相对比较大，**\n* 其他指令则是对栈顶值进行操作，因此指令集相对比较大，但是由于需要把寄存器地址编码进指令里，**所以指令的平均长度比较长**。\n\n\n按照指令长度是否固定，指令集可以分为**定长（Fixed-width）指令集**和**变长（Variable-width）指令集**两种\n\n* Java 虚拟机使用的是变长指令集，指令长度从 1 到多个字节不 \n* Lua 虚拟机采用的则是定长指令集，每条指令占 4 个字节（共 32 比特），\n\t* 其中 6 比特用于操作码（Opcode），\n\t* 其余 26 比特用于操作数（Operand）\n\n\nLua 5.3 一共定义了 47 条指令，按照作用，这些指令大致可以分为 6 大类\n\n* 常量加载指令、\n* 运算符相关指令、\n* 循环和跳转指令、\n* 函数调用相关指令、\n* 表操作指令以及 \n* Upvalue 操作指令 \n\n\n#  指令编码格式\n\n## 编码模式\n\n条 Lua 虚拟机指令占用 4 个字节，共 32 个比特（可以用 Go 语言 uint 32 类型表示），\n\n*  6 个比特用于操作码，\n* 高 26 个比特用于操作数\n\nLua 虚拟机指令可以分为四类，分别对应四种编码模式（Mode）: \n\n* iABC\n\t* 可以携带 A、B、C 三个操作数，分别占用 8、9、9 个比特\n\t* 有 39 条使用 iABC 模式\n* iABx、\n\t* 可以携带 A 和 Bx 两个操作数，分别占用 8 和 18 个比特\n\t*  3 条使用 iABx 指令\n* iAsBx、\n\t* 可以携带 A 和 sBx 两个操作数，分别占用 8 和 18 个比特\n\t* 4 条使用 iAsBx 模式\n* iAx \n\t* 只携带一个操作数，占用全部的 26 个比特\n\t* 1 条使用 iAx 格式（实际上这条指令并不是真正的指令，只是用来扩展其他指令操作数的）\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticPasted%20image%2020230806010858.png)\n\n### 操作码\n\n\n由于 Lua 虚拟机指令使用 6 个比特表示操作码，所以最多只能有 64 条指令\n\n\n操作码从 0 开始，到 46 截止。\n\n定义如下\n\n\n```\nconst (\n\tOP_MOVE = iota\n\tOP_LOADK\n\tOP_LOADKX\n\tOP_LOADBOOL\n\tOP_LOADNIL\n\tOP_GETUPVAL\n\tOP_GETTABUP\n\tOP_GETTABLE\n\tOP_SETTABUP\n\tOP_SETUPVAL\n\tOP_SETTABLE\n\tOP_NEWTABLE\n\tOP_SELF\n\tOP_ADD\n\tOP_SUB\n\tOP_MUL\n\tOP_MOD\n\tOP_POW\n\tOP_DIV\n\tOP_IDIV\n\tOP_BAND\n\tOP_BOR\n\tOP_BXOR\n\tOP_SHL\n\tOP_SHR\n\tOP_UNM\n\tOP_BNOT\n\tOP_NOT\n\tOP_LEN\n\tOP_CONCAT\n\tOP_JMP\n\tOP_EQ\n\tOP_LT\n\tOP_LE\n\tOP_TEST\n\tOP_TESTSET\n\tOP_CALL\n\tOP_TAILCALL\n\tOP_RETURN\n\tOP_FORLOOP\n\tOP_FORPREP\n\tOP_TFORCALL\n\tOP_TFORLOOP\n\tOP_SETLIST\n\tOP_CLOSURE\n\tOP_VARARG\n\tOP_EXTRAARG\n)\n```\n\n### 操作数\n\n操作数是指令的参数，每条指令（因编码模式而异）可以携带 1 到 3 个操作数。\n\n* 其中操作数 A 主要用来表示目标寄存器索引，\n* 其他操作数按照其表示的信息，可以粗略分为四种类型：\n\t* OpArgN\n\t\t* 不表示任何信息，也就是说不会被使用。比如 MOVE 指令（iABC 模式）只使用 A 和 B 操作数，不使用 C 操作数（OpArgN 类型\n\t* OpArgU\n\t\t* 操作数也可能表示布尔值、整数值、upvalue 索引、子函数索引等，这些情况都可以归到 OpArgU 类型里\n\t* OpArgR\n\t\t* 在 iABC 模式下表示寄存器索引，\n\t\t* 在 iAsBx 模式下表示跳转偏移\n\t* OpArgK \n\t\t* 表示常量表索引或者寄存器索引\n\t\t* 第一种情况是 LOADK 指令（iABx 模式，用于将常量表中的常量加载到寄存器中），该指令的 Bx 操作数表示**常量表索引**，如果用 Kst (N)表示常量表访问，则 LOADK 指令可以表示为伪代码 R (A) := Kst (Bx)\n\t\t* 第二种情况是部分 iABC 模式指令，**这些指令的 B 或 C 操作数既可以表示常量表索引也可以表示寄存器索引**，以加法指令 ADD 为例，如果用 RK (N)表示常量表或者寄存器访问，则该指令可以表示为伪代码 R (A):= RK (B)+RK (C)。\n\n\n### 指令表 \n\nLua 官方实现把每一条指令的基本信息（包括编码模式、是否设置寄存器 A、操作数 B 和 C 的使用类型等）都编码成了一个字节。\n\n我们也对其进行模仿，只不过把字节换成结构体，\n\n\n```\n\ntype opcode struct {\n\t// operator is a test (next instruction must be a jump)\n\ttestFlag byte\n\t// 是否设置寄存器A\n\tsetAFlag byte\n\t// 操作数B使用类型\n\targBMode byte\n\t//  操作数C使用类型\n\targCMode byte\n\t// 操作模式\n\topMode byte\n\tname   string\n}\n```\n\n所有的指令\n\n```\nvar opcodes = []opcode{\n\t//T A    B       C     mode  \t   name\n\t{0, 1, OpArgR, OpArgN, IABC, \"MOVE     \"},\n\t{0, 1, OpArgK, OpArgN, IABx, \"LOADK    \"},\n\t{0, 1, OpArgN, OpArgN, IABx, \"LOADKX  \"},\n\t{0, 1, OpArgU, OpArgU, IABC, \"LOADBOOL\"},\n\t{0, 1, OpArgU, OpArgN, IABC, \"LOADNIL \"},\n\t{0, 1, OpArgU, OpArgN, IABC, \"GETUPVAL\"},\n\t{0, 1, OpArgU, OpArgK, IABC, \"GETTABUP\"},\n\t{0, 1, OpArgR, OpArgK, IABC, \"GETTABLE\"},\n\t{0, 0, OpArgK, OpArgK, IABC, \"SETTABUP\"},\n\t{0, 0, OpArgU, OpArgN, IABC, \"SETUPVAL\"},\n\t{0, 0, OpArgK, OpArgK, IABC, \"SETTABLE\"},\n\t{0, 1, OpArgU, OpArgU, IABC, \"NEWTABLE\"},\n\t{0, 1, OpArgR, OpArgK, IABC, \"SELF     \"},\n\t{0, 1, OpArgK, OpArgK, IABC, \"ADD      \"},\n\t{0, 1, OpArgK, OpArgK, IABC, \"SUB      \"},\n\t{0, 1, OpArgK, OpArgK, IABC, \"MUL      \"},\n\t{0, 1, OpArgK, OpArgK, IABC, \"MOD      \"},\n\t{0, 1, OpArgK, OpArgK, IABC, \"POW      \"},\n\t{0, 1, OpArgK, OpArgK, IABC, \"DIV      \"},\n\t{0, 1, OpArgK, OpArgK, IABC, \"IDIV     \"},\n\t{0, 1, OpArgK, OpArgK, IABC, \"BAND     \"},\n\t{0, 1, OpArgK, OpArgK, IABC, \"BOR      \"},\n\t{0, 1, OpArgK, OpArgK, IABC, \"BXOR     \"},\n\t{0, 1, OpArgK, OpArgK, IABC, \"SHL      \"},\n\t{0, 1, OpArgK, OpArgK, IABC, \"SHR      \"},\n\t{0, 1, OpArgR, OpArgN, IABC, \"UNM      \"},\n\t{0, 1, OpArgR, OpArgN, IABC, \"BNOT     \"},\n\t{0, 1, OpArgR, OpArgN, IABC, \"NOT      \"},\n\t{0, 1, OpArgR, OpArgN, IABC, \"LEN      \"},\n\t{0, 1, OpArgR, OpArgR, IABC, \"CONCAT  \"},\n\t{0, 0, OpArgR, OpArgN, IAsBx, \"JMP      \"},\n\t{1, 0, OpArgK, OpArgK, IABC, \"EQ       \"},\n\t{1, 0, OpArgK, OpArgK, IABC, \"LT       \"},\n\t{1, 0, OpArgK, OpArgK, IABC, \"LE       \"},\n\t{1, 0, OpArgN, OpArgU, IABC, \"TEST     \"},\n\t{1, 1, OpArgR, OpArgU, IABC, \"TESTSET \"},\n\t{0, 1, OpArgU, OpArgU, IABC, \"CALL     \"},\n\t{0, 1, OpArgU, OpArgU, IABC, \"TAILCALL\"},\n\t{0, 0, OpArgU, OpArgN, IABC, \"RETURN  \"},\n\t{0, 1, OpArgR, OpArgN, IAsBx, \"FORLOOP \"},\n\t{0, 1, OpArgR, OpArgN, IAsBx, \"FORPREP \"},\n\t{0, 0, OpArgN, OpArgU, IABC, \"TFORCALL\"},\n\t{0, 1, OpArgR, OpArgN, IAsBx, \"TFORLOOP\"},\n\t{0, 0, OpArgU, OpArgU, IABC, \"SETLIST \"},\n\t{0, 1, OpArgU, OpArgN, IABx, \"CLOSURE \"},\n\t{0, 1, OpArgU, OpArgN, IABC, \"VARARG  \"},\n\t{0, 0, OpArgU, OpArgU, IAx, \"EXTRAARG\"},\n}\n\n```\n\n## 指令解码\n\n定义 Instruction 类型表示指令，定义五个方法，用于解码指令\n\n\n```\nype Instruction uint32\n  \n\n// Opcode()方法从指令中提取操作F\nfunc (self Instruction) Opcode() int {\n// ABC()方法从iABC模式指令中提取参数\nfunc (self Instruction) ABC() (a, b, c int) {\n// ABx()方法从iABx模式指令中提取参数，\nfunc (self Instruction) ABx() (a, bx int) {\n// AsBx()方法从iAsBx模式指令中提取参数\nfunc (self Instruction) AsBx() (a, sbx int) {\n// Ax()方法从iAx模式指令中提取参数\nfunc (self Instruction) Ax() int{\n```\n\n\nPcode ()、ABC ()、ABx ()、Ax ()这 4 个方法比较简单，只使用位移和逻辑与运算符从指令中提取信息\n\n\nSBx 操作数（共 18 个比特）表示的是**有符号整数**。有很多种方式可以把有符号整数编码成比特序列，比如 **2 的补码**（Two's Complement）等。Lua 虚拟机这里采用了一种叫作**偏移二进制码（Offset Binary，也叫作 Excess-K）的编码模式。**\n\n\u003e **偏移二进制码（Offset Binary，也叫作 Excess-K）\n\u003e 如果把 sBx 解释成无符号整数时它的值是 x，那么解释成有符号整数时它的值就是 x-K。那么 K 是什么呢？K 取 sBx 所能表示的最大无符号整数值的一半。也就是上面代码中的 MAXARG_sBx\n\n\n\n```\nconst MAXARG_Bx = 1\u003c\u003c18-1 // 2^18-1 = 262143 const MAXARG_sBx = MAXARG_Bx \u003e\u003e 1 // 262143 / 2 = 131071\n```\n","lastmodified":"2024-03-02T12:01:53.86221037Z","tags":[]},"/lua/%E7%94%A8Go%E5%AE%9E%E7%8E%B0Lua/3.lua-API":{"title":"3.lua API","content":"\nLua 核心是以库（Library）的形式被实现的，其他应用程序只需要链接 Lua 库就可以使用 Lua 提供的 API 轻松获得脚本执行能力\n\n\u003e  Lua 发布版包含的两个命令行程序，也就是我们已经很熟悉的 lua 和 luac，实际上就是 Lua 库的两个特殊的宿主程序。\n\n\n# Lua API 介绍\n\n官方 Lua 使用 Clean C（其语法是 C 和 C++语言的子集）编写，Lua API 主要是指一系列以“lua_”开头的 C 语言函数（也可能是宏定义，后文统称为函数）。\n\n\n**Lua state 的发展**\n\n1. 最开始 Lua 解释器的状态是完全隐藏在 API 后面的，散落在各种全局变量里。\n\n2. 由于某些宿主环境（比如 Web 服务器）需要同时使用多个 Lua 解释器实例 Lua 3.1 引入了 lua_State 结构体，对解释器状态进行了封装，从而使得用户可以在多个解释器实例之间切换。\n\n3. Lua 4.0 对 API 进行了重新设计，引入了虚拟栈的概念，并且让 lua_State 结构体从幕后走到了前台。\n\n4. 用户使用 lua_newstate ()函数创建 lua_State 实例，其他函数则用于操作 lua_State 实例。\n\n\nLua API、Lua State 以及宿主程序之间的关系如图 4-1 所示\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticPasted%20image%2020230806021610.png)\n\nLua State 是 Lua API 非常核心的一个概念，在本章，我们暂时先把 **Lua State 理解成一个不那么纯粹的栈（Stack )**, 之所以不够纯粹，是因为这个栈也可以通过索引直接进行访问\n\n\n## Lua 栈\n\n\nLua State 是 Lua API 非常核心的概念，全部的 API 函数都是围绕 Lua State 进行操作，而 Lua State 内部封装的最为基础的一个状态就是**虚拟栈（后面我们称其为 Lua 栈**）\n\n\n\nLua 栈是宿主语言（对于官方 Lua 来说是 C 语言，本次是Go 语言）和 Lua 语言进行沟通的桥梁，Lua API 函数有很大一部分是专门用来操作 Lua 栈的。宿主语言、Lua 语言、Lua 栈之间的关系如图4-2所示。\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticPasted%20image%2020230806022038.png)","lastmodified":"2024-03-02T12:01:53.86221037Z","tags":[]},"/lua/Lua%E9%AB%98%E7%BA%A7":{"title":"Lua高级","content":"\n# 元表\n\n元表 _(metatable)_ 的**表现行为类似于 C++ 语言中的操作符重载**，例如我们可以重载 \"__add\" 元方法 _(metamethod)_，来计算两个 Lua 数组的并集；或者重载 \"__index\" 方法，来定义我们自己的 Hash 函数。Lua 提供了两个十分重要的用来处理元表的方法\n\n- setmetatable(table, metatable)：此方法用于为一个表设置元表。\n    \n- getmetatable(table)：此方法用于获取表的元表对象\n    \n\n设置元表\n\n```Lua\nlocal mytable = {}\nlocal mymetatable = {}\nsetmetatable(mytable, mymetatable)\n```\n\n  \n\n## **修改表的操作符行为**\n\n  \n\n通过重载 \"__add\" 元方法来计算集合的并集实例\n\n```Lua\nlocal set1 = {10, 20, 30}   -- 集合\nlocal set2 = {20, 40, 50}   -- 集合\n\n-- 将用于重载__add的函数，注意第一个参数是self\nlocal union = function (self, another)\n    local set = {}\n    local result = {}\n\n    -- 利用数组来确保集合的互异性\n    for i, j in pairs(self) do set[j] = true end\n    for i, j in pairs(another) do set[j] = true end\n\n    -- 加入结果集合\n    for i, j in pairs(set) do table.insert(result, i) end\n    return result\nend\nsetmetatable(set1, {__add = union}) -- 重载 set1 表的 __add 元方法\n\nlocal set3 = set1 + set2\nfor _, j in pairs(set3) do\n    io.write(j..\" \")               --\u003eoutput：30 50 20 40 10\nend\n```\n\n除了加法可以被重载之外，Lua 提供的所有操作符都可以被重载：\n| 元方法        | 含义                                                                         |\n|------------|----------------------------------------------------------------------------|\n| \"__add    | #NAME?                                                                     |\n| \"__sub   | - 操作 其行为类似于 \"add\" 操作                                                       |\n| \"__mul    | * 操作 其行为类似于 \"add\" 操作                                                       |\n| \"__div   | / 操作 其行为类似于 \"add\" 操作                                                       |\n| \"__mod   | % 操作 其行为类似于 \"add\" 操作                                                       |\n| \"__pow    | ^ （幂）操作 其行为类似于 \"add\" 操作                                                    |\n| \"__unm\"   | 一元 - 操作                                                                    |\n| \"__concat\" | .. （字符串连接）操作                                                               |\n| \"__len\"    | # 操作                                                                       |\n| \"__eq\"     | == 操作 函数 getcomphandler 定义了 Lua 怎样选择一个处理器来作比较操作 仅在两个对象类型相同且有对应操作相同的元方法时才起效 |\n| \"__lt\"     | \u003c 操作                                                                       |\n| \"__le\"     | \u003c= 操作                                                                      |\n\n\n除了操作符之外，如下元方法也可以被重载，下面会依次解释使用方法：\n\n|   |   |\n|---|---|\n|元方法|含义|\n|\"__index\"|取下标操作用于访问 table[key]|\n|\"__newindex\"|赋值给指定下标 table[key] = value|\n|\"__tostring\"|转换成字符串|\n|\"__call\"|当 Lua 调用一个值时调用|\n|\"__mode\"|用于弱表(week table)|\n|\"__metatable\"|用于保护metatable不被访问|\n\n## **__index 元方法**\n\n```Lua\nmytable = setmetatable({key1 = \"value1\"},   --原始表\n{__index = function(self, key)            --重载函数\n    if key == \"key2\" then\n        return \"metatablevalue\"\n    end\nend\n})\n\nprint(mytable.key1,mytable.key2)  --\u003e output：value1 metatablevalue\n```\n\n关于 __index 元方法，有很多比较高阶的技巧，例如：__index 的元方法不需要非是一个函数，他也可以是一个表。\n\n```Lua\nt = setmetatable({[1] = \"hello\"}, {__index = {[2] = \"world\"}})\nprint(t[1], t[2])   --\u003ehello wor\n```\n\n## **__tostring 元方法**\n\n  \n\n与 Java 中的 toString() 函数类似，可以实现自定义的字符串转换。\n\n```Lua\narr = {1, 2, 3, 4}\narr = setmetatable(arr, {__tostring = function (self)\n    local result = '{'\n    local sep = ''\n    for _, i in pairs(self) do\n        result = result ..sep .. i\n        sep = ', '\n    end\n    result = result .. '}'\n    return result\nend})\nprint(arr)  --\u003e {1, 2, 3, 4}\n```\n\n## **__call 元方法**\n\n__call 元方法的功能类似于 C++ 中的仿函数，使得普通的表也可以被调用。\n\n  \n\n```Lua\nfunctor = {}\nfunction func1(self, arg)\n    print (\"called from\", arg)\nend\nsetmetatable(functor, {__call = func1})\n\nfunctor(\"functor\")  --\u003e called from functor\nprint(functor)      --\u003e output：0x00076fc8 （后面这串数字可能不一样）\n```\n\n## **__metatable 元方法**\n\n假如我们想保护我们的对象使其使用者既看不到也不能修改 metatables。我**们可以对 metatable 设置了 __metatable 的值，getmetatable 将返回这个域的值，而调用 setmetatable 将会出错**：\n\n```Lua\nbject = setmetatable({}, {__metatable = \"You cannot access here\"})\n\nprint(getmetatable(Object)) --\u003e You cannot access heresetmetatable(Object, {})    --\u003e 引发编译器报错\n```\n\n  \n\n# 面向对象\n\n## 类\n\n在 Lua 中，我们可以使用表和函数实现面向对象。**将函数和相关的数据放置于同一个表中就形成了一个对象。**\n\n```Plaintext\nlocal _M = {}\n\nlocal mt = { __index = _M }\n\nfunction _M.deposit (self, v)\n    self.balance = self.balance + v\nend\n\nfunction _M.withdraw (self, v)\n    if self.balance \u003e v then\n        self.balance = self.balance - v\n    else\n        error(\"insufficient funds\")\n    end\nend\n\nfunction _M.new (self, balance)\n    balance = balance or 0\n    return setmetatable({balance = balance}, mt)\nend\n\nreturn _M\n```\n\n引用\n\n```Lua\nlocal account = require(\"account\")\n\nlocal a = account:new()\na:deposit(100)\n\nlocal b = account:new()\nb:deposit(50)\n\nprint(a.balance)  --\u003e output: 100\nprint(b.balance)  --\u003e output: 50\n```\n\n上面这段代码 \"setmetatable({balance = balance}, mt)\"，其中 mt 代表 `{ __index = _M }` ，这句话值得注意。根据我们在元表这一章学到的知识，我们明白，setmetatable 将 `_M` 作为新建表的原型，所以在自己的表内找不到 'deposit'、'withdraw' 这些方法和变量的时候，便会到 __index 所指定的 _M 类型中去寻找。\n\n  \n\n## 继承\n\n继承可以用元表实现，它提供了在父类中查找存在的方法和变量的机制。在 Lua 中是不推荐使用继承方式完成构造的，这样做引入的问题可能比解决的问题要多，下面一个是字符串操作类库，给大家演示一下。\n\n```Lua\n---------- s_base.lualocal _M = {}\n\nlocal mt = { __index = _M }\n\nfunction _M.upper (s)return string.upper(s)\nendreturn _M\n\n---------- s_more.lualocal s_base = require(\"s_base\")\n\nlocal _M = {}\n_M = setmetatable(_M, { __index = s_base })\n\n\nfunction _M.lower (s)return string.lower(s)\nendreturn _M\n\n---------- test.lualocal s_more = require(\"s_more\")\n\nprint(s_more.upper(\"Hello\"))   -- output: HELLOprint(s_more.lower(\"Hello\"))   -- output: hello\n```\n\n  \n\n## 成员私有性\n\n在动态语言中引入成员私有性并没有太大的必要，反而会显著增加运行时的开销，毕竟这种检查无法像许多静态语言那样在编译期完成。下面的技巧把对象作为各方法的 upvalue，本身是很巧妙的，但会让子类继承变得困难，同时构造函数动态创建了函数，会导致构造函数无法被 JIT 编译。\n\n在 Lua 中，成员的私有性，使用类似于函数闭包的形式来实现。在我们之前的银行账户的例子中，我们使用一个工厂方法来创建新的账户实例，通过工厂方法对外提供的闭包来暴露对外接口。而不想暴露在外的例如 balance 成员变量，则被很好的隐藏起来。\n\n```Lua\nfunction newAccount (initialBalance)\n    local self = {balance = initialBalance}\n    local withdraw = function (v)\n        self.balance = self.balance - v\n    end\n    local deposit = function (v)\n        self.balance = self.balance + v\n    end\n    local getBalance = function () \n        return self.balance \n    end\n    \n    return {\n        withdraw = withdraw,\n        deposit = deposit,\n        getBalance = getBalance\n    }\nend\n\na = newAccount(100)\na.deposit(100)\nprint(a.getBalance()) --\u003e 200print(a.balance)      --\u003e nil\n```\n\n  \n\n# 局部变量\n\nLua 的设计有一点很奇怪，**在一个 block 中的变量，如果之前没有定义过，那么认为它是一个全局变量**，**而不是这个 block 的局部变量**。这一点和别的语言不同。**容易造成不小心覆盖了全局同名变量的错误**。\n\n## **定义**\n\nLua 中的局部变量要用 local 关键字来显式定义，不使用 local 显式定义的变量就是全局变量\n\n```Lua\ng_var = 1         -- global var\nlocal l_var = 2   -- local var\n```\n\n## **作用域**\n\n**局部变量的生命周期是有限的，它的作用域仅限于声明它的块（block）**。一个块是一个控制结构的执行体、或者是一个函数的执行体再或者是一个程序块（chunk）。\n\n```Lua\nx = 10\nlocal i = 1         -- 程序块中的局部变量 i\n\nwhile i \u003c=x do\n    local x = i * 2   -- while 循环体中的局部变量 x\n    print(x)          -- output： 2, 4, 6, 8, ...\n    i = i + 1\nend\n\nif i \u003e 20 then\n    local x           -- then 中的局部变量 x\n    x = 20\n    print(x + 2)      -- 如果i \u003e 20 将会打印 22，此处的 x 是局部变量\nelse\n    print(x)          -- 打印 10，这里 x 是全局变量\nend\n\nprint(x)            -- 打印 10\n```\n\n  \n\n## 使用局部变量的好处\n\n  \n\n1. 局部变量可以避免因为命名问题污染了全局环境\n    \n2. local 变量的访问比全局变量更快\n    \n3. 由于局部变量出了作用域之后生命周期结束，这样可以被垃圾回收器及时释放\n    \n\n  \n\n  \n\n## 检测模块的函数使用局部变量\n\nfoo.lua\n\n```Lua\nlocal _M = { _VERSION = '0.01' }\n\nfunction _M.add(a, b)     --两个number型变量相加\n    return a + b\nend\n\nfunction _M.update_A()    --更新变量值\n    A = 365               -- A 是全局变量\nend\n\nreturn _M\n```\n\nuse_foo.lua\n\n```Lua\nA = 360     --定义全局变量\n\nlocal foo = require(\"foo\")\n\nlocal b = foo.add(A, A)\nprint(\"b = \", b)\n\nfoo.update_A()\nprint(\"A = \", A)\n```\n\n因为A 是全局变量，改变了A的值\n\nLua 上下文中应当严格避免使用自己定义的全局变量。**可以使用一个 lj-releng 工具来扫描 Lua 代码，定位使用 Lua 全局变量的地方**。lj-releng 的相关链接：[https://github.com/openresty/openresty-devel-utils/blob/master/lj-releng](https://github.com/openresty/openresty-devel-utils/blob/master/lj-releng)\n\nWindows 用户把 lj-releng 文件所在的目录的绝对路径添加进 PATH 环境变量。然后进入你自己的 Lua 文件所在的工作目录，得到如下结果：\n\n```Lua\n#  lj-releng\nfoo.lua: 0.01 (0.01)\nChecking use of Lua global variables in file foo.lua...\nop no.  line  instruction args  ; code\n2  [8] SETGLOBAL 0 -1  ; A\nChecking line length exceeding 80...\nWARNING: No \"_VERSION\" or \"version\" field found in `use_foo.lua`.\nChecking use of Lua global variables in file use_foo.lua...\nop no.  line  instruction args  ; code\n2  [1] SETGLOBAL 0 -1  ; A\n7  [4] GETGLOBAL 2 -1  ; A\n8  [4] GETGLOBAL 3 -1  ; A\n18 [8] GETGLOBAL 4 -1  ; A\n```\n\n当然，更推荐采用 **luacheck 来检查项目中全局变量，之后的“代码静态分析”一节，我们还会讲到如何使用 luacheck**。\n\n  \n\n# 判断数组的大小\n\n- table.getn(t) 等价于 t 但**计算的是数组元素，不包括 hash 键值**。而且数组是以第一个 nil 元素来判断数组结束。\n    \n- `#` 只计算 array 的元素个数，它实际上调用了对象的 metatable 的 `__len` 函数。对于有 `__len` 方法的函数返回函数返回值，不然就返回数组成员数目\n    \n- _Lua_ 内部实际采用哈希表和数组分别保存键值对、普通值，所以不推荐混合使用这两种赋值方式。\n    \n- Lua 数组中允许 nil 值的存在，但是数组默认结束标志却是 nil。这类比于 C 语言中的字符串，字符串中允许 '\\0' 存在，但当读到 '\\0' 时，就认为字符串已经结束了。\n    \n- 初始化是例外，在 Lua 相关源码中，初始化数组时首先判断数组的长度，若长度大于 0 ，并且最后一个值不为 nil，返回包括 nil 的长度；若最后一个值为 nil，则返回截至第一个非 nil 值的长度。\n    \n- **如果你要删除一个数组中的元素，请使用 remove 函数，而不是用 nil 赋值**\n    \n\n```Lua\n-- test.lua\nlocal tblTest1 = { 1, a = 2, 3 }\nprint(\"Test1 \" .. #(tblTest1))\n\nlocal tblTest2 = { 1, nil }\nprint(\"Test2 \" .. #(tblTest2))\n\nlocal tblTest3 = { 1, nil, 2 }\nprint(\"Test3 \" .. #(tblTest3))\n\nlocal tblTest4 = { 1, nil, 2, nil }\nprint(\"Test4 \" .. #(tblTest4))\n\nlocal tblTest5 = { 1, nil, 2, nil, 3, nil }\nprint(\"Test5 \" .. #(tblTest5))\n\nlocal tblTest6 = { 1, nil, 2, nil, 3, nil, 4, nil }\nprint(\"Test6 \" .. #(tblTest6))\n```\n\n我们分别使用 Lua 和 LuaJIT 来执行一下：\n\n```Lua\n➜ luajit test.lua\nTest1 2\nTest2 1\nTest3 1\nTest4 1\nTest5 1\nTest6 1\n\n➜ lua test.lua\nTest1 2\nTest2 1\nTest3 3\nTest4 1\nTest5 3\nTest6 1\n```\n\n这一段的输出结果，就是这么 **匪夷所思**。不要在 Lua 的 table 中使用 nil 值，**如果一个元素要删除，直接 remove，不要用 nil 去代替**。\n\n  \n\n# 非空判断\n\n  \n\n有时候不小心引用了一个没有赋值的变量，这时它的值默认为 nil。如果对一个 nil 进行索引的话，会导致异常。\n\n```Plaintext\nlocal person = {name = \"Bob\", sex = \"M\"}\n\n-- do something\nperson = nil\n-- do something\nprint(person.name)\n```\n\n会报错\n\n```Lua\nstdin:1:attempt to index global 'person' (a nil value)\nstack traceback:\n   stdin:1: in main chunk\n   [C]: ?\n```\n\n在实际的工程代码中，我们很难这么轻易地发现我们引用了 nil 变量。因此，在很多情况下我们在访问一些 table 型变量时，需要先判断该变量是否为 nil，例如将上面的代码改成\n\n```Lua\nlocal person = {name = \"Bob\", sex = \"M\"}\n\n-- do something\nperson = nil\n-- do something\nif person ~= nil and person.name ~= nil then\n    print(person.name)\nelse\n-- do somethingend\n```\n\n对于简单类型的变量，我们可以用 _if (var == nil) then_ 这样的简单句子来判断。**但是对于 table 型的 Lua 对象，就不能这么简单判断它是否为空了。一个 table 型变量的值可能是** **`{}`**，这时它不等于 nil。我们来看下面这段代码：\n\n```Lua\nlocal next = next\nlocal a = {}\nlocal b = {name = \"Bob\", sex = \"Male\"}\nlocal c = {\"Male\", \"Female\"}\nlocal d = nil\n\nprint(#a)\nprint(#b)\nprint(#c)\n--print(#d)    -- error\n\nif a == nil then\n    print(\"a == nil\")\nend\n\nif b == nil then\n    print(\"b == nil\")\nend\n\nif c == nil then\n    print(\"c == nil\")\nend\n\nif d== nil then\n    print(\"d == nil\")\nend\n\nif next(a) == nil then\n    print(\"next(a) == nil\")\nend\n\nif next(b) == nil then\n    print(\"next(b) == nil\")\nend\n\nif next(c) == nil then\n    print(\"next(c) == nil\")\nend\n```\n\n输出\n\n```Lua\n0\n0\n2\nd == nil\nnext(a) == nil\n```\n\n因此，我们要判断一个 table 是否为 `{}`，不能采用 `#table == 0` 的方式来判断。可以用下面这样的方法来判断：\n\n```Plaintext\nfunction isTableEmpty(t)\n    return t == nil or next(t) == nil\nend\n```\n\n注意：**`next`** **指令是不能被 LuaJIT 的 JIT 编译优化，并且 LuaJIT 貌似没有明确计划支持这个指令优化，在不是必须的情况下，尽量少用。**\n\n  \n\n# 正则表达式\n\n同时存在两套正则表达式规范：_Lua_ 语言的规范和 `ngx.re.*` 的规范，即使您对 _Lua_ 语言中的规范非常熟悉，我们仍不建议使用 _Lua_ 中的正则表达式。\n\n- 一是因为 _Lua_ 中正则表达式的性能并不如 `ngx.re.*` 中的正则表达式优秀；\n    \n- 二是 _Lua_ 中的正则表达式并不符合 _POSIX_ 规范，而 `ngx.re.*` 中实现的是标准的 _POSIX_ 规范，后者明显更具备通用性。\n    \n\n`ngx.re.*` 中的 `o` 选项，指明该参数，被编译的 Pattern 将会在工作进程中缓存，并且被当前工作进程的每次请求所共享。Pattern 缓存的上限值通过 `lua_regex_cache_max_entries` 来修改，它的默认值为1024。\n\n`ngx.re.*` 中的 `j` 选项，指明该参数，如果使用的 PCRE 库支持 JIT，OpenResty 会在编译 Pattern 时启用 JIT。启用 JIT 后正则匹配会有明显的性能提升。较新的平台，自带的 PCRE 库均支持 JIT。如果系统自带的 PCRE 库不支持 JIT，出于性能考虑，最好自己编译一份 libpcre.so，然后在编译 OpenResty 时链接过去。要想验证当前 PCRE 库是否支持 JIT，可以这么做\n\n1. 编译 OpenResty 时在 `./configure` 中指定 `--with-debug` 选项\n    \n2. 在 `error_log` 指令中指定日志级别为 `debug`\n    \n3. 运行正则匹配代码，查看日志中是否有 `pcre JIT compiling result: 1`\n    \n\n即使运行在不支持 JIT 的 OpenResty 上，加上 `j` 选项也不会带来坏的影响。在 OpenResty 官方的 Lua 库中，正则匹配至少都会带上 `jo` 这两个选项。\n\n```Lua\nlocation /test {\n    content_by_lua_block {\n        local regex = [[\\d+]]\n\n        -- 参数 \"j\" 启用 JIT 编译，参数 \"o\" 是开启缓存必须的\n        local m = ngx.re.match(\"hello, 1234\", regex, \"jo\")\n        if m then\n            ngx.say(m[0])\n        else\n            ngx.say(\"not matched!\")\n        end\n    }\n}\n```\n\n#### **Lua 正则简单汇总**\n\n_Lua_ 中正则表达式语法上最大的区别，_Lua_ 使用 _'%'_ 来进行转义，而其他语言的正则表达式使用 _'\\'_ 符号来进行转义。其次，_Lua_ 中并不使用 _'?'_ 来表示非贪婪匹配，而是定义了不同的字符来表示是否是贪婪匹配。定义如下：\n\n|符号|匹配次数|匹配模式|\n|---|---|---|\n|+|匹配前一字符 1 次或多次|非贪婪|\n|`*`|匹配前一字符 0 次或多次|贪婪|\n|-|匹配前一字符 0 次或多次|非贪婪|\n|?|匹配前一字符 0 次或1次|仅用于此，不用于标识是否贪婪|\n\n|符号|匹配模式|\n|---|---|\n|.|任意字符|\n|%a|字母|\n|%c|控制字符|\n|%d|数字|\n|%l|小写字母|\n|%p|标点字符|\n|%s|空白符|\n|%u|大写字母|\n|%w|字母和数字|\n|%x|十六进制数字|\n|%z|代表 0 的字符|\n\n  \n\n# 虚变量\n\n当一个方法返回多个值时，有些返回值有时候用不到，要是声明很多变量来一一接收，显然不太合适（不是不能）。**Lua 提供了一个虚变量(dummy variable)的概念， 按照****[惯例](https://www.lua.org/pil/1.3.html)****以一个下划线（“_”）来命名，用它来表示丢弃不需要的数值，仅仅起到占位的作用。**\n\n  \n\n## 返回值\n\n```Lua\n-- string.find (s,p) 从string 变量s的开头向后匹配 string\n-- p，若匹配不成功，返回nil，若匹配成功，返回第一次匹配成功\n-- 的起止下标。\n\nlocal start, finish = string.find(\"hello\", \"he\") --start 值为起始下标，finish\n--值为结束下标\nprint ( start, finish )                          --输出 1   2\n\nlocal start = string.find(\"hello\", \"he\")      -- start值为起始下标\nprint ( start )                               -- 输出 1\n\n\nlocal _,finish = string.find(\"hello\", \"he\")   --采用虚变量（即下划线），接收起\n--始下标值，然后丢弃，finish接收\n--结束下标值\nprint ( finish )                              --输出 2\nprint ( _ )    \n```\n\n  \n\n## 迭代\n\n```Lua\n-- test.lua 文件\nlocal t = {1, 3, 5}\n\nprint(\"all  data:\")\nfor i,v in ipairs(t) do\n    print(i,v)\nend\n\nprint(\"\")\nprint(\"part data:\")\nfor _,v in ipairs(t) do\n    print(v)\nend\n```\n\n输出\n\n```Lua\n# luajit test.lua\nall  data:\n1   1\n2   3\n3   5\n\npart data:\n1\n3\n5\n```\n\n# **抵制使用 module() 定义模块**\n\n旧式的模块定义方式是通过 `module(\"filename\"[,package.seeall])*` 来显式声明一个包，现在官方不推荐再使用这种方式\n\n这种方式将会返回一个由 `filename` 模块函数组成的 `table`，并且还会定义一个包含该 `table` 的全局变量。\n\n  \n\n1. `package.seeall` 这种方式破坏了模块的高内聚，原本引入 \"filename\" 模块只想调用它的 _foobar()_ 函数，但是它却可以读写全局属性，例如 `\"filename.os\"`。\n    \n2. `module` 函数压栈操作引发的副作用，污染了全局环境变量。例如 `module(\"filename\")` 会创建一个 `filename` 的 `table`，并将这个 `table` 注入全局环境变量中，这样使得没有引用它的文件也能调用 `filename` 模块的方法。\n    \n\n  \n\n推荐的模块定义\n\n```Lua\n-- square.lua 长方形模块\nlocal _M = {}           -- 局部的变量\n_M._VERSION = '1.0'     -- 模块版本\n\nlocal mt = { __index = _M }\n\nfunction _M.new(self, width, height)\n    return setmetatable({ width=width, height=height }, mt)\nend\n\nfunction _M.get_square(self)\n    return self.width * self.height\nend\n\nfunction _M.get_circumference(self)\n    return (self.width + self.height) * 2\nend\n\nreturn _M\n```\n\n使用\n\n```Lua\nlocal square = require \"square\"\nlocal s1 = square:new(1, 2)\nprint(s1:get_square())          --output: 2\nprint(s1:get_circumference())   --output: 6\n```\n\n另一个跟 Lua 的 module 模块相关需要注意的点是，当 lua_code_cache on 开启时，require 加载的模块是会被缓存下来的，这样我们的模块就会以最高效的方式运行，直到被显式地调用如下语句（这里有点像模块卸载）：\n\n```Plaintext\npackage.loaded[\"square\"] = nil\n```\n\n  \n\n## 调用函数前先定义函数\n\nLua 里面的函数必须放在调用的代码之前，下面的代码是一个常见的错误：\n\n```Lua\n-- test.lua 文件local i = 100\ni = add_one(i)\n\nfunction add_one(i)\n    return i + 1\nend\n```\n\n因此在函数定义之前使用函数相当于在变量赋值之前使用变量，Lua 世界对于没有赋值的变量，默认都是 nil，所以这里也就产生了一个 nil 的错误。\n\n  \n\n# 点号操作符和冒号操作符的区别\n\n```Plaintext\nlocal str = \"abcde\"\n\nprint(\"case 1:\", str:sub(1, 2))\nprint(\"case 2:\", str.sub(str, 1, 2))\n```\n\n输出\n\n```Lua\ncase 1: ab\ncase 2: ab\n```\n\n- **冒号操作会带入一个** **`self`** **参数，用来代表** **`自己`****。**\n    \n- 而点号操作，只是 `内容` 的展开。\n    \n\n在函数定义时，使用冒号将默认接收一个 `self` 参数，而使用点号则需要显式传入 `self` 参数\n\n示例代码：\n\n```Plaintext\nobj = { x = 20 }\n\nfunction obj:fun1()\n    print(self.x)\nend\n```\n\n等价于\n\n```Plaintext\nobj = { x = 20 }\n\nfunction obj.fun1(self)\n    print(self.x)\nend\n```\n\n# module的缺点\n\n由于 `lua_code_cache off` 情况下，缓存的代码会伴随请求完结而释放。module 的最大好处缓存这时候是无法发挥的，所以本章的内容都是基于 `lua_code_cache on` 的情况下。\n\n先看看下面代码：\n\n```Plaintext\nlocal ngx_socket_tcp = ngx.socket.tcp           -- ①\n\nlocal _M = { _VERSION = '0.06' }                -- ②\nlocal mt = { __index = _M }                     -- ③\n\nfunction _M.new(self)\n    local sock, err = ngx_socket_tcp()          -- ④\n    if not sock then\n        return nil, err\n    end\n    return setmetatable({ sock = sock }, mt)    -- ⑤\nend\n\nfunction _M.set_timeout(self, timeout)\n    local sock = self.sock\n    if not sock then\n        return nil, \"not initialized\"\n    end\n\n    return sock:settimeout(timeout)\nend\n\n-- ... 其他功能代码，这里简略\n\nreturn _M\n```\n\n1. 对于比较底层的模块，内部使用到的非本地函数，都需要 local 本地化，这样做的好处：\n    \n    1. 避免命名冲突：防止外部是 `require(...)` 的方法调用造成全局变量污染\n        \n    2. 访问局部变量的速度比全局变量更快、更快、更快（重要事情说三遍）\n        \n\n  \n\n2. 每个基础模块最好有自己 `_VERSION` 标识，方便后期利用 `_VERSION` 完成热代码部署等高级特性，也便于使用者对版本有整体意识。\n    \n3. 其实 `_M` 和 `mt` 对于不同的请求实例（require 方法得到的对象）是相同的，因为 module 会被缓存到全局环境中。所以在这个位置千万不要放单请求内个性信息，例如 ngx.ctx 等变量。\n    \n4. **这里需要实现的是给每个实例绑定不同的 tcp 对象**，后**面 setmetatable 确保了每个实例拥有自己的 socket 对象，所以必须放在 new 函数中**。如果放在 ③ 的下面，那么这时候所有的不同实例内部将绑定了同一个 socket 对象。\n    \n\n```Plaintext\nlocal mt = { __index = _M }                     -- ③\nlocal sock = ngx_socket_tcp()                   -- ④ 错误的\n\nfunction _M.new(self)\n    return setmetatable({ sock = sock }, mt)    -- ⑤\nend\n```\n\n5. Lua 的 module 有两种类型：\n    \n    1. 支持面向对象痕迹可以保留私有属性；静态方法提供者，没有任何私有属性。\n        \n    2. 真正起到区别作用的就是 setmetatable 函数，是否有自己的个性元表，最终导致两种不同的形态。\n        \n\n# FFI\n\nhttps://moonbingbing.gitbooks.io/openresty-best-practices/content/lua/FFI.html\n\nFFI 库，是 LuaJIT 中最重要的一个扩展库。它允许从纯 Lua 代码调用外部 C 函数，使用 C 数据结构。\n\n  \n\nFFI 库最大限度的省去了使用 C 手工编写繁重的 `Lua/C` 绑定的需要。不需要学习一门独立/额外的绑定语言——它解析普通 C 声明。这样可以从 C 头文件或参考手册中，直接剪切，粘贴。它的任务就是绑定很大的库，但不需要捣鼓脆弱的绑定生成器。\n\nFFI 紧紧的整合进了 LuaJIT（几乎不可能作为一个独立的模块）。`JIT` 编译器在 C 数据结构上所产生的代码，等同于一个 C 编译器应该生产的代码。在 `JIT` 编译过的代码中，调用 C 函数，可以被内连处理，不同于基于 `Lua/C API` 函数调用。\n\n  \n\n## **ffi 库 词汇**\n\n|   |   |\n|---|---|\n|noun|Explanation|\n|cdecl|A definition of an abstract C type(actually, is a lua string)|\n|ctype|C type object|\n|cdata|C data object|\n|ct|C type format, is a template object, may be cdecl, cdata, ctype|\n|cb|callback object|\n|VLA|An array of variable length|\n|VLS|A structure of variable length|\n\n## **ffi.* API**\n\n**功能：** _Lua ffi 库的 API，与 LuaJIT 不可分割。_\n\n毫无疑问，在 `lua` 文件中使用 `ffi` 库的时候，必须要有下面的一行。\n\n```Plaintext\nlocal ffi = require \"ffi\"\n```\n\n# JIT\n\n看一下 LuaJIT 官方的解释：LuaJIT is a Just-In-Time Compilerfor the Lua programming language。\n\n**LuaJIT 的运行时环境包括一个用手写汇编实现的 Lua 解释器和一个可以直接生成机器代码的 JIT 编译器**\n\n- 一开始的时候，Lua 字节码总是被 LuaJIT 的解释器解释执行。LuaJIT 的解释器会在执行字节码时同时记录一些运行时的统计信息，比如每个 Lua 函数调用入口的实际运行次数，还有每个 Lua 循环的实际执行次数。\n    \n- 当这些次数超过某个预设的阈值时，便认为对应的 Lua 函数入口或者对应的 Lua 循环足够的“热”，这时便会触发 JIT 编译器开始工作。\n    \n- JIT 编译器会从热函数的入口或者热循环的某个位置开始尝试编译对应的 Lua 代码路径。编译的过程是把 LuaJIT 字节码先转换成 LuaJIT 自己定义的中间码（IR），然后再生成针对目标体系结构的机器码（比如 x86_64 指令组成的机器码）\n    \n- 如果当前 Lua 代码路径上的所有的操作都可以被 JIT 编译器顺利编译，则这条编译过的代码路径便被称为一个“trace”，在物理上对应一个 `trace` 类型的 GC 对象（即参与 Lua GC 的对象）。\n    \n\n  \n\nJIT 编译器不支持的原语被称为 **NYI（Not Yet Implemented）原语**。比较完整的 NYI 列表在这篇文档里面：\n\n```Plaintext\nhttp://wiki.luajit.org/NYI\n```\n\n所谓“让更多的 Lua 代码被 JIT 编译”，其实就是帮助更多的 Lua 代码路径能为 JIT 编译器所接受。这一般通过两种途径来实现：\n\n1. 调整对应的 Lua 代码，**避免使用 NYI 原语**。\n    \n2. 增强 JIT 编译器，让越来越多的 NYI 原语能够被编译。\n    \n\n## **可以被 JIT 编译的元操作**\n\n下面给大家列一下截止到目前已经可以被 JIT 编译的元操作。 其他还有 IO、Bit、FFI、Coroutine、OS、Package、Debug、JIT 等分类，使用频率相对较低，这里就不罗列了，可以参考官网：[http://wiki.luajit.org/NYI](http://wiki.luajit.org/NYI)。\n\n### **基础库的支持情况**\n\n|   |   |   |\n|---|---|---|\n|函数|编译?|备注|\n|assert|yes||\n|collectgarbage|no||\n|dofile|never||\n|error|never||\n|getfenv|2.1 partial|只有 getfenv(0) 能编译|\n|getmetatable|yes||\n|ipairs|yes||\n|load|never||\n|loadfile|never||\n|loadstring|never||\n|next|no||\n|pairs|no||\n|pcall|yes||\n|print|no||\n|rawequal|yes||\n|rawget|yes||\n|rawlen (5.2)|yes||\n|rawset|yes||\n|select|partial|第一个参数是静态变量的时候可以编译|\n|setfenv|no||\n|setmetatable|yes||\n|tonumber|partial|不能编译非10进制，非预期的异常输入|\n|tostring|partial|只能编译：字符串、数字、布尔、nil 以及支持 __tostring元方法的类型|\n|type|yes||\n|unpack|no||\n|xpcall|yes||\n\n### **字符串库**\n\n|   |   |   |\n|---|---|---|\n|函数|编译?|备注|\n|string.byte|yes||\n|string.char|2.1||\n|string.dump|never||\n|string.find|2.1 partial|只有字符串样式查找（没有样式）|\n|string.format|2.1 partial|不支持 %p 或 非字符串参数的 %s|\n|string.gmatch|no||\n|string.gsub|no||\n|string.len|yes||\n|string.lower|2.1||\n|string.match|no||\n|string.rep|2.1||\n|string.reverse|2.1||\n|string.sub|yes||\n|string.upper|2.1||\n\n### **表**\n\n|   |   |   |\n|---|---|---|\n|函数|编译?|备注|\n|table.concat|2.1||\n|table.foreach|no|2.1: 内部编译，但还没有外放|\n|table.foreachi|2.1||\n|table.getn|yes||\n|table.insert|partial|只有 push 操作|\n|table.maxn|no||\n|table.pack (5.2)|no||\n|table.remove|2.1|部分，只有 pop 操作|\n|table.sort|no||\n|table.unpack (5.2)|no||\n\n### **math 库**\n\n|   |   |   |\n|---|---|---|\n|函数|编译?|备注|\n|math.abs|yes||\n|math.acos|yes||\n|math.asin|yes||\n|math.atan|yes||\n|math.atan2|yes||\n|math.ceil|yes||\n|math.cos|yes||\n|math.cosh|yes||\n|math.deg|yes||\n|math.exp|yes||\n|math.floor|yes||\n|math.fmod|no||\n|math.frexp|no||\n|math.ldexp|yes||\n|math.log|yes||\n|math.log10|yes||\n|math.max|yes||\n|math.min|yes||\n|math.modf|yes||\n|math.pow|yes||\n|math.rad|yes||\n|math.random|yes||\n|math.randomseed|no||\n|math.sin|yes||\n|math.sinh|yes||\n|math.sqrt|yes||\n|math.tan|yes||\n|math.tanh|yes||","lastmodified":"2024-03-02T12:01:53.86221037Z","tags":["lua"]},"/lua/lua%E5%9F%BA%E7%A1%80":{"title":"lua基础","content":"\n\n# Lua 简介\n\nLua 是一个小巧的脚本语言。是巴西里约热内卢天主教大学（Pontifical Catholic University of Rio de Janeiro）里的一个研究小组并于 1993 年开发。**其设计目的是为了嵌入应用程序中，从而为应用程序提供灵活的扩展和定制功能**。Lua 由标准 C 编写而成，几乎在所有操作系统和平台上都可以编译、运行。Lua 并没有提供强大的库，这是由它的定位决定的。所以 Lua 不适合作为开发独立应用程序的语言。**Lua 有一个同时进行的 JIT 项目，提供在特定平台上的即时编译功能**。\n\n- **Lua 脚本可以很容易的被 C/C++ 代码调用，也可以反过来调用 C/C++ 的函数，这使得 Lua 在应用程序中可以被广泛应用**。\n    \n- **不仅仅作为扩展脚本，也可以作为普通的配置文件，代替 XML、ini 等文件格式，并且更容易理解和维护**。\n    \n- 标准 Lua 5.1 解释器由标准 C 编写而成，代码简洁优美，几乎在所有操作系统和平台上都可以编译和运行；\n    \n- 一个完整的标准 Lua 5.1 解释器不足 200 KB。而本书推荐使用的 LuaJIT 2 的代码大小也只有不足 500 KB\n    \n- 同时也支持大部分常见的体系结构。在目前所有脚本语言引擎中，LuaJIT 2 实现的速度应该算是最快的之一。这一切都决定了 Lua 是作为嵌入式脚本的最佳选择。\n    \n\nLua 语言的各个版本是不相兼容的。因此本书只介绍 Lua 5.1 语言，这是为标准 Lua 5.1 解释器和 LuaJIT 2 所共同支持的。LuaJIT 支持的对 Lua 5.1 向后兼容的 Lua 5.2 和 Lua 5.3 的特性，我们也会在方便的时候予以介绍。\n\n  \n\n# Lua 环境搭建\n\n[http://openresty.org](http://openresty.org/)\n\n  \n\n## Helloworld\n\n```Go\n# cat hello.lua\nprint(\"hello world\")\n# luajit hello.lua\nhello world\n```\n\n  \n\n# 基本数据类型\n\n  \n\n```Go\nprint(type(\"helloworld\"))\nprint(type('helloworld'))\nprint(type('true'))\nprint(type(1))\nprint(type(2.1))\nprint(type(nil))\nfunction hello()\n    print(\"hello\")\nend\nprint(type(hello))\n```\n\n输出\n\n```Go\nstring\nstring\nstring\nnumber\nnumber\nnil\nfunction\n```\n\n## Nil\n\nNil 是一种类型，Lua 将 nil 用于表示“无效值”。\n\n- 一个变量在第一次赋值前的默认值是 nil，\n    \n- 将 nil 赋予给一个全局变量就等同于删除它。\n    \n\n```Go\nlocal num\nprint(num)        --\u003eoutput:nil\n\nnum = 100\nprint(num)        --\u003eoutput:100\n```\n\n## Boolean (布尔)\n\n布尔类型，可选值 true/false；\n\n- Lua 中 nil 和 false 为“假”\n    \n- 其它所有值均为“真”。比如 0 和空字符串就是“真”；\n    \n\n```Go\nlocal a = true\nlocal b = 0\nlocal c = nil\nif a then\n    print(\"a\")        --\u003eoutput:a\nelse\n    print(\"not a\")    --这个没有执行\nend\n\nif b then\n    print(\"b\")        --\u003eoutput:b\nelse\n    print(\"not b\")    --这个没有执行\nend\n\nif c then\n    print(\"c\")        --这个没有执行\nelse\n    print(\"not c\")    --\u003eoutput:not c\nend\n```\n\n## **number（数字）**\n\nNumber 类型用于表示实数，和 C/C++ 里面的 double 类型很类似。可以使用数学函数 math. Floor（向下取整）和 math. Ceil（向上取整）进行取整操作。\n\n一般地，Lua 的 number 类型就是用双精度浮点数来实现的。值得一提的是，LuaJIT 支持所谓的“dual-number”（双数）模式，\n\n- 即 **LuaJIT 会根据上下文用整型来存储整数，而用双精度浮点数来存放浮点数。**\n    \n\n```Go\nlocal order = 3.99\nlocal score = 98.01\nprint(math.floor(order))   --\u003eoutput:3\nprint(math.ceil(score))    --\u003eoutput:99\nprint(9223372036854775807LL - 1)  --\u003eoutput:9223372036854775806LL\n```\n\n## String（字符串）\n\nLua 中有三种方式表示字符串:\n\n1. 使用一对匹配的单引号。例：'hello'。\n    \n2. 使用一对匹配的双引号。例：\"abclua\"。\n    \n3. 字符串还可以用一种长括号（即 [[ ]]）括起来的方式定义\n    \n    1. 我们把两个正的方括号（即[[）间插入 n 个等号定义为第 n 级正长括号。\n        \n    2. 0 级正的长括号写作 [[ ，一级正的长括号写作 [=[\n        \n    3. 反的长括号也作类似定义；举个例子，4 级反的长括号写作 ]====]\n        \n    4. **一个长字符串可以由任何一级的正的长括号开始，而由第一个碰到的同级反的长括号结束**。整个词法分析过程将**不受分行限制，不处理任何转义符，并且忽略掉任何不同级别的长括号**\n        \n\n  \n\n```Plaintext\nlocal str1 = 'hello world'\nlocal str2 = \"hello lua\"\nlocal str3 = [[\"add\\name\",'hello']]\nlocal str4 = [=[string have a [[]].]=]\nlocal str5 = [=[asdfasd]=]\n\nprint(str1)    --\u003eoutput:hello world\nprint(str2)    --\u003eoutput:hello lua\nprint(str3)    --\u003eoutput:\"add\\name\",'hello'\nprint(str4)    --\u003eoutput:string have a [[]].\nprint(str5)    --\u003eoutput:asdfasd\n```\n\n在 Lua 实现中，Lua 字符串一般都会经历一个“内化”（intern）的过程，**即两个完全一样的 Lua 字符串在 Lua 虚拟机中只会存储一份**。每一个 Lua 字符串在创建时都会**插入到 Lua 虚拟机内部的一个全局的哈希表**中\n\n1. 创建相同的 Lua 字符串并不会引入新的动态内存分配操作，所以相对便宜（但仍有全局哈希表查询的开销），\n    \n2. 内容相同的 Lua 字符串不会占用多份存储空间，\n    \n3. 已经创建好的 Lua 字符串之间进行相等性比较时是 `O(1)` 时间度的开销，而不是通常见到的 `O(n)`.\n    \n\n## Table (表)\n\nTable 类型实现了一种抽象的“关联数组”。“关联数组”是一种具有特殊索引方式的数组，\n\n- 索引通常是**字符串（string）或者 number 类型，但也可以是除** **`nil`** **以外的任意类型的值**\n    \n\n```Go\n\nlocal corp = {\n    web = \"www.google.com\",   --索引为字符串，key = \"web\",\n    --            value = \"www.google.com\"\n    telephone = \"12345678\",   --索引为字符串\n    staff = {\"Jack\", \"Scott\", \"Gary\"}, --索引为字符串，值也是一个表\n    100876,              --相当于 [1] = 100876，此时索引为数字\n    --      key = 1, value = 100876\n    100191,              --相当于 [2] = 100191，此时索引为数字\n    [10] = 360,          --直接把数字索引给出\n    [\"city\"] = \"Beijing\" --索引为字符串\n}\n\nprint(corp.web)               --\u003eoutput:www.google.com\nprint(corp[\"web\"])               --\u003eoutput:www.google.com\nprint(corp[\"telephone\"])      --\u003eoutput:12345678\nprint(corp[2])                --\u003eoutput:100191\nprint(corp[\"city\"])           --\u003eoutput:\"Beijing\"\nprint(corp.staff[1])          --\u003eoutput:Jack\nprint(corp[\"staff\"][1])          --\u003eoutput:Jack\nprint(corp[10])               --\u003eoutput:360\n```\n\n在内部实现上，table 通常实现为一个哈希表、一个数组、或者两者的混合。具体的实现为何种形式，动态依赖于具体的 table 的键分布特点。\n\n## Function (函数)\n\n在 Lua 中，**函数** 也是一种数据类型，函数可以存储在变量中，可以通过参数传递给其他函数，还可以作为其他函数的返回值\n\n```Go\nlocal function foo()\n    print(\"in the function\")\n    --dosomething()\n    local x = 10\n    local y = 20\n    return x + y\nend\n\nlocal a = foo    --把函数赋给变量\n\nprint(a())\n\n--output:\n--in the function\n--30\n\nfunction foo()\nend\n--等价于\n\nfoo = function ()\nend\n\nlocal function foo()\nend\n-- 等价于\n\nlocal foo = function ()\nend\n```\n\n  \n\n# 表达式\n\n## 算术运算符\n\n|            |      |\n| ---------- | ---- |\n| 算术运算符 | 说明 |\n| +          | 加法 |\n| -          | 减法 |\n| *          | 乘法 |\n| /          | 除法 |\n| ^          | 指数 |\n| %          | 取模 |\n\n```Go\nprint(1 + 2)       --\u003e打印 3\nprint(5 / 10)      --\u003e打印 0.5。 这是Lua不同于c语言的\nprint(5.0 / 10)    --\u003e打印 0.5。 浮点数相除的结果是浮点数\n-- print(10 / 0)   --\u003e注意除数不能为0，计算的结果会出错\nprint(2 ^ 10)      --\u003e打印 1024。 求2的10次方\n\nlocal num = 1357\nprint(num % 2)       --\u003e打印 1\nprint((num % 2) == 1) --\u003e打印 true。 判断num是否为奇数\n```\n\n## 关系运算符\n\n  \n\n|            |          |\n| ---------- | -------- |\n| 关系运算符 | 说明     |\n| \u003c          | 小于     |\n| \u003e          | 大于     |\n| \u003c=         | 小于等于 |\n| \u003e=         | 大于等于 |\n| ==         | 等于     |\n| ~=         | 不等于   |\n\n  \n\n```Go\nprint(1 \u003c 2)    --\u003e打印 true\nprint(1 == 2)   --\u003e打印 false\nprint(1 ~= 2)   --\u003e打印 true\nlocal a, b = true, false\nprint(a == b)  --\u003e打印 false\n```\n\n- 在使用“==”做等于判断时，要注意对于 table, userdate 和函数， Lua 是作引用比较的。也就是说，只有当两个变量引用同一个对象时，才认为它们相等\n    \n\n```Go\nlocal a = { x = 1, y = 0}\nlocal b = { x = 1, y = 0}\nif a == b then\n    print(\"a==b\")\nelse\n    print(\"a~=b\")\nend\n---output:\na~=b\n```\n\n- Lua 字符串总是会被“内化”，即相同内容的字符串只会被保存一份，因此 Lua 字符串之间的相等性比较可以简化为其内部存储地址的比较。\n    \n- 这意味着 Lua 字符串的相等性比较总是为 O (1)\n    \n\n## 逻辑运算符\n\n|            |        |\n| ---------- | ------ |\n| 逻辑运算符 | 说明   |\n| and        | 逻辑与 |\n| or         | 逻辑或 |\n| not        | 逻辑非 |\n\n在 c 语言中，and 和 or 只得到两个值 1 和 0，其中 1 表示真，0 表示假。而 Lua 中 and 的执行过程是这样的：\n\n- `a and b` 如果 a 为 nil，则返回 a，否则返回 b;\n    \n- `a or b` 如果 a 为 nil，则返回 b，否则返回 a。\n    \n- **所有逻辑操作符将 false 和 nil 视作假，其他任何值视作真，对于 and 和 or，“短路求值”，对于 not，永远只返回 true 或者 false。**\n    \n\n```Go\nlocal c = nil\nlocal d = 0\nlocal e = 100\nprint(c and d)  --\u003e打印 nil\nprint(c and e)  --\u003e打印 nil\nprint(d and e)  --\u003e打印 100\nprint(c or d)   --\u003e打印 0\nprint(c or e)   --\u003e打印 100\nprint(not c)    --\u003e打印 true\nprint(not d)    --\u003e打印 false\n```\n\n## 字符串连接\n\nLua 中连接两个字符串，可以使用操作符“..”（两个点）\n\n- 如果其任意一个操作数是数字的话，Lua 会将这个数字转换成字符串。\n    \n- 注意，连接操作符只会创建一个新字符串，而不会改变原操作数\n    \n- 也可以使用 string 库函数 `string.format` 连接字符串\n    \n\n```Go\nprint(\"Hello \" .. \"World\")    --\u003e打印 Hello Worldprint(0 .. 1)                 --\u003e打印 01\n\nstr1 = string.format(\"%s-%s\",\"hello\",\"world\")\nprint(str1)              --\u003e打印 hello-world\n\nstr2 = string.format(\"%d-%s-%.2f\",123,\"world\",1.21)\nprint(str2)              --\u003e打印 123-world-1.21\n```\n\n于 Lua 字符串本质上是只读的，**因此字符串连接运算符几乎总会创建一个新的（更大的）字符串**。这意味着如果有很多这样的连接操作（比如在循环中使用 .. 来拼接最终结果），则性能损耗会非常大。在这种情况下，推荐使用 table 和 `table.concat()` 来进行很多字符串的拼接\n\n```Go\nlocal pieces = {}\nfor i, elem in ipairs(my_list) do\n    pieces[i] = my_process(elem)\nend\nlocal res = table.concat(pieces)\n```\n\n上面的例子还可以使用 LuaJIT 独有的 `table.new` 来恰当地初始化 `pieces` 表的空间，以避免该表的动态生长。\n\n## 优先级\n\n| f               |     |\n| --------------- | --- |\n| ^               |     |\n| not # -         |     |\n| * / %           |     |\n| + -             |     |\n| ..              |     |\n| \u003c \u003e \u003c= \u003e= == ~= |     |\n| and             |     |\n| or              |     |\n  \n\n```Go\nlocal a, b = 1, 2\nlocal x, y = 3, 4\nlocal i = 10\nlocal res = 0\nres = a + i \u003c b/2 + 1  --\u003e等价于res =  (a + i) \u003c ((b/2) + 1)\nres = 5 + x^2*8        --\u003e等价于res =  5 + ((x^2) * 8)\nres = a \u003c y and y \u003c=x  --\u003e等价于res =  (a \u003c y) and (y \u003c= x)\n```\n\n  \n\n# 控制结构\n\n## If-else\n\n### **单个 if 分支型**\n\n```Go\nx = 10\nif x \u003e 0 then\n    print(\"x is a positive number\")\nend\n```\n\n### **两个分支 if-else 型**\n\n```Go\nx = 10\nif x \u003e 0 then\n    print(\"x is a positive number\")\nelse\n    print(\"x is a non-positive number\")\nend\n```\n\n### 多个分支的 if-elseif-else\n\n```Go\n\nscore = 90\nif score == 100 then\n    print(\"Very good!Your score is 100\")\nelseif score \u003e= 60 then\n    print(\"Congratulations, you have passed it,your score greater or equal to 60\")\n    --此处可以添加多个elseif\nelse\n    print(\"Sorry, you do not pass the exam! \")\nend\n```\n\n与 C 语言的不同之处是 else 与 if 是连在一起的，若将 else 与 if 写成 \"else if\" 则相当于在 else 里嵌套另一个 if 语句，如下代码：\n\n```Go\nscore = 0\nif score == 100 then\n    print(\"Very good!Your score is 100\")\nelseif score \u003e= 60 then\n    print(\"Congratulations, you have passed it,your score greater or equal to 60\")\nelse\n    if score \u003e 0 then\n        print(\"Your score is better than 0\")\n    else\n        print(\"My God, your score turned out to be 0\")\n    end --与上一示例代码不同的是，此处要添加一个end\nend\n```\n\n## While\n\n```Go\nwhile 表达式 do\n    --body\nend\n```\n\n  \n\n## Repeat\n\nLua 中的 repeat 控制结构类似于其他语言（如：C++ 语言）中的 do-while，但是控制方式是刚好相反的。简单点说，**执行 repeat 循环体后，直到 until 的条件为真时才结束**\n\n```Lua\n-- 以下代码会死循环\nx = 10\nrepeat\n    print(x)\nuntil false\n```\n\n  \n\n## For\n\n### **for 数字型**\n\n```Lua\nfor var = begin, finish, step do\n    --body\nend\n```\n\n1. Var 从 begin 变化到 finish，每次变化都以 step 作为步长递增 var\n    \n2. Begin、finish、step 三个表达式只会在循环开始时执行一次\n    \n3. 第三个表达式 step 是可选的，默认为 1\n    \n4. 控制变量 var 的作用域仅在 for 循环内，需要在外面控制，则需将值赋给一个新的变量\n    \n5. 循环过程中不要改变控制变量的值，那样会带来不可预知的影响\n    \n\n```Lua\nfor i = 1, 5 do\n    print(i)\nend\n-- output:\n1\n2\n3\n4\n5\n\nfor i = 1, 10, 2 do\n    print(i)\nend\n-- output:\n1\n3\n5\n7\n9\n```\n\n## For 泛型\n\n泛型 for 循环通过一个迭代器（iterator）函数来遍历所有值：\n\n```Lua\n-- 打印数组a的所有值local a = {\"a\", \"b\", \"c\", \"d\"}\nfor i, v in ipairs(a) do\n    print(\"index:\", i, \" value:\", v)\nend\n-- output:\nindex:  1  value: a\nindex:  2  value: b\nindex:  3  value: c\nindex:  4  value: d\n```\n\nLua 的基础库提供了 **ipairs，这是一个用于遍历数组的迭代器函数**。在每次循环中，i 会被赋予一个索引值，同时 v 被赋予一个对应于该索引的数组元素值。\n\n```Lua\n-- 打印table t中所有的\nkeyfor k in pairs(t) do\n    print(k)\nend\n```\n\n通过不同的迭代器，几乎可以遍历所有的东西，而且写出的代码极具可读性。标准库提供了几种迭代器，包括用于迭代文件中每行的（io. Lines）、迭代 table 元素的（pairs）、迭代数组元素的（ipairs）、迭代字符串中单词的（string. Gmatch）\n\n泛型 for 循环与数字型 for 循环有两个相同点：\n\n1. 循环变量是循环体的局部变量；\n    \n2. 决不应该对循环变量作任何赋值。\n    \n\n在 LuaJIT 2.1 中，**`ipairs()`** **内建函数是可以被 JIT 编译的，而** **`pairs()`** **则只能被解释执行。因此在性能敏感的场景，应当合理安排数据结构，避免对哈希表进行遍历**\n\n  \n\n## Break\n\n语句 `break` 用来终止 `while`、`repeat` 和 `for` 三种循环的执行，并跳出当前循环体，继续执行当前循环之后的语句\n\n```Lua\n-- 计算最小的x,使从1到x的所有数相加和大于100\nsum = 0\ni = 1while true do\n    sum = sum + i\n    if sum \u003e 100 then\n        break\n    end\n    i = i + 1\nend\nprint(\"The result is \" .. i)  \n--\u003eoutput:The result is 14\n```\n\n## Return\n\n  \n\n`return` 主要用于从函数中返回结果，或者用于简单的结束一个函数的执行。\n\n```Lua\nlocal function add(x, y)\n    return x + y\n    --print(\"add: I will return the result \" .. (x + y))\n    --因为前面有个return，若不注释该语句，则会报错\nend\n\nlocal function is_positive(x)\n    if x \u003e 0 then\n        return x .. \" is positive\"\n    else\n        return x .. \" is non-positive\"\n    end\n\n    --由于return只出现在前面显式的语句块，所以此语句不注释也不会报错\n    --，但是不会被执行，此处不会产生输出\n    print(\"function end!\")\nend\n\nlocal sum = add(10, 20)\nprint(\"The sum is \" .. sum)  --\u003eoutput:The sum is 30\nlocal answer = is_positive(-10)\nprint(answer)                --\u003eoutput:-10 is non-positive\n```\n\n  \n\n## Goto\n\n有了 `goto`，我们可以实现 `continue` 的功能：\n\n```Lua\nfor i=1, 3 do\n    if i \u003c= 2 then\n        print(i, \"yes continue\")\n        goto continue\n    end\n    print(i, \" no continue\")\n\n    ::continue::\n    print([[i'm end]])\nend\n```\n\n输出结果\n\n```Lua\n$ luajit test.lua\n1   yes continue\ni'm end\n2   yes continue\ni'm end\n3    no continue\ni'm end\n```\n\n# 函数\n\n## 定义\n\n```Lua\nfunction function_name (arc)  -- arc 表示参数列表，函数的参数列表可以为空\n    -- body\nend\n```\n\n上面的语法定义了一个全局函数，名为 `function_name`. 全局函数本质上就是函数类型的值赋给了一个全局变量，即上面的语法等价于\n\n```Lua\nfunction_name = function (arc)\n     -- body\nend\n```\n\n由于全局变量一般会污染全局名字空间，同时也有性能损耗（即查询全局环境表的开销），因此我们应当尽量使用“局部函数”，其记法是类似的，只是开头加上 `local` 修饰符：\n\n```Lua\nlocal function function_name (arc)\n    -- body\nend\n```\n\n定义函数\n\n1. 利用名字来解释函数、变量的目的，使人通过名字就能看出来函数、变量的作用。\n    \n2. 每个函数的长度要尽量控制在一个屏幕内，一眼可以看明白。\n    \n3. 让代码自己说话，不需要注释最好。\n    \n\n  \n\n由于函数定义等价于变量赋值，我们也可以把函数名替换为某个 Lua 表的某个字段，例如\n\n```Lua\nlocal foo = {}\nfunction foo.pr()\n    print(\"ssss\")\nend\n\nfoo.pr()\n```\n\n  \n\n## 参数\n\n### 按值传递\n\n**Lua 函数的参数大部分是按值传递的**。**当函数参数是 table 类型时，传递进来的是实际参数的引用**\n\n值传递就是调用函数时，实参把它的值通过赋值运算传递给形参，然后形参的改变和实参就没有关系了。在这个过程中，实参是通过它在参数表中的位置与形参匹配起来的。\n\n```Lua\nlocal function swap(a, b) --定义函数swap,函数内部进行交换两个变量的值\n    local temp = a\n    a = b\n    b = temp\n    print(a, b)\nend\n\nlocal x = \"hello\"\nlocal y = 20\nprint(x, y)\nswap(x, y)    --调用swap函数\nprint(x, y)   --调用swap函数后，x和y的值并没有交换\n\n--\u003eoutput\nhello 20\n20  hello\nhello 20\n```\n\n在调用函数的时候，**若形参个数和实参个数不同时，Lua 会自动调整实参个数**。调整规则：\n\n- 若实参个数大于形参个数，从左向右，多余的实参被忽略；\n    \n- 若实参个数小于形参个数，从左向右，**没有被实参初始化的形参会被初始化为 nil**\n    \n\n```Lua\nlocal function fun1(a, b)       --两个形参，多余的实参被忽略掉\n    print(a, b)\nend\n\nlocal function fun2(a, b, c, d) --四个形参，没有被实参初始化的形参，用nil初始化\n    print(a, b, c, d)\nend\n\nlocal x = 1\nlocal y = 2\nlocal z = 3\n\nfun1(x, y, z)         -- z被函数fun1忽略掉了，参数变成 x, y\nfun2(x, y, z)         -- 后面自动加上一个nil，参数变成 x, y, z, nil\n\n--\u003eoutput\n1   2\n1   2   3   nil\n```\n\n### 变长参数\n\n其实 Lua 还支持变长参数。若形参为 `...`，表示该函数可以接收不同长度的参数。访问参数的时候也要使用 `...`\n\n```Lua\n\nlocal function func( ... )                -- 形参为 ... ,表示函数采用变长参数\n\n    local temp = {...}                     -- 访问的时候也要使用 ...\n    local ans = table.concat(temp, \" \")    -- 使用 table.concat 库函数对数\n    -- 组内容使用 \" \" 拼接成字符串。\n    print(ans)\nend\n\nfunc(1, 2)        -- 传递了两个参数\nfunc(1, 2, 3, 4)  -- 传递了四个参数\n\n--\u003eoutput\n1 2\n\n1 2 3 4\n```\n\n### **具名参数**\n\nLua 还支持通过名称来指定实参，这时候要把所有的实参组织到一个 table 中，并将这个 table 作为唯一的实参传给函数。\n\n```Lua\nlocal function change(arg) -- change 函数，改变长方形的长和宽，使其各增长一倍\n  arg.width = arg.width * 2\n  arg.height = arg.height * 2return arg\nendlocal rectangle = { width = 20, height = 15 }\nprint(\"before change:\", \"width  =\", rectangle.width,\n                        \"height =\", rectangle.height)\nrectangle = change(rectangle)\nprint(\"after  change:\", \"width  =\", rectangle.width,\n                        \"height =\", rectangle.height)\n\n--\u003eoutput\nbefore change: width = 20  height =  15\nafter  change: width = 40  height =  30\n```\n\n  \n\n### 按引用传递\n\n**当函数参数是 table 类型时，传递进来的是实际参数的引用**，此时在函数内部对该 table 所做的修改，会直接对调用者所传递的实际参数生效，而无需自己返回结果和让调用者进行赋值\n\n```Plaintext\nfunction change(arg) --change函数，改变长方形的长和宽，使其各增长一倍\n  arg.width = arg.width * 2  --表arg不是表rectangle的拷贝，他们是同一个表\n  arg.height = arg.height * 2end                  -- 没有return语句了local rectangle = { width = 20, height = 15 }\nprint(\"before change:\", \"width = \", rectangle.width,\n                        \" height = \", rectangle.height)\nchange(rectangle)\nprint(\"after change:\", \"width = \", rectangle.width,\n                       \" height =\", rectangle.height)\n\n--\u003e output\nbefore change: width = 20  height = 15\nafter  change: width = 40  height = 30\n```\n\n## 函数返回值\n\nLua 具有一项与众不同的特性，允许函数返回多个值。\n\n```Lua\nlocal function swap(a, b)   \n    -- 定义函数 swap，实现两个变量交换值\n    return b, a              \n    -- 按相反顺序返回变量的值\nend\n\nlocal x = 1\nlocal y = 20\nx, y = swap(x, y)           -- 调用 swap 函数\nprint(x, y)                 --\u003e output   20     1\n```\n\n  \n\n当函数返回值的个数和接收返回值的变量的个数不一致时，Lua 也会自动调整参数个数调整规则：\n\n- 若返回值个数大于接收变量的个数，多余的返回值会被忽略掉；\n    \n- 若返回值个数小于参数个数，从左向右，没有被返回值初始化的变量会被初始化为 nil。\n    \n\n```Lua\nfunction init()             \n    --init 函数 返回两个值 1 和 \"lua\"\n    return 1, \"lua\"\nend\n\nx = init()\nprint(x)\n\nx, y, z = init()\nprint(x, y, z)\n\n--output\n1\n1 lua nil\n```\n\n  \n\n当一个函数有一个以上返回值，且函数调用不是一个列表表达式的最后一个元素，那么函数调用只会产生一个返回值, 也就是第一个返回值。\n\n```Lua\nlocal function init()       -- init 函数 返回两个值 1 和 \"lua\"\n    return 1, \"lua\"\nend\n\nlocal x, y, z = init(), 2   -- init 函数的位置不在最后，此时只返回 1\nprint(x, y, z)              --\u003eoutput  1  2  nil\n\nlocal a, b, c = 2, init()   -- init 函数的位置在最后，此时返回 1 和 \"lua\"\nprint(a, b, c)              --\u003eoutput  2  1  lua\n```\n\n函数调用的实参列表也是一个列表表达式。考虑下面的例子：\n\n```Lua\nlocal function init()\n    return 1, \"lua\"\nend\n\nprint(init(), 2)   --\u003eoutput  1  2\nprint(2, init())   --\u003eoutput  2  1  lua\n```\n\n如果你确保只取函数返回值的第一个值，可以使用括号运算符\n\n```Lua\nlocal function init()\n    return 1, \"lua\"\nend\nprint((init()), 2)   --\u003eoutput  1  2\nprint(2, (init()))   --\u003eoutput  2  1\n```\n\n**值得一提的是，如果实参列表中某个函数会返回多个值，同时调用者又没有显式地使用括号运算符来筛选和过滤，则这样的表达式是不能被 LuaJIT 2 所 JIT 编译的，而只能被解释执行。**\n\n  \n\n  \n\n# 全动态函数调用\n\n调用回调函数，并把一个数组参数作为回调函数的参数。\n\n```Lua\nlocal args = {...} or {}\nmethod_name(unpack(args, 1, table.maxn(args)))\n```\n\n```Lua\nlocal function run(x, y)\n    print('run', x, y)\nend\n\nlocal function attack(targetId)\n    print('targetId', targetId)\nend\n\nlocal function do_action(method, ...)\n    local args = {...} or {}\n    method(unpack(args, 1, table.maxn(args)))\nend\n\ndo_action(run, 1, 2)         -- output: run 1 2\ndo_action(attack, 1111)      -- output: targetId    1111\n```\n\n  \n\n# 模块\n\n从 Lua 5.1 语言添加了对模块和包的支持。一**个 Lua 模块的数据结构是用一个 Lua 值（通常是一个 Lua 表或者 Lua 函数）**。**一个 Lua 模块代码就是一个会返回这个 Lua 值的代码块**\n\n- 可以使用内建函数 `require()` 来加载和缓存模块。\n    \n- 简单的说，一个代码模块就是一个程序库，可以通过 `require` 来加载。**模块加载后的结果通过是一个 Lua table**\n    \n- **这个表就像是一个命名空间**，其内容就是模块中导出的所有东西，**比如函数和变量**。`require` 函数会返回 Lua 模块加载后的结果，即用于表示该 Lua 模块的 Lua 值。\n    \n\n  \n\n  \n\nLua 提供了一个名为 `require` 的函数用来加载模块。**要加载一个模块，只需要简单地调用** **`require`** **\"file\" 就可以了，file 指模块所在的文件名**。这个调用会返回一个由模块函数组成的 table，并且还会定义一个包含该 table 的全局变量。\n\n在 Lua 中创建一个模块最简单的方法是：**创建一个 table，并将所有需要导出的函数放入其中，最后返回这个 table 就可以了。相当于将导出的函数作为 table 的一个字段，在 Lua 中函数是第一类值，提供了天然的优势。**\n\n- 创建 my. Lua\n    \n\n```Lua\nlocal _M = {}\n\nlocal function get_name()\n    return \"Lucy\"\n    end\nfunction _M.greeting()\n    print(\"hello \" .. get_name())\nend\n\nreturn _M\n```\n\n- 把下面代码保存在文件 main. Lua 中，然后执行 main. Lua，调用上述模块。\n    \n\n```Lua\nlocal my_module = require(\"my\")\nmy_module.greeting()     --\u003eoutput: hello Lucy\n```\n\n  \n\n\u003e - 对于需要导出给外部使用的公共模块，处于安全考虑，**是要避免全局变量的出现**。我们可以使用 lj-releng 或 luacheck 工具完成全局变量的检测。至于如何做，到后面再讲。\n\u003e     \n\u003e - 另一个要注意的是，由于在 LuaJIT 中，**require 函数内不能进行上下文切换**，**所以不能够在模块的顶级上下文中调用 cosocket 一类的 API**。否则会报 `attempt to yield across C-call boundary` 错误。\n\u003e     \n\n  \n\n# String\n\nLua 字符串总是由字节构成的。Lua 核心并不尝试理解具体的字符集编码（比如 GBK 和 UTF-8 这样的多字节字符编码）\n\nLua 字符串内部用来标识各个组成字节的下标是从 1 开始的，这不同于像 C 和 Perl 这样的编程语言。这样数字符串位置的时候再也不用调整，对于非专业的开发者来说可能也是一个好事情，**string.Sub (str, 3, 7) 直接表示从第三个字符开始到第七个字符（含）为止的子串。**\n\n## **string.Byte (s [, i [, j ]])**\n\n返回字符 s[i]、s[i + 1]、s[i + 2]、······、s[j] 所对应的 ASCII 码\n\n```Lua\nprint(string.byte(\"abc\", 1, 3))\nprint(string.byte(\"abc\", 3)) -- 缺少第三个参数，第三个参数默认与第二个相同，此时为 3\nprint(string.byte(\"abc\"))    -- 缺少第二个和第三个参数，此时这两个参数都默认为 1\n\n--\u003eoutput\n97    98    99\n99\n97\n```\n\n## **string. Char (...)**\n\n接收 0 个或更多的整数（整数范围：0~255），返回这些整数所对应的 ASCII 码字符组成的字符串。当参数为空时，默认是一个 0。\n\n```Lua\nprint(string.char(96, 97, 98))\nprint(string.char())        -- 参数为空，默认是一个0，-- 你可以用string.byte(string.char())测试一下print(string.char(65, 66))\n\n--\u003e output\n`ab\n\nAB\n```\n\n## **string.Upper (s)**\n\n接收一个字符串 s，返回一个把所有小写字母变成大写字母的字符串。\n\n```Lua\nprint(string.upper(\"Hello Lua\"))  --\u003eoutput  HELLO LUA\n```\n\n## **string.Lower (s)**\n\n接收一个字符串 s，返回一个把所有大写字母变成小写字母的字符串。\n\n```Lua\nprint(string.lower(\"Hello Lua\"))  --\u003eoutput   hello lua\n```\n\n## **string.Len (s)**\n\n接收一个字符串，返回它的长度。\n\n```Lua\nprint(string.len(\"hello lua\")) --\u003eoutput  9\n```\n\n使用此函数是不推荐的。应当总是使用 `#` 运算符来获取 Lua 字符串的长度\n\n## **string.Find (s, p [, init [, plain]])**\n\n在 s 字符串中第一次匹配 p 字符串。若匹配成功，则返回 p 字符串在 s 字符串中出现的开始位置和结束位置；若匹配失败，则返回 nil,\n\n第三个参数第三个参数 init 默认为 1，并且可以为负整数，\n\n当 init 为负数时，表示从 s 字符串的 string.Len (s) + init + 1 索引处开始向后匹配字符串 p 。\n\n第四个参数默认为 false，当其为 true 时，只会把 p 看成一个字符串对待。\n\n```Lua\nlocal find = string.find\nprint(find(\"abc cba\", \"ab\"))\nprint(find(\"abc cba\", \"ab\", 2))     -- 从索引为2的位置开始匹配字符串：ab\nprint(find(\"abc cba\", \"ba\", -1))    -- 从索引为7的位置开始匹配字符串：ba\nprint(find(\"abc cba\", \"ba\", -3))    -- 从索引为5的位置开始匹配字符串：ba\nprint(find(\"abc cba\", \"(%a+)\", 1))  -- 从索引为1处匹配最长连续且只含字母的字符串\nprint(find(\"abc cba\", \"(%a+)\", 1, true)) --从索引为1的位置开始匹配字符串：(%a+)\n\n--\u003eoutput\n1   2\nnil\nnil\n6   7\n1   3   abc\nnil\n```\n\n## **string.Format (formatstring, ...)**\n\n按照格式化参数 formatstring，返回后面 `...` 内容的格式化版本\n\n```Plaintext\nprint(string.format(\"%.4f\", 3.1415926))     -- 保留4位小数\nprint(string.format(\"%d %x %o\", 31, 31, 31))-- 十进制数31转换成不同进制\nd = 29; m = 7; y = 2015                     -- 一行包含几个语句，用；分开\nprint(string.format(\"%s %02d/%02d/%d\", \"today is:\", d, m, y))\n\n--\u003eoutput\n3.1416\n31 1f 37\ntoday is: 29/07/2015\n```\n\n## **string.Match (s, p [, init])**\n\n在字符串 s 中匹配（模式）字符串 p，若匹配成功，则返回目标字符串中与模式匹配的子串；否则返回 nil。第三个参数 init 默认为 1，并且可以为负整数，当 init 为负数时，表示从 s 字符串的 string.Len (s) + init + 1 索引处开始向后匹配字符串 p。\n\n```Lua\nprint(string.match(\"hello lua\", \"lua\"))\nprint(string.match(\"lua lua\", \"lua\", 2))  --匹配后面那个luaprint(string.match(\"lua lua\", \"hello\"))\nprint(string.match(\"today is 27/7/2015\", \"%d+/%d+/%d+\"))\n\n--\u003eoutput\nlua\nlua\nnil27/7/2015\n```\n\n## **string.Gmatch (s, p)**\n\n返回一个迭代器函数，通过这个迭代器函数可以遍历到在字符串 s 中出现模式串 p 的所有地方。\n\n```Lua\ns = \"hello world from Lua\"\nfor w in string.gmatch(s, \"%a+\") do  --匹配最长连续且只含字母的字符串\n    print(w)\nend\n\n--\u003eoutput\nhello\nworld\nfrom\nLua\n\n\nt = {}\ns = \"from=world, to=Lua\"\nfor k, v in string.gmatch(s, \"(%a+)=(%a+)\") do  --匹配两个最长连续且只含字母的\n    t[k] = v                                    --字符串，它们之间用等号连接\nend\nfor k, v in pairs(t) do\n    print (k,v)\nend\n\n--\u003eoutput\nto      Lua\nfrom    worl\n```\n\n## **string.Rep (s, n)**\n\n返回字符串 s 的 n 次拷贝。\n\n```Lua\nprint(string.rep(\"abc\", 3)) \n\n--拷贝3次\"abc\"--\u003eoutput  abcabcabc\n```\n\n## **string.Sub (s, i [, j])**\n\n返回字符串 s 中，索引 i 到索引 j 之间的子字符串。当 j 缺省时，默认为 -1，也就是字符串 s 的最后位置。I 可以为负数。当索引 i 在字符串 s 的位置在索引 j 的后面时，将返回一个空字符串。\n\n```Lua\nprint(string.sub(\"Hello Lua\", 4, 7))\nprint(string.sub(\"Hello Lua\", 2))\nprint(string.sub(\"Hello Lua\", 2, 1))    --看到返回什么了吗print(string.sub(\"Hello Lua\", -3, -1))\n\n--\u003eoutput\nlo L\nello Lua\n\nLua\n```\n\n## **string.Gsub (s, p, r [, n])**\n\n将目标字符串 s 中所有的子串 p 替换成字符串 r。可选参数 n，表示限制替换次数。返回值有两个，第一个是被替换后的字符串，第二个是替换了多少次。\n\n```Plaintext\nprint(string.gsub(\"Lua Lua Lua\", \"Lua\", \"hello\"))\nprint(string.gsub(\"Lua Lua Lua\", \"Lua\", \"hello\", 2)) --指明第四个参数--\u003eoutput\nhello hello hello   3\nhello hello Lua     2\n```\n\n## **string. Reverse (s)**\n\n接收一个字符串 s，返回这个字符串的反转\n\n```Lua\nprint(string.reverse(\"Hello Lua\"))  --\u003e output: auL olleH\n```\n\n  \n\n# Table\n\n## **下标从 1 开始**\n\n数组下标从 1 开始计数。\n\n而 Lua 最初设计是一种类似 XML 的数据描述语言，所以索引（index）反应的是数据在里面的位置，而不是偏移量。\n\n  \n\n在初始化一个数组的时候，**若不显式地用键值对方式赋值，则会默认用数字作为下标**，从 1 开始。由于在 _Lua_ 内部实际采用哈希表和数组分别保存键值对、普通值，所以不推荐混合使用这两种赋值方式\n\n```Lua\nlocal color={first=\"red\", \"blue\", third=\"green\", \"yellow\"}\nprint(color[\"first\"])                 --\u003e output: red\nprint(color[1])                       --\u003e output: blue\nprint(color[\"third\"])                 --\u003e output: green\nprint(color[2])                       --\u003e output: yellow\nprint(color[3])                       --\u003e output: nil\n```\n\n- **当我们把 table 当作栈或者队列使用的时候，容易犯错，追加到 table 的末尾用的是** **`s[#s+1] = something`****, 而不是** **`s[#s] = something`**\n    \n- 而且如果这个 something 是一个 nil 的话**，会导致这一次压栈（或者入队列）没有存入任何东西**， s 的值没有变\n    \n- 如果 `s = { 1, 2, 3, 4, 5, 6 }`，你令 `s[4] = nil`， s 会令你“匪夷所思”地变成 3。\n    \n\n## **table. Getn 获取长度**\n\n取长度操作符写作一元操作 。字符串的长度是它的字节数（就是以一个字符一个字节计算的字符串长度）\n\n- 对于常规的数组，里面从 1 到 n 放着一些非空的值的时候，它的长度就精确的为 n，即最后一个值的下标\n    \n- 如果数组有一个“空洞”（**就是说，nil 值被夹在非空值之间**），**那么 t 可能是指向任何一个是 nil 值的前一个位置的下标**\n    \n- 这也就说明对于有“空洞”的情况，table 的长度存在一定的 **不可确定性**\n    \n\n```Lua\nlocal tblTest1 = { 1, a = 2, 3 }\nprint(\"Test1 \" .. table.getn(tblTest1))\n\nlocal tblTest2 = { 1, nil }\nprint(\"Test2 \" .. table.getn(tblTest2))\n\nlocal tblTest3 = { 1, nil, 2 }\nprint(\"Test3 \" .. table.getn(tblTest3))\n\nlocal tblTest4 = { 1, nil, 2, nil }\nprint(\"Test4 \" .. table.getn(tblTest4))\n\nlocal tblTest5 = { 1, nil, 2, nil, 3, nil }\nprint(\"Test5 \" .. table.getn(tblTest5))\n\nlocal tblTest6 = { 1, nil, 2, nil, 3, nil, 4, nil }\nprint(\"Test6 \" .. table.getn(tblTest6))\n```\n\n我们使用 Lua 5.1 和 LuaJIT 2.1 分别执行这个用例，结果如下：\n\n```Lua\n# lua test.lua\nTest1 2\nTest2 1\nTest3 3\nTest4 1\nTest5 3\nTest6 1\n# luajit test.lua\nTest1 2\nTest2 1\nTest3 1\nTest4 1\nTest5 1\nTest6 1\n```\n\n不要在 Lua 的 table 中使用 nil 值，**如果一个元素要删除，直接 remove，不要用 nil 去代替**。\n\n## **table. Concat (table [, sep [, i [, j ] ] ])**\n\n对于元素是 string 或者 number 类型的表 table，返回 `table[i]..sep..table[i+1] ··· sep..table[j]` 连接成的字符串。填充字符串 sep 默认为空白字符串。起始索引位置 i 默认为 1，结束索引位置 j 默认是 table 的长度。\n\n```Lua\nlocal a = {1, 3, 5, \"hello\" }\nprint(table.concat(a))              -- output: 135hello\nprint(table.concat(a, \"|\"))         -- output: 1|3|5|hello\nprint(table.concat(a, \" \", 4, 2))   -- output:\nprint(table.concat(a, \" \", 2, 4))   -- output: 3 5 hello\n```\n\n## **table. Insert (table, [pos ,] value)**\n\n在（数组型）表 table 的 pos 索引位置插入 value，其它元素向后移动到空的地方。Pos 的默认值是表的长度加一，即默认是插在表的最后\n\n```Lua\nlocal a = {1, 8}             --a[1] = 1,a[2] = 8\ntable.insert(a, 1, 3)   --在表索引为1处插入3\nprint(a[1], a[2], a[3])\ntable.insert(a, 10)    --在表的最后插入10\nprint(a[1], a[2], a[3], a[4])\n\n--\u003eoutput\n3    1    8\n3    1    8    10\n```\n\n## **table. Maxn (table)**\n\n返回（数组型）表 table 的最大索引编号；如果此表没有正的索引编号，返回 0。\n\n```Lua\nlocal a = {}\na[-1] = 10\nprint(table.maxn(a))\na[5] = 10\nprint(table.maxn(a))\n\n--\u003eoutput05\n```\n\n## **table. Remove (table [, pos])**\n\n在表 table 中删除索引为 pos（pos 只能是 number 型）的元素，并返回这个被删除的元素，它后面所有元素的索引值都会减一。Pos 的默认值是表的长度，即默认是删除表的最后一个元素。\n\n```Lua\nlocal a = { 1, 2, 3, 4}\nprint(table.remove(a, 1)) --删除速索引为1的元素print(a[1], a[2], a[3], a[4])\n\nprint(table.remove(a))   --删除最后一个元素print(a[1], a[2], a[3], a[4])\n\n--\u003eoutput12    3    4    nil42    3    nil    nil\n```\n\n## **table. Sort (table [, comp])**\n\n按照给定的比较函数 comp 给表 table 排序，也就是从 table[1] 到 table[n]，这里 n 表示 table 的长度。比较函数有两个参数，如果希望第一个参数排在第二个的前面，就应该返回 true，否则返回 false。如果比较函数 comp 没有给出，默认从小到大排序。\n\n```Lua\n\nlocal function compare(x, y) --从大到小排序\n    return x \u003e y         --如果第一个参数大于第二个就返回true，否则返回false\nend\n\nlocal a = { 1, 7, 3, 4, 25}\ntable.sort(a)           --默认从小到大排序\nprint(a[1], a[2], a[3], a[4], a[5])\ntable.sort(a, compare) --使用比较函数进行排序\nprint(a[1], a[2], a[3], a[4], a[5])\n\n--\u003eoutput\n1    3    4    7    25\n25    7    4    3    1\n```\n\n## 其他\n\nLuaJIT 2.1 新增加的 `table.new` 和 `table.clear` 函数是非常有用的。前者主要用来预分配 Lua table 空间，后者主要用来高效的释放 table 空间，并且它们都是可以被 JIT 编译的\n\n  \n\n# 日期时间\n\n函数 time、date 和 difftime 提供了所有的日期和时间功能。\n\n在 OpenResty 的世界里，不推荐使用这里的标准时间函数，因为这些函数通常会引发不止一个昂贵的系统调用，同时无法为 LuaJIT JIT 编译，对性能造成较大影响。推荐使用 ngx_lua 模块提供的带缓存的时间接口，如 `ngx.today`, `ngx.time`, `ngx.utctime`, `ngx.localtime`, `ngx.now`, `ngx.http_time`，以及 `ngx.cookie_time` 等。\n\n  \n\n## **os. Time ([table])**\n\n如果不使用参数 table 调用 time 函数，\n\n- 它会返回当前的时间和日期（它表示从某一时刻到现在的秒数）。\n    \n- 如果用 table 参数，它会返回一个数字，表示该 table 中所描述的日期和时间（它表示从某一时刻到 table 中描述日期和时间的秒数）。Table 的字段如下：\n    \n\n|          |                            |\n| -------- | -------------------------- |\n| 字段名称 | 取值范围                   |\n| year     | 四位数字                   |\n| month    | 1--12                      |\n| day      | 1--31                      |\n| hour     | 0--23                      |\n| min      | 0--59                      |\n| sec      | 0--61                      |\n| isdst    | boolean（true 表示夏令时） |\n\n对于 time 函数，如果参数为 table，那么 table 中必须含有 year、month、day 字段。其他字缺省时段默认为中午（12:00:00）。\n\n\u003e 示例代码：（地点为北京）\n\n```Plaintext\nprint(os.time())    --\u003eoutput  1438243393\na = { year = 1970, month = 1, day = 1, hour = 8, min = 1 }\nprint(os.time(a))   --\u003eoutput  60\n```\n\n## **os. Difftime (t 2, t 1)**\n\n返回 t 1 到 t 2 的时间差，单位为秒。\n\n\u003e 示例代码:\n\n```Plaintext\nlocal day1 = { year = 2015, month = 7, day = 30 }\nlocal t1 = os.time(day1)\n\nlocal day2 = { year = 2015, month = 7, day = 31 }\nlocal t2 = os.time(day2)\nprint(os.difftime(t2, t1))   --\u003eoutput  86400\n```\n\n## **os. Date ([format [, time]])**\n\n把一个表示日期和时间的数值，转换成更高级的表现形式。\n\n- 其第一个参数 format 是一个格式化字符串，描述了要返回的时间形式。\n    \n- 第二个参数 time 就是日期和时间的数字表示，缺省时默认为当前的时间。\n    \n- 使用格式字符 \"*t\"，创建一个时间表。\n    \n\n\u003e 示例代码：\n\n```Plaintext\nlocal tab1 = os.date(\"*t\")  --返回一个描述当前日期和时间的表\nlocal ans1 = \"{\"\nfor k, v in pairs(tab1) do  --把tab1转换成一个字符串\n    ans1 = string.format(\"%s %s = %s,\", ans1, k, tostring(v))\nend\n\nans1 = ans1 .. \"}\"\nprint(\"tab1 = \", ans1)\n\n\nlocal tab2 = os.date(\"*t\", 360)  --返回一个描述日期和时间数为360秒的表\nlocal ans2 = \"{\"\nfor k, v in pairs(tab2) do      --把tab2转换成一个字符串\n    ans2 = string.format(\"%s %s = %s,\", ans2, k, tostring(v))\nend\n\nans2 = ans2 .. \"}\"\nprint(\"tab2 = \", ans2)\n\n--\u003eoutput\ntab1 = { hour = 17, min = 28, wday = 5, day = 30, month = 7, year = 2015, sec = 10, yday = 211, isdst = false,}\ntab2 = { hour = 8, min = 6, wday = 5, day = 1, month = 1, year = 1970, sec = 0, yday = 1, isdst = false,}\n```\n\n该表中除了使用到了 time 函数参数 table 的字段外，这还提供了星期（wday，星期天为 1）和一年中的第几天（yday，一月一日为 1）。除了使用 \"*t\" 格式字符串外，如果使用带标记（见下表）的特殊字符串，os. Date 函数会将相应的标记位以时间信息进行填充，得到一个包含时间的字符串。表如下：\n\n|          |                                           |\n| -------- | ----------------------------------------- |\n| 格式字符 | 含义                                      |\n| %a       | 一星期中天数的简写（例如：Wed）           |\n| %A       | 一星期中天数的全称（例如：Wednesday）     |\n| %b       | 月份的简写（例如：Sep）                   |\n| %B       | 月份的全称（例如：September）             |\n| %c       | 日期和时间（例如：07/30/15 16:57:24）     |\n| %d       | 一个月中的第几天[01 ~ 31]                 |\n| %H       | 24 小时制中的小时数[00 ~ 23]              |\n| %I       | 12 小时制中的小时数[01 ~ 12]              |\n| %j       | 一年中的第几天[001 ~ 366]                 |\n| %M       | 分钟数[00 ~ 59]                           |\n| %m       | 月份数[01 ~ 12]                           |\n| %p       | “上午（am）”或“下午（pm）”                |\n| %S       | 秒数[00 ~ 59]                             |\n| %w       | 一星期中的第几天[1 ~ 7 = 星期天 ~ 星期六] |\n| %x       | 日期（例如：07/30/15）                    |\n| %X       | 时间（例如：16:57:24）                    |\n| %y       | 两位数的年份[00 ~ 99]                     |\n| %Y       | 完整的年份（例如：2015）                  |\n| %%       | 字符'%'                                   |\n\n\u003e 示例代码：\n\n```Plaintext\nprint(os.date(\"today is %A, in %B\"))\nprint(os.date(\"now is %x %X\"))\n\n--\u003eoutput\ntoday is Thursday, in July\nnow is 07/30/15 17:39:22\n```\n\n  \n\n# 数学库\n\nUa 数学库由一组标准的数学函数构成。数学库的引入丰富了 Lua 编程语言的功能，同时也方便了程序的编写。常用数学函数见下表：\n\n|               asd           |                                                                                        sdfa                                                                                                      | \n| ------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| 函数名                   | 函数功能                                                                                                                                                                                     |\n| math.Rad (x)             | 角度 x 转换成弧度                                                                                                                                                                            |\n| math.Deg (x)             | 弧度 x 转换成角度                                                                                                                                                                            |\n| math.Max (x, ...)        | 返回参数中值最大的那个数，参数必须是 number 型                                                                                                                                               |\n| math.Min (x, ...)        | 返回参数中值最小的那个数，参数必须是 number 型                                                                                                                                               |\n| math. Random ([m [, n]]) | 不传入参数时，返回一个在区间[0,1)内均匀分布的伪随机实数；只使用一个整数参数 m 时，返回一个在区间[1, m]内均匀分布的伪随机整数；使用两个整数参数时，返回一个在区间[m, n]内均匀分布的伪随机整数 |\n| math. Randomseed (x)     | 为伪随机数生成器设置一个种子 x，相同的种子将会生成相同的数字序列                                                                                                                             |\n| math.Abs (x)             | 返回 x 的绝对值                                                                                                                                                                              |\n| math.Fmod (x, y)         | 返回 x 对 y 取余数                                                                                                                                                                           |\n| math.Pow (x, y)          | 返回 x 的 y 次方                                                                                                                                                                             |\n| math.Sqrt (x)            | 返回 x 的算术平方根                                                                                                                                                                          |\n| math.Exp (x)             | 返回自然数 e 的 x 次方                                                                                                                                                                       |\n| math.Log (x)             | 返回 x 的自然对数                                                                                                                                                                            |\n| math. Log 10 (x)         | 返回以 10 为底，x 的对数                                                                                                                                                                     |\n| math.Floor (x)           | 返回最大且不大于 x 的整数                                                                                                                                                                    |\n| math.Ceil (x)            | 返回最小且不小于 x 的整数                                                                                                                                                                    |\n| math. Pi                 | 圆周率                                                                                                                                                                                       |\n| math.Sin (x)             | 求弧度 x 的正弦值                                                                                                                                                                            |\n| math.Cos (x)             | 求弧度 x 的余弦值                                                                                                                                                                            |\n| math.Tan (x)             | 求弧度 x 的正切值                                                                                                                                                                            |\n| math.Asin (x)            | 求 x 的反正弦值                                                                                                                                                                              |\n| math.Acos (x)            | 求 x 的反余弦值                                                                                                                                                                              |\n| math.Atan (x)            | 求 x 的反正切值                                                                                                                                                                              |\n\n```Lua\nprint(math.pi)           --\u003eoutput  3.1415926535898\nprint(math.rad(180))     --\u003eoutput  3.1415926535898\nprint(math.deg(math.pi)) --\u003eoutput  180\n\nprint(math.sin(1))       --\u003eoutput  0.8414709848079\nprint(math.cos(math.pi)) --\u003eoutput  -1\nprint(math.tan(math.pi / 4))  --\u003eoutput  1\n\nprint(math.atan(1))      --\u003eoutput  0.78539816339745\nprint(math.asin(0))      --\u003eoutput  0\n\nprint(math.max(-1, 2, 0, 3.6, 9.1))     --\u003eoutput  9.1\nprint(math.min(-1, 2, 0, 3.6, 9.1))     --\u003eoutput  -1\n\nprint(math.fmod(10.1, 3))   --\u003eoutput  1.1\nprint(math.sqrt(360))      --\u003eoutput  18.97366596101\n\nprint(math.exp(1))         --\u003eoutput  2.718281828459\nprint(math.log(10))        --\u003eoutput  2.302585092994\nprint(math.log10(10))      --\u003eoutput  1\n\nprint(math.floor(3.1415))  --\u003eoutput  3\nprint(math.ceil(7.998))    --\u003eoutput  8\n```\n\n使用 `math.random()` 函数获得伪随机数时，如果不使用 `math.randomseed()` 设置伪随机数生成种子或者设置相同的伪随机数生成种子，那么得得到的伪随机数序列是一样的。\n\n```Lua\nmath.randomseed (100) --把种子设置为100\nprint(math.random())         --\u003eoutput  0.0012512588885159\nprint(math.random(100))      --\u003eoutput  57\nprint(math.random(100, 360)) --\u003eoutput  150\n```\n\n稍等片刻，再次运行上面的代码。\n\n```Lua\nmath.randomseed (100) --把种子设置为100\nprint(math.random())         --\u003eoutput  0.0012512588885159\nprint(math.random(100))      --\u003eoutput  57\nprint(math.random(100, 360)) --\u003eoutput  150\n```\n\n两次运行的结果一样。为了避免每次程序启动时得到的都是相同的伪随机数序列，通常是使用当前时间作为种子。\n\n\u003e 修改上例中的代码：\n\n```Lua\nmath.randomseed (os.time())   --把100换成os.time()\nprint(math.random())          --\u003eoutput 0.88369396038697\nprint(math.random(100))       --\u003eoutput 66\nprint(math.random(100, 360))  --\u003eoutput 228\n```\n\n稍等片刻，再次运行上面的代码。\n\n```Plaintext\nmath.randomseed (os.time())   --把100换成os.time()\nprint(math.random())          --\u003eoutput 0.88946195867794\nprint(math.random(100))       --\u003eoutput 68\nprint(math.random(100, 360))  --\u003eoutput 129\n```\n\n  \n\n# 文件\n\nLua I/O 库提供两种不同的方式处理文件：隐式文件描述，显式文件描述。\n\n这些文件 I/O 操作，**在 OpenResty 的上下文中对事件循环是会产生阻塞效应**。OpenResty 比较擅长的是高并发网络处理，在这个环境中，任何文件的操作，都将阻塞其他并行执行的请求。**实际中的应用，在 OpenResty 项目中应尽可能让网络处理部分、文件 I/0 操作部分相互独立，不要揉和在一起**。\n\n## **隐式文件描述**\n\n设置一个默认的输入或输出文件，然后在这个文件上进行所有的输入或输出操作。所有的操作函数由 io 表提供。\n\n\u003e 打开已经存在的 `test1.txt` 文件，并读取里面的内容\n\n```Plaintext\nfile = io.input(\"test1.txt\")    -- 使用 io.input() 函数打开文件repeat\n    line = io.read()            -- 逐行读取内容，文件结束时返回nil\n    if nil == line then\n        break\n    end\n    print(line)\nuntil (false)\n\nio.close(file)                  -- 关闭文件--\u003e output\nmy test file\nhello\nlua\n```\n\n\u003e 在 `test1.txt` 文件的最后添加一行 \"hello world\"\n\n```Plaintext\nfile = io.open(\"test1.txt\", \"a+\")   -- 使用 io.open() 函数，以添加模式打开文件\nio.output(file)                     -- 使用 io.output() 函数，设置默认输出文件\nio.write(\"\\nhello world\")           -- 使用 io.write() 函数，把内容写到文件\nio.close(file)\n```\n\n在相应目录下打开 `test1.txt` 文件，查看文件内容发生的变化。\n\n## **显式文件描述**\n\n使用 file: XXX () 函数方式进行操作, 其中 file 为 io.Open () 返回的文件句柄。\n\n\u003e 打开已经存在的 test 2. Txt 文件，并读取里面的内容\n\n```Plaintext\nfile = io.open(\"test2.txt\", \"r\")    -- 使用 io.open() 函数，以只读模式打开文件\n\nfor line in file:lines() do         -- 使用 file:lines() 函数逐行读取文件\n    print(line)\nend\n\nfile:close()\n\n--\u003eoutput\nmy test2\nhello lua\n```\n\n\u003e 在 test 2. Txt 文件的最后添加一行 \"hello world\"\n\n```Plaintext\nfile = io.open(\"test2.txt\", \"a\")  -- 使用 io.open() 函数，以添加模式打开文件\nfile:write(\"\\nhello world\")       -- 使用 file:write() 函数，在文件末尾追加内容\nfile:close()\n```\n\n在相应目录下打开 `test2.txt` 文件，查看文件内容发生的变化。\n\n## **文件操作函数**\n\n#### **io. Open (filename [, mode])**\n\n按指定的模式 mode，打开一个文件名为 `filename` 的文件，成功则返回文件句柄，失败则返回 nil 加错误信息。模式：\n\n|      |                                                |                     | \n| ---- | ---------------------------------------------- | ------------------- |\n| 模式 | 含义                                           | 文件不存在时        |\n| \"r\"  | 读模式 (默认)                                  | 返回 nil 加错误信息 |\n| \"w\"  | 写模式                                         | 创建文件            |\n| \"a\"  | 添加模式                                       | 创建文件            |\n| \"r+\" | 更新模式，保存之前的数据                       | 返回 nil 加错误信息 |\n| \"w+\" | 更新模式，清除之前的数据                       | 创建文件            |\n| \"a+\" | 添加更新模式，保存之前的数据, 在文件尾进行添加 | 创建文件            |\n\n模式字符串后面可以有一个 'b'，用于在某些系统中打开二进制文件。\n\n注意 \"w\" 和 \"wb\" 的区别\n\n- \"w\" 表示文本文件。某些文件系统 (如 Linux 的文件系统)认为 0 x 0 A 为文本文件的换行符，Windows 的文件系统认为 0 x 0 D 0 A 为文本文件的换行符。为了兼容其他文件系统（如从 Linux 拷贝来的文件），Windows 的文件系统在写文件时，会在文件中 0 x 0 A 的前面加上 0 x 0 D。使用 \"w\"，其属性要看所在的平台。\n    \n- \"wb\" 表示二进制文件。文件系统会按纯粹的二进制格式进行写操作，因此也就不存在格式转换的问题。（Linux 文件系统下 \"w\" 和 \"wb\" 没有区别）\n    \n\n#### **file: close ()**\n\n关闭文件。注意：当文件句柄被垃圾收集后，文件将自动关闭。句柄将变为一个不可预知的值。\n\n#### **io. Close ([file])**\n\n关闭文件，和 file: close () 的作用相同。没有参数 file 时，关闭默认输出文件。\n\n#### **file: flush ()**\n\n把写入缓冲区的所有数据写入到文件 file 中。\n\n#### **io. Flush ()**\n\n相当于 file: flush ()，把写入缓冲区的所有数据写入到默认输出文件。\n\n#### **io. Input ([file])**\n\n当使用一个文件名调用时，打开这个文件（以文本模式），并设置文件句柄为默认输入文件；当使用一个文件句柄调用时，设置此文件句柄为默认输入文件；当不使用参数调用时，返回默认输入文件句柄。\n\n#### **file: lines ()**\n\n返回一个迭代函数, 每次调用将获得文件中的一行内容, 当到文件尾时，将返回 nil，但不关闭文件。\n\n#### **io. Lines ([filename])**\n\n打开指定的文件 filename 为读模式并返回一个迭代函数, 每次调用将获得文件中的一行内容, 当到文件尾时，将返回 nil，并自动关闭文件。若不带参数时 io.Lines () 等价于 io.Input (): lines () 读取默认输入设备的内容，结束时不关闭文件。\n\n#### **io. Output ([file])**\n\n类似于 io. Input，但操作在默认输出文件上。\n\n#### **file: read (...)**\n\n按指定的格式读取一个文件。按每个格式将返回一个字符串或数字, 如果不能正确读取将返回 nil，若没有指定格式将指默认按行方式进行读取。格式：\n\n|        |                                                                                                        |\n| ------ | ------------------------------------------------------------------------------------------------------ |\n| 格式   | 含义                                                                                                   |\n| \"*n\"   | 读取一个数字                                                                                           |\n| \"*a\"   | 从当前位置读取整个文件。若当前位置为文件尾，则返回空字符串                                             |\n| \"*l\"   | 读取下一行的内容。若为文件尾，则返回 nil。(默认)                                                       |\n| number | 读取指定字节数的字符。若为文件尾，则返回 nil。如果 number 为 0, 则返回空字符串，若为文件尾, 则返回 nil |\n\n#### **io. Read (...)**\n\n相当于 io.Input ():read\n\n#### **io. Type (obj)**\n\n检测 obj 是否一个可用的文件句柄。如果 obj 是一个打开的文件句柄，则返回 \"file\" 如果 obj 是一个已关闭的文件句柄，则返回 \"closed file\" 如果 obj 不是一个文件句柄，则返回 nil。\n\n#### **file: write (...)**\n\n把每一个参数的值写入文件。参数必须为字符串或数字，若要输出其它值，则需通过 tostring 或 string. Format 进行转换。\n\n#### **io. Write (...)**\n\n相当于 io.Output (): write。\n\n#### **file: seek ([whence] [, offset])**\n\n设置和获取当前文件位置，成功则返回最终的文件位置 (按字节，相对于文件开头), 失败则返回 nil 加错误信息。缺省时，whence 默认为 \"cur\"，offset 默认为 0 。参数 whence：\n\n|        |                     |\n| ------ | ------------------- |\n| whence | 含义                |\n| \"set\"  | 文件开始            |\n| \"cur\"  | 文件当前位置 (默认) |\n| \"end\"  | 文件结束            |\n\n#### **file: setvbuf (mode [, size])**\n\n设置输出文件的缓冲模式。模式：\n\n|        |                                                              |\n| ------ | ------------------------------------------------------------ |\n| 模式   | 含义                                                         |\n| \"no\"   | 没有缓冲，即直接输出                                         |\n| \"full\" | 全缓冲，即当缓冲满后才进行输出操作 (也可调用 flush 马上输出) |\n| \"line\" | 以行为单位，进行输出                                         |\n\n最后两种模式，size 可以指定缓冲的大小（按字节），忽略 size 将自动调整为最佳的大小。","lastmodified":"2024-03-02T12:01:53.86221037Z","tags":["lua"]}}