{"/":{"title":"_index","content":"\n😀😁😲🌞🙀\n\n这是我的 [Obsidian](https://obsidian.md/) 的 vault ,我使用了 [quartz](https://github.com/jackyzha0/quartz) 搭建了这个页面。\n\n\u003e 关于如何搭建可以看这篇文章 [使用quartz发布obsidian  vault](Obsidian/使用quartz发布obsidian%20%20vault.md)\n\n可以算是我的博客，和资源库。主要包括的内容：\n\n* [工具](工具和环境/工具.md)\n\n* [环境搭建](工具和环境/环境搭建.md)\n\n* 各种笔记\n\n* [资源汇总](资源/资源汇总.md)\n\n\n\n\n\n\n\n\n","lastmodified":"2024-02-25T17:02:23.03496398Z","tags":[]},"/%E5%88%86%E5%B8%83%E5%BC%8F%E9%AB%98%E5%B9%B6%E5%8F%91%E9%AB%98%E6%80%A7%E8%83%BD%E9%AB%98%E5%8F%AF%E7%94%A8/%E6%97%A5%E5%BF%97/%E6%9C%8D%E5%8A%A1%E6%B2%BB%E7%90%86%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%8B%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86":{"title":"服务治理：分布式下如何进行日志管理？","content":"![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticPasted%20image%2020230802010117.png)","lastmodified":"2024-02-25T17:02:23.150963679Z","tags":[]},"/%E5%88%86%E5%B8%83%E5%BC%8F%E9%AB%98%E5%B9%B6%E5%8F%91%E9%AB%98%E6%80%A7%E8%83%BD%E9%AB%98%E5%8F%AF%E7%94%A8/%E7%9B%91%E6%8E%A7/%E6%9C%8D%E5%8A%A1%E6%B2%BB%E7%90%86%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E5%A6%82%E4%BD%95%E5%81%9A":{"title":"服务治理：监控系统如何做？","content":"![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticPasted%20image%2020230802010009.png)","lastmodified":"2024-02-25T17:02:23.150963679Z","tags":[]},"/%E5%B7%A5%E5%85%B7%E5%92%8C%E7%8E%AF%E5%A2%83/%E5%B7%A5%E5%85%B7":{"title":"工具","content":"","lastmodified":"2024-02-25T17:02:23.150963679Z","tags":[]},"/%E5%B7%A5%E5%85%B7%E5%92%8C%E7%8E%AF%E5%A2%83/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA":{"title":"环境搭建","content":"","lastmodified":"2024-02-25T17:02:23.150963679Z","tags":[]},"/%E5%B7%A5%E5%85%B7%E5%92%8C%E7%8E%AF%E5%A2%83/emacs/%E5%AE%89%E8%A3%85":{"title":"安装","content":"https://github.com/kiennq/emacs-build\n\n\n### 添加到菜单栏\n\n* 需要打开 server-mode\n\n```\n(server-mode 1)\n```\n\n\n* 新建文件 `emacs.reg`\n\n\u003e 注意修改路径\n\n```\nWindows Registry Editor Version 5.00\n\n[HKEY_CLASSES_ROOT\\*\\shell]\n[HKEY_CLASSES_ROOT\\*\\shell\\openwemacs]\n@=\"\u0026Edit with Emacs\"\n[HKEY_CLASSES_ROOT\\*\\shell\\openwemacs\\command]\n@=\"C:\\\\emax64\\\\bin\\\\emacsclientw.exe -n \\\"%1\\\"\"\n[HKEY_CLASSES_ROOT\\Directory\\shell\\openwemacs]\n@=\"Edit \u0026with Emacs\"\n[HKEY_CLASSES_ROOT\\Directory\\shell\\openwemacs\\command]\n@=\"C:\\\\emax64\\\\bin\\\\emacsclientw.exe -n \\\"%1\\\"\"\n```","lastmodified":"2024-02-25T17:02:23.150963679Z","tags":[]},"/%E5%B7%A5%E5%85%B7%E5%92%8C%E7%8E%AF%E5%A2%83/emacs/%E5%BF%AB%E6%8D%B7%E9%94%AE":{"title":"快捷键","content":"Emacs 这个东东听说功能很强大。不过感觉有些难学，还好网络上的资源还是比较丰富的。目前基于最基本的文本编辑来学习。而且它的快捷键很多，所以要在使用过程中学习会比较容易记住。这个是从网上搜索来的，总结的比较好的，贴在自己这里当做摘录了，方便查询。\n\nC = Control  \nM = Meta = Alt \nS =  Super = APPs\nDel = Backspace  \nRET = Enter\n\n\n**我常用的**\nM-x  所以命令\nC-x  C-r 最近的文件\nC-c C-l 重新加载配置\n\n\u003cf11\u003e 全屏\n\n\u003cf6\u003e 功能配置\n\nC-\u003cf6\u003e  mode-line功能配置\n\n  \n\n\n**基本快捷键 (Basic)**  \nC-x C-f  “find”文件, 即在缓冲区打开/新建一个文件  \nC-x C-s 保存文件  \nC-x C-w 使用其他文件名另存为文件  \nC-x C-v 关闭当前缓冲区文件并打开新文件  \nC-x i 在当前光标处插入文件  \nC-x b 新建/切换缓冲区  \nC-x C-b 显示缓冲区列表  \nC-x k 关闭当前缓冲区  \nC-z 挂起 emacs  \nC-x C-c 关闭 emacs\n\n**光标移动基本快捷键 (Basic Movement)**  \nC-f 后一个字符  \nC-b 前一个字符  \nC-p 上一行  \nC-n 下一行  \nM-f 后一个单词  \nM-b 前一个单词  \nC-a 行首  \nC-e 行尾  \nC-v 向下翻一页  \nM-v 向上翻一页  \nM-\u003c 到文件开头注意这里是‘\u003c’不是‘,’需要按 shift，遇到相同情况下同  \nM-\u003e 到文件末尾\n\n**编辑 (Editint)**  \nM-n 重复执行后一个命令 n 次  \nC-u 重复执行后一个命令 4 次  \nC-u n 重复执行后一个命令 n 次  \nC-d 删除 (delete)后一个字符  \nM-d 删除后一个单词  \nDel 删除前一个字符  \nM-Del 删除前一个单词  \nC-k 移除 (kill)一行\n\nC-Space 设置开始标记 (例如标记区域)  \nC-@ 功能同上, 用于 C-Space 被操作系统拦截的情况  \nC-w 移除 (kill)标记区域的内容  \nM-w 复制标记区域的内容  \nC-y 召回 (yank)复制/移除的区域/行  \nM-y 召回更早的内容 (在 kill 缓冲区内循环)  \nC-x C-x 交换光标和标记\n\nC-t 交换两个字符的位置  \nM-t 交换两个单词的位置  \nC-x C-t 交换两行的位置  \nM-u 使从光标位置到单词结尾处的字母变成大写  \nM-l 与 M-u 相反  \nM-c 使从光标位置开始的单词的首字母变为大写\n\n**重要快捷键 (Important)**  \nC-g 停止当前运行/输入的命令  \nC-x u 撤销前一个命令  \nM-x revert-buffer RETURN (照着这个输入)撤销上次存盘后所有改动  \nM-x recover-file RETURN 从自动存盘文件恢复  \nM-x recover-session RETURN 如果你编辑了几个文件, 用这个恢复\n\n**在线帮助 (Online-Help)**  \nC-h c 显示快捷键绑定的命令  \nC-h k 显示快捷键绑定的命令和它的作用  \nC-h l 显示最后 100 个键入的内容  \nC-h w 显示命令被绑定到哪些快捷键上  \nC-h f 显示函数的功能  \nC-h v 显示变量的含义和值  \nC-h b 显示当前缓冲区所有可用的快捷键  \nC-h t 打开 emacs 教程  \nC-h i 打开 info 阅读器  \nC-h C-f 显示 emacs FAQ  \nC-h p 显示本机 Elisp 包的信息\n\n**搜索/替换 (Seach/Replace)**  \nC-s 向后搜索  \nC-r 向前搜索  \nC-g 回到搜索开始前的位置 (如果你仍然在搜索模式中)  \nM-% 询问并替换 (query replace)\n\nSpace 或 y 替换当前匹配  \nDel 或 n 不要替换当前匹配  \n. 仅仅替换当前匹配并退出 (替换)  \n, 替换并暂停 (按 Space 或 y 继续)  \n! 替换以下所有匹配  \n^ 回到上一个匹配位置  \nRETURN 或 q 退出替换\n\n**使用正则表达式 (Regular expression)搜索/替换**  \n可在正则表达式中使用的符号:  \n^ 行首  \n$ 行尾  \n. 单个字符  \n.\\* 任意多个 (包括没有)字符  \n/\u003c 单词开头  \n/\u003e 单词结尾  \n\\[\\] 括号中的任意一个字符 (例如\\[a-z\\]表示所有的小写字母)\n\nM C-s RETURN 使用正则表达式向后搜索  \nM C-r RETURN 使用正则表达式向前搜索  \nC-s 增量搜索  \nC-s 重复增量搜索  \nC-r 向前增量搜索  \nC-r 重复向前增量搜索  \nM-x query-replace-regexp 使用正则表达式搜索并替换\n\n**窗口命令 (Window Commands)**  \nC-x 2 水平分割窗格  \nC-x 3 垂直分割窗格  \nC-x o 切换至其他窗格  \nC-x 0 关闭窗格  \nC-x 1 关闭除了光标所在窗格外所有窗格  \nC-x ^ 扩大窗格  \nM-x shrink-window 缩小窗格  \nM C-v 滚动其他窗格内容  \nC-x 4 f 在其他窗格中打开文件  \nC-x 4 0 关闭当前缓冲区和窗格  \nC-x 5 2 新建窗口 (frame)  \nC-x 5 f 在新窗口中打开文件  \nC-x 5 o 切换至其他窗口  \nC-x 5 0 关闭当前窗口\n\n**书签命令 (Bookmark commands)**  \nC-x r m 在光标当前位置创建书签  \nC-x r b 转到书签  \nM-x bookmark-rename 重命名书签  \nM-x bookmark-delete 删除书签  \nM-x bookmark-save 保存书签  \nC-x r l 列出书签清单\n\nD 标记等待删除  \nDel 取消删除标记  \nX 删除被标记的书签  \nR 重命名  \nS 保存列表内所有书签  \nF 转到当前书签指向的位置  \nM 标记在多窗口中打开  \nV 显示被标记的书签 (或者光标当前位置的书签)  \nT 切换是否显示路径列表  \nW 显示当前文件路径  \nQ 退出书签列表\n\nM-x bookmark-write 将所有书签导出至指定文件  \nM-x bookmark-load 从指定文件导入书签\n\n**Shell**  \nM-x shell 打开 shell 模式  \nC-c C-c 类似 unix 里的 C-c (停止正在运行的程序)  \nC-d 删除光标后一个字符  \nC-c C-d 发送 EOF  \nC-c C-z 挂起程序 (unix 下的 C-z)  \nM-p 显示前一条命令  \nM-n 显示后一条命令\n\n**DIRectory EDitor (dired)**  \nC-x d 打开 dired  \nC (大写 C) 复制  \nD 标记等待删除  \nD 立即删除  \nE 或 f 打开文件或目录  \nG 刷新当前目录  \nG 改变文件所属组 (chgrp)  \nK 从屏幕上的列表里删除一行 (不是真的删除)  \nM 用\\*标记  \nN 光标移动到下一行  \nO 在另一个窗格打开文件并移动光标  \nC-o 在另一个窗格打开文件但不移动光标  \nP 打印文件  \nQ 退出 dired  \nQ 在标记的文件中替换  \nR 重命名文件  \nU 移除标记  \nV 显示文件内容  \nX 删除有 D 标记的文件  \nZ 压缩/解压缩文件  \nM-Del 移除标记 (默认为所有类型的标记)  \n~ 标记备份文件 (文件名有~的文件)等待删除  \n\\# 标记自动保存文件 (文件名形如 #name #)等待删除  \n\\*/ 用\\*标记所有文件夹 (用 C-u \\*/n 移除标记)  \n\\= 将当前文件和标记文件 (使用 C-@标记而不是 dired 的 m 标记)比较  \nM-= 将当前文件和它的备份比较  \n! 对当前文件应用 shell 命令  \nM-} 移动光标至下一个用\\*或 D 标记的文件  \nM-{ 移动光标至上一个用\\*或 D 标记的文件  \n% d 使用正则表达式标记文件等待删除  \n% m 使用正则表达式标记文件为\\*  \n\\+ 新建文件夹  \n\\\u003e 移动光标至后一个文件夹  \n\u003c 移动光标至前一个文件夹  \nS 切换排序模式 (按文件名/日期)\n\n或许把这个命令归入这一类也很合适:  \nM-x speedbar 打开一个独立的目录显示窗口\n\n**Telnet**（大致了解）  \nM-x telnet 打开 telnet 模式  \nC-d 删除后一个字符或发送 EOF  \nC-c C-c 停止正在运行的程序 (和 unix 下的 C-c 类似)  \nC-c C-d 发送 EOF  \nC-c C-o 清除最后一个命令的输出  \nC-c C-z 挂起正在运行的命令  \nC-c C-u 移除前一行  \nM-p 显示前一条命令\n\n**Text**  \n只能在 text 模式里使用  \nM-s 使当前行居中  \nM-S 使当前段落居中  \nM-x center-region 使被选中的区域居中\n\n**宏命令 (Macro-commands)**（大致了解）  \nC-x ( 开始定义宏  \nC-x ) 结束定义宏  \nC-x e 运行最近定义的宏  \nM-n C-x e 运行最近定义的宏 n 次  \nM-x name-last-kbd-macro 给最近定义的宏命名 (用来保存)  \nM-x insert-kbd-macro 将已命名的宏保存到文件  \nM-x load-file 载入宏\n\n**编程 (Programming)**  \nM C-/ 自动缩进光标和标记间的区域  \nM-m 移动光标到行首第一个 (非空格)字符  \nM-^ 将当前行接到上一行末尾处  \nM-; 添加缩进并格式化的注释  \nC, C++和 Java 模式  \nM-a 移动光标到声明的开始处  \nM-e 移动光标到声明的结尾处  \nM C-a 移动光标到函数的开始处  \nM C-e 移动光标到函数的结尾处  \nC-c RETURN 将光标移动到函数的开始处并标记到结尾处  \nC-c C-q 根据缩进风格缩进整个函数  \nC-c C-a 切换自动换行功能  \nC-c C-d 一次性删除光标后的一串空格 (greedy delete)\n\n为了实现下面的一些技术, 你需要在保存源代码的目录里运行”etags  \n\\*. C \\*. H \\*. Cpp”(或者源代码的其他的扩展名)  \nM-. (点) 搜索标签  \nM-x tags-search ENTER 在所有标签里搜索 (使用正则表达式)  \nM-, (逗号) 在 tags-search 里跳至下一个匹配处  \nM-x tags-query-replace 在设置过标签的所有文件里替换文本\n\n**GDB (调试器)（大致了解）**  \nM-x gdb 在另一个的窗格中打开 gdb\n\n**版本控制 (Version Control)（以后会用到现在大致了解就可以了）**  \nC-x v d 显示当前目录下所有注册过的文件 (show all registered files in this dir)  \nC-x v = 比较不同版本间的差异 (show diff between versions)  \nC-x v u 移除上次提交之后的更改 (remove all changes since last checkin)  \nC-x v ~ 在不同窗格中显示某个版本 (show certain version in different window)  \nC-x v l 打印日志 (print log)  \nC-x v i 标记文件等待添加版本控制 (mark file for version control add)  \nC-x v h 给文件添加版本控制文件头 (insert version control header into file)  \nC-x v r 获取命名过的快照 (check out named snapshot)  \nC-x v s 创建命名的快照 (create named snapshot)  \nC-x v a 创建 gnu 风格的更改日志 (create changelog file in gnu-style)\n\n**文件操作：**\n\nC+x C+f  \n打开文件  \nC+x C+r  \n以只读的方式打开文件  \nC+x C+q  \n进行只读/读写模式切换  \nC+x C+v  \n切换缓冲区  \nC+x C+s  \n保存文件  \nC+x C+w  \n文件另存为  \nC+x i  \n向缓冲区中插入文件\n\n移动操作：C+f  \n前进一个字符 C+b  \n后退一个字符 M+f  \n前进一个单词 M+b  \n后退一个单词 C+a  \n移动到行首 C+e  \n移动到行尾 M+a  \n移动到句首 M+e  \n移动到句尾 C+p  \n后退一行 C+n  \n前进一行 M+g g  \n跳到指定行 C+v  \n向下翻页 M+v  \n向上翻页 M+\u003c 移动到缓冲区首M+\u003e  \n移动到缓冲区尾 C+M+f  \n向前匹配括号 C+M+b  \n向后匹配括号标记/复制/剪切/粘贴：C+xh  \n全选 C+@  \n标记开始 M+w  \n复制区域到 kill ring 中，但不删除 C+w  \n删除区域 C+y  \n将 kill ring 中的内容粘贴到缓冲区 C+Del  \n剪切光标到单词结束 M+Del  \n剪切光标到单词开始 C+k  \n剪切光标到行结尾 M+k  \n剪切光标到句结尾 (C+d)/Del  \n删除光标上的字 M+d  \n剪切光标到下一个单词结尾 ctrl-S (shift+s)-Backspace  \n删除当前行\n\n**缓冲区操作：**\n\nC+x C+f 打开/创建一个文件，并创建一个新的缓冲区\n\nC+x C+s 保存缓冲区内容到文件\n\nC+x C+w 保存缓冲区内容到其它文件\n\nC+xk 关闭当前缓冲区\n\nC+x C+b 显示缓冲区列表，可以使用方向键来选择缓冲区\n\nC+x C+c 关闭所有缓冲区，并推出 emacs\n\n**M+x 命令：**\n\n查找和替换：  \nC+s 向前查找 C+r 向后查找按下这两个快捷键后，  \nM+p 显示上一个搜索词，  \nM+n 显示下一个搜索词。输入查找内容后，按 C+s 跳到下一个结果，  \nC+r 跳到上一个结果。  \nEnter 结束查找光标在当前位置，C+g 取消查找光标返回原处。\n\n2，查找单词\n\n按 C - s RET C - w 或 C - r RET C - w 来使用单词搜索。\n\n3，查找及替换\n\n按 M - %启动查找替换，输入要被替换的词，回车，然后输入要替换的词，再回车。\n\n被替换的词会高亮起来，这时，输入 y 替换并跳到下一个，输入 n 忽略并跳到下一个，输入 q 结束，输入！替换剩下的全部。\n\n一些常用的选项：\n\nC - g 中断查找替换过程。\n\n^ 返回上一个替换点，按 y 继续下一个，如果不想替换上一个的话，用^返回到上一个，然后按 C - r 进入编辑，修改完后按 C- M - c 退出继续下一个。\n\nC - l 使当前匹配显示在文档中间。\n\nC - r 进入修改。\n\n4，列出匹配的模式\n\n有时候想列出匹配的全面模式，而不是在文档中浏览，这个可以使用 occur 这个函数。\n\n例子：M - x occur RET Create RET\n\n这时，emacs 会新开一个窗口来列出匹配的行，用鼠标点击或把光标移到一行按回车就会跳转到那里。\n\n执行 SHELL 命令\n\nM-x shell  \n打开 shell 命令  \nM-!  \n执行 shell 命令（shell-command）  \nM-1 M-!  \n执行 Shell 命令，命令输出插入光标位置，不打开新输入窗口  \nM-|  \n针对某一特定区域执行命令 (shell-command-on-region), 比如 C-x h M-juuencode\n\n窗口操作\n\nC-x 0  \n关闭本窗口  \nC-x 1  \n只留下一个窗口  \nC-x 2  \n垂直均分窗口  \nC-x 3  \n水平均分窗口  \nC-x o  \n切换到别的窗口  \nC-x s  \n保存所有窗口的缓冲  \nC-x b  \n选择当前窗口的缓冲区  \nC-x ^  \n纵向扩大窗口  \nC-x }  \n横向扩大窗口\n\n目录操作\n\nC-x d  \n打开目录模式  \nS  \n按日期/文件名排序显示  \nV  \n阅读光标所在的文件  \nQ  \n退出阅读的文件  \nD  \n标记为删除  \nX  \n执行标记  \nD  \n马上删除当前文件  \nC  \n拷贝当前文件  \nR  \n重命名当前文件  \n+  \n新建文件  \nZ  \n压缩文件  \n！  \n对光标所在的文件执行 SHELL 命令  \nG  \n刷新显示  \nI  \n在当前缓冲区的末尾插入子目录的内容  \n\\[n\\]m  \n标记光标所在的文件，如果指定 n, 则从光标所在的文件后 n 个文件被标记  \n\\[n\\]u  \n取消当前光标标记的文件，n 的含义同上  \nT  \n反向标记文件  \n%-m  \n正则标记  \nQ  \n退出目录模式\n\n其他：\n\nC+x u 撤销\n\nC+x C+c 退出 emacs","lastmodified":"2024-02-25T17:02:23.150963679Z","tags":[]},"/%E5%B7%A5%E5%85%B7%E5%92%8C%E7%8E%AF%E5%A2%83/git/git":{"title":"git","content":"\n## 版本控制\n\n### 什么是版本控制\n\n版本控制是一种记录一个或若干文件内容变化，以便将来查阅特定版本修订情况的系统。除了项目源代码，你可以对任何类型的文件进行版本控制。\n\n### 为什么要版本控制\n\n有了它你就可以将某个文件回溯到之前的状态，甚至将整个项目都回退到过去某个时间点的状态，你可以比较文件的变化细节，查出最后是谁修改了哪个地方，从而找出导致怪异问题出现的原因，又是谁在何时报告了某个功能缺陷等等。\n\n### 本地版本控制系统\n\n许多人习惯用复制整个项目目录的方式来保存不同的版本，或许还会改名加上备份时间以示区别。这么做唯一的好处就是简单，但是特别容易犯错。有时候会混淆所在的工作目录，一不小心会写错文件或者覆盖意想外的文件。\n\n为了解决这个问题，人们很久以前就开发了许多种本地版本控制系统，大多都是采用某种简单的数据库来记录文件的历次更新差异。\n\n![本地版本控制系统](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic%E6%9C%AC%E5%9C%B0%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6%E7%B3%BB%E7%BB%9F.png)\n\n### 集中化的版本控制系统\n\n接下来人们又遇到一个问题，如何让在不同系统上的开发者协同工作？ 于是，集中化的版本控制系统（Centralized Version Control Systems，简称 CVCS）应运而生。\n\n集中化的版本控制系统都有一个单一的集中管理的服务器，保存所有文件的修订版本，而协同工作的人们都通过客户端连到这台服务器，取出最新的文件或者提交更新。\n\n![集中化的版本控制系统](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic%E9%9B%86%E4%B8%AD%E5%8C%96%E7%9A%84%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6%E7%B3%BB%E7%BB%9F.png)\n\n这么做虽然解决了本地版本控制系统无法让在不同系统上的开发者协同工作的诟病，但也还是存在下面的问题：\n\n- **单点故障：** 中央服务器宕机，则其他人无法使用；如果中心数据库磁盘损坏又没有进行备份，你将丢失所有数据。本地版本控制系统也存在类似问题，只要整个项目的历史记录被保存在单一位置，就有丢失所有历史更新记录的风险。\n- **必须联网才能工作：** 受网络状况、带宽影响。\n\n### 分布式版本控制系统\n\n于是分布式版本控制系统（Distributed Version Control System，简称 DVCS）面世了。 Git 就是一个典型的分布式版本控制系统。\n\n这类系统，客户端并不只提取最新版本的文件快照，而是把代码仓库完整地镜像下来。这么一来，任何一处协同工作用的服务器发生故障，事后都可以用任何一个镜像出来的本地仓库恢复。因为每一次的克隆操作，实际上都是一次对代码仓库的完整备份。\n\n![分布式版本控制系统](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic%E5%88%86%E5%B8%83%E5%BC%8F%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6%E7%B3%BB%E7%BB%9F.png)\n\n分布式版本控制系统可以不用联网就可以工作，因为每个人的电脑上都是完整的版本库，当你修改了某个文件后，你只需要将自己的修改推送给别人就可以了。但是，在实际使用分布式版本控制系统的时候，很少会直接进行推送修改，而是使用一台充当“中央服务器”的东西。这个服务器的作用仅仅是用来方便“交换”大家的修改，没有它大家也一样干活，只是交换修改不方便而已。\n\n分布式版本控制系统的优势不单是不必联网这么简单，后面我们还会看到 Git 极其强大的分支管理等功能。\n\n## 认识 Git\n\n### Git 简史\n\nLinux 内核项目组当时使用分布式版本控制系统 BitKeeper 来管理和维护代码。但是，后来开发 BitKeeper 的商业公司同 Linux 内核开源社区的合作关系结束，他们收回了 Linux 内核社区免费使用 BitKeeper 的权力。 Linux 开源社区（特别是 Linux 的缔造者 Linus Torvalds）基于使用 BitKeeper 时的经验教训，开发出自己的版本系统，而且对新的版本控制系统做了很多改进。\n\n### Git 与其他版本管理系统的主要区别\n\nGit 在保存和对待各种信息的时候与其它版本控制系统有很大差异，尽管操作起来的命令形式非常相近，理解这些差异将有助于防止你使用中的困惑。\n\n下面我们主要说一个关于 Git 与其他版本管理系统的主要差别：**对待数据的方式**。\n\n**Git 采用的是直接记录快照的方式，而非差异比较。我后面会详细介绍这两种方式的差别。**\n\n大部分版本控制系统（CVS、Subversion、Perforce、Bazaar 等等）都是以文件变更列表的方式存储信息，这类系统**将它们保存的信息看作是一组基本文件和每个文件随时间逐步累积的差异。**\n\n具体原理如下图所示，理解起来其实很简单，每当我们提交更新一个文件之后，系统都会记录这个文件做了哪些更新，以增量符号 Δ(Delta)表示。\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic2019-3deltas.png)\n\n**我们怎样才能得到一个文件的最终版本呢？**\n\n很简单，高中数学的基本知识，我们只需要将这些原文件和这些增加进行相加就行了。\n\n**这种方式有什么问题呢？**\n\n比如我们的增量特别特别多的话，如果我们要得到最终的文件是不是会耗费时间和性能。\n\nGit 不按照以上方式对待或保存数据。反之，Git 更像是把数据看作是对小型文件系统的一组快照。每次你提交更新，或在 Git 中保存项目状态时，它主要对当时的全部文件制作一个快照并保存这个快照的索引。为了高效，如果文件没有修改，Git 不再重新存储该文件，而是只保留一个链接指向之前存储的文件。 Git 对待数据更像是一个 **快照流**。\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic2019-3snapshots.png)\n\n### Git 的三种状态\n\nGit 有三种状态，你的文件可能处于其中之一：\n\n1. **已提交（committed）**：数据已经安全的保存在本地数据库中。\n2. **已修改（modified）**：已修改表示修改了文件，但还没保存到数据库中。\n3. **已暂存（staged）**：表示对一个已修改文件的当前版本做了标记，使之包含在下次提交的快照中。\n\n由此引入 Git 项目的三个工作区域的概念：**Git 仓库 (. Git directory)**、**工作目录 (Working Directory)** 以及 **暂存区域 (Staging Area)** 。\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic2019-3areas.png)\n\n**基本的 Git 工作流程如下：**\n\n1. 在工作目录中修改文件。\n2. 暂存文件，将文件的快照放入暂存区域。\n3. 提交更新，找到暂存区域的文件，将快照永久性存储到 Git 仓库目录。\n\n## Git 使用快速入门\n\n### 获取 Git 仓库\n\n有两种取得 Git 项目仓库的方法。\n\n1. 在现有目录中初始化仓库: 进入项目目录运行 `git init` 命令, 该命令将创建一个名为 `.git` 的子目录。\n2. 从一个服务器克隆一个现有的 Git 仓库: `git clone [url]` 自定义本地仓库的名字: `git clone [url] directoryname`\n\n### 记录每次更新到仓库\n\n1. **检测当前文件状态** : `git status`\n2. **提出更改（把它们添加到暂存区**）：`git add filename` (针对特定文件)、`git add *` (所有文件)、`git add *.txt`（支持通配符，所有 .txt 文件）\n3. **忽略文件**：`.gitignore` 文件\n4. **提交更新:** `git commit -m \"代码提交信息\"` （每次准备提交前，先用 `git status` 看下，是不是都已暂存起来了，然后再运行提交命令 `git commit`）\n5. **跳过使用暂存区域更新的方式** : `git commit -a -m \"代码提交信息\"`。 `git commit` 加上 `-a` 选项，Git 就会自动把所有已经跟踪过的文件暂存起来一并提交，从而跳过 `git add` 步骤。\n6. **移除文件**：`git rm filename` （从暂存区域移除，然后提交。）\n7. **对文件重命名**：`git mv README.md README` (这个命令相当于 `mv README.md README`、`git rm README.md`、`git add README` 这三条命令的集合)\n\n### 一个好的 Git 提交消息\n\n一个好的 Git 提交消息如下：\n\n```\n标题行：用这一行来描述和解释你的这次提交\n\n主体部分可以是很少的几行，来加入更多的细节来解释提交，最好是能给出一些相关的背景或者解释这个提交能修复和解决什么问题。\n\n主体部分当然也可以有几段，但是一定要注意换行和句子不要太长。因为这样在使用 \"git log\" 的时候会有缩进比较好看。\n```\n\n提交的标题行描述应该尽量的清晰和尽量的一句话概括。这样就方便相关的 Git 日志查看工具显示和其他人的阅读。\n\n### 推送改动到远程仓库\n\n- 如果你还没有克隆现有仓库，并欲将你的仓库连接到某个远程服务器，你可以使用如下命令添加：`git remote add origin \u003cserver\u003e` ,比如我们要让本地的一个仓库和 GitHub 上创建的一个仓库关联可以这样 `git remote add origin https://github.com/Snailclimb/test.git`\n- 将这些改动提交到远端仓库：`git push origin master` (可以把 _master_ 换成你想要推送的任何分支)\n\n  如此你就能够将你的改动推送到所添加的服务器上去了。\n\n### 远程仓库的移除与重命名\n\n- 将 test 重命名为 test 1：`git remote rename test test 1`\n- 移除远程仓库 test 1:`git remote rm test 1`\n\n### 查看提交历史\n\n在提交了若干更新，又或者克隆了某个项目之后，你也许想回顾下提交历史。完成这个任务最简单而又有效的工具是 `git log` 命令。`git log` 会按提交时间列出所有的更新，最近的更新排在最上面。\n\n**可以添加一些参数来查看自己希望看到的内容：**\n\n只看某个人的提交记录：\n\n```shell\nGit log --author=bob\n```\n\n### 撤销操作\n\n有时候我们提交完了才发现漏掉了几个文件没有添加，或者提交信息写错了。此时，可以运行带有 `--amend` 选项的提交命令尝试重新提交：\n\n```shell\nGit commit --amend\n```\n\n取消暂存的文件\n\n```shell\nGit reset filename\n```\n\n撤消对文件的修改:\n\n```shell\nGit checkout -- filename\n```\n\n假如你想丢弃你在本地的所有改动与提交，可以到服务器上获取最新的版本历史，并将你本地主分支指向它：\n\n```shell\nGit fetch origin\nGit reset --hard origin/master\n```\n\n### 分支\n\n分支是用来将特性开发绝缘开来的。在你创建仓库的时候，_master_ 是“默认”的分支。在其他分支上进行开发，完成后再将它们合并到主分支上。\n\n我们通常在开发新功能、修复一个紧急 bug 等等时候会选择创建分支。单分支开发好还是多分支开发好，还是要看具体场景来说。\n\n创建一个名字叫做 test 的分支\n\n```shell\nGit branch test\n```\n\n切换当前分支到 test（当你切换分支的时候，Git 会重置你的工作目录，使其看起来像回到了你在那个分支上最后一次提交的样子。 Git 会自动添加、删除、修改文件以确保此时你的工作目录和这个分支最后一次提交时的样子一模一样）\n\n```shell\nGit checkout test\n```\n\n\n你也可以直接这样创建分支并切换过去 (上面两条命令的合写)\n\n```shell\nGit checkout -b feature_x\n```\n\n切换到主分支\n\n```shell\nGit checkout master\n```\n\n合并分支 (可能会有冲突)\n\n```shell\n Git merge test\n```\n\n把新建的分支删掉\n\n```shell\nGit branch -d feature_x\n```\n\n将分支推送到远端仓库（推送成功后其他人可见）：\n\n```shell\nGit push origin\n```\n\n\n---\nTitle: Github 实用小技巧总结\nCategory: 开发工具\nTag:\n  - Git\n---\n\n我使用 Github 已经有 6 年多了，今天毫无保留地把自己觉得比较有用的 Github 小技巧送给关注 JavaGuide 的各位小伙伴。\n\n## 一键生成 Github 简历 \u0026 Github 年报\n\n通过 [https://resume.github.io/](https://resume.github.io/) 这个网站你可以一键生成一个在线的 Github 简历。\n\n当时我参加的校招的时候，个人信息那里就放了一个在线的 Github 简历。我觉得这样会让面试官感觉你是一个内行，会提高一些印象分。\n\n但是，如果你的 Github 没有什么项目的话还是不要放在简历里面了。生成后的效果如下图所示。\n\n![Github简历](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticGithub%E7%AE%80%E5%8E%86.png)\n\n通过 \u003chttps://www.githubtrends.io/wrapped\u003e 这个网站，你可以生成一份 Github 个人年报，这个年报会列举出你在这一年的项目贡献情况、最常使用的编程语言、详细的贡献信息。\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticimage-20211226144607457.png)\n\n## 个性化 Github 首页\n\nGithub 目前支持在个人主页自定义展示一些内容。展示效果如下图所示。\n\n![个性化首页展示效果](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic%E4%B8%AA%E6%80%A7%E5%8C%96%E9%A6%96%E9%A1%B5%E5%B1%95%E7%A4%BA%E6%95%88%E6%9E%9C.png)\n\n想要做到这样非常简单，你只需要创建一个和你的 Github 账户同名的仓库，然后自定义 `README.md` 的内容即可。\n\n展示在你主页的自定义内容就是 `README.md` 的内容（_不会 Markdown 语法的小伙伴自行面壁 5 分钟_）。\n\n![创建一个和你的Github账户同名的仓库](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AA%E5%92%8C%E4%BD%A0%E7%9A%84Github%E8%B4%A6%E6%88%B7%E5%90%8C%E5%90%8D%E7%9A%84%E4%BB%93%E5%BA%93.png)\n\n这个也是可以玩出花来的！比如说：通过 [github-readme-stats](https://hellogithub.com/periodical/statistics/click/?target=https://github.com/anuraghazra/github-readme-stats) 这个开源项目，你可以 README 中展示动态生成的 GitHub 统计信息。展示效果如下图所示。\n\n![通过github-readme-stats动态生成GitHub统计信息 ](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic%E9%80%9A%E8%BF%87github-readme-stats%E5%8A%A8%E6%80%81%E7%94%9F%E6%88%90GitHub%E7%BB%9F%E8%AE%A1%E4%BF%A1%E6%81%AF_.png)\n\n关于个性化首页这个就不多提了，感兴趣的小伙伴自行研究一下。\n\n## 自定义项目徽章\n\n你在 Github 上看到的项目徽章都是通过 [https://shields.io/](https://shields.io/) 这个网站生成的。我的 JavaGuide 这个项目的徽章如下图所示。\n\n![项目徽章](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic%E9%A1%B9%E7%9B%AE%E5%BE%BD%E7%AB%A0.png)\n\n并且，你不光可以生成静态徽章，shield. Io 还可以动态读取你项目的状态并生成对应的徽章。\n\n![自定义项目徽章](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic%E8%87%AA%E5%AE%9A%E4%B9%89%E9%A1%B9%E7%9B%AE%E5%BE%BD%E7%AB%A0.png)\n\n生成的描述项目状态的徽章效果如下图所示。\n\n![描述项目状态的徽章](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic%E6%8F%8F%E8%BF%B0%E9%A1%B9%E7%9B%AE%E7%8A%B6%E6%80%81%E7%9A%84%E5%BE%BD%E7%AB%A0.png)\n\n## 自动为项目添加贡献情况图标\n\n通过 repobeats 这个工具可以为 Github 项目添加如下图所示的项目贡献基本情况图表，挺不错的 👍\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticrepobeats.png)\n\n地址：\u003chttps://repobeats.axiom.co/\u003e 。\n\n## Github 表情\n\n![Github表情](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticGithub%E8%A1%A8%E6%83%85.png)\n\n如果你想要在 Github 使用表情的话，可以在这里找找：[www.webfx.com/tools/emoji-cheat-sheet/](https://www.webfx.com/tools/emoji-cheat-sheet/)。\n\n![在线Github表情](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic%E5%9C%A8%E7%BA%BFGithub%E8%A1%A8%E6%83%85.png)\n\n## 高效阅读 Github 项目的源代码\n\nGithub 前段时间推出的 Codespaces 可以提供类似 VS Code 的在线 IDE，不过目前还没有完全开发使用。\n\n简单介绍几种我最常用的阅读 Github 项目源代码的方式。\n\n### Chrome 插件 Octotree\n\n这个已经老生常谈了，是我最喜欢的一种方式。使用了 Octotree 之后网页侧边栏会按照树形结构展示项目，为我们带来 IDE 般的阅读源代码的感受。\n\n![Chrome插件Octotree](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticChrome%E6%8F%92%E4%BB%B6Octotree.png)\n\n### Chrome 插件 SourceGraph\n\n我不想将项目 clone 到本地的时候一般就会使用这种方式来阅读项目源代码。SourceGraph 不仅可以让我们在 Github 优雅的查看代码，它还支持一些骚操作，比如：类之间的跳转、代码搜索等功能。\n\n当你下载了这个插件之后，你的项目主页会多出一个小图标如下图所示。点击这个小图标即可在线阅读项目源代码。\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticimage-20201107145749659.png)\n\n使用 SourceGraph 阅读代码的就像下面这样，同样是树形结构展示代码，但是我个人感觉没有 Octotree 的手感舒服。不过，SourceGraph 内置了很多插件，而且还支持类之间的跳转！\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticimage-20201107150307314.png)\n\n### 克隆项目到本地\n\n先把项目克隆到本地，然后使用自己喜欢的 IDE 来阅读。可以说是最酸爽的方式了！\n\n如果你想要深入了解某个项目的话，首选这种方式。一个 `git clone` 就完事了。\n\n## 扩展 Github 的功能\n\n**Enhanced GitHub** 可以让你的 Github 更好用。这个 Chrome 插件可以可视化你的 Github 仓库大小，每个文件的大小并且可以让你快速下载单个文件。\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticimage-20201107160817672.png)\n\n## 自动为 Markdown 文件生成目录\n\n如果你想为 Github 上的 Markdown 文件生成目录的话，通过 VS Code 的 **Markdown Preview Enhanced** 这个插件就可以了。\n\n生成的目录效果如下图所示。你直接点击目录中的链接即可跳转到文章对应的位置，可以优化阅读体验。\n\n![](\u003chttps://oss.javaguide.cn/2020-11/iShot2020-11-07%2016.14.14%20(1).png\u003e)\n\n不过，目前 Github 已经自动为 Markdown 文件生成了目录，只是需要通过点击的方式才能显示出来。\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticimage-20211227093215005.png)\n\n## 善用 Github Explore\n\n其实，Github 自带的 Explore 是一个非常强大且好用的功能。不过，据我观察，国内很多 Github 用户都不知道这个到底是干啥的。\n\n简单来说，Github Explore 可以为你带来下面这些服务：\n\n1. 可以根据你的个人兴趣为你推荐项目；\n2. Githunb Topics 按照类别/话题将一些项目进行了分类汇总。比如 [Data visualization](https://github.com/topics/data-visualization) 汇总了数据可视化相关的一些开源项目，[Awesome Lists](https://github.com/topics/awesome) 汇总了 Awesome 系列的仓库；\n3. 通过 Github Trending 我们可以看到最近比较热门的一些开源项目，我们可以按照语言类型以及时间维度对项目进行筛选；\n4. Github Collections 类似一个收藏夹集合。比如 [Teaching materials for computational social science](https://github.com/collections/teaching-computational-social-science) 这个收藏夹就汇总了计算机课程相关的开源资源，[Learn to Code](https://github.com/collections/learn-to-code) 这个收藏夹就汇总了对你学习编程有帮助的一些仓库；\n5. ......\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticgithub-explore.png)\n\n## GitHub Actions 很强大\n\n你可以简单地将 GitHub Actions 理解为 Github 自带的 CI/CD ，通过 GitHub Actions 你可以直接在 GitHub 构建、测试和部署代码，你还可以对代码进行审查、管理 API、分析项目依赖项。总之，GitHub Actions 可以自动化地帮你完成很多事情。\n\n关于 GitHub Actions 的详细介绍，推荐看一下阮一峰老师写的 [GitHub Actions 入门教程](https://www.ruanyifeng.com/blog/2019/09/getting-started-with-github-actions.html) 。\n\nGitHub Actions 有一个官方市场，上面有非常多别人提交的 Actions ，你可以直接拿来使用。\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticimage-20211227100147433.png)\n\n## 后记\n\n这一篇文章，我毫无保留地把自己这些年总结的 Github 小技巧分享了出来，真心希望对大家有帮助，真心希望大家一定要利用好 Github 这个专属程序员的宝藏。\n\n另外，这篇文章中，我并没有提到 Github 搜索技巧。在我看来，Github 搜索技巧不必要记网上那些文章说的各种命令啥的，真没啥卵用。你会发现你用的最多的还是关键字搜索以及 Github 自带的筛选功能。\n\n\n\n## 学习资料推荐\n\n**在线演示学习工具：**\n\n「补充，来自 [issue729](https://github.com/Snailclimb/JavaGuide/issues/729) 」Learn Git Branching \u003chttps://oschina.gitee.io/learn-git-branching/\u003e 。该网站可以方便的演示基本的 git 操作，讲解得明明白白。每一个基本命令的作用和结果。\n\n**推荐阅读：**\n\n- [Git 入门图文教程(1.5W 字 40 图)](https://www.cnblogs.com/anding/p/16987769.html)：超用心的一篇文章，内容全面且附带详细的图解，强烈推荐！\n- [Git - 简明指南](https://rogerdudler.github.io/git-guide/index.zh.html)：涵盖 Git 常见操作，非常清晰。\n- [图解 Git](https://marklodato.github.io/visual-git-guide/index-zh-cn.html)：图解 Git 中的最常用命令。如果你稍微理解 git 的工作原理，这篇文章能够让你理解的更透彻。\n- [猴子都能懂得 Git 入门](https://backlog.com/git-tutorial/cn/intro/intro1_1.html)：有趣的讲解。\n- [Pro Git book](https://git-scm.com/book/zh/v2)：国外的一本 Git 书籍，被翻译成多国语言，质量很高。","lastmodified":"2024-02-25T17:02:23.150963679Z","tags":[]},"/%E5%B7%A5%E5%85%B7%E5%92%8C%E7%8E%AF%E5%A2%83/msys2/pacman":{"title":"pacman","content":"# 安装软件\n\n- `pacman -S (软件名)`：安装软件，若有多个软件包，空格分隔\n- `pacman -S --needed （软件名）`：安装软件，若存在，不重新安装最新的软件\n- `pacman -Sy (软件名)`：安装软件前，先从远程仓库下载软件包数据库\n- `pacman -Sv (软件名)`：输出操作信息后安装\n- `pacman -Sw (软件名)`：只下载软件包，而不安装\n- `pacman -U (软件名.pkg.tar.gz)`：安装本地软件包\n- `pacman -U (http://www.xxx.com/xxx.pkg.tar.xz)`：安装一个远程包\n\n# 卸载软件\n\n- `pacman -R (软件名)`：只卸载软件包不卸载依赖的软件\n- `pacman -Rv (软件名)`：卸载软件，并输出卸载信息\n- `pacman -Rs (软件名)`：卸载软件，并同时卸载该软件的依赖软件\n- `pacman -Rsc (软件名)`：卸载软件，并卸载依赖该软件的程序\n- `pacman -Ru (软件名)`：卸载软件，同时卸载不被任何软件所依赖\n\n# 搜索软件\n\n- `pacman -Ss (关键字)`：在仓库搜索包含关键字的软件包\n- `pacman -Sl`：显示软件仓库所有软件的列表\n- `pacman -Qs (关键字)`：搜索已安装的软件包\n- `pacman -Qu`：列出可升级的软件包\n- `pacman -Qt`：列出不被任何软件要求的软件包\n- `pacman -Q (软件名)`：查看软件包是否已安装\n- `pacman -Qi (软件包)`：查看某个软件包详细信息\n- `pacman -Ql (软件名)`：列出软件包所有文件安装路径\n\n# 软件包组\n\n- `pacman -Sg`：列出软件仓库上所有软件包组\n- `pacman -Qg`：列出本地已经安装的软件包组和子软件包\n- `pacman -Sg (软件包组)`：查看软件包组所包含的软件包\n- `pacman -Qg (软件包组)`：查看软件包组所包含的软件包\n\n# 更新系统\n\n- `pacman -Sy`：从服务器下载最新的软件包数据库到本地\n- `pacman -Su`：升级所有已安装的软件包\n- `pacman -Syu`：升级整个系统\n\n# 清理缓存\n\n- `pacman -Sc`：清理未安装的软件包文件\n- `pacman -Scc`：清理所有的缓存文件","lastmodified":"2024-02-25T17:02:23.150963679Z","tags":[]},"/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E5%AF%B9%E6%AF%94":{"title":"消息队列对比","content":"\n# 性能和可靠性\n\n## 副本与存储结构\n\nPulsar通过BookKeeper实现了数据的高可靠。在BookKeeper中Ledger是基本的持久化存储单元。Pulsar的每个主题的数据都会在逻辑上映射为多个Ledger。每个Ledger在服务端会存储多个副本。为了灵活地控制存储时的一致性，BookKeeper在存储时提供了3个关键的参数—数据存储的副本数（Ensemble Size，直译为集合数量）、最大写入副本数（Write Quorum Size，直译为法定写入数量）、最小写入副本数（Ack Quorum Size，直译为法定确认数量）\n集群的高可用一般通过多副本机制来保障。Pulsar、Kafka、RabbitMQ 与 RocketMQ 都依赖副本或备份来保障高可用。\n\n* Kafka 以分区维度进行高可用保障，每个分区的数据会保存多个副本。在多个副本中会有一个被选为主副本并负责数据的读取与写入。与此同时，主副本还负责将数据同步至其他副本。在集群视角下，各个主副本会分布在不同的节点上，从全局来看，每个服务端的负载是相对均衡的\n* RocketMQ 依赖主从复制机制来实现数据的多副本，从而保证服务的可靠性。不同于 Kafka 采用物理分区方式（每个分区对应一个真实的日志文件），RocketMQ 采用逻辑分区的方式。RocketMQ 消息的存储由逻辑队列和物理日志一同实现，其中物理日志负责将消息存储在物理存储介质中，而消息的逻辑队列里存储对应消息的物理存储地址。在物理存储部分，RabbitMQ 也采用类似的主从复制机制来保障高可用。\n* Pulsar 通过 BookKeeper 实现了数据的高可靠。在 BookKeeper 中 Ledger 是基本的持久化存储单元。Pulsar 的每个主题的数据都会在逻辑上映射为多个 Ledger。每个 Ledger 在服务端会存储多个副本。为了灵活地控制存储时的一致性，BookKeeper 在存储时提供了 3 个关键的参数—数据存储的副本数（Ensemble Size，直译为集合数量）、最大写入副本数（Write Quorum Size，直译为法定写入数量）、最小写入副本数（Ack Quorum Size，直译为法定确认数量）\n\n## 语义支持与一致性级别\n\n\n根据 CAP 定理，在一个分布式系统中，一致性 (Consistency)、可用性 (Availability)、分区容错性 (Partition tolerance)三者不能同时满足。\n\n消息在生产者和消费者之间进行传输的方式有 3 种—**至多一次 (At most once)**、**至少一次 (At least once)**、**精确一次（Exactly once，又称精准一次）**\n\n* Kafka，其具有幂等性和事务功能。Kafka 的幂等性是指单个生产者对于单分区单会话的幂等，而事务可以保证消息原子性地写入多个分区，即消息写入多个分区要么全部成功，要么全部回滚。**Kafka 具备精确一次语义的能力**\n* Pulsar 可以通过幂等生产者在单个分区上写入数据，并保证其可靠性。通过客户端的自增序列 ID、重试机制与服务端的去重机制，幂等生产者可以保证发送到单个分区的每条消息只会被持久化一次，且不会丢失数据\n\t* Pulsar 事务中的所有生产或消费操作都作为一个单元提交。一个事务中的所有操作要么全部提交，要么全部失败。，Kafka 与 Pulsar 的事务功能都是为了支持精确一次语义的\n* RocketMQ 的事务流程被分为正常事务消息的发送和提交以及事务消息的补偿两个阶段。\n\t* 在消息发送过程中，生产者将消息发送到服务端后，若服务端未收到生产者对该消息的二次确认，则该消息会被标记成不可用状态。处于不可用状态的消息称为半事务消息，此时消费者无法正常消费这条消息。\n\t* 另外，若发生网络闪断、生产者应用重启等情况，导致某条消息的二次确认丢失，那么 RocketMQ 服务端需要主动向消息生产者询问该消息的最终状态（Commit 或 Rollback），该询问过程即消息回查\n\n## 扩展能力\n\n消息队列集群到达瓶颈的时候，需要对集群进行扩容。扩容一般分为水平扩容和垂直扩容两种方式：\n\n* 水平扩容指的是往集群中增加节点，\n* 垂直扩容指的是把集群中部分节点的配置调高以增加其处理能力\n\n在分布式系统中，大家更加期待能够发挥分布式集群的水平扩容能力。\n\n* Kafka 是一个存储与计算混合的消息队列。由于 Kafka 集群采用主题物理分区设计，数据会存储在服务端节点上，而**新加入集群的节点并没有存储分区，所以无法马上对外提供服务**。因此需要把一些主题的分区分配到新加入的节点，此时需要运维人员介入。\n* 由于采用了主备设计，RocketMQ 的服务端扩展能力比较强，只要将主备设备新增到集群中即可。但是需要在扩容完毕后，在新增的服务端节点创建对应的主题和订阅组信息。\n* RocketMQ 服务端具备读、写权限控制能力，可以针对单个主题的单个队列进行读写控制，这非常便于进行运维操作。\n\n# 功能特性\n\n## 消息模式\n\n* 消息队列一般有两种消息读取模式—点对点 (Point to Point, P 2 P)模式和发布订阅模式 \n\t* RabbitMQ 采用的是点对点模式，而 Kafka、Pulsar 与 RocketMQ 采用的是发布订阅模式。不过在 RabbitMQ 中可以通过设置交换器类型实现发布订阅模式以达到广播消费的效果，在发布订阅模式中也能以点对点的形式进行消息消费。\n\n\n* 消息的可回溯性也是消息队列的重要特性。一般消息在消费完成之后就被处理了，之后再也不能消费该条消息。通过消息回溯可在消息被消费完成之后，再次消费该消息\n\t* Kafka、Pulsar、RocketMQ 都支持消息回溯，可以根据时间戳或指定消费位置，重置消费组的偏移量使对应消息可以被重复消费。RabbitMQ 不支持回溯，消息一旦被标记确认就会被删除\n\n* 对于业务场景中对消息队列的使用需求，我们称为传统的消息队列应用场景。消息队列的主要应用场景包括**低延迟订阅服务、流量削峰、异步请求处理**等\n* 在大数据系统中，消息队列是**流数据的存储介质**，是连接实时计算的基础组件，为大数据系统提供缓存与部分存储能力\n\t* 高吞吐量是最先被考虑的指标。例如，目前大数据的流处理系统事实标准 Kafka 就用了诸多设计来保障高吞吐量。首先，Kafka 使用了物理分区的设计（每个分区对应独立的存储文件），这使我们可以利用磁盘的顺序写入特性来增加吞吐量；其次，Kafka 使用了页缓存与零拷贝的底层技术，这也增加了消息队列的吞吐量\n\n## 多租户\n\n多租户是一种软件架构技术，主要用来实现多用户的环境下共用相同的系统或程序组件，并确保各用户的数据具有一定的隔离性。\n\n* RabbitMQ 支持多租户技术，每一个租户为一个虚拟主机 (vhost)，本质上是一个独立的小型 RabbitMQ 服务器，具有自己独立的队列、交换器、绑定关系及权限等*\n* 官方原生的 Kafka 没有完善的体系化多租户功能，但是包含一些配额管理与用户管理功能。基于 Kafka 协议的部分商业版消息队列支持多租户功能。例如 CKafka (Cloud Kafka)是一个具有分布式、高吞吐量、高可扩展等特性的消息系统，完全兼容开源 Kafka API 0.9.0 至 2.8.0版本\n* Pulsar 是天生支持多租户的消息队列。Pulsar 租户可以分布在多个集群中，并且每个租户都可以应用自己的身份验证和授权方案。命名空间是租户内的独立管理单元。在命名空间上设置的配置策略适用于在该命名空间中创建的所有主题\n\n## 优先级队列\n\n优先级队列不同于先进先出队列，优先级高的消息具备优先被消费的特权，这样可以为下游提供不同消息级别。\n\n优先级队列在消费速度小于生产速度时才有意义，因为只有这样才可以保证高优先级消息总是被消费\n\n\n* **RabbitMQ 支持优先级队列**，使用客户端提供的可选参数即可为任何队列设定优先级。\n* Kafka、RocketMQ、Pulsar 皆**不支持原生的优先级队列**，若想在这 3 类消息队列中使用优先级队列功能，需要**用户通过不同主题或分区在业务层进行优先级划分**。\n\n## 延迟队列\n\n在一般的消息队列中，消息一旦入队就会被马上消费，而进入延迟队列的消息会被延迟消费。延迟队列存储的是延迟消息。所谓延迟消息是指消息被发送以后，并不想让消费者立刻拿到，而是等到特定时间消费者才能拿到的消息\n\n* RabbitMQ：在 3.6 版本后，RabbitMQ **官方提供了延迟队列的插件**。RabbitMQ 需要在服务端插件目录中安装 rabbitmq_delayed_message_exchange 插件才能使用延迟队列功能 \n* Kafka：Kafka 基于时间轮 (TimingWheel)自定义了一个用于实现延迟功能的定时器。但是该定时器无法被用户使用，仅用于实现内部的延时操作，比如延时请求和延时删除等。**因此 Kafka 不支持用户使用延迟队列**\n* RocketMQ 开源版：RocketMQ 将延迟消息临时存储在一个内部主题中，**不支持任意时间精度，支持特定的延迟级别**，如 5 s、10 s、1 min 等。RocketMQ 发送延迟消息时，会在写入存储数据前将消息按照设置的延迟时间发送到指定的定时队列中。**每个定时队列对应一个定时器**。RocketMQ 通过定时器对定时队列进行轮询，并查看消息是否到期。若消息到期，RocketMQ 会将这条消息写入存储\n* Pulsar：支持秒级的延迟消息，所有延迟投递的消息都会被内部组件跟踪，消费组在消费消息时，会先去延迟消息追踪器中检查，以明确是否有到期需要投递的消息 \n\n## 重试队列和死信队列\n\n\n在提供消息不丢失保障功能的消息队列中，这条消息就可能会被不断处理，从而导致消息队列陷入死循环。为了解决这个问题，消息队列系统可以为需要重试的消息提供一个**重试队列**，由重试队列进行消息重试\n\n在消息队列中，当由于某些原因导致消息多次重试，仍无法被正确投递时，为了确保消息不被无故丢弃，一般将其置于一个特殊角色的队列，这个队列一般称为**死信队列** (Dead-Letter Queue)。\n\n\n* RabbitMQ 支持消息重试，可以对最大重试次数、重试间隔时间等进行设置。RabbitMQ 也支持死信队列。当队列中的消息超出重试次数或生存时间时，如果 RabbitMQ 配置了死信队列，那么这些应该被丢弃的消息会被放入死信队列中。\n* RocketMQ 中每个消费组都有一个重试队列，并且消息重试超过一定次数后就会被放入死信队列中\n* Kafka 暂不支持死信队列。\n* Pulsar 也支持死信队列。在 Pulsar 中某些消息可能会被多次重新传递，甚至可能永远都在重试中。通过使用死信队列，可让消息具有最大重新传递次数。当实际传递次数超过最大重新传递次数时，对应的消息会被发送到死信主题并自动确认。","lastmodified":"2024-02-25T17:02:23.154963669Z","tags":[]},"/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Pulsar/1.Pulsar%E6%A6%82%E8%BF%B0":{"title":"1.Pulsar概述","content":"Pulsar 是一个分布式发布、订阅 (pub-sub)消息的平台，具有非常灵活的消息传递模型以及跨语言的客户端 API。Pulsar 也是一个集消息传递、消息存储、轻量化函数式计算于一体的流数据平台。Pulsar 采用了计算与存储分离的架构，支持**云原生、多租户、持久化存储、多机房跨区域数据复制**等，具有高一致性、高吞吐、低延时及高可扩展性等流数据存储系统特性\n\n# Pular 不只是消息队列\n\n1. Pulsar 是一个分布式消息平台，可以同时处理**流式数据和异构系统数据对**接这两类问题\n2. 1Pulsar 是一个分布式消息平台，可以同时处理流式数据和异构系统数据对接这两类问题\n3. Pulsar 是一个集消息传递、消息存储、轻量化函数式计算于一体的流数据平台\n4. Pulsar 是一个分布式可扩展的流式存储系统，并在数据存储的基础上构建了消息队列和流服务的统一模型\n\n# 存储计算分离\n\n### 存储计算结合\n\n* 在 Kafka 中，每个分区的管理与存储职能都依赖其中一个服务端节点（承担分区 Leader 角色的 Broker 节点）。\n* 该节点在处理数据写入请求的同时，会将数据写到本机的存储路径下，并负责向其他副本写入数据。\n* 在数据的读取过程中，该节点负责读取磁盘数据并发送回客户端。\n\n\n存储与计算功能都由一个 Kafka Broker 节点负责，这样可简化服务端处理流程，增大单机的处理吞吐量。RabbitMQ 和 RocketMQ 与 Kafka 类似，采用的也是存储与计算相结合的设计方式。\n\n\n### Pulsar 存储与计算分离的原理\n\nPulsar 是一个存储与计算分离的消息队列，其中\n\n* 提供计算服务的角色被称为 **Broker**，提供的是无状态的计算服务\n* 提供存储服务的角色被称为 **Bookie**，提供的是有状态的存储服务\n\n\n\nPulsar 中的数据会以数据块的形式分配到不同的 Bookie 节点。当存储资源不够时，可通过增加 Bookie 节点进行扩容。Pulsar 会感知 Bookie 集群的变化，并在合适的时机使用新增加的 Bookie 节点进行存储\n\n\n\n# 云原生架构\n\n云原生的代表技术包括**容器、服务网格 (Service Mesh)、微服务、不可变基础设施和声明式 API** 等。利用这些技术能够构建容错性好、易于管理和便于观察的松耦合系统。\n\n\n* Pulsar 是一个云原生应用，拥有诸多云原生应用的特性，如无状态计算层、计算与存储分离，可以很好地利用云的弹性（伸缩能力），从而具有足够高的扩容性和容错性 \n* Pulsar 对 Kubernetes 有良好的支持。在开源项目 Apache Pulsar Helm Chart[插图]的支持下，Pulsar 可以保障业务轻松迁移到 Kubernetes 环境中。在 Apache Pulsar Helm Chart 项目中，Kubernetes 可以单独管理各类组件，如 Zookeeper、Bookie、Broker、Function、Proxies。除此之外，Apache Pulsar Helm Chart 项目中还集成了 Pulsar 的管理与监控工具，如 Pulsar Manager、Prometheus 与 Grafana。\\\n\n\n# Pulsar 的存储特性\n\nPulsar 依赖 BookKeeper 构建存储能力，并因此具备了分块存储、分层存储、存储与计算分离的特性\n\n\n使用**分块存储**的系统有着悠久的历史，从 GFS（Google File System，Google 文件系统）到开源的 HDFS (Hadoop File System)。基于分块存储的文件系统可以运行在廉价的普通硬件设备上，并提供灾难冗余的能力\n\n通过对比 Kafka 与 RocketMQ 来介绍 Pulsar 的分块存储结构。\n\n\n### Kafka 的存储结构 \n\n* Kafka 基于**只追加日志文件**策略构建了核心存储结构，消息队列中的数据以日志的方式进行组织，对日志的所有写操作都提交在日志的最末端，而对日志的读取也只能按顺序进行\n* 每个主题的每个分区都对应着一个独立文件，Kafka 的分区对应着文件系统的物理分区. 该设计让 Kafka 具有了高吞吐量与低成本的优\n\n\nKafka 可以借助多分区来实现主题级别的扩展，也可以通过增加物理机的方式实现一定程度的横向扩容。但是，也正是因为这种存储结构，在大规模集群中使用 Kafka 会引入了新的问题。\n\n* 会带来额外的运维成本。在 Kafka 中每一个分区都只能归属于一台机器，即 ISR（In-Sync Replicas，同步的副本）集合中的一个主节点。**Kafka 的多个数据副本只能保证高可用性**，每个分区的容量大小受限于主节点的磁盘大小\n* 有单机分区上限问题。每个 Kafka 分区都会使用一个顺序写入的文件进行数据存储。有单机分区上限问题。每个 Kafka 分区都会使用一个顺序写入的文件进行数据存储。\n\n### RocketMQ 的存储结构\n\n* 在 RocketMQ 消息队列中，消息的存储是由内部的消费队列 (ConsumeQueue)和提交日志 (CommitLog)配合完成的消息的物理存储文件是 CommitLog,ConsumeQueue 是消息的逻辑队列，在消息队列中起索引的作用\n* 在 RocketMQ 中每个实际的主题都对应着一个 ConsumeQueue，其中存放着 CommitLog 中所有消息的存放位置。\n* CommitLog 以物理文件的形式存放在服务器中，并被当前服务器中所有 ConsumeQueue 共享。不同于 Kafka 使每个逻辑队列都对应着一个物理分区，RocketMQ 采用**物理存储与逻辑队列相互分离的分区方式**\n\n\n\n### Pulsar的存储结构\n\n\nPulsar 利用 BookKeeper 实现了分块存储的能力，它在一定程度上兼具 Kafka 物理分区与 RocketMQ 逻辑分区的优点\n\n\nEdger 代表一个独立日志块或一段数据流，是持久化存储的单元。记录会被有序地写入 Ledger 中。数据一经写入就不允许进行修改了。Pulsar 能够将每个主题映射为多个独立的数据段，**每个数据段对应一个 Ledger**\n\n**每个 Ledger 都拥有独立的 I/O 能力**，Pulsar 可以将 Broker 上的网络 I/O 均匀分布在不同的 Bookie 节点上，又可以充分利用 Bookie 节点的 I/O 能力。Pulsar 通过 BookKeeper 获得了容量和吞吐量方面的水平可扩展能力.\n\nPulsar 通过 BookKeeper 获得了容量和吞吐量方面的水平可扩展能力，通过向集群添加更多 Bookie 节点，可以立即增加容量与吞吐量。\n\n\n\n# 消息协议\n\n\nPulsar 支持可插拔的协议处理机制，可以在运行时动态加载额外的**协议处理程序**。**基于消息队列协议层**，目前 Pulsar 已经支持 Kafka、RocketMQ、AMQP 和 MQTT 等多种协议。并将自身云原生、分层存储、自动负载管理等诸多特性推广至更多的消息队列系统\n\n\nPulsar 协议层支持的 Kafka 项目为 Kafka on Pulsar (KoP)协议。通过将 KoP 协议部署在现有的 Pulsar 集群中，用户可以在 Pulsar 集群中继续使用原生的 Kafka 协议，同时能够利用 Pulsar 的强大功能，完善存量 Kafka 应用的使用体验。\n\n\n\n# 消费方式\n\n\n消费者从消息队列中读取数据有两种方法—主动拉取（Pull 模式）与被动接收（Push 模式）\n\n* 在 Pull 模式下，消费者会不断轮询消息队列，判断是否有新的数据，如果有就读取该数据。 \n* 在 Push 模式下，一旦生产者有新数据放入消息队列中，系统就会推送给消费者。\n\n\n**RocketMQ 与 Kafk都基于 Pull 模式进行数据读取**。Pull 模式的优势在于可以控制数据的消费速度和消费数量，保证消费者不会达到饱和状态\n\n\n**Pulsar 中的消费者在读取数据时采用以 Push 模式为主、Pull 模式为辅的同步模式**。Pulsar 中的客户端有一个缓冲队列。客户端会向服务端发送流量配额请求，服务端会主动向客户端推送配额允许范围内的数据。\n\n* 消费者连接建立后，服务端通过配额向消费者推送数据。\n* 与此同时，消费者每消费一条数据都会增加客户端流量配额计数，在配额计数达到队列的一半时，客户端会再次发送流量配额请求，请求服务端推送数据\n\n\n# 生态\n\nPulsar 官方提供了多种导入与导出数据的连接器。通过简单地配置 Pulsar I/O，可灵活地将 Pulsar 与关系型数据库、非关系型数据库（如 MongoDB）、数据湖、Hadoop 生态等外部系统相结合\n\n\nPulsar 可以用于存储结构化数据。结构化数据由预定义的字段构成，Pulsar 提供了 Schema 功能来进行结构化定义。通过 Pulsar SQL 功能，Trino Pulsar 连接器使 Trino 集群内的 Trino Worker 能够通过 SQL 语句查询数据。\n\n\n在 Pulsar 中使用运维管理与监控工具，如 Prometheus、Grafana、Pulsar Manager 等，能够减少在运维、优化、排错方面的投入\n\n\nPulsar 可以与多种大数据生态结合，如 Kafka、HDFS、HBase、Flink、Spark、Trino\n\n\n\n# 消息队列对比\n\n### RabbitMQ\n\nRabbitMQ 是采用 Erlang 语言实现的 AMQP 消息中间件, AMQP 是一种用于异步消息传递的应用层协议，AMQP 客户端能够无视消息来源，任意发送和接收消息，服务端负责提供消息路由、队列等功能。\n\n\nRabbitMQ 的服务端节点称为 Broker。Broker 主要由交换器 (Exchange)和队列 (Queue)组成。\n\n* 交换器负责接收与转发消息。\n* 队列负责存储消息，提供持久化等功能。\n* AMQP 客户端通过 AMQP 信道 (Channel)与 Broker 通信，通过该信道生产者与消费者完成数据发送与接收。\n\n### RocketMQ\n\n\nRocketMQ 的架构可以分为 4 个部分—Broker、NameServer、Producer、Consumer。\n\n* RocketMQ 的服务端节点称为 Broker，Broker 负责管理消息存储分发、主备数据同步、为消息建立索引、提供消息查询等。\n* NameServer 主要用来管理所有的 Broker 节点及路由信息。\n* Producer 与 Consumer 负责数据发送与接收。\n\nRocketMQ Broker 依靠主备同步实现高可用，消息到达主服务器后，需要同步到备用服务器上，默认情况下 RocketMQ 会优先选择从主服务器拉取消息, 如果主服务器宕机，消费者可从备用服务器拉取消息。备用服务器会通过定时任务从主服务器定时同步路由信息、消息消费进度、延迟队列处理进度、消费组订阅信息等\n\n\nRocketMQ 5.0 版本在架构上进行了存储与计算的分离改造。它引入无状态的 Proxy 集群来承担计算职责，原 Broker 节点逐步演化为以存储为核心的有状态集群。在不同场景下，可以根据应用场景和部署环境（公有云或私有云）为 RocketMQ 选择存储与计算一体化或者分离的使用方式","lastmodified":"2024-02-25T17:02:23.154963669Z","tags":[]},"/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Pulsar/2.doccker-%E4%B8%AD%E5%90%AF%E5%8A%A8-standalone-Pulsar":{"title":"2.doccker 中启动 standalone Pulsar","content":"\n```\n\n$ docker run -it -p 6650:6650  -p 8080:8080 --mount source=pulsardata,target=/pulsar/data --mount source=pulsarconf,target=/pulsar/conf apachepulsar/pulsar:@pulsar:version@ bin/pulsar standalone\n\n```","lastmodified":"2024-02-25T17:02:23.154963669Z","tags":[]},"/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/%E5%9C%BA%E6%99%AF%E9%A2%98/%E5%A6%82%E4%BD%95":{"title":"如何","content":"\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticPasted%20image%2020230802012455.png)","lastmodified":"2024-02-25T17:02:23.154963669Z","tags":[]},"/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/%E5%9C%BA%E6%99%AF%E9%A2%98/%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E4%B8%80%E4%B8%AA%E6%8E%92%E8%A1%8C%E6%A6%9C":{"title":"如何设计一个排行榜？","content":"![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticPasted%20image%2020230802012459.png)","lastmodified":"2024-02-25T17:02:23.154963669Z","tags":[]},"/%E8%B5%84%E6%BA%90/%E8%B5%84%E6%BA%90%E6%B1%87%E6%80%BB":{"title":"资源汇总","content":"","lastmodified":"2024-02-25T17:02:23.162963648Z","tags":[]},"/GO/%E5%85%AB%E8%82%A1%E6%96%87/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86":{"title":"内存管理","content":"## []( https://youandgentleness.cn/2023/09/21/Golang%E5%85%AB%E8%82%A1%E6%96%87%E6%B1%87%E6%80%BB/#%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86 \"内存管理\")内存管理\n\n### []( https://youandgentleness.cn/2023/09/21/Golang%E5%85%AB%E8%82%A1%E6%96%87%E6%B1%87%E6%80%BB/#Golang%E7%9A%84%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%EF%BC%8C%E4%B8%BA%E4%BB%80%E4%B9%88%E5%B0%8F%E5%AF%B9%E8%B1%A1%E5%A4%9A%E4%BA%86%E4%BC%9A%E9%80%A0%E6%88%90gc%E5%8E%8B%E5%8A%9B%E3%80%82 \"Golang 的内存模型，为什么小对象多了会造成 gc 压力。\") Golang 的内存模型，为什么小对象多了会造成 gc 压力。\n\n通常小对象过多会导致 GC 三色法消耗过多的 GPU。优化思路是，减少对象分配。\n\n### []( https://youandgentleness.cn/2023/09/21/Golang%E5%85%AB%E8%82%A1%E6%96%87%E6%B1%87%E6%80%BB/#Go%E8%AF%AD%E8%A8%80%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%EF%BC%8C%E5%86%99%E4%BB%A3%E7%A0%81%E7%9A%84%E6%97%B6%E5%80%99%E5%A6%82%E4%BD%95%E5%87%8F%E5%B0%91%E5%AF%B9%E8%B1%A1%E5%88%86%E9%85%8D \"Go 语言什么时候垃圾回收，写代码的时候如何减少对象分配\") Go 语言什么时候垃圾回收，写代码的时候如何减少对象分配\n\n当 goroutine 申请新的内存管理单元时触发垃圾回收。写代码的时候如何减少对象分配，这是一个关于性能的问题，例如如果需要把数字转换成字符串，使用 strconv.Itoa () 比 fmt.Sprintf () 要快一倍左右。如果需要把数字转换成字符串，使用 strconv.Itoa () 比 fmt.Sprintf () 要快一倍左右。这里就不一一展开了。\n\n### []( https://youandgentleness.cn/2023/09/21/Golang%E5%85%AB%E8%82%A1%E6%96%87%E6%B1%87%E6%80%BB/#%E6%80%8E%E4%B9%88%E9%81%BF%E5%85%8D%E5%86%85%E5%AD%98%E9%80%83%E9%80%B8%EF%BC%9F \"怎么避免内存逃逸？\")怎么避免内存逃逸？\n\n[https://mp.weixin.qq.com/s/VzRTHz1JaDUvNRVB_yJa1A](https://mp.weixin.qq.com/s/VzRTHz1JaDUvNRVB_yJa1A) \n\n### []( https://youandgentleness.cn/2023/09/21/Golang%E5%85%AB%E8%82%A1%E6%96%87%E6%B1%87%E6%80%BB/#%E7%AE%80%E5%8D%95%E8%81%8A%E8%81%8A%E5%86%85%E5%AD%98%E9%80%83%E9%80%B8%EF%BC%9F \"简单聊聊内存逃逸？\")简单聊聊内存逃逸？\n\n[https://mp.weixin.qq.com/s/wJmztRMB1ZAAIItyMcS0tw](https://mp.weixin.qq.com/s/wJmztRMB1ZAAIItyMcS0tw) \n\n### []( https://youandgentleness.cn/2023/09/21/Golang%E5%85%AB%E8%82%A1%E6%96%87%E6%B1%87%E6%80%BB/#%E7%BB%99%E5%A4%A7%E5%AE%B6%E4%B8%A2%E8%84%B8%E4%BA%86%EF%BC%8C%E7%94%A8%E4%BA%86%E4%B8%89%E5%B9%B4Golang%EF%BC%8C%E6%88%91%E8%BF%98%E6%98%AF%E6%B2%A1%E7%AD%94%E5%AF%B9%E8%BF%99%E9%81%93%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E9%A2%98 \"给大家丢脸了，用了三年 Golang，我还是没答对这道内存泄漏题\")给大家丢脸了，用了三年 Golang，我还是没答对这道内存泄漏题\n\n[https://mp.weixin.qq.com/s/-agtdhlW7Yj7S88a0z7KHg](https://mp.weixin.qq.com/s/-agtdhlW7Yj7S88a0z7KHg) \n\n### []( https://youandgentleness.cn/2023/09/21/Golang%E5%85%AB%E8%82%A1%E6%96%87%E6%B1%87%E6%80%BB/#Go%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%EF%BC%9F%E4%B8%8D%E6%98%AF%E9%82%A3%E4%B9%88%E7%AE%80%E5%8D%95 \"Go 内存泄漏？不是那么简单\") Go 内存泄漏？不是那么简单\n\n[https://colobu.com/2019/08/28/go-memory-leak-i-dont-think-so/](https://colobu.com/2019/08/28/go-memory-leak-i-dont-think-so/) \n\n### []( https://youandgentleness.cn/2023/09/21/Golang%E5%85%AB%E8%82%A1%E6%96%87%E6%B1%87%E6%80%BB/#Go%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%EF%BC%8C%E5%92%8C-tcmalloc-%E7%9A%84%E5%8C%BA%E5%88%AB \"Go 内存分配，和 tcmalloc 的区别?\") Go 内存分配，和 tcmalloc 的区别?\n\nGo 内存分配核心思想就是把内存分为多级管理，从而降低锁的粒度。它将可用的堆内存采用二级分配的方式进行管理：每个线程都会自行维护一个独立的内存池，进行内存分配时优先从该内存池中分配，当内存池不足时才会向全局内存池申请，以避免不同线程对全局内存池的频繁竞争。\n\n- Go 在程序启动时，会向操作系统申请一大块内存，之后自行管理。\n- Go 内存管理的基本单元是 mspan，它由若干个页组成，每种 mspan 可以分配特定大小的 object。\n- Mcache, mcentral, mheap 是 Go 内存管理的三大组件，层层递进。Mcache 管理线程在本地缓存的 mspan；mcentral 管理全局的 mspan 供所有线程使用；mheap 管理 Go 的所有动态分配内存。\n- 极小的对象 (\u003c=16B)会分配在一个object中，以节省资源，使用tiny分配器分配内存；一般对象(16B-32KB)通过mspan分配内存；大对象(\u003e32 KB)则直接由 mheap 分配内存。\n\n**tcmalloc**  \nTcmalloc 是 google 开发的内存分配算法库，最开始它是作为 google 的一个性能工具库 perftools 的一部分。TCMalloc 是用来替代传统的 malloc 内存分配函数。它有减少内存碎片，适用于多核，更好的并行性支持等特性。  \nTC 就是 Thread Cache 两英文的简写。它提供了很多优化，如：  \n1. TCMalloc 用固定大小的 page (页)来执行内存获取、分配等操作。这个特性跟 Linux 物理内存页的划分是不是有同样的道理。  \n2. TCMalloc 用固定大小的对象，比如 8 KB，16 KB 等用于特定大小对象的内存分配，这对于内存获取或释放等操作都带来了简化的作用。  \n3. TCMalloc 还利用缓存常用对象来提高获取内存的速度。  \n4. TCMalloc 还可以基于每个线程或者每个 CPU 来设置缓存大小，这是默认设置。  \n5. TCMalloc 基于每个线程独立设置缓存分配策略，减少了多线程之间锁的竞争。\n\nGo 中的内存分类并不像 TCMalloc 那样分成小、中、大对象，但是它的小对象里又细分了一个 Tiny 对象，Tiny 对象指大小在 1 Byte 到 16 Byte 之间并且不包含指针的对象。小对象和大对象只用大小划定，无其他区分。  \nGo 内存管理与 tcmalloc 最大的不同在于，它提供了逃逸分析和垃圾回收机制。\n\n### []( https://youandgentleness.cn/2023/09/21/Golang%E5%85%AB%E8%82%A1%E6%96%87%E6%B1%87%E6%80%BB/#Golang-%E9%87%8C%E6%80%8E%E4%B9%88%E9%81%BF%E5%85%8D%E5%86%85%E5%AD%98%E9%80%83%E9%80%B8%EF%BC%9F \"Golang 里怎么避免内存逃逸？\") Golang 里怎么避免内存逃逸？\n\n1. 不要盲目使用变量指针作为参数，虽然减少了复制，但变量逃逸的开销更大。\n2. 预先设定好 slice 长度，避免频繁超出容量，重新分配。\n3. 一个经验是，指针指向的数据大部分在堆上分配的，请注意。\n\n出现内存逃逸的情况有：\n\n1. 发送指针或带有指针的值到 channel，因为编译时候无法知道那个 goroutine 会在 channel 接受数据，编译器无法知道什么时候释放。\n\n2. 在一个切片上存储指针或带指针的值。比如[]*string，导致切片内容逃逸，其引用值一直在堆上。\n\n3. 切片的 append 导致超出容量，切片重新分配地址，切片背后的存储基于运行时的数据进行扩充，就会在堆上分配。\n\n4. 调用接口类型时，接口类型的方法调用是动态调度，实际使用的具体实现只能在运行时确定，如一个接口类型为 io. Reader 的变量 r，对r.Read (b)的调用将导致 r 的值和字节片 b 的后续转义并因此分配到堆上。\n\n5. 在方法内把局部变量指针返回，被外部引用，其生命周期大于栈，导致内存溢出。\n\n### []( https://youandgentleness.cn/2023/09/21/Golang%E5%85%AB%E8%82%A1%E6%96%87%E6%B1%87%E6%80%BB/#Go%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84%E5%A0%86%E5%92%8C%E6%A0%88 \"Go 语言中的堆和栈\") Go 语言中的堆和栈\n\n栈主要用来存储值类型的数据，如**整数、浮点数、布尔值**等。因为值类型的数据大小是固定的，所以可以直接分配在栈上，访问速度非常快。\n\n堆主要用来存储引用类型的数据，如字**符串、切片、字典**等。因为引用类型的数据大小是不固定的，所以需要动态分配内存，通常在堆上进行。同时，由于引用类型的数据通常需要共享和修改，因此使用指针来进行引用和操作，从而避免了复制大量的数据。\n\n可以看出，栈的性能会更好——**不需要额外的垃圾回收机制**（离开该作用域，它们的内存就会被自动回收），**CPU 可以连续缓存**（内存空间是连续的）。堆是通过**GC 回收内存**的。\n\n\n# Go 内存分配机制？\n\nGo 语言内置运行时（就是 runtime），抛弃了传统的内存分配方式，改为自主管理。这样可以自主地实现更好的内存使用模式，比如内存池、预分配等等。这样，不会每次内存分配都需要进行系统调用。\n\n## 设计思想\n\n- 内存分配算法采用 Google 的 `TCMalloc算法`，每个线程都会自行维护一个独立的内存池，进行内存分配时优先从该内存池中分配，当内存池不足时才会向加锁向全局内存池申请，减少系统调用并且避免不同线程对全局内存池的锁竞争\n- 把内存切分的非常的细小，分为多级管理，以降低锁的粒度\n- 回收对象内存时，并没有将其真正释放掉，只是放回预先分配的大块内存中，以便复用。只有内存闲置过多的时候，才会尝试归还部分内存给操作系统，降低整体开销\n\n## 分配组件\n\nGo 的内存管理组件主要有：`mspan`、`mcache`、`mcentral` 和 `mheap`\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226003340.png)\n## 内存管理单元：mspan\n\n`mspan` 是内存管理的基本单元，该结构体中包含 `next` 和 `prev` 两个字段，它们分别指向了前一个和后一个 mspan，每个 `mspan` 都管理 `npages` 个大小为 8 KB 的页，一个 span 是由多个 page 组成的，这里的页不是操作系统中的内存页，它们是操作系统内存页的整数倍。\n\n`page` 是内存存储的基本单元，“对象”放到 `page` 中\n\n```\ntype mspan struct {\n    next *mspan // 后指针\n    prev *mspan // 前指针\n    startAddr uintptr // 管理页的起始地址，指向page\n    npages    uintptr // 页数\n    spanclass   spanClass // 规格\n    ...\n}\n\ntype spanClass uint8\n```\n\nGo 有 68 种不同大小的 spanClass，用于小对象的分配\n\n```\nconst _NumSizeClasses = 68\nvar class_to_size = [_NumSizeClasses]uint16{0, 8, 16, 32, 48, 64, 80, 96, 112, 128, 144, 160, 176, 192, 208, 224, 240, 256, 288, 320, 352, 384, 416, 448, 480, 512, 576, 640, 704, 768, 896, 1024, 1152, 1280, 1408, 1536,1792, 2048, 2304, 2688, 3072, 3200, 3456, 4096, 4864, 5376, 6144, 6528, 6784, 6912, 8192, 9472, 9728, 10240, 10880, 12288, 13568, 14336, 16384, 18432, 19072, 20480, 21760, 24576, 27264, 28672, 32768}\n```\n\n如果按照序号为 1 的 spanClass（对象规格为 8 B）分配，每个 span 占用堆的字节数：8 k，mspan 可以保存 1024个对象\n\n如果按照序号为 2 的 spanClass（对象规格为 16 B）分配，每个 span 占用堆的字节数：8 k，mspan 可以保存 512个对象\n\n…\n\n如果按照序号为 67 的 spanClass（对象规格为 32 K）分配，每个 span 占用堆的字节数：32 k，mspan 可以保存1个对象\n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226003424.png)\n\n\n字段含义：\n\n- Class： class ID，每个 span 结构中都有一个 class ID, 表示该 span 可处理的对象类型\n- Bytes/obj：该 class 代表对象的字节数\n- Bytes/span：每个 span 占用堆的字节数，也即页数*页大小\n- Objects: 每个 span 可分配的对象个数，也即（bytes/spans）/（bytes/obj）\n- Waste bytes: 每个 span 产生的内存碎片，也即（bytes/spans）%（bytes/obj）\n\n大于 32 k 的对象出现时，会直接从 heap 分配一个特殊的 span，这个特殊的 span 的类型 (class)是 0, 只包含了一个大对象\n\n## 线程缓存：mcache\n\nmcache 管理线程在本地缓存的 mspan，每个 goroutine 绑定的 P 都有一个 `mcache` 字段\n\n```\ntype mcache struct {\n    alloc [numSpanClasses]*mspan\n}\n\n_NumSizeClasses = 68\nnumSpanClasses = _NumSizeClasses \u003c\u003c 1\n```\n\n`mcache` 用 `Span Classes` 作为索引管理多个用于分配的 `mspan`，它包含所有规格的 `mspan`。它是 `_NumSizeClasses` 的 2 倍，也就是 `68*2=136`，其中* 2 是将 spanClass 分成了有指针和没有指针两种, 方便与垃圾回收。对于每种规格，有 2 个 mspan，一个 mspan 不包含指针，另一个 mspan 则包含指针。对于无指针对象的 `mspan` 在进行垃圾回收的时候无需进一步扫描它是否引用了其他活跃的对象。\n\n`mcache` 在初始化的时候是没有任何 `mspan` 资源的，在使用过程中会动态地从 `mcentral` 申请，之后会缓存下来。当对象小于等于 32 KB 大小时，使用 `mcache` 的相应规格的 `mspan` 进行分配。\n\n## 中心缓存：mcentral\n\nMcentral 管理全局的 mspan 供所有线程使用，全局 mheap 变量包含 central 字段，每个 mcentral 结构都维护在**mheap**结构内\n \n```\ntype mcentral struct {\n    spanclass spanClass // 指当前规格大小\n\n    partial [2]spanSet // 有空闲object的mspan列表\n    full    [2]spanSet // 没有空闲object的mspan列表\n}\n```\n\n每个 mcentral 管理一种 spanClass 的 mspan，并将有空闲空间和没有空闲空间的 mspan 分开管理。Partial 和 full `的数据类型为` spanSet，表示 `mspans` 集，可以通过 pop、push 来获得 mspans\n\n```\ntype spanSet struct {\n    spineLock mutex\n    spine     unsafe.Pointer // 指向[]span的指针\n    spineLen  uintptr        // Spine array length, accessed atomically\n    spineCap  uintptr        // Spine array cap, accessed under lock\n\n    index headTailIndex  // 前32位是头指针，后32位是尾指针\n}\n```\n\n简单说下 `mcache` 从 `mcentral` 获取和归还 `mspan` 的流程：\n\n- 获取；加锁，从 `partial` 链表找到一个可用的 `mspan`；并将其从 `partial` 链表删除；将取出的 `mspan` 加入到 `full` 链表；将 `mspan` 返回给工作线程，解锁。\n- 归还；加锁，将 `mspan` 从 `full` 链表删除；将 `mspan` 加入到 `partial` 链表，解锁。\n\n## 页堆：mheap\n\nMheap 管理 Go 的所有动态分配内存，可以认为是 Go 程序持有的整个堆空间，全局唯一\n\n```\nvar mheap_ mheap\ntype mheap struct {\n    lock      mutex    // 全局锁\n    pages     pageAlloc // 页面分配的数据结构\n    allspans []*mspan // 所有通过 mheap_ 申请的mspans\n        // 堆\n    arenas [1 \u003c\u003c arenaL1Bits]*[1 \u003c\u003c arenaL2Bits]*heapArena\n    \n        // 所有中心缓存mcentral\n    central [numSpanClasses]struct {\n        mcentral mcentral\n        pad      [cpu.CacheLinePadSize - unsafe.Sizeof(mcentral{})%cpu.CacheLinePadSize]byte\n    }\n    ...\n}\n```\n\n所有 `mcentral` 的集合则是存放于 `mheap` 中的。`mheap` 里的 `arena` 区域是堆内存的抽象，运行时会将 `8KB` 看做一页，这些内存页中存储了所有在堆上初始化的对象。运行时使用二维的 runtime. HeapArena 数组管理所有的内存，每个 runtime. HeapArena 都会管理 64 MB 的内存。\n\n当申请内存时，依次经过 `mcache` 和 `mcentral` 都没有可用合适规格的大小内存，这时候会向 `mheap` 申请一块内存。然后按指定规格划分为一些列表，并将其添加到相同规格大小的 `mcentral` 的 `非空闲列表` 后面\n\n### 分配对象\n\n- 微对象 (0, 16 B)：先使用线程缓存上的微型分配器，再依次尝试线程缓存、中心缓存、堆分配内存；\n- 小对象 [16 B, 32 KB]：依次尝试线程缓存、中心缓存、堆分配内存；\n- 大对象 (32 KB, +∞)：直接尝试堆分配内存；\n\n### 分配流程\n\n- 首先通过计算使用的大小规格\n- 然后使用 `mcache` 中对应大小规格的块分配。\n- 如果 `mcentral` 中没有可用的块，则向 `mheap` 申请，并根据算法找到最合适的 `mspan`。\n- 如果申请到的 `mspan` 超出申请大小，将会根据需求进行切分，以返回用户所需的页数。剩余的页构成一个新的 mspan 放回 mheap 的空闲列表。\n- 如果 mheap 中没有可用 span，则向操作系统申请一系列新的页（最小 1 MB）\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226003626.png)\n\n# Go 内存逃逸机制？\n\n## 概念\n\n在一段程序中，每一个函数都会有自己的内存区域存放自己的局部变量、返回地址等，这些内存会由编译器在栈中进行分配，每一个函数都会分配一个栈桢，在函数运行结束后进行销毁，但是有些变量我们想在函数运行结束后仍然使用它，那么就需要把这个变量在堆上分配，这种从”栈”上逃逸到”堆”上的现象就成为内存逃逸。\n\n在栈上分配的地址，一般由系统申请和释放，不会有额外性能的开销，比如函数的入参、局部变量、返回值等。在堆上分配的内存，如果要回收掉，需要进行 GC，那么 GC 一定会带来额外的性能开销。编程语言不断优化 GC 算法，主要目的都是为了减少 GC 带来的额外性能开销，变量一旦逃逸会导致性能开销变大。\n\n## 逃逸机制\n\n编译器会根据变量是否被外部引用来决定是否逃逸：\n\n1. 如果函数外部没有引用，则优先放到栈中；\n2. 如果函数外部存在引用，则必定放到堆中;\n3. 如果栈上放不下，则必定放到堆上;\n\n逃逸分析也就是由编译器决定哪些变量放在栈，哪些放在堆中，通过编译参数 `-gcflag=-m` 可以查看编译过程中的逃逸分析，发生逃逸的几种场景如下：\n\n### 指针逃逸\n\n```\npackage main\n\nfunc escape1() *int {\n    var a int = 1\n    return \u0026a\n}\n\nfunc main() {\n    escape1()\n}\n```\n\n通过 `go build -gcflags=-m main.go` 查看逃逸情况：\n\n```\n./main.go:4:6: moved to heap: a\n```\n\n函数返回值为局部变量的指针，函数虽然退出了，但是因为指针的存在，指向的内存不能随着函数结束而回收，因此只能分配在堆上。\n\n### 栈空间不足\n\n```\npackage main\n\nfunc escape2() {\n    s := make([]int, 0, 10000)\n    for index, _ := range s {\n        s[index] = index\n    }\n}\n\nfunc main() {\n    escape2()\n}\n```\n\n通过 `go build -gcflags=-m main.go` 查看逃逸情况：\n\n```\n./main.go:4:11: make([]int, 10000, 10000) escapes to heap\n```\n\n当栈空间足够时，不会发生逃逸，但是当变量过大时，已经完全超过栈空间的大小时，将会发生逃逸到堆上分配内存。局部变量 s 占用内存过大，编译器会将其分配到堆上\n\n### 变量大小不确定\n\n```\npackage main\n\nfunc escape3() {\n    number := 10\n    s := make([]int, number) // 编译期间无法确定slice的长度\n    for i := 0; i \u003c len(s); i++ {\n        s[i] = i\n    }\n}\n\nfunc main() {\n    escape3()\n}\n```\n\n编译期间无法确定 slice 的长度，这种情况为了保证内存的安全，编译器也会触发逃逸，在堆上进行分配内存。直接 `s := make([]int, 10)` 不会发生逃逸\n\n### 动态类型\n\n动态类型就是编译期间不确定参数的类型、参数的长度也不确定的情况下就会发生逃逸\n\n空接口 interface{} 可以表示任意的类型，如果函数参数为 interface{}，编译期间很难确定其参数的具体类型，也会发生逃逸。\n\n```\npackage main\n\nimport \"fmt\"\n\nfunc escape4() {\n    fmt.Println(1111)\n}\n\nfunc main() {\n    escape4()\n}\n```\n\n通过 `go build -gcflags=-m main.go` 查看逃逸情况：\n\n```\n./main.go:4:6: moved to heap: i\n```\n\nFmt.Println (a …interface{})函数参数为 interface，编译器不确定参数的类型，会将变量分配到堆上\n\n##### []( https://youandgentleness.cn/2023/08/28/Go%E8%AF%AD%E8%A8%80%E9%9D%A2%E8%AF%95%E9%A2%98%E7%B2%BE%E8%AE%B2/#%E9%97%AD%E5%8C%85%E5%BC%95%E7%94%A8%E5%AF%B9%E8%B1%A1 \"闭包引用对象\")闭包引用对象\n\n\n```\npackage main\n\nfunc escape5() func() int {\n    var i int = 1\n    return func() int {\n        i++\n        return i\n    }\n}\n\nfunc main() {\n    escape5()\n}\n```\n\n通过 `go build -gcflags=-m main.go` 查看逃逸情况：\n\n```\n./main.go:4:6: moved to heap: i\n```\n\n闭包函数中局部变量 i 在后续函数是继续使用的，编译器将其分配到堆上\n\n## 总结\n\n1. 栈上分配内存比在堆中分配内存效率更高\n2. 栈上分配的内存不需要 GC 处理，而堆需要\n3. 逃逸分析目的是决定内分配地址是栈还是堆\n4. 逃逸分析在编译阶段完成\n\n因为无论变量的大小，只要是指针变量都会在堆上分配，所以对于小变量我们还是使用传值效率（而不是传指针）更高一点。\n\n# Go 内存对齐机制？\n\n## 什么是内存对齐\n\n为了能让 CPU 可以更快的存取到各个字段，Go 编译器会帮你把 struct 结构体做数据的对齐。**所谓的数据对齐，是指内存地址是所存储数据大小（按字节为单位）的整数倍，以便 CPU 可以一次将该数据从内存中读取出来。** 编译器通过在结构体的各个字段之间填充一些空白已达到对齐的目的。\n\n## 对齐系数\n\n不同硬件平台占用的大小和对齐值都可能是不一样的，每个特定平台上的编译器都有自己的默认”对齐系数”，32 位系统对齐系数是 4，64 位系统对齐系数是 8\n\n不同类型的对齐系数也可能不一样，使用 `Go` 语言中的 `unsafe.Alignof` 函数可以返回相应类型的对齐系数，对齐系数都符合 `2^n` 这个规律，最大也不会超过8\n\n```\npackage main\n\nimport (\n    \"fmt\"\n    \"unsafe\"\n)\n\nfunc main() {\n    fmt.Printf(\"bool alignof is %d\\n\", unsafe.Alignof(bool(true)))\n    fmt.Printf(\"string alignof is %d\\n\", unsafe.Alignof(string(\"a\")))\n    fmt.Printf(\"int alignof is %d\\n\", unsafe.Alignof(int(0)))\n    fmt.Printf(\"float alignof is %d\\n\", unsafe.Alignof(float64(0)))\n    fmt.Printf(\"int32 alignof is %d\\n\", unsafe.Alignof(int32(0)))\n    fmt.Printf(\"float32 alignof is %d\\n\", unsafe.Alignof(float32(0)))\n}\n\n```\n\n可以查看到各种类型在 Mac 64 位上的对齐系数如下：\n\n```\nbool alignof is 1\nstring alignof is 8\nint alignof is 8\nint32 alignof is 4\nfloat32 alignof is 4\nfloat alignof is 8\n```\n\n## 优点\n\n1. 提高可移植性，有些 `CPU` 可以访问任意地址上的任意数据，而有些 `CPU` 只能在特定地址访问数据，因此不同硬件平台具有差异性，这样的代码就不具有移植性，如果在编译时，将分配的内存进行对齐，这就具有平台可以移植性了\n2. 提高内存的访问效率，32 位 CPU 下一次可以从内存中读取 32 位（4 个字节）的数据，64 位 CPU 下一次可以从内存中读取 64 位（8 个字节）的数据，这个长度也称为 CPU 的字长。CPU 一次可以读取 1 个字长的数据到内存中，如果所需要读取的数据正好跨了 1 个字长，那就得花两个 CPU 周期的时间去读取了。因此在内存中存放数据时进行对齐，可以提高内存访问效率。\n\n## 缺点\n\n1. 存在内存空间的浪费，实际上是空间换时间\n\n## 结构体对齐\n\n对齐原则：\n\n1. **结构体变量中成员的偏移量必须是成员大小的整数倍**\n2. **整个结构体的地址必须是最大字节的整数倍**（结构体的内存占用是 1/4/8/16 byte…)\n\n```\npackage main\n\nimport (\n    \"fmt\"\n    \"runtime\"\n    \"unsafe\"\n)\n\ntype T1 struct {\n    i16  int16 // 2 byte\n    bool bool  // 1 byte\n}\n\ntype T2 struct {\n    i8  int8  // 1 byte\n    i64 int64 // 8 byte\n    i32 int32 // 4 byte\n}\n\ntype T3 struct {\n    i8  int8  // 1 byte\n    i32 int32 // 4 byte\n    i64 int64 // 8 byte\n}\n\nfunc main() {\n    fmt.Println(runtime.GOARCH) // amd64\n\n    t1 := T1{}\n    fmt.Println(unsafe.Sizeof(t1)) // 4 bytes\n\n    t2 := T2{}\n    fmt.Println(unsafe.Sizeof(t2)) // 24 bytes\n\n    t3 := T3{}\n    fmt.Println(unsafe.Sizeof(t3)) // 16 bytes\n}\n```\n\n以 T 1 结构体为例，实际存储数据的只有 3 字节，但实际用了 4 字节，浪费了 1 个字节：\n\nI 16 并没有直接放在 bool 的后面，而是在 bool 中填充了一个空白后，放到了偏移量为 2 的位置上。如果 i 16 从偏移量为 1 的位置开始占用 2 个字节，根据对齐原则 2：构体变量中成员的偏移量必须是成员大小的整数倍，套用公式 1 % 2 = 1，就不满足对齐的要求，所以 i 16 从偏移量为2的位置开始\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226004114.png)\n\n以 T 2 结构体为例，实际存储数据的只有 13 字节，但实际用了 24 字节，浪费了 11 个字节：\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226004122.png)\n\n以 T 3 结构体为例，实际存储数据的只有 13 字节，但实际用了 16 字节，浪费了 3 个字节：\n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226004134.png)\n\n\n# Go GC 实现原理？\n\n## 什么是 GC？\n\n垃圾回收也称为 GC（Garbage Collection），是一种自动内存管理机制\n\n现代高级编程语言管理内存的方式分为两种：自动和手动，像 C、C++ 等编程语言使用手动管理内存的方式，工程师编写代码过程中需要主动申请或者释放内存；而 PHP、Java 和 Go 等语言使用自动的内存管理系统，有内存分配器和垃圾收集器来代为分配和回收内存，其中垃圾收集器就是我们常说的 GC。\n\n在应用程序中会使用到两种内存，分别为堆（Heap）和栈（Stack），GC 负责回收堆内存，而不负责回收栈中的内存：\n\n栈是线程的专用内存，专门为了函数执行而准备的，存储着函数中的局部变量以及调用栈，函数执行完后，编译器可以将栈上分配的内存可以直接释放，不需要通过 GC 来回收。\n\n堆是程序共享的内存，需要 GC 进行回收在堆上分配的内存。\n\n垃圾回收器的执行过程被划分为两个半独立的组件：\n\n- 赋值器（Mutator）：这一名称本质上是在指代用户态的代码。因为对垃圾回收器而言，用户态的代码仅仅只是在修改对象之间的引用关系，也就是在对象图（对象之间引用关系的一个有向图）上进行操作。\n- 回收器（Collector）：负责执行垃圾回收的代码。\n\n## 主流 GC 算法\n\n目前比较常见的垃圾回收算法有三种：\n\n1. 引用计数：为每个对象维护一个引用计数，当引用该对象的对象销毁时，引用计数 -1，当对象引用计数为 0 时回收该对象。\n    - 代表语言：**Python**、**PHP**、**Swift**\n    - 优点：对象回收快，不会出现内存耗尽或达到某个阈值时才回收。\n    - 缺点：不能很好的处理循环引用，而实时维护引用计数也是有损耗的。\n2. 分代收集：按照对象生命周期长短划分不同的代空间，生命周期长的放入老年代，短的放入新生代，不同代有不同的回收算法和回收频率。\n    - 代表语言：**Java**\n    - 优点：回收性能好\n    - 缺点：算法复杂\n3. 标记-清除：从根变量开始遍历所有引用的对象，标记引用的对象，没有被标记的进行回收。\n    - 代表语言：**Golang**（三色标记法）\n    - 优点：解决了引用计数的缺点。\n    - 缺点：需要 STW，暂时停掉程序运行。\n Go GC 算法\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226004206.png)\n\n## **三色标记法**\n\n此算法是在 Go 1.5 版本开始使用，Go 语言采用的是标记清除算法，并在此基础上使用了三色标记法和混合写屏障技术，GC 过程和其他用户 goroutine 可并发运行，但需要一定时间的 STW\n\n三色标记法只是为了叙述方便而抽象出来的一种说法，实际上的对象是没有三色之分的。这里的三色，对应了垃圾回收过程中对象的三种状态：\n\n- 灰色：对象还在标记队列中等待\n- 黑色：对象已被标记，`gcmarkBits` 对应位为 `1` （该对象不会在本次 GC 中被回收）\n- 白色：对象未被标记，`gcmarkBits` 对应位为 `0` （该对象将会在本次 GC 中被清理）\n\n- Step 1: 创建：白、灰、黑三个集合\n\n- Step 2: 将所有对象放入白色集合中\n\n- Step 3: 遍历所有**root 对象**，把遍历到的对象从白色集合放入灰色集合 (这里放入灰色集合的都是根节点的对象)\n\n- Step 4: 遍历灰色集合，将灰色对象引用的对象从白色集合放入灰色集合，自身标记为黑色\n\n- Step 5: 重复步骤 4，直到灰色中无任何对象，其中用到 2 个机制：\n\n\t- **写屏障（Write Barrier）**：上面说到的 STW 的目的是防止 GC 扫描时内存变化引起的混乱，而写屏障就是让 goroutine 与 GC 同时运行的手段，虽然不能完全消除 STW，但是可以大大减少 STW 的时间。写屏障在 GC 的特定时间开启，开启后**指针传递时**会把指针标记，即本轮不回收，下次 GC 时再确定。\n\t- **辅助 GC（Mutator Assist）**：为了防止内存分配过快，在 GC 执行过程中，GC 过程中 mutator 线程会并发运行，而 mutator assist 机制会协助 GC 做一部分的工作。\n\nStep 6: 收集所有白色对象（垃圾）\n\n### **root 对象**\n\n根对象在垃圾回收的术语中又叫做根集合，它是垃圾回收器在标记过程时最先检查的对象，包括：\n\n全局变量：程序在编译期就能确定的那些存在于程序整个生命周期的变量。执行栈：每个 goroutine 都包含自己的执行栈，这些执行栈上指向堆内存的指针。寄存器：寄存器的值可能表示一个指针，参与计算的这些指针可能指向某些赋值器分配的堆内存区块。\n\n### **插入写屏障**\n\n对象被引用时触发的机制（只在堆内存中生效）：赋值器这一行为通知给并发执行的回收器，被引用的对象标记为灰色\n\n缺点：结束时需要 STW 来重新扫描栈，标记栈上引用的白色对象的存活\n\n### **删除写屏障**\n\n对象被删除时触发的机制（只在堆内存中生效）：赋值器将这一行为通知给并发执行的回收器，被删除的对象，如果自身为灰色或者白色，那么标记为灰色\n\n缺点：一个对象的引用被删除后，即使没有其他存活的对象引用它，它仍然会活到下一轮，会产生很大冗余扫描成本，且降低了回收精度\n\n### **混合写屏障**\n\nGC 没有混合写屏障前，一直是插入写屏障；混合写屏障是插入写屏障 + 删除写屏障，写屏障只应用在堆上应用，栈上不启用（栈上启用成本很高）\n\n- GC 开始将栈上的对象全部扫描并标记为黑色。\n- GC 期间，任何在栈上创建的新对象，均为黑色。\n- 被删除的对象标记为灰色。\n- 被添加的对象标记为灰色。\n\n##  GC 流程\n\n一次完整的垃圾回收会分为四个阶段，分别是标记准备、标记开始、标记终止、清理：\n\n1. **标记准备（Mark Setup）**：打开写屏障（Write Barrier），需 STW（stop the world)\n2. **标记开始（Marking）**：使用三色标记法并发标记，与用户程序并发执行\n3. **标记终止（Mark Termination**）：对触发写屏障的对象进行重新扫描标记，关闭写屏障（Write Barrier），需 STW（stop the world)\n4. **清理（Sweeping）**：将需要回收的内存归还到堆中，将过多的内存归还给操作系统，与用户程序并发执行\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226004354.png)\n\n## GC 触发时机\n\n**主动触发：**\n\n- 调用 runtime.GC () 方法，触发 GC\n\n**被动触发：**\n\n- 定时触发，该触发条件由 `runtime.forcegcperiod` 变量控制，默认为 2 分钟。当超过两分钟没有产生任何 GC 时，触发 GC\n- 根据内存分配阈值触发，该触发条件由环境变量 GOGC 控制，默认值为 100（100%），当前堆内存占用是上次 GC 结束后占用内存的 2 倍时，触发 GC\n\n## GC 算法演进\n\n- Go 1：mark and sweep 操作都需要 STW\n- **Go 1.3**：分离了 mark 和 sweep 操作，mark 过程需要 STW，mark 完成后让 sweep 任务和普通协程任务一样并行，停顿时间在约几百 ms\n- **Go 1.5**：引入三色并发标记法、插入写屏障，不需要每次都扫描整个内存空间，可以减少 stop the world 的时间，停顿时间在 100 ms 以内\n- Go 1.6：使用 bitmap 来记录回收内存的位置，大幅优化垃圾回收器自身消耗的内存，停顿时间在 10 ms 以内\n- Go 1.7：停顿时间控制在 2 ms 以内\n- **Go 1.8**：混合写屏障（插入写屏障和删除写屏障），停顿时间在 0.5 ms 左右\n- Go 1.9：彻底移除了栈的重扫描过程\n- Go 1.12：整合了两个阶段的 Mark Termination\n- Go 1.13：着手解决向操作系统归还内存的，提出了新的 Scavenger\n- Go 1.14：替代了仅存活了一个版本的 scavenger，全新的页分配器，优化分配内存过程的速率与现有的扩展性问题，并引入了异步抢占，解决了由于密集循环导致的 STW 时间过长的问题\n\n## Go GC 如何调优？\n\n- 控制内存分配的速度，限制 Goroutine 的数量，提高赋值器 mutator 的 CPU 利用率（降低 GC 的 CPU 利用率）\n- 少量使用 `+` 连接 string\n- Slice 提前分配足够的内存来降低扩容带来的拷贝\n- 避免 map key 对象过多，导致扫描时间增加\n- 变量复用，减少对象分配，例如使用 sync. Pool 来复用需要频繁创建临时对象、使用全局变量等\n- 增大 GOGC 的值，降低 GC 的运行频率\n\n##  Go 如何查看 GC 信息？\n\n###  1. GODEBUG=’gctrace=1’\n\n```\npackage main\nfunc main() {\n    for n := 1; n \u003c 100000; n++ {\n        _ = make([]byte, 1\u003c\u003c20)\n    }\n}\n```\n\n```\n$ GODEBUG='gctrace=1' go run main.go\n\ngc 1 @0.003s 4%: 0.013+1.7+0.008 ms clock, 0.10+0.67/1.2/0.018+0.064 ms cpu, 4-\u003e6-\u003e2 MB, 5 MB goal, 8 P\ngc 2 @0.006s 2%: 0.006+4.5+0.058 ms clock, 0.048+0.070/0.027/3.6+0.47 ms cpu, 4-\u003e5-\u003e1 MB, 5 MB goal, 8 P\ngc 3 @0.011s 3%: 0.021+1.3+0.009 ms clock, 0.17+0.041/0.41/0.046+0.072 ms cpu, 4-\u003e6-\u003e2 MB, 5 MB goal, 8 P\ngc 4 @0.013s 5%: 0.025+0.38+0.26 ms clock, 0.20+0.054/0.15/0.009+2.1 ms cpu, 4-\u003e6-\u003e2 MB, 5 MB goal, 8 P\ngc 5 @0.014s 5%: 0.021+0.16+0.002 ms clock, 0.17+0.098/0.028/0.001+0.016 ms cpu, 4-\u003e5-\u003e1 MB, 5 MB goal, 8 P\ngc 6 @0.014s 7%: 0.025+1.6+0.003 ms clock, 0.20+0.061/2.9/1.5+0.025 ms cpu, 4-\u003e6-\u003e2 MB, 5 MB goal, 8 P\ngc 7 @0.016s 7%: 0.019+1.0+0.002 ms clock, 0.15+0.053/1.0/0.018+0.017 ms cpu, 4-\u003e6-\u003e2 MB, 5 MB goal, 8 P\ngc 8 @0.017s 7%: 0.029+0.17+0.002 ms clock, 0.23+0.037/0.10/0.063+0.022 ms cpu, 4-\u003e4-\u003e0 MB, 5 MB goal, 8 P\ngc 9 @0.018s 7%: 0.019+0.23+0.002 ms clock, 0.15+0.040/0.16/0.023+0.018 ms cpu, 4-\u003e5-\u003e1 MB, 5 MB goal, 8 P\ngc 10 @0.018s 7%: 0.022+0.23+0.003 ms clock, 0.17+0.061/0.13/0.006+0.024 ms cpu, 4-\u003e6-\u003e2 MB, 5 MB goal, 8 P\ngc 11 @0.018s 7%: 0.019+0.11+0.001 ms clock, 0.15+0.033/0.051/0.013+0.015 ms cpu, 4-\u003e5-\u003e1 MB, 5 MB goal, 8 P\ngc 12 @0.019s 7%: 0.018+0.19+0.001 ms clock, 0.14+0.035/0.10/0.018+0.014 ms cpu, 4-\u003e5-\u003e1 MB, 5 MB goal, 8 P\ngc 13 @0.019s 7%: 0.018+0.35+0.002 ms clock, 0.15+0.21/0.054/0.013+0.016 ms cpu, 4-\u003e5-\u003e1 MB, 5 MB goal, 8 P\ngc 14 @0.019s 8%: 0.024+0.27+0.002 ms clock, 0.19+0.022/0.13/0.014+0.017 ms cpu, 4-\u003e5-\u003e1 MB, 5 MB goal, 8 P\ngc 15 @0.020s 8%: 0.019+0.42+0.038 ms clock, 0.15+0.060/0.28/0.007+0.31 ms cpu, 4-\u003e17-\u003e13 MB, 5 MB goal, 8 P\ngc 16 @0.021s 8%: 0.018+0.53+0.060 ms clock, 0.14+0.045/0.39/0.005+0.48 ms cpu, 21-\u003e28-\u003e7 MB, 26 MB goal, 8 P\ngc 17 @0.021s 10%: 0.020+0.91+0.64 ms clock, 0.16+0.050/0.36/0.027+5.1 ms cpu, 12-\u003e16-\u003e4 MB, 14 MB goal, 8 P\ngc 18 @0.023s 10%: 0.020+0.55+0.002 ms clock, 0.16+0.053/0.50/0.081+0.023 ms cpu, 7-\u003e9-\u003e2 MB, 8 MB goal, 8 P\n```\n\n字段含义由下表所示：\n\n|字段|含义|\n|:--|:--|\n|gc 2|第二个 GC 周期|\n|0.006|程序开始后的 0.006 秒|\n|2%|该 GC 周期中 CPU 的使用率|\n|0.006|标记开始时， STW 所花费的时间（wall clock）|\n|4.5|标记过程中，并发标记所花费的时间（wall clock）|\n|0.058|标记终止时， STW 所花费的时间（wall clock）|\n|0.048|标记开始时， STW 所花费的时间（cpu time）|\n|0.070|标记过程中，标记辅助所花费的时间（cpu time）|\n|0.027|标记过程中，并发标记所花费的时间（cpu time）|\n|3.6|标记过程中，GC 空闲的时间（cpu time）|\n|0.47|标记终止时， STW 所花费的时间（cpu time）|\n|4|标记开始时，堆的大小的实际值|\n|5|标记结束时，堆的大小的实际值|\n|1|标记结束时，标记为存活的对象大小|\n|5|标记结束时，堆的大小的预测值|\n|8|P 的数量|\n\n### 2. Go tool trace\n\n```\npackage main\n\nimport (\n    \"os\"\n    \"runtime/trace\"\n)\n\nfunc main() {\n    f, _ := os.Create(\"trace.out\")\n    defer f.Close()\n    trace.Start(f)\n    defer trace.Stop()\n    for n := 1; n \u003c 100000; n++ {\n        _ = make([]byte, 1\u003c\u003c20)\n    }\n}\n```\n\n```\n$ go run main.go\n$ go tool trace trace.out\n```\n\n打开浏览器后，可以看到如下统计：\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226004606.png)\n\n点击 View trace，可以查看当时的 trace 情况\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226004617.png)\n\n\n点击 Minimum mutator utilization，可以查看到赋值器 mutator （用户程序）对 CPU 的利用率 74.1%，接近 100%则代表没有针对 GC 的优化空间了\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226004625.png)\n\n### 3. Debug. ReadGCStats\n\n```\npackage main\n\nimport (\n    \"fmt\"\n    \"runtime/debug\"\n    \"time\"\n)\n\nfunc printGCStats() {\n    t := time.NewTicker(time.Second)\n    s := debug.GCStats{}\n    for {\n        select {\n        case \u003c-t.C:\n            debug.ReadGCStats(\u0026s)\n            fmt.Printf(\"gc %d last@%v, PauseTotal %v\\n\", s.NumGC, s.LastGC, s.PauseTotal)\n        }\n    }\n}\nfunc main() {\n    go printGCStats()\n    for n := 1; n \u003c 100000; n++ {\n        _ = make([]byte, 1\u003c\u003c20)\n    }\n}\n```\n\n```\n$ go run main.go\n\ngc 3392 last@2022-05-04 19:22:52.877293 +0800 CST, PauseTotal 117.524907ms\ngc 6591 last@2022-05-04 19:22:53.876837 +0800 CST, PauseTotal 253.254996ms\ngc 10028 last@2022-05-04 19:22:54.87674 +0800 CST, PauseTotal 376.981595ms\ngc 13447 last@2022-05-04 19:22:55.87689 +0800 CST, PauseTotal 511.420111ms\ngc 16938 last@2022-05-04 19:22:56.876955 +0800 CST, PauseTotal 649.293449ms\ngc 20350 last@2022-05-04 19:22:57.876756 +0800 CST, PauseTotal 788.003014ms\n```\n\n字段含义由下表所示：\n\n|字段|含义|\n|:--|:--|\n|NumGC|GC 总次数|\n|LastGC|上次 GC 时间|\n|PauseTotal|STW 总耗时|\n\n### 4. Runtime. ReadMemStats\n\n```\npackage main\n\nimport (\n    \"fmt\"\n    \"runtime\"\n    \"time\"\n)\n\nfunc printMemStats() {\n    t := time.NewTicker(time.Second)\n    s := runtime.MemStats{}\n    for {\n        select {\n        case \u003c-t.C:\n            runtime.ReadMemStats(\u0026s)\n            fmt.Printf(\"gc %d last@%v, heap_object_num: %v, heap_alloc: %vMB, next_heap_size: %vMB\\n\",\n                s.NumGC, time.Unix(int64(time.Duration(s.LastGC).Seconds()), 0), s.HeapObjects, s.HeapAlloc/(1\u003c\u003c20), s.NextGC/(1\u003c\u003c20))\n        }\n    }\n}\nfunc main() {\n    go printMemStats()\n    fmt.Println(1 \u003c\u003c 20)\n    for n := 1; n \u003c 100000; n++ {\n        _ = make([]byte, 1\u003c\u003c20)\n    }\n}\n\n```\n\n```\n$ go run main.go\n\ngc 2978 last@2022-05-04 19:38:04 +0800 CST, heap_object_num: 391, heap_alloc: 20MB, next_heap_size: 28MB\ngc 5817 last@2022-05-04 19:38:05 +0800 CST, heap_object_num: 370, heap_alloc: 4MB, next_heap_size: 4MB\ngc 9415 last@2022-05-04 19:38:06 +0800 CST, heap_object_num: 392, heap_alloc: 7MB, next_heap_size: 8MB\ngc 11429 last@2022-05-04 19:38:07 +0800 CST, heap_object_num: 339, heap_alloc: 4MB, next_heap_size: 5MB\ngc 14706 last@2022-05-04 19:38:08 +0800 CST, heap_object_num: 436, heap_alloc: 6MB, next_heap_size: 8MB\ngc 18253 last@2022-05-04 19:38:09 +0800 CST, heap_object_num: 375, heap_alloc: 4MB, next_heap_size: 6M\n```\n\n\n\n字段含义由下表所示：\n\n|字段|含义|\n|:--|:--|\n|NumGC|GC 总次数|\n|LastGC|上次 GC 时间|\n|HeapObjects|堆中已经分配的对象总数，GC 内存回收后 HeapObjects 取值相应减小|\n|HeapAlloc|堆中已经分配给对象的字节数，GC 内存回收后 HeapAlloc 取值相应减小|\n|NextGC|下次 GC 目标堆的大小|\n","lastmodified":"2024-02-25T17:02:23.022964011Z","tags":[]},"/GO/%E5%85%AB%E8%82%A1%E6%96%87/%E5%B9%B6%E5%8F%91":{"title":"并发","content":"\n\n\n\n# 下面哪个不是 Go 语言中的并发原语?\n\n- Channel\n- Mutex\n- WaitGroup\n- ~~**Semaphore**~~\n\n# **什么是** sync. Once\n\nOnce 可以用来执行且仅仅执行一次动作，常常用于单例对象的初始化场景。\n\nOnce 常常用来初始化单例资源，或者并发访问只需初始化⼀次的共享资源，或者在测试的时候初始化⼀次测试资源。\n\nSync. Once 只暴露了⼀个⽅法 Do，你可以多次调⽤ Do ⽅法，但是只有第⼀次调⽤ Do 方法时 f 参数才会执行，这⾥的 f 是⼀个无参数无返回值的函数。\n\n**源码**\n\n```\ntype Once struct {\n\tm    Mutex\n\tdone uint32\n}\n\nfunc (o *Once) Do(f func()) {\n\tif atomic.LoadUint32(\u0026o.done) == 1 {\n\t\treturn\n\t}\n\to.m.Lock()\n\tdefer o.m.Unlock()\n\tif o.done == 0 {\n\t\tdefer atomic.StoreUint32(\u0026o.done, 1)\n\t\tf()\n\t}\n}\n```\n\n# Golang 除了 goroutine 还有什么处理并发的方法\n\n处理并发的方法，主要使用 goroutine，还可以使用 channel + goroutine 以及使用 sync 包提供的并发锁以及经常用的信号量机制.\n\n# select 可以用于什么\n\nGo 的通道有两种操作方式，一种是带 range 子句的 for 语句，另一种则是 select 语句，它是专门为了操作通道而存在的。这里主要介绍 select 的用法。\n\nSelect 的语法如下：\n\n```\nselect {\n   case \u003c-ch1 :\n     statement(s)   \n   case ch2 \u003c- 1 :\n      statement(s)\n    …\n   default : /* 可选 */\n      statement(s)\n}\n```\n\n这里要注意：\n\n- 每个 case 都必须是一个通信。由于 select 语句是专为通道设计的，所以每个 case 表达式中都只能包含操作通道的表达式，比如接收表达式。\n- 如果有多个 case 都可以运行，select 会随机公平地选出一个执行，其他不会执行。\n- 如果多个 case 都不能运行，若有 default 子句，则执行该语句，反之，select 将阻塞，直到某个 case 可以运行。\n- 所有 channel 表达式都会被求值。\n- Select 机制⽤来处理异步 IO 问题。\n- Select 机制最⼤的⼀条限制就是每个 case 语句⾥必须是⼀个 IO 操作。\n\n**实例**\n\n```\npackage main\n\nimport (\n    \"fmt\"\n    \"math/rand\"\n)\n\nfunc main() {\n    // 准备好几个通道。\n    intChannels := [5]chan int{\n        make(chan int, 1),\n        make(chan int, 1),\n        make(chan int, 1),\n        make(chan int, 1),\n        make(chan int, 1)\n    }\n    // 随机选择一个通道，并向它发送元素值。\n    index := rand.Intn(5)\n    fmt.Printf(\"The index: %d\", index)\n    intChannels[index] \u003c- index\n    // 哪一个通道中有可取的元素值，哪个对应的分支就会被执行。\n    select {\n        case \u003c-intChannels[0]:\n            fmt.Println(\"The first candidate case is selected.\")\n        case \u003c-intChannels[1]:\n            fmt.Println(\"The second candidate case is selected.\")\n        case elem := \u003c-intChannels[2]:\n            fmt.Printf(\"The third candidate case is selected. The element is %d.\", elem)\n        default:\n            fmt.Println(\"No candidate case is selected!\")\n    }\n}\n```\n\n**select 死锁**  \nSelect 使用不当会发生死锁。如果通道没有数据发送，但 select 中有存在接收通道数据的语句，将发生死锁。\n\n```\nfunc main() {  \n        ch := make(chan string)\n        select {\n            case \u003c-ch:\n        }\n}\n/*\nfatal error: all goroutines are asleep - deadlock!\ngoroutine 1 [chan receive]:\nmain.main()\n/workspace/src/test.go:5 +0x52\nexit status 2\n*/\n//可以添加 default 语句来避免产生死锁。\n```\n\n**空 select{}**\n\n```\nfunc main() {  \n        select {}\n}\n\n/*\nfatal error: all goroutines are asleep - deadlock!\ngoroutine 1 [select (no cases)]:\nmain.main()\n\t/workspace/src/test.go:3 +0x20\nexit status 2\n*/\n```\n\n**select 和 for 结合使用**\n\nSelect 语句只能对其中的每一个 case 表达式各求值一次。所以，如果想连续或定时地操作其中的通道的话，就需要通过在 for 语句中嵌入 select 语句的方式实现。\n\n```\nfunc main() {\n    tick := time.Tick(time.Second)\n    for {\n        select {\n            case t := \u003c-tick:\n                fmt.Println(t)\n                break\n            }\n        }\n        fmt.Println(\"end\")\n    }\n```\n\n你会发现 break 只跳出了 select，无法跳出 for。解决办法有两种：  \n**使用 goto 跳出循环**\n\n```\nfunc main() {\n    tick := time.Tick(time.Second)\n    for {\n        select {\n            case t := \u003c-tick:\n                fmt.Println(t)\n                //跳到指定位置\n                goto END\n            }\n        }\nEND:\n        fmt.Println(\"end\")\n    }\n```\n\n**使用标签**\n\n```\nfunc main() {\n    tick := time.Tick(time.Second)\n//这是标签\nFOREND:\n    for {\n        select {\n            case t := \u003c-tick:\n                fmt.Println(t)\n                //跳出FOREND标签\n                break ForEnd\n            }\n        }\nEND:\n        fmt.Println(\"end\")\n    }\n```\n\n**select 实现超时机制**  \n主要使用的 time. After 实现超时控制。\n\n```\nfunc main() {\n    ch := make(chan int)\n    quit := make(chan bool)\n\n    go func() {\n        for {\n            select {\n                case num := \u003c-ch:  //如果有数据，下面打印。但是有可能ch一直没数据\n                fmt.Println(\"num = \", num)\n                case \u003c-time.After(3 * time.Second): //上面的ch如果一直没数据会阻塞，那么select也会检测其他case条件，检测到后3秒超时\n                fmt.Println(\"超时\")\n                quit \u003c- true  //写入\n            }\n        }\n\n    }()\n\n    for i := 0; i \u003c 5; i++ {\n        ch \u003c- i\n        time.Sleep(time.Second)\n    }\n    \u003c-quit //这里暂时阻塞，直到可读\n    fmt.Println(\"程序结束\")\n}\n```\n\n执行后，可以观察到：依次打印出 0-4，几秒过后打印出“超时”和“程序结束”，打印结果如下：\n\n```\nnum =  0\nnum =  1\nnum =  2\nnum =  3\nnum =  4\n超时\n程序结束\n```\n\nselect 的底层原理：[Go select使用与底层原理](https://juejin.cn/post/7123037385419407374?searchId=20230920141239DA74937FA19C8E97461E#heading-2) \n\n# WaitGroup 的坑\n\n① Add 一个负数\n\n如果计数器的值小于 0 会直接 panic\n\n② Add 在 Wait 之后调用\n\n比如一些子协程开头调用 Add 结束调用 Wait，这些 Wait 无法阻塞子协程。正确做法是在开启子协程之前先 Add 特定的值。\n\n③ 未置为 0 就重用\n\nWaitGroup 可以完成一次编排任务，计数值降为 0 后可以继续被其他任务所用，但是不要在还没使用完的时候就用于其他任务，这样由于带着计数值，很可能出问题。\n\n④ 复制 waitgroup\n\nWaitGroup 有 nocopy 字段，不能被复制。也意味着 WaitGroup 不能作为函数的参数。\n\n# 深入理解 sync. Waitgroup\n\n[https://juejin.cn/post/7181812988461252667](https://juejin.cn/post/7181812988461252667) \n\n#  Data Race 问题怎么解决？能不能不加锁解决这个问题？\n\n![image-20230724164303002](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticimage-20230724164303002.png)\n\n#  runtime 提供常见的方法\n\n1. **Gosched ()**：让当前线程让出 cpu 以让其它线程运行，它不会挂起当前线程，因此当前线程未来会继续执行。\n2. **NumCPU ()**：返回当前系统的 CPU 核数量。\n3. **GOMAXPROCS ()**：设置最大的可同时使用的 CPU 核数。  \n    通过 runtime. GOMAXPROCS 函数，应用程序可以设置运行时系统中的 P 最大数量。注意，如果在运行期间设置该值的话，会引起“Stop the World”。所以，应在应用程序最早期调用，并且最好是在运行 Go 程序之前设置好操作程序的环境变量 GOMAXPROCS，而不是在程序中调用 runtime. GOMAXPROCS 函数。\n\n无论我们传递给函数的整数值是什么值，运行时系统的 P 最大值总会在 1~256 之间。\n\nGo 1.8 后，默认让程序运行在多个核上，可以不用设置了。\n\nGo 1.8 前，还是要设置一下，可以更高效的利用 cpu。\n\n1. Goexit ()：退出当前 goroutine（但是 defer 语句会照常执行）。\n2. **NumGoroutine**：返回正在执行和排队的任务总数。  \n    Runtime. NumGoroutine 函数在被调用后，会返回系统中的处于特定状态的 Goroutine 的数量。这里的特定状态是指 GrunnableGruningGsyscallGwaition。处于这些状态的 Goroutine 即被看做是活跃的或者说正在被调度。\n\n注意：垃圾回收所在 Goroutine 的状态也处于这个范围内的话，也会被纳入该计数器。\n\n1. **GOOS**：查看目标操作系统。很多时候，我们会根据平台的不同实现不同的操作，就可以用 GOOS 来查看自己所在的操作系统。\n2. **runtime. GC**：会让运行时系统进行一次强制性的垃圾收集。  \n    强制的垃圾回收：不管怎样，都要进行的垃圾回收。非强制的垃圾回收：只会在一定条件下进行的垃圾回收（即运行时，系统自上次垃圾回收之后新申请的堆内存的单元（也成为单元增量）达到指定的数值）。\n3. **GOROOT ()**：获取 goroot 目录。\n4. **runtime. LockOSThread 和 runtime. UnlockOSThread 函数**：前者调用会使调用他的 Goroutine 与当前运行它的 M 锁定到一起，后者调用会解除这样的锁定。\n\n# Go 语言怎么做的连接复用，怎么支持的并发请求\n\nGo 的 netpoll 是怎么实现的像阻塞 read 一样去使用底层的非阻塞 read\n\n[Golang的IO多路复用的netpoll模型](https://www.cnblogs.com/luozhiyun/p/14390824.html) \n\n**go 语言怎么做的连接复用**\nGo 语言中 IO 多路复用使用 netpoll 模型\nNetpoll 本质上是对 I/O 多路复用技术的封装，所以自然也是和 epoll 一样脱离不了下面几步：\n\n1. Netpoll 创建及其初始化；\n2. 向 netpoll 中加入待监控的任务；\n3. 从 netpoll 获取触发的事件；\n在 go 中对 epoll 提供的三个函数进行了封装\n\n```\nfunc netpollinit()\nfunc netpollopen(fd uintptr, pd *pollDesc) int32\nfunc netpoll(delay int64) gList\n```\n\n\nNetpollinit 函数负责初始化 netpoll；\nNetpollopen 负责监听文件描述符上的事件；\nNetpoll 会阻塞等待返回一组已经准备就绪的 Goroutine；\n\n**go 语言怎么支持的并发请求**\n``Go`` 中有 goroutine，所以可以采用多协程来解决并发问题。Accept 连接后，将连接丢给 goroutine 处理后续的读写操作。在开发者看到的这个 goroutine 中业务逻辑是同步的，也不用考虑 IO 是否阻塞。\n\n Golang 的协程通信有哪些方式\n\n1）共享内存\n\n- 共享内存是指多个协程直接访问共享变量的方式，这种方式不需要显式地进行通信，但需要考虑并发访问时的竞态问题，需要使用互斥锁等机制来确保同步和一致性。\n\n2）通道\n\n- 通道是 Go 语言中一个重要的并发原语，它是一种线程安全的、带缓冲的 FIFO 队列。通道支持阻塞式读写，可以用来在不同的协程之间传递数据，也可以用来进行同步操作。通道在多个协程之间传递数据时，会自动进行同步，不需要程序员显式地进行加锁和解锁操作。\n\n3）选择器\n\n- 选择器是 Go 语言中的一种控制结构，可以同时监听多个通道的操作，并选择其中一个可以进行操作的通道。选择器可以用来实现非阻塞的通信操作，避免了因等待某个通道操作而导致的阻塞。选择器通常与通道配合使用，用于多个协程之间的协作和同步。\n\n4）条件变量（Cond）\n\n- 条件变量用于在协程之间进行复杂的通信和协调。在 Go 中，可以使用`sync`包中的`Cond`类型来实现条件变量。它通常与互斥锁一起使用，以便协程可以在特定条件下等待或被唤醒。\n\n5）原子操作（Atomic Operations）\n\n- Go 语言提供了`sync/atomic`包，用于执行原子操作，这些操作通常用于共享资源的更新，以避免竞态条件。原子操作可以用于对变量的读取、写入、加法等操作，而不需要额外的锁定。\n\n总之，Go 协程之间的通信是非常重要的，不同的应用场景需要选择不同的通信方式，以确保程序的正确性和性能。共享内存通常用于需要高性能的并发场景，但需要注意线程安全和同步问题；通道是一种简单、安全、高效的通信方式，适用于大多数并发场景；选择器则适用于多通道协作和同步的场景。\n\n# Go 为啥使用 CSP 模型来实现并发?\n\nGo 语言使用 CSP（Communicating Sequential Processes，通信顺序进程）模型来实现并发，这是由 Go 语言设计者选择的一种并发模型，有以下几个重要的原因：\n\n1. **简单性和清晰性**：CSP 模型提供了一种清晰且直观的方式来表达并发程序。它基于协程之间的通信来进行协作，通过通道（channel）进行消息传递，使得并发程序的结构和逻辑更加简单和可读。\n2. **避免共享状态**：CSP 模型强调避免共享状态，而是通过通信共享数据。共享状态是许多并发程序中的错误和难点来源之一，而 CSP 模型可以减少竞态条件（race condition）等问题的出现。\n3. **安全性**：Go 的 CSP 模型通过通道提供了一种安全的并发机制。通道的发送和接收操作都是原子的，不需要额外的锁定，因此减少了程序中出现的锁定问题，如死锁和竞态条件。\n4. **可扩展性**：CSP 模型可以轻松扩展到大量的协程，因为通道和协程的创建成本相对较低。这使得 Go 非常适合构建高并发的系统，如 Web 服务器、分布式系统和网络服务。\n5. **编译器和运行时支持**：Go 编译器和运行时系统针对 CSP 模型进行了优化。Go 的并发原语在语言级别得到支持，而不是通过库的方式实现，这使得并发编程更加容易。\n\n总之，Go 选择 CSP 模型是为了提供一种简单、安全、高效和可扩展的并发编程模型，以便开发者能够更轻松地构建并发程序，同时避免共享状态和典型的并发问题。这使得 Go 成为了一个流行的选择，特别适用于需要高度并发性能的应用程序和系统。\n\n# sync. Pool 有什么用\n\n对于很多需要重复分配、回收内存的地方，sync. Pool 是一个很好的选择。频繁地分配、回收内存会给 GC 带来一定的负担，严重的时候会引起 CPU 的毛刺，而 sync. Pool 可以将暂时不用的对象缓存起来，待下次需要的时候直接使用，不用再次经过内存分配，复用对象的内存，减轻 GC 的压力，提升系统的性能。\n\n[sync.Pool底层原理](https://zhuanlan.zhihu.com/p/399150710) \n\n# 有没有什么线程安全的办法？\n\n在 Go 语言中，线程安全一般指协程安全，因为 Go 一般使用协程进行调度；而 Go 中为了保证其协程安全，有以下几种机制：\n\n1、互斥锁：在 Go 的标准库中有 sync 包，sync. Mutex 就是解决并发冲突导致的安全性问题的一种方式。\n\n2、读写锁：是在互斥锁上的进一步升级版本，主要为了解决并发多写少读、少写多读两种高并发的情况\n\n3、如果不是需要强制使用同一个对象，那么也可以采用创建对象副本的方式，每个协程独占一个对象，相互之间不关联，但是这显然不符合我们的要求。\n\n综上，使用互斥锁或者读写锁就能很好的解决问题。\n\n\n\n\n\n# Go 常用的并发模型？\n\n并发模型说的是系统中的线程如何协作完成并发任务，不同的并发模型，线程以不同的方式进行**通信**和协作。\n\n## 线程间通信方式\n\n线程间通信方式有两种：共享内存和消息传递，无论是哪种通信模型，线程或者协程最终都会从内存中获取数据，所以更为准确的说法是直接共享内存、发送消息的方式来同步信息\n\n### **共享内存**\n\n**抽象层级**：抽象层级低，当我们遇到对资源进行更细粒度的控制或者对性能有极高要求的场景才应该考虑抽象层级更低的方法\n\n**耦合**：高，线程需要在读取或者写入数据时先获取保护该资源的互斥锁\n\n**线程竞争**：需要加锁，才能避免线程竞争和数据冲突\n\n### **发送消息**\n\n**抽象层级**：抽象层级高，提供了更良好的封装和与领域更相关和契合的设计，比如 Go 语言中的 `Channel` 就提供了 Goroutine 之间用于传递信息的方式，它在内部实现时就广泛用到了共享内存和锁，通过对两者进行的组合提供了更高级的同步机制\n\n**耦合**：低，生产消费者模型\n\n**线程竞争**：保证同一时间只有一个活跃的线程能够访问数据，channel 维护所有被该 chanel 阻塞的协程，保证有资源的时候只唤醒一个协程，从而避免竞争\n\nGo 语言中实现了两种并发模型，一种是共享内存并发模型，另一种则是 CSP 模型。\n\n## 共享内存并发模型\n\n通过直接共享内存 + 锁的方式同步信息，传统多线程并发\n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226005141.png)\n\n## CSP 并发模型\n\n通过发送消息的方式来同步信息，Go 语言推荐使用的_通信顺序进程_（communicating sequential processes）并发模型，通过 goroutine 和 channel 来实现\n\n- `goroutine` 是 Go 语言中并发的执行单位，可以理解为”线程“\n- `channel` 是 Go 语言中各个并发结构体 (`goroutine`)之前的通信机制。通俗的讲，就是各个 `goroutine` 之间通信的”管道“，类似于 Linux 中的管道\n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226005155.png)\n\n# Go 有哪些并发同步原语？\n\nGo 是一门以并发编程见长的语言，它提供了一系列的同步原语方便开发者使用\n\n## 原子操作\n\nMutex、RWMutex 等并发原语的底层实现是通过 atomic 包中的一些原子操作来实现的，原子操作是最基础的并发原语\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226005223.png)\n\n```\npackage main\n\nimport (\n    \"fmt\"\n    \"sync/atomic\"\n)\n\nvar opts int64 = 0\n\nfunc main() {\n    add(\u0026opts, 3)\n    load(\u0026opts)\n    compareAndSwap(\u0026opts, 3, 4)\n    swap(\u0026opts, 5)\n    store(\u0026opts, 6)\n}\n\nfunc add(addr *int64, delta int64) {\n    atomic.AddInt64(addr, delta) //加操作\n    fmt.Println(\"add opts: \", *addr)\n}\n\nfunc load(addr *int64) {\n    fmt.Println(\"load opts: \", atomic.LoadInt64(\u0026opts))\n}\n\nfunc compareAndSwap(addr *int64, oldValue int64, newValue int64) {\n    if atomic.CompareAndSwapInt64(addr, oldValue, newValue) {\n        fmt.Println(\"cas opts: \", *addr)\n        return\n    }\n}\n\nfunc swap(addr *int64, newValue int64) {\n    atomic.SwapInt64(addr, newValue)\n    fmt.Println(\"swap opts: \", *addr)\n}\n\nfunc store(addr *int64, newValue int64) {\n    atomic.StoreInt64(addr, newValue)\n    fmt.Println(\"store opts: \", *addr)\n}\n```\n\n## Channel\n\n`channel` 管道，高级同步原语，goroutine 之间通信的桥梁\n\n使用场景：消息队列、数据传递、信号通知、任务编排、锁\n\n```\npackage main\n\nimport (\n    \"fmt\"\n    \"time\"\n)\n\nfunc main() {\n    c := make(chan struct{}, 1)\n    for i := 0; i \u003c 10; i++ {\n        go func() {\n            c \u003c- struct{}{}\n            time.Sleep(1 * time.Second)\n            fmt.Println(\"通过ch访问临界区\")\n            \u003c-c\n        }()\n    }\n    for {\n    }\n}\n```\n\n## 基本并发原语\n\nGo 语言在 `sync` 包中提供了用于同步的一些基本原语，这些基本原语提供了较为基础的同步功能，但是它们是一种相对原始的同步机制，在多数情况下，我们都应该使用抽象层级更高的 Channel 实现同步。\n\n常见的并发原语如下：`sync.Mutex`、`sync.RWMutex`、`sync.WaitGroup`、`sync.Cond`、`sync.Once`、`sync.Pool`、`sync.Context`\n\n### **sync. Mutex**\n\n`sync.Mutex` （互斥锁） 可以限制对临界资源的访问，保证只有一个 goroutine 访问共享资源\n\n使用场景：大量读写，比如多个 goroutine 并发更新同一个资源，像计数器\n\n```\npackage main\n\nimport (\n    \"fmt\"\n    \"sync\"\n)\n\nfunc main() {\n    // 封装好的计数器\n    var counter Counter\n    var wg sync.WaitGroup\n    var gNum = 1000\n    wg.Add(gNum)\n    // 启动10个goroutine\n    for i := 0; i \u003c gNum; i++ {\n        go func() {\n            defer wg.Done()\n            counter.Incr() // 受到锁保护的方法\n        }()\n    }\n    wg.Wait()\n    fmt.Println(counter.Count())\n}\n\n// 线程安全的计数器类型\ntype Counter struct {\n    mu    sync.Mutex\n    count uint64\n}\n\n// 加1的方法，内部使用互斥锁保护\nfunc (c *Counter) Incr() {\n    c.mu.Lock()\n    c.count++\n    c.mu.Unlock()\n}\n\n// 得到计数器的值，也需要锁保护\nfunc (c *Counter) Count() uint64 {\n    c.mu.Lock()\n    defer c.mu.Unlock()\n    return c.count\n}\n```\n\n### sync. RWMutex\n\n`sync.RWMutex` （读写锁） 可以限制对临界资源的访问，保证只有一个 goroutine 写共享资源，可以有多个 goroutine 读共享资源\n\n使用场景：大量并发读，少量并发写，有强烈的性能要求\n\n```\npackage main\n\nimport (\n    \"fmt\"\n    \"sync\"\n    \"time\"\n)\n\nfunc main() {\n    // 封装好的计数器\n    var counter Counter\n    var gNum = 1000\n    // 启动10个goroutine\n    for i := 0; i \u003c gNum; i++ {\n        go func() {\n            counter.Count() // 受到锁保护的方法\n        }()\n    }\n    for { // 一个writer\n        counter.Incr() // 计数器写操作\n        fmt.Println(\"incr\")\n        time.Sleep(time.Second)\n    }\n}\n\n// 线程安全的计数器类型\ntype Counter struct {\n    mu    sync.RWMutex\n    count uint64\n}\n\n// 加1的方法，内部使用互斥锁保护\nfunc (c *Counter) Incr() {\n    c.mu.Lock()\n    c.count++\n    c.mu.Unlock()\n}\n\n// 得到计数器的值，也需要锁保护\nfunc (c *Counter) Count() uint64 {\n    c.mu.RLock()\n    defer c.mu.RUnlock()\n    return c.count\n}\n```\n\n### **sync. WaitGroup**\n\n`sync.WaitGroup` 可以等待一组 Goroutine 的返回\n\n使用场景：并发等待，任务编排，一个比较常见的使用场景是批量发出 RPC 或者 HTTP 请求\n\n```\nrequests := []*Request{...}\nwg := \u0026sync.WaitGroup{}\nwg.Add(len(requests))\n\nfor _, request := range requests {\n    go func(r *Request) {\n        defer wg.Done()\n        // res, err := service.call(r)\n    }(request)\n}\nwg.Wait()\n```\n\n### **sync. Cond**\n\n`sync.Cond` 可以让一组的 Goroutine 都在满足特定条件时被唤醒\n\n使用场景：利用等待 / 通知机制实现阻塞或者唤醒\n\n```\npackage main\n\nimport (\n    \"fmt\"\n    \"sync\"\n    \"sync/atomic\"\n    \"time\"\n)\n\nvar status int64\n\nfunc main() {\n    c := sync.NewCond(\u0026sync.Mutex{})\n    for i := 0; i \u003c 10; i++ {\n        go listen(c)\n    }\n    time.Sleep(1 * time.Second)\n    go broadcast(c)\n    time.Sleep(1 * time.Second)\n}\n\nfunc broadcast(c *sync.Cond) {\n    c.L.Lock()\n    atomic.StoreInt64(\u0026status, 1)\n    c.Signal()\n    c.L.Unlock()\n}\n\nfunc listen(c *sync.Cond) {\n    c.L.Lock()\n    for atomic.LoadInt64(\u0026status) != 1 {\n        c.Wait()\n    }\n    fmt.Println(\"listen\")\n    c.L.Unlock()\n}\n```\n\n### **sync. Once**\n\n`sync.Once` 可以保证在 Go 程序运行期间的某段代码只会执行一次\n\n使用场景：常常用于单例对象的初始化场景\n\n```\npackage main\n\nimport (\n    \"fmt\"\n    \"sync\"\n)\n\nfunc main() {\n    o := \u0026sync.Once{}\n    for i := 0; i \u003c 10; i++ {\n        o.Do(func() {\n            fmt.Println(\"only once\")\n        })\n    }\n}\n```\n\n### **sync. Pool**\n\n`sync.Pool` 可以将暂时将不用的对象缓存起来，待下次需要的时候直接使用，不用再次经过内存分配，复用对象的内存，减轻 GC 的压力，提升系统的性能（频繁地分配、回收内存会给 GC 带来一定的负担，严重的时候会引起 CPU 的毛刺）\n\n使用场景：对象池化， TCP 连接池、数据库连接池、Worker Pool\n\n```\npackage main\n\nimport (\n    \"fmt\"\n    \"sync\"\n)\n\nfunc main() {\n    pool := sync.Pool{\n        New: func() interface{} {\n            return 0\n        },\n    }\n\n    for i := 0; i \u003c 10; i++ {\n        v := pool.Get().(int)\n        fmt.Println(v) // 取出来的值是put进去的，对象复用；如果是新建对象，则取出来的值为0\n        pool.Put(i)\n    }\n}\n```\n\n### **sync. Map**\n\n`sync.Map` 线程安全的 map\n\n使用场景：map 并发读写\n\n```\npackage main\n\nimport (\n    \"fmt\"\n    \"sync\"\n)\n\nfunc main() {\n    var scene sync.Map\n    // 将键值对保存到sync.Map\n    scene.Store(\"1\", 1)\n    scene.Store(\"2\", 2)\n    scene.Store(\"3\", 3)\n    // 从sync.Map中根据键取值\n    fmt.Println(scene.Load(\"1\"))\n    // 根据键删除对应的键值对\n    scene.Delete(\"1\")\n    // 遍历所有sync.Map中的键值对\n    scene.Range(func(k, v interface{}) bool {\n        fmt.Println(\"iterate:\", k, v)\n        return true\n    })\n}\n```\n\n##### []( https://youandgentleness.cn/2023/08/28/Go%E8%AF%AD%E8%A8%80%E9%9D%A2%E8%AF%95%E9%A2%98%E7%B2%BE%E8%AE%B2/#sync-Context \"sync. Context\")**sync. Context**\n\n`sync.Context` 可以进行上下文信息传递、提供超时和取消机制、控制子 goroutine 的执行\n\n使用场景：取消一个 goroutine 的执行\n\n```\npackage main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"time\"\n)\n\nfunc main() {\n    ctx, cancel := context.WithCancel(context.Background())\n    go func() {\n        defer func() {\n            fmt.Println(\"goroutine exit\")\n        }()\n        for {\n            select {\n            case \u003c-ctx.Done():\n                fmt.Println(\"receive cancel signal!\")\n                return\n            default:\n                fmt.Println(\"default\")\n                time.Sleep(time.Second)\n            }\n        }\n    }()\n    time.Sleep(time.Second)\n    cancel()\n    time.Sleep(2 * time.Second)\n}\n```\n\n## 扩展并发原语\n\n### **ErrGroup**\n\n`errgroup` 可以在一组 Goroutine 中提供了同步、错误传播以及上下文取消的功能\n\n使用场景：只要一个 goroutine 出错我们就不再等其他 goroutine 了，减少资源浪费，并且返回错误\n\n```\npackage main\n\nimport (\n    \"fmt\"\n    \"net/http\"\n\n    \"golang.org/x/sync/errgroup\"\n)\n\nfunc main() {\n    var g errgroup.Group\n    var urls = []string{\n        \"http://www.baidu.com/\",\n        \"https://www.sina.com.cn/\",\n    }\n    for i := range urls {\n        url := urls[i]\n        g.Go(func() error {\n            resp, err := http.Get(url)\n            if err == nil {\n                resp.Body.Close()\n            }\n            return err\n        })\n    }\n    err := g.Wait()\n    if err == nil {\n        fmt.Println(\"Successfully fetched all URLs.\")\n    } else {\n        fmt.Println(\"fetched error:\", err.Error())\n    }\n}\n```\n\n### **Semaphore**\n\n`Semaphore` 带权重的信号量，控制多个 goroutine 同时访问资源\n\n使用场景：控制 goroutine 的阻塞和唤醒\n\n```\npackage main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"log\"\n    \"runtime\"\n    \"time\"\n\n    \"golang.org/x/sync/semaphore\"\n)\n\nvar (\n    maxWorkers = runtime.GOMAXPROCS(0)\n    sema       = semaphore.NewWeighted(int64(maxWorkers)) //信号量\n    task       = make([]int, maxWorkers*4)\n\n// 任务数，是worker的四\n)\n\nfunc main() {\n    ctx := context.Background()\n    for i := range task {\n        // 如果没有worker可用，会阻塞在这里，直到某个worker被释放\n        if err := sema.Acquire(ctx, 1); err != nil {\n            break\n        }\n        // 启动worker goroutine\n        go func(i int) {\n            defer sema.Release(1)\n            time.Sleep(100 * time.Millisecond) // 模拟一个耗时操作\n            task[i] = i + 1\n        }(i)\n    }\n    // 请求所有的worker,这样能确保前面的worker都执行完\n    if err := sema.Acquire(ctx, int64(maxWorkers)); err != nil {\n        log.Printf(\"获取所有的worker失败: %v\", err)\n    }\n    fmt.Println(maxWorkers, task)\n}\n```\n\n### **SingleFlight**\n\n用于抑制对下游的重复请求\n\n使用场景：访问缓存、数据库等场景，缓存过期时只有一个请求去更新数据库\n\n```\npackage main\n\nimport (\n    \"fmt\"\n    \"sync\"\n    \"sync/atomic\"\n    \"time\"\n\n    \"golang.org/x/sync/singleflight\"\n)\n\n// 模拟从数据库读取\nfunc getArticle(id int) (article string, err error) {\n    // 假设这里会对数据库进行调用, 模拟不同并发下耗时不同\n    atomic.AddInt32(\u0026count, 1)\n    time.Sleep(time.Duration(count) * time.Millisecond)\n\n    return fmt.Sprintf(\"article: %d\", id), nil\n}\n\n// 模拟优先读缓存，缓存不存在读取数据库，并且只有一个请求读取数据库，其它请求等待\nfunc singleflightGetArticle(sg *singleflight.Group, id int) (string, error) {\n    v, err, _ := sg.Do(fmt.Sprintf(\"%d\", id), func() (interface{}, error) {\n        return getArticle(id)\n    })\n\n    return v.(string), err\n}\n\nvar count int32\n\nfunc main() {\n    time.AfterFunc(1*time.Second, func() {\n        atomic.AddInt32(\u0026count, -count)\n    })\n\n    var (\n        wg  sync.WaitGroup\n        now = time.Now()\n        n   = 1000\n        sg  = \u0026singleflight.Group{}\n    )\n\n    for i := 0; i \u003c n; i++ {\n        wg.Add(1)\n        go func() {\n            res, _ := singleflightGetArticle(sg, 1)\n            // res, _ := getArticle(1)\n            if res != \"article: 1\" {\n                panic(\"err\")\n            }\n            wg.Done()\n        }()\n    }\n\n    wg.Wait()\n    fmt.Printf(\"同时发起 %d 次请求，耗时: %s\", n, time.Since(now))\n}\n```\n\n# Go WaitGroup 实现原理？\n\n## 概念\n\n`Go`标准库提供了`WaitGroup`原语, 可以用它来等待一批 Goroutine 结束\n\n```\n// A WaitGroup must not be copied after first use.\ntype WaitGroup struct {\n noCopy noCopy\n state1 [3]uint32\n}\n```\n\n## 底层数据结构\n\n其中 `noCopy` 是 golang 源码中检测禁止拷贝的技术。如果程序中有 WaitGroup 的赋值行为，使用 `go vet` 检查程序时，就会发现有报错。但需要注意的是，noCopy 不会影响程序正常的编译和运行。\n\n`state 1`主要是存储着状态和信号量，状态维护了 2 个计数器，一个是请求计数器 counter ，另外一个是等待计数器 waiter（已调用 `WaitGroup. Wait` 的 goroutine 的个数）\n\n当数组的首地址是处于一个`8`字节对齐的位置上时，那么就将这个数组的前`8`个字节作为`64`位值使用表示状态，后`4`个字节作为`32`位值表示信号量 (`semaphore`)；同理如果首地址没有处于`8`字节对齐的位置上时，那么就将前`4`个字节作为`semaphore`，后`8`个字节作为`64`位数值。\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226005747.png)\n\n## 使用方法\n\n在 WaitGroup 里主要有 3 个方法：\n\n- `WaitGroup.Add ()`：可以添加或减少请求的 goroutine 数量，*`Add (n)` 将会导致 `counter += n`*\n- `WaitGroup.Done ()`：相当于 Add (-1)，`Done ()` 将导致 `counter -=1`，请求计数器 counter 为 0 时通过信号量调用`runtime_Semrelease`唤醒 waiter 线程\n- `WaitGroup.Wait ()`：会将 `waiter++`，同时通过信号量调用 `runtime_Semacquire (semap)`阻塞当前 goroutine\n\n```\nfunc main() {\n    var wg sync.WaitGroup\n    for i := 1; i \u003c= 5; i++ {\n        wg.Add(1)\n        go func() {\n            defer wg.Done()\n            println(\"hello\")\n        }()\n    }\n\n    wg.Wait()\n}\n```\n\n# Go Cond 实现原理？\n\n## 概念\n\n`Go`标准库提供了`Cond`原语，可以让 Goroutine 在满足特定条件时被阻塞和唤醒\n\n```\ntype Cond struct {\n    noCopy noCopy\n\n    // L is held while observing or changing the condition\n    L Locker\n\n    notify  notifyList\n    checker copyChecker\n}\n\ntype notifyList struct {\n    wait   uint32\n    notify uint32\n    lock   uintptr // key field of the mutex\n    head   unsafe.Pointer\n    tail   unsafe.Pointer\n}\n```\n\n## 底层数据结构\n\n主要有`4`个字段：\n\n- `nocopy` ： golang 源码中检测禁止拷贝的技术。如果程序中有 WaitGroup 的赋值行为，使用 `go vet` 检查程序时，就会发现有报错，但需要注意的是，noCopy 不会影响程序正常的编译和运行\n- `checker`：用于禁止运行期间发生拷贝，双重检查 (`Double check`)\n- `L`：可以传入一个读写锁或互斥锁，当修改条件或者调用`Wait`方法时需要加锁\n- `notify`：通知链表，调用`Wait ()`方法的`Goroutine`会放到这个链表中，从这里获取需被唤醒的 Goroutine 列表\n\n## 使用方法\n\n在 Cond 里主要有 3 个方法：\n\n- `sync.NewCond (l Locker)`: 新建一个 sync. Cond 变量，注意该函数需要一个 Locker 作为必填参数，这是因为在 `cond.Wait ()` 中底层会涉及到 Locker 的锁操作\n- `Cond.Wait ()`: 阻塞等待被唤醒，调用 Wait 函数前**需要先加锁**；并且由于 Wait 函数被唤醒时存在虚假唤醒等情况，导致唤醒后发现，条件依旧不成立，因此需要使用 for 语句来循环地进行等待，直到条件成立为止\n- `Cond.Signal ()`: 只唤醒一个最先 Wait 的 goroutine，可以不用加锁\n- `Cond.Broadcast ()`: 唤醒所有 Wait 的 goroutine，可以不用加锁\n\n```\npackage main\n\nimport (\n    \"fmt\"\n    \"sync\"\n    \"sync/atomic\"\n    \"time\"\n)\n\nvar status int64\n\nfunc main() {\n    c := sync.NewCond(\u0026sync.Mutex{})\n    for i := 0; i \u003c 10; i++ {\n        go listen(c)\n    }\n    go broadcast(c)\n    time.Sleep(1 * time.Second)\n}\n\nfunc broadcast(c *sync.Cond) {\n    // 原子操作\n    atomic.StoreInt64(\u0026status, 1) \n    c.Broadcast()\n}\n\nfunc listen(c *sync.Cond) {\n    c.L.Lock()\n    for atomic.LoadInt64(\u0026status) != 1 {\n        c.Wait() \n        // Wait 内部会先调用 c.L.Unlock()，来先释放锁，如果调用方不先加锁的话，会报错\n    }\n    fmt.Println(\"listen\")\n    c.L.Unlock()\n}\n```\n\n# Go 有哪些方式安全读写共享变量？\n\n|方法|并发原语|备注|\n|---|---|---|\n|不要修改变量|sync. Once|不要去写变量，变量只初始化一次|\n|只允许一个 goroutine 访问变量|Channel|不要通过共享变量来通信，通过通信 (channel)来共享变量|\n|允许多个 goroutine 访问变量，但是同一时间只允许一个 goroutine 访问|sync. Mutex、sync. RWMutex、原子操作|实现锁机制，同时只有一个线程能拿到|\n\n#  Go 如何排查数据竞争问题？\n\n## 概念\n\n只要有两个以上的 goroutine 并发访问同一变量，且至少其中的一个是写操作的时候就会发生数据竞争；全是读的情况下是不存在数据竞争的。\n\n## 排查方式\n\n```\npackage main\n\nimport \"fmt\"\n\nfunc main() {\n    i := 0\n\n    go func() {\n        i++ // write i\n    }()\n\n    fmt.Println(i) // read i\n}\n```\n\n`go 命令行`有个参数`race`可以帮助检测代码中的数据竞争\n\n```\n$ go run -race main.go\n\nWARNING: DATA RACE\nWrite at 0x00c0000ba008 by goroutine 7:\nexit status 66\n```\n\n","lastmodified":"2024-02-25T17:02:23.022964011Z","tags":[]},"/GO/%E5%85%AB%E8%82%A1%E6%96%87/Channel":{"title":"Channel","content":"\n\n#  Channel 的大小是否对性能有影响\n\nChannel 的大小对性能会产生一定的影响。Channel 的大小是指 Channel 可以容纳的元素数量，可以通过在创建 Channel 时指定容量大小来控制。当 Channel 的容量较小时，可能会导致发送和接收操作的阻塞，从而影响程序的性能。而当 Channel 的容量较大时，可能会增加系统的内存开销，也可能会导致 Channel 中的元素被占用的时间较长，从而影响程序的响应性。\n\n# Channel 的内存模型是什么\n\n在 Go 语言中，Channel 的内存模型是基于通信顺序进程（Communicating Sequential Processes，CSP）模型的。CSP 模型是一种并发计算模型，它将并发程序看作是一组顺序进程，这些进程通过 Channel 进行通信和同步。\n\n在 CSP 模型中，每个进程都是独立的，它们之间通过 Channel 进行通信。Channel 是一个具有 FIFO 特性的数据结构，用于在多个进程之间传递数据。当一个进程向 Channel 发送数据时，它会阻塞等待，直到另一个进程从 Channel 中接收到数据。同样地，当一个进程从 Channel 中接收数据时，它也会阻塞等待，直到另一个进程向 Channel 发送数据。\n\n在 Go 语言中，Channel 的内存模型采用了 CSP 模型的概念，即每个 Channel 都是一个独立的顺序进程。当一个进程向 Channel 发送数据时，数据会被复制到 Channel 的缓冲区或者直接发送到接收方。当一个进程从 Channel 中接收数据时，数据会被从 Channel 的缓冲区中取出或者等待发送方发送数据。\n\n# Channel 的读写操作是否是原子性的，如何实现\n\nChannel 的读写操作是原子性的，并且是由 Go 语言内部的同步机制来保证的。\n\n当一个 goroutine 进行 Channel 的读写操作时，Go 语言内部会自动进行同步，保证该操作的原子性和顺序性。这种同步机制主要涉及到两个部分：\n\n1. 基于锁的同步：在 Channel 的底层实现中，使用了一种基于锁的同步机制，它可以保证每个读写操作都是原子性的，避免了多个 goroutine 同时读写导致的数据竞争问题。\n2. 基于等待的同步：当一个 goroutine 进行 Channel 的读写操作时，如果 Channel 当前为空或已满，它就会被添加到等待队列中，直到满足条件后才会被唤醒，这种等待的同步机制可以避免因 Channel 状态不满足条件而导致的死锁问题。\n\n通过这种基于锁和等待的同步机制，Go 语言保证了 Channel 的读写操作是原子性的，可以在多个 goroutine 之间安全地进行通信和同步。\n\n# 如何避免在 Channel 中出现死锁的情况\n\n1. 避免在单个 goroutine 中对 Channel 进行读写操作：如果一个 goroutine 同时进行 Channel 的读写操作，很容易出现死锁的情况，因为该 goroutine 无法切换到其他任务，导致无法释放 Channel 的读写锁。因此，在进行 Channel 的读写操作时，应该尽量将它们分配到不同的 goroutine 中，以便能够及时切换任务。\n2. 使用缓冲 Channel：缓冲 Channel 可以在一定程度上缓解读写操作的同步问题，避免因为 Channel 状态不满足条件而导致的死锁问题。如果 Channel 是非缓冲的，那么写操作必须等到读操作执行之后才能完成，反之亦然，这种同步会导致程序无法继续执行。而如果使用缓冲 Channel，就可以避免这种同步问题，即使读写操作之间存在时间差，也不会导致死锁。\n3. 使用 select 语句：select 语句可以在多个 Channel 之间进行选择操作，避免因为某个 Channel 状态不满足条件而导致的死锁问题。在使用 select 语句时，应该注意判断每个 Channel 的状态，避免出现同时等待多个 Channel 的情况，这可能导致死锁。\n4. 使用超时机制：在进行 Channel 的读写操作时，可以设置一个超时时间，避免因为 Channel 状态不满足条件而一直等待的情况。如果超过一定时间仍然无法读写 Channel，就可以选择放弃或者进行其他操作，以避免死锁。\n\n# Channel 在 go 中起什么作用\n\n在 Go 中，`channel` 是一种用于在 goroutine 之间传递数据的并发原语。`channel` 可以让 goroutine 在发送和接收操作之间同步，从而避免了竞态条件，从而更加安全地共享内存。\n\n`channel` 类似于一个队列，数据可以从一个 goroutine 中发送到 `channel`，然后从另一个 goroutine 中接收。`channel` 可以是有缓冲的，这意味着可以在 `channel` 中存储一定数量的值，而不仅仅是一个。如果 `channel` 是无缓冲的，则发送和接收操作将会同步阻塞，直到有 goroutine 准备好接收或发送数据。\n\n#  Channel 为什么需要两个队列实现\n\n一个 Channel 可以被看作是一个通信通道，用于在不同的进程之间传递数据。在具体的实现中，一个 Channel 通常需要使用两个队列来实现。这两个队列是发送队列和接收队列。\n\n发送队列是用来存储将要发送的数据的队列。当一个进程想要通过 Channel 发送数据时，它会将数据添加到发送队列中。发送队列中的数据会按照先进先出的顺序被逐个发送到接收进程。如果发送队列已经满了，那么发送进程就需要等待，直到有足够的空间可以存储数据。\n\n接收队列是用来存储接收进程已经准备好接收的数据的队列。当一个进程从 Channel 中接收数据时，它会从接收队列中取出数据。如果接收队列是空的，那么接收进程就需要等待，直到有新的数据可以接收。\n\n使用两个队列实现 Channel 的主要原因是为了实现异步通信。发送进程可以在发送数据之后立即继续执行其他任务，而不需要等待接收进程确认收到数据。同样，接收进程也可以在等待数据到达的同时执行其他任务。这种异步通信的实现方式可以提高系统的吞吐量和响应速度。\n\n# Go 为什么要开发 Channel，而别的语言为什么没有\n\n在 Go 语言中，Channel 是一种非常重要的并发原语。Go 语言将 Channel 作为语言内置的原语，可能是出于以下几个方面的考虑：\n\n1. 并发安全：在多线程并发环境下，使用 Channel 可以保证数据的安全性，避免多个线程同时访问共享数据导致的数据竞争和锁的开销。\n2. 简单易用：Go 语言中的 Channel 是一种高度抽象的概念，可以非常方便地实现不同线程之间的数据传输和同步。通过 Channel，程序员不需要手动地管理锁、条件变量等底层的同步原语，使得程序的编写更加简单和高效。\n3. 天然支持并发：Go 语言中的 Channel 与 goroutine 密切相关，这使得 Channel 天然地支持并发。程序员可以通过使用 Channel 和 goroutine 来实现非常高效的并发编程。\n\n虽然其他编程语言中没有像 Go 语言中的 Channel 这样的内置并发原语，但是许多编程语言提供了类似于 Channel 的实现，比如 Java 的 ConcurrentLinkedQueue、Python 的 Queue、C++的 std:: queue 等。这些实现虽然没有 Go 语言中的 Channel 那么简单易用和高效，但也能够满足多线程编程中的数据传输和同步需求。\n\n# Channel 底层是使用锁控制并发的，为什么不直接使用锁\n\n虽然在 Go 语言中，Channel 底层实现是使用锁控制并发的，但是 Channel 和锁的使用场景是不同的，具有不同的优势和适用性。\n\n首先，Channel 比锁更加高级和抽象。Channel 可以实现多个 goroutine 之间的同步和数据传递，不需要程序员显式地使用锁来进行线程间的协调。Channel 可以避免常见的同步问题，比如死锁、饥饿等问题。\n\n其次，Channel 在语言层面提供了一种更高效的并发模型。在使用锁进行并发控制时，需要程序员自己手动管理锁的获取和释放，这增加了代码复杂度和错误的风险。而使用 Channel 时，可以通过 goroutine 的调度和 Channel 的阻塞机制来实现更加高效和简单的并发控制。\n\n此外，Channel 还可以避免一些由锁导致的性能问题，如锁竞争、锁粒度过大或过小等问题。Channel 提供了一种更加精细的控制机制，能够更好地平衡不同 goroutine 之间的并发性能。\n\n总的来说，虽然 Channel 底层是使用锁控制并发的，但是 Channel 在语言层面提供了更加高级、抽象和高效的并发模型，可以使程序员更加方便和安全地进行并发编程。\n\n#  Channel 可以在多个 goroutine 之间传递什么类型的数据\n\n在 Go 语言中，Channel 可以在多个 goroutine 之间传递任何类型的数据，包括基本数据类型、复合数据类型、结构体、自定义类型等。这些数据类型在传递过程中都会被封装成对应的指针类型，并由 Channel 进行传递。\n\n# 如何在 Channel 中传递复杂的数据类型\n\n在 Go 语言中，Channel 可以传递任何类型的数据，包括复杂的数据类型。如果要在 Channel 中传递复杂的数据类型，可以将其定义为一个结构体，然后通过 Channel 进行传递。\n\n例如，假设我们有一个结构体类型 Person，它包含姓名和年龄两个字段：\n\n```\ntype Person struct {\n    Name string\n    Age  int\n}\n```\n\n我们可以定义一个 Channel，用于传递 Person 类型的数据：\n\n```\nch := make(chan Person)\n```\n\n现在我们可以在不同的 Goroutine 中向 Channel 发送和接收 Person 类型的数据：\n\n```\n// 发送Person类型数据到Channel\ngo func() {\n    p := Person{Name: \"Alice\", Age: 18}\n    ch \u003c- p\n}()\n\n// 从Channel接收Person类型数据\np := \u003c-ch\nfmt.Println(p.Name, p.Age)\n```\n\n注意，如果要在 Channel 中传递复杂的数据类型，需要确保该类型是可导出的。\n\n# 在 Go 语言中，Channel 和锁的使用场景有哪些区别\n\n在 Go 语言中，Channel 和锁（sync. Mutex 等）都可以用于并发编程中的同步和共享数据，但它们的使用场景有一些区别。\n\nChannel 通常用于 Goroutine 之间传递数据，并发的 Goroutine 之间可以通过 Channel 进行同步。使用 Channel 可以避免锁的问题，例如死锁、饥饿等问题。Channel 可以将数据在多个 Goroutine 之间进行传递和共享，而且在数据传递的过程中，不需要使用锁来保证数据的安全性，这也是 Channel 比锁更加安全和高效的原因之一。因此，当需要在不同的 Goroutine 之间传递数据时，使用 Channel 是比较合适的选择。\n\n锁通常用于对共享资源进行保护，防止多个 Goroutine 同时访问和修改同一个共享资源，从而导致数据的竞争和不一致。使用锁可以保证同一时刻只有一个 Goroutine 能够访问和修改共享资源，从而保证数据的安全性和一致性。当需要对共享资源进行保护时，使用锁是比较合适的选择。\n\nChannel 和锁都是 Go 语言中常用的并发编程工具，它们各自有不同的使用场景。在实际开发中，应根据具体的需求选择合适的并发编程工具来实现同步和共享数据。\n\n# 在使用 Channel 时，如何保证数据的同步性和一致性\n\n在使用 Channel 时，为了保证数据的同步性和一致性，可以采用以下几种方式：\n\n1. 合理设计 Channel 的容量：当 Channel 容量过小时，容易出现发送者和接收者之间的阻塞，而当容量过大时，可能会出现数据不一致的问题。因此，在设计 Channel 时，需要根据实际情况合理设定容量大小，以避免数据同步性和一致性的问题。\n2. 使用互斥锁保证数据访问的互斥性：如果多个 goroutine 同时对某个共享的数据进行访问，可能会导致数据不一致的问题。此时，可以使用互斥锁来保证数据访问的互斥性，以避免多个 goroutine 同时对同一份数据进行访问。\n3. 使用同步机制实现数据同步：在某些情况下，我们可能需要在多个 goroutine 之间进行数据同步，以确保数据的一致性。此时，可以使用一些同步机制，例如 WaitGroup、Barrier、Cond 等，来实现数据同步。\n\n# 如何保证 Channel 的安全性\n\n1. 确保 Channel 的正确使用：在使用 Channel 时，需要确保发送和接收操作的正确性。特别是在并发环境下，必须正确处理并发操作，避免出现竞争条件或死锁等问题。因此，在使用 Channel 时，需要根据实际情况选择合适的同步机制，例如互斥锁、条件变量、原子操作等，以确保 Channel 的正确使用。\n2. 避免 Channel 的泄漏：如果 Channel 没有被及时关闭，可能会导致资源泄漏和性能问题。因此，在使用 Channel 时，需要确保及时关闭 Channel，避免出现资源泄漏的情况。\n3. 避免 Channel 的阻塞：如果 Channel 的容量较小，可能会导致发送和接收操作的阻塞。此时，可以使用缓冲 Channel 或者带超时的发送和接收操作，避免 Channel 的阻塞。\n4. 避免 Channel 的死锁：如果多个 goroutine 之间出现死锁，可能会导致程序的停滞和性能问题。因此，在使用 Channel 时，需要避免死锁的情况，例如避免循环依赖、避免同时使用多个 Channel 等\n\n#  channel 的应用场景\n\nChannel 适用于数据在多个协程中流动的场景，有很多实际应用：\n\n1.  任务定时\n\n比如超时处理：\n\n```\nselect {\n    case \u003c-time.After(time.Second):\n```\n\n定时任务\n\n```\nselect {\n    case \u003c- time.Tick(time.Second)\n```\n\n\n2.  解耦生产者和消费者\n\n可以将生产者和消费者解耦出来，生产者只需要往 channel 发送数据，而消费者只管从 channel 中获取数据。\n\n3.  控制并发数\n\n以爬虫为例，比如需要爬取 1 w 条数据，需要并发爬取以提高效率，但并发量又不过过大，可以通过 channel 来控制并发规模，比如同时支持 5 个并发任务：ch := make (chan int, 5)\n\n```\nfor _, url := range urls {\ngo func() {\n\tch \u003c- 1\n\tworker(url)\n\t\u003c- ch\n\t}\n}\n```\n\n4. 协程间通信\n\n协程之间的通信. 通过 channel 传递数据, 实现通信\n\n# 给 channel 用空结构体的好处是什么?\n\n在 Go 语言中，使用空结构体作为通道（channel）元素的类型有一些优点和好处：\n\n1. **低内存开销**：空结构体不包含任何字段，因此它的内存占用非常小，通常为零字节。这意味着使用空结构体的通道在存储元素时几乎没有内存开销。这对于需要大量通信的高并发应用程序非常有用，因为它可以减少内存占用，提高性能。\n2. **高效的信号传递**：空结构体通道通常用于实现信号传递或同步操作，而不是传递实际的数据。由于空结构体的内存占用极小，它的传输速度非常快，适用于高频率的通信，如控制并发数量的信号量。\n3. **语义清晰**：使用空结构体作为通道元素的类型可以传达出一种清晰的语义，即通道的目的是进行信号传递或同步，而不是传输实际的数据。这可以使代码更容易理解和维护。\n4. **防止数据竞态**：当通道用于多个协程之间的同步时，使用空结构体可以帮助防止数据竞态。因为空结构体通常不存储实际的数据，所以不会发生多个协程同时访问或修改相同数据的情况。\n5. **编译时类型检查**：使用空结构体作为通道元素可以在编译时进行类型检查，确保只有空结构体可以被发送到和接收到该通道，从而减少了在运行时出现类型错误的可能性。\n\n总的来说，使用空结构体作为通道元素的类型是一种有效的方式来实现轻量级的信号传递和同步，同时保持低内存开销和高性能。这在 Go 中的并发编程中非常有用，特别是在需要进行大量协程间通信的情况下\n\n# 如何判断 channel 是否关闭?\n\n首先官方没有提供判断 channel 是否关闭的接口，也不需要去判断，因此在使用的时候，需要保证好时序，避免往已关闭的 channel 中写入数据引发 panic。  \n但是可以通过以下几个办法判断：\n\n1. 通过读来判断，s， ok := \u003c- c，如果 c 是个阻塞的，并且没有关闭的话，会阻塞在这，没办法正常调用。最好是结合 select 使用，而且要有 default 语句，不然又阻塞了！\n \n```\nfunc isChanClose(ch chan int) bool {\n \tselect {\n \t\tcase _, received := \u003c- ch:\n    \t\treturn !received\n \t\tdefault:\n \t\t}\n \treturn false\n}\n```\n\n2. 通过写来判断，立马 panic，可以捕捉一下进行判断，够野…\n    \n\n# 怎么理解“不要用共享内存来通信，而是用通信来共享内存”\n\n共享内存会涉及到多个线程同时访问修改数据的情况，为了保证数据的安全性，那就会加锁，加锁会让并行变为串行，cpu 此时也会忙于线程抢锁。另外使用过多的锁，容易使得程序的代码逻辑坚涩难懂，并且容易使程序死锁，死锁了以后排查问题相当困难，特别是很多锁同时存在的时候。\n\n在这种情况下，不如换一种方式，把数据复制一份，每个线程有自己的，只要一个线程干完一件事其他线程不用去抢锁了，这就是一种通信方式，把共享的以通知方式交给线程，实现并发。Go 语言的 channel 就保证同一个时间只有一个 goroutine 能够访问里面的数据，为开发者提供了一种优雅简单的工具，所以 go 原生的做法就是使用 channel 来通信，而不是使用共享内存来通信。\n\n# channel 和共享内存有什么优劣势?\n\n**“不要通过共享内存来通信，我们应该使用通信来共享内存”** 这句话想必大家已经非常熟悉了，在官方的博客，初学时的教程，甚至是在 Go 的源码中都能看到\n\n无论是通过共享内存来通信还是通过通信来共享内存，最终我们应用程序都是读取的内存当中的数据，只是前者是直接读取内存的数据，而后者是通过发送消息的方式来进行同步。而通过发送消息来同步的这种方式常见的就是 Go 采用的 CSP (Communication Sequential Process) 模型以及 Erlang 采用的 Actor 模型，这两种方式都是通过通信来共享内存。\n\n![02_Go进阶03_blog_channel.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic02_Go%E8%BF%9B%E9%98%B603_blog_channel.png)\n\n大部分的语言采用的都是第一种方式直接去操作内存，然后通过互斥锁，CAS 等操作来保证并发安全。Go 引入了 Channel 和 Goroutine 实现 CSP 模型将生产者和消费者进行了解耦，Channel 其实和消息队列很相似。而 Actor 模型和 CSP 模型都是通过发送消息来共享内存，但是它们之间最大的区别就是 Actor 模型当中并没有一个独立的 Channel 组件，而是 Actor 与 Actor 之间直接进行消息的发送与接收，每个 Actor 都有一个本地的“信箱”消息都会先发送到这个“信箱当中”。\n\n**优点**\n\n- 使用 channel 可以帮助我们解耦生产者和消费者，可以降低并发当中的耦合\n\n**缺点**\n\n- 容易出现死锁的情况\n\n# Go 里的 Mutex 和 channel 的性能有区别吗？\n\nChannel 的底层也是用了 syns. Mutex, 算是对锁的封装，性能应该是有损耗的，用测试的数据更有说服力\n\n\n```\npackage channel\n\nimport \"sync\"\nvar mutex = sync.Mutex{}\nvar ch = make(chan struct{}, 1)\nfunc UseMutex() {\n\tmutex.Lock()\n\tmutex.Unlock()\n}\nfunc UseChan() {\n\tch \u003c- struct{}{}\n\t\u003c-ch\n}\npackage channel\n\nimport \"testing\"\n\nfunc BenchmarkUseMutex(b *testing.B) {\n\tfor i := 0; i \u003c b.N; i++ {\n\t\tUseMutex()\n\t}\n}\n\nfunc BenchmarkUseChan(b *testing.B) {\n\tfor i := 0; i \u003c b.N; i++ {\n\t\tUseChan()\n\t}\n}\n```\n\n执行 bench 命令\n\n```\ngo test -bench=.\n```\n\n测试结果如下\n\n```\nBenchmarkUseMutex-8     87120927                13.61 ns/op\nBenchmarkUseChan-8      42295345                26.47 ns/op\nPASS\nok      mytest/channel  2.906s\n```\n\n**根据压测结果来说 Mutex 比 channel 的性能快了两倍左右**\n\n# Channel 的 ring buffer 实现\n\n![image-20230922140315653](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticimage-20230922140315653.png)\n\n# 用 Go 撸一个生产者消费型，用 channel 通信，怎么友好的关闭 chan？\n\n如何优雅的关闭 channel 记住两点\n\n1. 向一个已关闭的 channel 发送数据会 panic\n2. 关闭一个已经关闭的 channel 会 panic\n\n**针对单个生产者在发送侧关闭 channel 即可**\n\n单个生产者单个消费者模型\n\n```\nfunc main() {\n\tvar ch = make(chan int)\n\n\t// 单生产者\n\tgo func() {\n\t\tfor i := 1; i \u003c 100; i++ {\n\t\t\tch \u003c- i\n\t\t}\n\t\tclose(ch)\n\t}()\n\n\t// 消费者\n\tgo func() {\n\t\tfor elem := range ch {\n\t\t\tfmt.Println(elem)\n\t\t}\n\t}()\n\n\tselect {}\n}\n```\n\n单个生产者多个消费者模型\n\n```\nfunc main() {\n\tvar ch = make(chan int)\n\n\t// 单生产者\n\tgo func() {\n\t\tfor i := 1; i \u003c 100; i++ {\n\t\t\tch \u003c- i\n\t\t}\n\t\tclose(ch)\n\t}()\n\n\t// 多消费者\n\tfor i := 0; i \u003c 100; i++ {\n\t\tgo func() {\n\t\t\tfor elem := range ch {\n\t\t\t\tfmt.Println(elem)\n\t\t\t}\n\t\t}()\n\t}\n\n\tselect {}\n}\n```\n\n**针对多个生产者不应该关闭生产者，消费者通知生产者不发送数据即可**\n\n多生产者单消费者模型\n\n```\nfunc main() {\n\tvar ch = make(chan int)\n\tvar stopCh = make(chan struct{})\n\t// 多生产者\n\tfor i := 1; i \u003c= 100; i++ {\n\t\tgo func(n int) {\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase ch \u003c- n:\n\t\t\t\tcase \u003c-stopCh:\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t}\n\t\t}(i)\n\t}\n\n\t// 单消费者\n\tgo func() {\n\t\tfor elem := range ch {\n\t\t\tfmt.Println(elem)\n\t\t\tif elem == 100{\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t}()\n\n\tselect {}\n}\n```\n\n多生产者多消费者模型\n\n```\nfunc main() {\n\tvar ch = make(chan int)\n\t// 停止信号\n\tvar stopCh = make(chan struct{})\n\t// 协调者\n\tvar toStopCh = make(chan struct{}, 1)\n\t// 多生产者\n\tfor i := 1; i \u003c= 100; i++ {\n\t\tgo func(n int) {\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase ch \u003c- n:\n\t\t\t\tcase \u003c-stopCh:\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t}\n\t\t}(i)\n\t}\n\n\t// 接收通知给协调者\n\tgo func() {\n\t\t\u003c-toStopCh\n\t\tclose(stopCh)\n\t}()\n\n\t// 多消费者\n\tfor i := 0; i \u003c 100; i++ {\n\t\tgo func() {\n\t\t\tfor  {\n\t\t\t\tselect {\n\t\t\t\tcase elem := \u003c-ch:\n\t\t\t\t\tif elem == 100 {\n\t\t\t\t\t\ttoStopCh \u003c- struct{}{}\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tfmt.Println(elem)\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\t}\n\n\tselect {}\n}\n```\n\n\n\n\n\n\n# Go channel 的底层实现原理\n\n**概念：**\n\nGo 中的 channel 是一个队列，遵循先进先出的原则，负责协程之间的通信（Go 语言提倡不要通过共享内存来通信，而要通过通信来实现内存共享，CSP (Communicating Sequential Process)并发模型，就是通过 goroutine 和 channel 来实现的）\n\n**使用场景：**\n\n停止信号监听\n\n定时任务\n\n生产方和消费方解耦\n\n控制并发数\n\n**底层数据结构：**\n\n通过 var 声明或者 make 函数创建的 channel 变量是一个存储在函数栈帧上的指针，占用 8 个字节，指向堆上的 hchan 结构体\n\n源码包中 `src/runtime/chan.go` 定义了 hchan 的数据结构：\n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240225234031.png)\n\nHchan 结构体：\n\n```\ntype hchan struct {\n closed   uint32   // channel是否关闭的标志\n elemtype *_type   // channel中的元素类型\n \n // channel分为无缓冲和有缓冲两种。\n // 对于有缓冲的channel存储数据，使用了 ring buffer（环形缓冲区) 来缓存写入的数据，本质是循环数组\n // 为啥是循环数组？普通数组不行吗，普通数组容量固定更适合指定的空间，弹出元素时，普通数组需要全部都前移\n // 当下标超过数组容量后会回到第一个位置，所以需要有两个字段记录当前读和写的下标位置\n buf      unsafe.Pointer // 指向底层循环数组的指针（环形缓冲区）\n qcount   uint           // 循环数组中的元素数量\n dataqsiz uint           // 循环数组的长度\n elemsize uint16                 // 元素的大小\n sendx    uint           // 下一次写下标的位置\n recvx    uint           // 下一次读下标的位置\n  \n // 尝试读取channel或向channel写入数据而被阻塞的goroutine\n recvq    waitq  // 读等待队列\n sendq    waitq  // 写等待队列\n\n lock mutex //互斥锁，保证读写channel时不存在并发竞争问题\n}\n```\n\n\n\n等待队列：\n\n双向链表，包含一个头结点和一个尾结点\n\n每个节点是一个 sudog 结构体变量，记录哪个协程在等待，等待的是哪个 channel，等待发送/接收的数据在哪里\n\n\n```\ntype hchan struct {\n closed   uint32   // channel是否关闭的标志\n elemtype *_type   // channel中的元素类型\n \n // channel分为无缓冲和有缓冲两种。\n // 对于有缓冲的channel存储数据，使用了 ring buffer（环形缓冲区) 来缓存写入的数据，本质是循环数组\n // 为啥是循环数组？普通数组不行吗，普通数组容量固定更适合指定的空间，弹出元素时，普通数组需要全部都前移\n // 当下标超过数组容量后会回到第一个位置，所以需要有两个字段记录当前读和写的下标位置\n buf      unsafe.Pointer // 指向底层循环数组的指针（环形缓冲区）\n qcount   uint           // 循环数组中的元素数量\n dataqsiz uint           // 循环数组的长度\n elemsize uint16                 // 元素的大小\n sendx    uint           // 下一次写下标的位置\n recvx    uint           // 下一次读下标的位置\n  \n // 尝试读取channel或向channel写入数据而被阻塞的goroutine\n recvq    waitq  // 读等待队列\n sendq    waitq  // 写等待队列\n\n lock mutex //互斥锁，保证读写channel时不存在并发竞争问题\n}\n```\n\n\n**操作**：\n\n**创建**\n\n使用 `make(chan T, cap)` 来创建 channel，make 语法会在编译时，转换为 `makechan64` 和 `makechan`\n\n```\nfunc makechan64(t *chantype, size int64) *hchan {\n    if int64(int(size)) != size {\n        panic(plainError(\"makechan: size out of range\"))\n    }\n\n    return makechan(t, int(size))\n}\n```\n\n创建 channel 有两种，一种是带缓冲的 channel，一种是不带缓冲的 channel\n\n```\n// 带缓冲\nch := make(chan int, 3)\n// 不带缓冲\nch := make(chan int)\n```\n\n创建时会做一些检查:\n\n- 元素大小不能超过 64 K\n- 元素的对齐大小不能超过 maxAlign 也就是 8 字节\n- 计算出来的内存是否超过限制\n\n创建时的策略:\n\n- 如果是无缓冲的 channel，会直接给 hchan 分配内存\n- 如果是有缓冲的 channel，并且元素不包含指针，那么会为 hchan 和底层数组分配一段连续的地址\n- 如果是有缓冲的 channel，并且元素包含指针，那么会为 hchan 和底层数组分别分配地址\n\n**发送**\n\n发送操作，编译时转换为 `runtime.chansend` 函数\n\n```\nfunc chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool \n\n```\n\n阻塞式：\n\n调用 chansend 函数，并且 block=true\n\n```\nfunc chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool \n```\n\n非阻塞式：\n\n调用 chansend 函数，并且 block=false\n\n```\nselect {\n    case ch \u003c- 10:\n    ...\n\n  default\n}\n```\n\n向 channel 中发送数据时大概分为两大块：检查和数据发送，数据发送流程如下：\n\n- 如果 channel 的读等待队列存在接收者 goroutine\n    - 将数据**直接发送**给第一个等待的 goroutine， **唤醒接收的 goroutine**\n- 如果 channel 的读等待队列不存在接收者 goroutine\n    - 如果循环数组 buf 未满，那么将会把数据发送到循环数组 buf 的队尾\n    - 如果循环数组 buf 已满，这个时候就会走阻塞发送的流程，将当前 goroutine 加入写等待队列，并**挂起等待唤醒**\n\n**接收**\n\n发送操作，编译时转换为 `runtime.chanrecv` 函数\n\n```\nfunc chanrecv(c *hchan, ep unsafe.Pointer, block bool) (selected, received bool) \n```\n\n阻塞式：\n\n调用 chanrecv 函数，并且 block=true\n\n```\n\u003c-ch\n\nv := \u003c-ch\n\nv, ok := \u003c-ch\n\n// 当channel关闭时，for循环会自动退出，无需主动监测channel是否关闭，可以防止读取已经关闭的channel,造成读到数据为通道所存储的数据类型的零值\nfor i := range ch {\n    fmt.Println(i)\n}\n```\n\n非阻塞式：\n\n调用 chanrecv 函数，并且 block=false\n\n```\nselect {\n    case \u003c-ch:\n    ...\n\n  default\n}\n```\n\n向 channel 中接收数据时大概分为两大块，检查和数据发送，而数据接收流程如下：\n\n- 如果 channel 的写等待队列存在发送者 goroutine\n    - 如果是无缓冲 channel，**直接**从第一个发送者 goroutine 那里把数据拷贝给接收变量，**唤醒发送的 goroutine**\n    - 如果是有缓冲 channel（已满），将循环数组 buf 的队首元素拷贝给接收变量，将第一个发送者 goroutine 的数据拷贝到 buf 循环数组队尾，**唤醒发送的 goroutine**\n- 如果 channel 的写等待队列不存在发送者 goroutine\n    - 如果循环数组 buf 非空，将循环数组 buf 的队首元素拷贝给接收变量\n    - 如果循环数组 buf 为空，这个时候就会走阻塞接收的流程，将当前 goroutine 加入读等待队列，并**挂起等待唤醒**\n\n**关闭**\n\n关闭操作，调用 close 函数，编译时转换为 `runtime.closechan` 函数\n\n```\nclose(ch)\n```\n\n\n\n\n```\nfunc closechan(c *hchan) \n```\n\n\n**案例分析：**\n\n```\npackage main\n\nimport (\n    \"fmt\"\n    \"time\"\n    \"unsafe\"\n)\n\nfunc main() {\n  // ch是长度为4的带缓冲的channel\n  // 初始hchan结构体重的buf为空，sendx和recvx均为0\n    ch := make(chan string, 4)\n    fmt.Println(ch, unsafe.Sizeof(ch))\n    go sendTask(ch)\n    go receiveTask(ch)\n    time.Sleep(1 * time.Second)\n}\n\n// G1是发送者\n// 当G1向ch里发送数据时，首先会对buf加锁，然后将task存储的数据copy到buf中，然后sendx++，然后释放对buf的锁\nfunc sendTask(ch chan string) {\n    taskList := []string{\"this\", \"is\", \"a\", \"demo\"}\n    for _, task := range taskList {\n        ch \u003c- task //发送任务到channel\n    }\n}\n\n// G2是接收者\n// 当G2消费ch的时候，会首先对buf加锁，然后将buf中的数据copy到task变量对应的内存里，然后recvx++,并释放锁\nfunc receiveTask(ch chan string) {\n    for {\n        task := \u003c-ch                  //接收任务\n        fmt.Println(\"received\", task) //处理任务\n    }\n}\n```\n\n总结 hchan 结构体的主要组成部分有四个：\n\n- 用来保存 goroutine 之间传递数据的循环数组：buf\n- 用来记录此循环数组当前发送或接收数据的下标值：sendx 和 recvx\n- 用于保存向该 chan 发送和从该 chan 接收数据被阻塞的 goroutine 队列： sendq 和 recvq\n- 保证 channel 写入和读取数据时线程安全的锁：lock\n\n# Go channel 有什么特点？\n\nChannel 有 2 种类型：无缓冲、有缓冲\n\nChannel 有 3 种模式：写操作模式（单向通道）、读操作模式（单向通道）、读写操作模式（双向通道）\n\n| 写操作模式 | 读操作模式 | 读写操作模式 |  |\n| ---- | ---- | ---- | ---- |\n| 创建 | make (chan\u003c- int) | make (\u003c-chan int) | make (chan int) |\n\nChannel 有 3 种状态：未初始化、正常、关闭\n\n| 未初始化 | 关闭 | 正常 |  |\n| ---- | ---- | ---- | ---- |\n| 关闭 | panic | panic | 正常关闭 |\n| 发送 | 永远阻塞导致死锁 | panic | 阻塞或者成功发送 |\n| 接收 | 永远阻塞导致死锁 | 缓冲区为空则为零值, 否则可以继续读 | 阻塞或者成功接收 |\n\n**注意点**：\n\n1. 一个 channel 不能多次关闭，会导致 painc\n2. 如果多个 goroutine 都监听同一个 channel，那么 channel 上的数据都**可能随机被某一个 goroutine 取走进行消费**\n3. 如果多个 goroutine 监听同一个 channel，如果这个 channel 被关闭，则所有 goroutine **都能收到退出信号**\n\n# Go channel 有无缓冲的区别？\n\n无缓冲：一个送信人去你家送信，你不在家他不走，你一定要接下信，他才会走。\n\n有缓冲：一个送信人去你家送信，扔到你家的信箱转身就走，除非你的信箱满了，他必须等信箱有多余空间才会走。\n\n| 无缓冲 | 有缓冲 |  |\n| ---- | ---- | ---- |\n| 创建方式 | make (chan TYPE) | make (chan TYPE, SIZE) |\n| 发送阻塞 | 数据接收前发送阻塞 | 缓冲满时发送阻塞 |\n| 接收阻塞 | 数据发送前接收阻塞 | 缓冲空时接收阻塞 |\n\n**非缓冲** `channel`\n\n\n```\npackage main\n\nimport (\n    \"fmt\"\n    \"time\"\n)\n\nfunc loop(ch chan int) {\n    for {\n        select {\n        case i := \u003c-ch:\n            fmt.Println(\"this  value of unbuffer channel\", i)\n        }\n    }\n}\n\nfunc main() {\n    ch := make(chan int)\n    ch \u003c- 1\n    go loop(ch)\n    time.Sleep(1 * time.Millisecond)\n}\n```\n\n\n这里会报错 `fatal error: all goroutines are asleep - deadlock!` 就是因为 `ch\u003c-1` 发送了，但是同时没有接收者，所以就发生了阻塞\n\n但如果我们把 `ch \u003c- 1` 放到 `go loop(ch)` 下面，程序就会正常运行\n\n**缓冲** `channel`\n\n```\npackage main\n\nimport (\n    \"fmt\"\n    \"time\"\n)\n\nfunc loop(ch chan int) {\n    for {\n        select {\n        case i := \u003c-ch:\n            fmt.Println(\"this  value of unbuffer channel\", i)\n        }\n    }\n}\n\nfunc main() {\n    ch := make(chan int,3)\n    ch \u003c- 1\n    ch \u003c- 2\n    ch \u003c- 3\n    ch \u003c- 4\n    go loop(ch)\n    time.Sleep(1 * time.Millisecond)\n}\n```\n\n这里也会报 fatal error: all goroutines are asleep - deadlock! ，这是因为 channel 的大小为 3 ，而我们要往里面塞 4 个数据，所以就会阻塞住，解决的办法有两个:\n\n1. 把 channel 长度调大一点\n2. 把 channel 的信息发送者 ch \u003c- 1 这些代码移动到 go loop (ch) 下面，让 channel 实时消费就不会导致阻塞了\n\n# Go channel 为什么是线程安全的？\n\n**为什么设计成线程安全？**\n\n不同协程通过 channel 进行通信，本身的使用场景就是多线程，为了保证数据的一致性，必须实现线程安全\n\n**如何实现线程安全的？**\n\nChannel 的底层实现中，hchan 结构体中采用 Mutex 锁来保证数据读写安全。在对循环数组 buf 中的数据进行入队和出队操作时，必须先获取互斥锁，才能操作 channel 数据\n\n# Go channel 如何控制 goroutine 并发执行顺序？\n\n**多个 goroutine 并发执行时，每一个 goroutine 抢到处理器的时间点不一致，gorouine 的执行本身不能保证顺序**。即代码中先写的 gorouine 并不能保证先执行\n\n思路：使用 channel 进行通信通知，用 channel 去传递信息，从而控制并发执行顺序\n\n```\npackage main\n\nimport (\n    \"fmt\"\n    \"sync\"\n    \"time\"\n)\n\nvar wg sync.WaitGroup\n\nfunc main() {\n    ch1 := make(chan struct{}, 1)\n    ch2 := make(chan struct{}, 1)\n    ch3 := make(chan struct{}, 1)\n    ch1 \u003c- struct{}{}\n    wg.Add(3)\n    start := time.Now().Unix()\n    go print(\"gorouine1\", ch1, ch2)\n    go print(\"gorouine2\", ch2, ch3)\n    go print(\"gorouine3\", ch3, ch1)\n    wg.Wait()\n    end := time.Now().Unix()\n    fmt.Printf(\"duration:%d\\n\", end-start)\n}\n\nfunc print(gorouine string, inputchan chan struct{}, outchan chan struct{}) {\n    // 模拟内部操作耗时\n    time.Sleep(1 * time.Second)\n    select {\n    case \u003c-inputchan:\n        fmt.Printf(\"%s\\n\", gorouine)\n        outchan \u003c- struct{}{}\n    }\n    wg.Done()\n}\n/*\ngorouine1\ngorouine2\ngorouine3\nduration:1\n*/\n```\n\n# Go channel 共享内存有什么优劣势？\n\n**“不要通过共享内存来通信，我们应该使用通信来共享内存”** 这句话想必大家已经非常熟悉了，在官方的博客，初学时的教程，甚至是在 Go 的源码中都能看到\n\n无论是通过共享内存来通信还是通过通信来共享内存，最终我们应用程序都是读取的内存当中的数据，只是前者是直接读取内存的数据，而后者是通过发送消息的方式来进行同步。而通过发送消息来同步的这种方式常见的就是 Go 采用的 CSP (Communication Sequential Process) 模型以及 Erlang 采用的 Actor 模型，这两种方式都是通过通信来共享内存。\n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240225234650.png)\n\n大部分的语言采用的都是第一种方式直接去操作内存，然后通过互斥锁，CAS 等操作来保证并发安全。Go 引入了 Channel 和 Goroutine 实现 CSP 模型将生产者和消费者进行了解耦，Channel 其实和消息队列很相似。而 Actor 模型和 CSP 模型都是通过发送消息来共享内存，但是它们之间最大的区别就是 Actor 模型当中并没有一个独立的 Channel 组件，而是 Actor 与 Actor 之间直接进行消息的发送与接收，每个 Actor 都有一个本地的“信箱”消息都会先发送到这个“信箱当中”。\n\n**优点**\n\n- 使用 channel 可以帮助我们解耦生产者和消费者，可以降低并发当中的耦合\n\n**缺点**\n\n- 容易出现死锁的情况\n\n# Go channel 发送和接收什么情况下会死锁？\n\n**死锁：**\n\n- 单个协程永久阻塞\n- 两个或两个以上的协程的执行过程中，由于竞争资源或由于彼此通信而造成的一种阻塞的现象。\n\n**channel 死锁场景：**\n\n- 非缓存 channel 只写不读\n- 非缓存 channel 读在写后面\n- 缓存 channel 写入超过缓冲区数量\n- 空读\n- 多个协程互相等待\n\n**1、非缓存 channel 只写不读**\n\n```\nfunc deadlock1() {\n    ch := make(chan int) \n    ch \u003c- 3 //  这里会发生一直阻塞的情况，执行不到下面一句\n}\n```\n\n**2、非缓存 channel 读在写后面**\n\n```\nfunc deadlock2() {\n    ch := make(chan int)\n    ch \u003c- 3  //  这里会发生一直阻塞的情况，执行不到下面一句\n    num := \u003c-ch\n    fmt.Println(\"num=\", num)\n}\n\nfunc deadlock2() {\n    ch := make(chan int)\n    ch \u003c- 100 //  这里会发生一直阻塞的情况，执行不到下面一句\n    go func() {\n        num := \u003c-ch\n        fmt.Println(\"num=\", num)\n    }()\n    time.Sleep(time.Second)\n}\n```\n\n**3、缓存 channel 写入超过缓冲区数量**\n\n```\nfunc deadlock3() {\n    ch := make(chan int, 3)\n    ch \u003c- 3\n    ch \u003c- 4\n    ch \u003c- 5\n    ch \u003c- 6  //  这里会发生一直阻塞的情况\n}\n```\n\n**4、空读**\n\n```\nfunc deadlock4() {\n    ch := make(chan int)\n    // ch := make(chan int, 1)\n    fmt.Println(\u003c-ch)  //  这里会发生一直阻塞的情况\n}\n```\n\n**5、多个协程互相等待**\n\n```\nfunc deadlock5() {\n    ch1 := make(chan int)\n    ch2 := make(chan int)\n    // 互相等对方造成死锁\n    go func() {\n        for {\n            select {\n            case num := \u003c-ch1:\n                fmt.Println(\"num=\", num)\n                ch2 \u003c- 100\n            }\n        }\n    }()\n\n    for {\n        select {\n        case num := \u003c-ch2:\n            fmt.Println(\"num=\", num)\n            ch1 \u003c- 300\n        }\n    }\n}\n```\n","lastmodified":"2024-02-25T17:02:23.022964011Z","tags":[]},"/GO/%E5%85%AB%E8%82%A1%E6%96%87/GMP":{"title":"GMP","content":"\n# P 和 M 的数量一定是 1：1 吗？如果一个 G 阻塞了会怎么样？\n\n不一定，M 必须持有 P 才可以执行代码，跟系统中的其他线程一样，M 也会被系统调用阻塞。P 的个数在启动程序时决定，默认情况下等于 CPU 的核数，可以使用环境变量 GOMAXPROCS 或在程序中使用 runtime.GOMAXPROCS ()方法指定 P 的个数。  \nM 的个数通常稍大于 P 的个数，因为除了运行 Go 代码，runtime 包还有其他内置任务需要处理。\n\n# Golang GMP 模型，全局队列中的 G 会不会饥饿, 为什么？P 的数量是多少？能修改吗？M 的数量是多少？\n\n1. 全局队列中的 G 不会饥饿。因为线程想运行任务就得获取 P，从 P 的本地队列获取 G，P 队列为空时，M 也会尝试从全局队列拿一批 G 放到 P 的本地队列，或从其他 P 的本地队列偷一半放到自己 P 的本地队列。  \n    M 运行 G，G 执行之后，M 会从 P 获取下一个 G，不断重复下去。所以全局队列中的 G 总是能被消费掉.\n2. P 的数量可以理解为最大为本机可执行的 cpu 的最大数量。  \n    通过 runtime.GOMAXPROCS (runtime.NumCPU ())设置。  \n    Runtime.NumCPU ()方法返回当前进程可用的逻辑 cpu 数量。\n\n# 服务器能开多少个 P 由什么决定\n\n- P 的个数在程序启动时决定，默认情况下等同于 CPU 的核数\n- 程序中可以使用 runtime.GOMAXPROCS () 设置 P 的个数，在某些 IO 密集型的场景下可以在一定程度上提高性能。\n- 一般来讲，程序运行时就将 GOMAXPROCS 大小设置为 CPU 核数，可让 Go 程序充分利用 CPU。在某些 IO 密集型的应用里，这个值可能并不意味着性能最好。理论上当某个 Goroutine 进入系统调用时，会有一个新的 M 被启用或创建，继续占满 CPU。但由于 Go 调度器检测到 M 被阻塞是有一定延迟的，也即旧的 M 被阻塞和新的 M 得到运行之间是有一定间隔的，所以在 IO 密集型应用中不妨把 GOMAXPROCS 设置的大一些，或许会有好的效果。\n\n# 服务器能开多少个 M 由什么决定\n\n- 由于 M 必须持有一个 P 才可以运行 Go 代码，所以同时运行的 M 个数，也即线程数一般等同于 CPU 的个数，以达到尽可能的使用 CPU 而又不至于产生过多的线程切换开销。\n- P 的个数默认等于 CPU 核数，每个 M 必须持有一个 P 才可以执行 G，一般情况下 M 的个数会略大于 P 的个数，这多出来的 M 将会在 G 产生系统调用时发挥作用。\n- Go 语⾔本身是限定 M 的最⼤量是 10000，可以在 runtime/debug 包中的 SetMaxThreads 函数来修改设置\n\n#  M 和 P 是怎么样的关系\n\n- M 必须拥有 P 才可以执行 G 中的代码，理想情况下一个 M 对应一个 P，P 含有包含多个 G 的队列，P 会周期性地将 G 调度到 M 种执行。\n\n# GMP 调度过程中存在哪些阻塞\n\n- I/O，select\n- Block on syscall\n- Channel\n- 等待锁\n- Runtime.Gosched ()\n\n#  GMP 当一个 G 堵塞时，G、M、P 会发生什么\n\n当 g 阻塞时，p 会和 m 解绑，去寻找下一个可用的 m。  \nG\u0026m 在阻塞结束之后会优先寻找之前的 p，如果此时 p 已绑定其他 m，当前 m 会进入休眠，g 以可运行的状态进入全局队列\n\n# **sysmon** **有什么作用**\n\nSysmon 也叫监控线程，变动的周期性检查，好处\n\n- 释放闲置超过 5 分钟的 span 物理内存；\n- 如果超过 2 分钟没有垃圾回收，强制执行；\n- 将长时间未处理的 netpoll 添加到全局队列；\n- 向长时间运行的 G 任务发出抢占调度 (超过 10 ms 的 g，会进行 retake)；\n- 收回因 syscall 长时间阻塞的 P；\n\n# GMP 模型里为什么要有 P？\n\n[https://mp.weixin.qq.com/s/SEE2TUeZQZ7W1BKkmnelAA](https://mp.weixin.qq.com/s/SEE2TUeZQZ7W1BKkmnelAA) \n\n# 为什么 GMP 模型会更快\n\n谈到 Go 语言调度器，绕不开操作系统，进程与线程这些概念。线程是操作系统调度的最小单元，而 Linux 调度器并不区分进程和线程的调度，它们在不同操作系统上的实现也不同，但是在大多数实现中线程属于进程。多个线程可以属于同一个进程并共享内存空间。因为多线程不需要创建新的虚拟内存空间，所以它们也不需要内存管理单元处理上下文的切换，线程之间的通信也正是基于共享内存进行的，与重量级进程相比，线程显得比较轻量。虽然线程比较轻量，但是在调度时也有比较大的额外开销。每个线程会都占用 1 MB 以上的内存空间，在切换线程时不止会消耗较多内存，恢复寄存器中的内存还需要向操作系统申请或者销毁资源。每一个线程上下文的切换都需要消耗 1 us 的时间，而 Go 调度器对 Goroutine 的上下文切换越为 0.2 us，减少了 80% 的额外开销。Go 语言的调度器使用与 CPU 数量相等的线程来减少线程频繁切换带来的内存开销，同时在每一个线程上执行额外开销更低的 Goroutine 来降低操作系统和硬件的负载。\n\n# 同时启动了一万个 G，如何调度？\n\n首先一万个 G 会按照 P 的设定个数，尽量平均地分配到每个 P 的本地队列中。如果所有本地队列都满了，那么剩余的 G 则会分配到 GMP 的全局队列上。接下来便开始执行 GMP 模型的调度策略：\n\n- **本地队列轮转**：每个 P 维护着一个包含 G 的队列，不考虑 G 进入系统调用或 IO 操作的情况下，P 周期性的将 G 调度到 M 中执行，执行一小段时间，将上下文保存下来，然后将 G 放到队列尾部，然后从队首中重新取出一个 G 进行调度。\n- **系统调用**：上面说到 P 的个数默认等于 CPU 核数，每个 M 必须持有一个 P 才可以执行 G，一般情况下 M 的个数会略大于 P 的个数，这多出来的 M 将会在 G 产生系统调用时发挥作用。当该 G 即将进入系统调用时，对应的 M 由于陷入系统调用而进被阻塞，将释放 P，进而某个空闲的 M1获取 P，继续执行 P 队列中剩下的 G。\n- **工作量窃取**：多个 P 中维护的 G 队列有可能是不均衡的，当某个 P 已经将 G 全部执行完，然后去查询全局队列，全局队列中也没有新的 G，而另一个 M 中队列中还有 3 很多 G 待运行。此时，空闲的 P 会将其他 P 中的 G 偷取一部分过来，一般每次偷取一半。\n\n#  Go 如何调度，假设 4 核的 cpu 应该有几个 M，那能有几个 groutinue，groutinue 数量的上限是多少？\n\n协程的数量, 理论上没有上限  \nM 的最大数量一万  \n4 核的 cpu 默认最大并发的 M=4\n\n# GMP 并发模型，Goroutine 切换的时候上下文环境放在哪里\n\n协程切换时候的上下文存储在处理器中\n\n#  Golang 调度能不能不要 p\n\n**1. 介绍 golang 调度器中 P 是什么？**\n\nProcessor 的简称，处理器，上下文。\n\n**2. 简述 p 的功能与为什么必须要 P**\n\n它的主要用途就是用来执行 goroutine 的，它维护了一个 goroutine 队列，即 runqueue。Processor 是让咱们从 N: 1 调度到 M: N 调度的重要部分。\n\n# Goroutine 的调度是出现在什么情况下，调度时做了什么\n\nGo 调度器会在以下三种情况对 goroutine 进行调度：\n\n1. Goroutine 执行某个操作因条件不满足需要等待而发生的调度。\n2. Goroutine 主动调用 Gosched ()让出 CPU 而发生的调度。\n3. Goroutine 运行时间太长或长时间处于系统调用中，被调度器剥夺运行权而发生的调度。\n\n调度器一般做以下事：\n\n- 协程调度。因为系统内核不能再决定协程的切换，那么协程的切换时间点则是由程序内部的调度器决定的。\n- 垃圾回收。垃圾回收的必要条件是内存位于一致状态，这就需要暂停所有的线程，如果交给系统去做，那么会暂停所有的线程使其一致。程序自身的调度器知道什么时候内存位于一致状态，那么就没有必要暂停所有运行的协程。\n\n# 为什么 P 的 local queue 可无锁访问，任务窃取的时候要加锁吗?\n\n绑定在 P 上的 local queue 是顺序执行的，不存在执行状态的 G 协程抢占，所以可以无锁访问。\n\n任务窃取也是窃取其他 P 上等待状态的 G 协程，所以也可以不用加锁。\n\n# 一个 goroutine sleep 了，操作系统是怎么唤醒的\n\n1. **goroutine 唤醒**  \n    Goroutine 的唤醒涉及到一个很重要的函数 (goready), 它的作用就是唤醒 waiting 状态的 goroutine.  \n    通过 systemstack 切到 g 0 栈，在 g 0 栈上发起调度.  \n    获取 goroutine 的状态.  \n    将 waiting 状态的 goroutine 切换到 runable 状态  \n    尝试唤起一个 p 来执行当前 goroutine\n2. 注释: go 程序中，每个 M 都会绑定一个叫 g 0 的初代 goroutine，它在 M 的创建的时候创建，g 0 的主要工作就是 goroutine 的调度、垃圾回收等.\n\n# Go 的协程可以只挂在一个线程上面吗\n\n不能。可以保证一个 P，用 runtime.GOMAXPROCS (1)设置处理器 P 只启动一个，但程序初始化的线程 M 一般不会只有一个。\n\n\n\n\n\n\n# Go 线程实现模型？\n\nGo 实现的是两级线程模型（M：N)，准确的说是 GMP 模型，是对两级线程模型的改进实现，使它能够更加灵活地进行线程之间的调度。\n\n## 背景\n\n| 含义 | 缺点 |  |\n| ---- | ---- | ---- |\n| 单进程时代 | 每个程序就是一个进程，直到一个程序运行完，才能进行下一个进程 | 1. 无法并发，只能串行 2. 进程阻塞所带来的 CPU 时间浪费 |\n| 多进程/线程时代 | 一个线程阻塞， cpu 可以立刻切换到其他线程中去执行 | 1. 进程/线程占用内存高 2. 进程/线程上下文切换成本高 |\n| 协程时代 | 协程（用户态线程）绑定线程（内核态线程），cpu 调度线程执行 | 1. 实现起来较复杂，协程和线程的绑定依赖调度器算法 |\n\n线程 -\u003e CPU 由操作系统调度，协程 -\u003e 线程由 Go 调度器来调度，协程与线程的映射关系有三种线程模型\n\n## 三种线程模型\n\n线程实现模型主要分为：`内核级线程模型`、`用户级线程模型`、`两级线程模型`，他们的区别在于用户线程与内核线程之间的对应关系。\n\n### **内核级线程模型（1：1）**\n\n1 个用户线程对应 1 个内核线程，这种最容易实现，协程的调度都由 CPU 完成了\n\n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226001710.png)\n\n\n\n优点：\n\n- 实现起来最简单\n- 能够利用多核\n- 如果进程中的一个线程被阻塞，不会阻塞其他线程，是能够切换同一进程内的其他线程继续执行\n\n缺点：\n\n- 上下文切换成本高，创建、删除和切换都由 CPU 完成\n\n### **用户级线程模型（N：1）**\n\n1 个进程中的所有线程对应 1 个内核线程\n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226001725.png)\n\n优点：\n\n- 上下文切换成本低，在用户态即可完成协程切换\n\n缺点：\n\n- 无法利用多核\n- 一旦协程阻塞，造成线程阻塞，本线程的其它协程无法执行\n\n### **两级线程模型（M：N)**\n\nM 个线程对应 N 个内核线程\n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226001737.png)\n\n优点：\n\n- 能够利用多核\n- 上下文切换成本低\n- 如果进程中的一个线程被阻塞，不会阻塞其他线程，是能够切换同一进程内的其他线程继续执行\n\n缺点：\n\n- 实现起来最复杂\n\n# Go GMP 和 GM 模型？\n\n什么才是一个好的调度器？\n\n能在适当的时机将合适的协程分配到合适的位置，保证公平和效率。\n\nGo 采用了 GMP 模型（对两级线程模型的改进实现），使它能够更加灵活地进行线程之间的调度。\n\n## GMP 模型\n\nGMP 是 Go 运行时调度层面的实现，包含 4 个重要结构，分别是 G、M、P、Sched\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226001847.png)\n\n- **G（Goroutine）**：代表 Go 协程 Goroutine，存储了 Goroutine 的执行栈信息、Goroutine 状态以及 Goroutine 的任务函数等。**G 的数量无限制，理论上只受内存的影响**，创建一个 G 的初始栈大小为 2-4 K，配置一般的机器也能简简单单开启数十万个 Goroutine ，而且 Go 语言在 G 退出的时候还会把 G 清理之后放到 P 本地或者全局的闲置列表 gFree 中以便复用。\n\n- **M（Machine）**： Go 对操作系统线程（OS thread）的封装，可以看作操作系统内核线程，想要在 CPU 上执行代码必须有线程，通过系统调用 clone 创建。M 在绑定有效的 P 后，进入一个调度循环，而调度循环的机制大致是从 P 的本地运行队列以及全局队列中获取 G，切换到 G 的执行栈上并执行 G 的函数，调用 goexit 做清理工作并回到 M，如此反复。M 并不保留 G 状态，这是 G 可以跨 M 调度的基础。**M 的数量有限制，默认数量限制是 10000**，可以通过 debug.SetMaxThreads () 方法进行设置，如果有 M 空闲，那么就会回收或者睡眠。\n\n- **P（Processor）：虚拟处理器，M 执行 G 所需要的资源和上下文，只有将 P 和 M 绑定，才能让 P 的 runq 中的 G 真正运行起来。P 的数量决定了系统内最大可并行的 G 的数量，**P 的数量受本机的 CPU 核数影响，可通过环境变量$GOMAXPROCS 或在 runtime.GOMAXPROCS ()来设置，默认为 CPU 核心数。\n\n- **Sched：调度器结构**，它维护有存储 M 和 G 的全局队列，以及调度器的一些状态信息\n\n|  | G | M | P |\n| ---- | ---- | ---- | ---- |\n| 数量限制 | 无限制，受机器内存影响 | 有限制，默认最多 10000 | 有限制，最多 GOMAXPROCS 个 |\n| 创建时机 | go func | 当没有足够的 M 来关联 P 并运行其中的可运行的 G 时会请求创建新的 M | 在确定了 P 的最大数量 n 后，运行时系统会根据这个数量创建个 P |\n\n**核心数据结构:**\n\n\n\n```\n//src/runtime/runtime2.go\ntype g struct {\n    goid    int64 // 唯一的goroutine的ID\n    sched gobuf // goroutine切换时，用于保存g的上下文\n    stack stack // 栈\n  gopc        // pc of go statement that created this goroutine\n    startpc    uintptr // pc of goroutine function\n    ...\n}\n\ntype p struct {\n    lock mutex\n    id          int32\n    status      uint32 // one of pidle/prunning/...\n\n    // Queue of runnable goroutines. Accessed without lock.\n    runqhead uint32 // 本地队列队头\n    runqtail uint32 // 本地队列队尾\n    runq     [256]guintptr // 本地队列，大小256的数组，数组往往会被都读入到缓存中，对缓存友好，效率较高\n    runnext guintptr // 下一个优先执行的goroutine（一定是最后生产出来的)，为了实现局部性原理，runnext中的G永远会被最先调度执行\n    ... \n}\n\ntype m struct {\n    g0            *g     \n    // 每个M都有一个自己的G0，不指向任何可执行的函数，在调度或系统调用时，M会切换到G0，使用G0的栈空间来调度\n    curg          *g    \n    // 当前正在执行的G\n    ... \n}\n\ntype schedt struct {\n    ...\n    runq     gQueue // 全局队列，链表（长度无限制）\n    runqsize int32  // 全局队列长度\n    ...\n}\n```\n\nGMP 模型的实现算是 Go 调度器的一大进步，但调度器仍然有一个令人头疼的问题，那就是不支持抢占式调度，这导致一旦某个 G 中出现死循环的代码逻辑，那么 G 将永久占用分配给它的 P 和 M，而位于同一个 P 中的其他 G 将得不到调度，出现“饿死”的情况。\n\n当只有一个 P（GOMAXPROCS=1）时，整个 Go 程序中的其他 G 都将“饿死”。于是在 Go 1.2 版本中实现了基于协作的“抢占式”调度，在 Go 1.14 版本中实现了基于信号的“抢占式”调度。\n\n## GM 模型\n\nGo 早期是 GM 模型，没有 P 组件\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226002031.png)\n\n\n**GM 调度存在的问题： **\n\n1. **全局队列的锁竞争**，当 M 从全局队列中添加或者获取 G 的时候，都需要获取队列锁，导致激烈的锁竞争\n2. **M 转移 G 增加额外开销**，当 M 1 在执行 G 1 的时候， M 1 创建了 G 2，为了继续执行 G 1，需要把 G 2 保存到全局队列中，无法保证 G 2 是被 M 1 处理。因为 M 1 原本就保存了 G 2 的信息，所以 G 2 最好是在 M 1 上执行，这样的话也不需要转移 G 到全局队列和线程上下文切换\n3. **线程使用效率不能最大化**，没有**work-stealing** 和**hand-off** 机制\n\n计算机科学领域的任何问题都可以通过增加一个间接的中间层来解决，为了解决这一的问题 go 从 1.1 版本引入 P，在运行时系统的时候加入 P 对象，让 P 去管理这个 G 对象，M 想要运行 G，必须绑定 P，才能运行 P 所管理的 G\n\n# Go 调度原理？\n\nGoroutine 调度的本质就是将 **Goroutine (G）**按照一定算法放到 CPU 上去执行。\n\nCPU 感知不到 Goroutine，只知道内核线程，所以需要**Go 调度器**将协程调度到内核线程上面去，然后**操作系统调度器**将内核线程放到 CPU 上去执行\n\nM 是对内核级线程的封装，**所以 Go 调度器的工作就是将 G 分配到 M**\n\nGo 调度器的实现不是一蹴而就的，它的调度模型与算法也是几经演化，从最初的 GM 模型、到 GMP 模型，从**不支持抢占**，到**支持协作式抢占**，再到**支持基于信号的异步抢占**，经历了不断地优化与打磨。\n\n## 设计思想\n\n- 线程复用（**work stealing 机制**和**hand off 机制**）\n- 利用并行（利用多核 CPU）\n- 抢占调度（解决公平性问题）\n\n## 调度对象\n\nGo 调度器\n\n\u003e Go 调度器是属于 Go runtime 中的一部分，Go runtime 负责实现 Go 的**并发调度**、**垃圾回收**、**内存堆栈管理**等关键功能\n\n##  被调度对象\n\nG 的来源\n\n- P 的 runnext（只有 1 个 G，局部性原理，永远会被最先调度执行）\n- P 的本地队列（数组，最多 256 个 G）\n- 全局 G 队列（链表，无限制）\n- 网络轮询器_network poller_（存放网络调用被阻塞的 G）\n\nP 的来源\n\n- 全局 P 队列（数组，GOMAXPROCS 个 P）\n\nM 的来源\n\n- 休眠线程队列（未绑定 P，长时间休眠会等待 GC 回收销毁）\n- 运行线程（绑定 P，指向 P 中的 G）\n- 自旋线程（绑定 P，指向 M 的 G0）\n\n其中运行线程数 + 自旋线程数 \u003c= P的数量（GOMAXPROCS），M个数 \u003e= P 个数\n\n## 调度流程\n\n协程的调度采用了生产者-消费者模型，实现了用户任务与调度器的解耦\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226002132.png)\n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226002138.png)\n\n\n生产端我们开启的每个协程都是一个计算任务，这些任务会被提交给 go 的 runtime。如果计算任务非常多，有成千上万个，那么这些任务是不可能同时被立刻执行的，所以这个计算任务一定会被先暂存起来，一般的做法是放到内存的队列中等待被执行。\n\nG 的生命周期：G 从创建、保存、被获取、调度和执行、阻塞、销毁，步骤如下：\n\n- **步骤 1：创建 G**，关键字 `go func()` 创建 G **步骤 2：保存 G**，创建的 G 优先保存到本地队列 P，如果 P 满了，则会平衡部分 P 到全局队列中\n\n- **步骤 3**：**唤醒或者新建 M**执行任务，进入调度循环（步骤 4,5,6)\n\n- **步骤 4：M 获取 G**，M 首先从 P 的本地队列获取 G，如果 P 为空，则从全局队列获取 G，如果全局队列也为空，则从另一个本地队列偷取一半数量的 G（负载均衡），这种从其它 P 偷的方式称之为 work stealing\n\n- **步骤 5：M 调度和执行 G**，M 调用 `G.func()` 函数执行 G\n\n\t- 如果 M 在执行 G 的过程发生**系统调用阻塞**（同步），会阻塞 G 和 M（操作系统限制），此时 P 会和当前 M 解绑，并寻找新的 M，如果没有空闲的 M 就会新建一个 M ，接管正在阻塞 G 所属的 P，接着继续执行 P 中其余的 G，这种阻塞后释放 P 的方式称之为 hand off。当**系统调用结束**后，这个 G 会尝试获取一个空闲的 P 执行，优先获取之前绑定的 P，并放入到这个 P 的本地队列，如果获取不到 P，那么这个线程 M 变成休眠状态，加入到空闲线程中，然后这个 G 会被放入到全局队列中。\n\t- 如果 M 在执行 G 的过程发生网络 IO 等操作阻塞时（异步），阻塞 G，**不会阻塞 M**。M 会寻找 P 中其它可执行的 G 继续执行，G 会被网络轮询器 network poller 接手，当阻塞的 G 恢复后，G 1 从 network poller 被移回到 P 的 LRQ 中，重新进入可执行状态。异步情况下，通过调度，Go scheduler 成功地将 I/O 的任务转变成了 CPU 任务，或者说将内核级别的线程切换转变成了用户级别的 goroutine 切换，大大提高了效率。\n\n- **步骤 6：M 执行完 G 后清理现场**，重新进入调度循环（将 M 上运⾏的 goroutine 切换为 G 0，G 0 负责调度时协程的切换）。其中步骤 2 中保存 G 的详细流程如下：\n\n\t- 执行 go func 的时候，主线程 M 0 会调用 newproc ()生成一个 G 结构体，这里会先选定当前 M 0 上的 P 结构\n\t- 每个协程 G 都会被尝试先放到 P 中的 runnext，若 runnext 为空则放到 runnext 中，生产结束\n\t- 若 runnext 满，则将原来 runnext 中的 G 踢到本地队列中，将当前 G 放到 runnext 中，生产结束\n\t- 若本地队列也满了，则将本地队列中的 G 拿出一半，放到全局队列中，生产结束。\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226002235.png)\n\n## 调度时机\n\n**什么时候进行调度（执行/切换）？**\n\n在以下情形下，会切换正在执行的 goroutine\n\n- 抢占式调度\n    - Sysmon 检测到协程运行过久（比如 sleep，死循环）\n        - 切换到 g 0，进入调度循环\n- 主动调度\n    - 新起一个协程和协程执行完毕\n        - 触发调度循环\n    - 主动调用 runtime.Gosched ()\n        - 切换到 g 0，进入调度循环\n    - 垃圾回收之后\n        - Stw 之后，会重新选择 g 开始执行\n- 被动调度\n    - 系统调用（比如文件 IO）阻塞（同步）\n        - 阻塞 G 和 M，P 与 M 分离，将 P 交给其它 M 绑定，其它 M 执行 P 的剩余 G\n    - 网络 IO 调用阻塞（异步）\n        - 阻塞 G，G 移动到 NetPoller，M 执行 P 的剩余 G\n    - Atomic/mutex/channel 等阻塞（异步）\n        - 阻塞 G，G 移动到 channel 的等待队列中，M 执行 P 的剩余 G\n\n## 调度策略\n\n**使用什么策略来挑选下一个 goroutine 执行？**\n\n由于 P 中的 G 分布在 runnext、本地队列、全局队列、网络轮询器中，则需要挨个判断是否有可执行的 G，大体逻辑如下：\n\n- 每执行 61 次调度循环，从全局队列获取 G，若有则直接返回\n- 从 P 上的 runnext 看一下是否有 G，若有则直接返回\n- 从 P 上的本地队列看一下是否有 G，若有则直接返回\n- 上面都没查找到时，则去全局队列、网络轮询器查找或者从其他 P 中窃取，**一直阻塞**直到获取到一个可用的 G 为止\n\n源码实现如下：\n\n```\nfunc schedule() {\n    _g_ := getg()\n    var gp *g\n    var inheritTime bool\n    ...\n    if gp == nil {\n        // 每执行61次调度循环会看一下全局队列。为了保证公平，避免全局队列一直无法得到执行的情况，当全局运行队列中有待执行的G时，通过schedtick保证有一定几率会从全局的运行队列中查找对应的Goroutine；\n        if _g_.m.p.ptr().schedtick%61 == 0 \u0026\u0026 sched.runqsize \u003e 0 {\n            lock(\u0026sched.lock)\n            gp = globrunqget(_g_.m.p.ptr(), 1)\n            unlock(\u0026sched.lock)\n        }\n    }\n    if gp == nil {\n        // 先尝试从P的runnext和本地队列查找G\n        gp, inheritTime = runqget(_g_.m.p.ptr())\n    }\n    if gp == nil {\n        // 仍找不到，去全局队列中查找。还找不到，要去网络轮询器中查找是否有G等待运行；仍找不到，则尝试从其他P中窃取G来执行。\n        gp, inheritTime = findrunnable() // blocks until work is available\n        // 这个函数是阻塞的，执行到这里一定会获取到一个可执行的G\n    }\n    ...\n    // 调用execute，继续调度循环\n    execute(gp, inheritTime)\n}\n```\n\n从全局队列查找时，如果要所有 P 平分全局队列中的 G，每个 P 要分得多少个，这里假设会分得 n 个。然后把这 n 个 G，转移到当前 G 所在 P 的本地队列中去。但是最多不能超过 P 本地队列长度的一半（即 128）。这样做的目的是，如果下次调度循环到来的时候，就不必去加锁到全局队列中在获取一次 G 了，性能得到了很好的保障。\n\n```\nfunc globrunqget(_p_ *p, max int32) *g {\n   ...\n   // gomaxprocs = p的数量\n   // sched.runqsize是全局队列长度\n   // 这里n = 全局队列的G平分到每个P本地队列上的数量 + 1\n   n := sched.runqsize/gomaxprocs + 1\n   if n \u003e sched.runqsize {\n      n = sched.runqsize\n   }\n   if max \u003e 0 \u0026\u0026 n \u003e max {\n      n = max\n   }\n   // 平分后的数量n不能超过本地队列长度的一半，也就是128\n   if n \u003e int32(len(_p_.runq))/2 {\n      n = int32(len(_p_.runq)) / 2\n   }\n\n   // 执行将G从全局队列中取n个分到当前P本地队列的操作\n   sched.runqsize -= n\n\n   gp := sched.runq.pop()\n   n--\n   for ; n \u003e 0; n-- {\n      gp1 := sched.runq.pop()\n      runqput(_p_, gp1, false)\n   }\n   return gp\n}\n```\n\n从其它 P 查找时，会偷一半的 G 过来放到当前 P 的本地队列\n\n# Go work stealing 机制？\n\n## 概念\n\n当线程 M⽆可运⾏的 G 时，尝试从其他 M 绑定的 P 偷取 G，减少空转，提高了线程利用率（避免闲着不干活）。\n\n当从本线程绑定 P 本地队列、全局 G 队列、netpoller 都找不到可执行的 g，会从别的 P 里窃取 G 并放到当前 P 上面。\n\n从_netpoller_ 中拿到的 G 是_Gwaiting 状态（ 存放的是因为网络 IO 被阻塞的 G），从其它地方拿到的 G 是_Grunnable 状态\n\n从全局队列取的 G 数量：N = min (len (GRQ)/GOMAXPROCS + 1, len (GRQ/2)) （根据 GOMAXPROCS 负载均衡）\n\n从其它 P 本地队列**窃取**的 G 数量：N = len (LRQ)/2（平分）\n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226002437.png)\n## 窃取流程\n\n源码见 runtime/proc. Go stealWork 函数，窃取流程如下，如果经过多次努力一直找不到需要运行的 goroutine 则调用 stopm 进入睡眠状态，等待被其它工作线程唤醒。\n\n1. 选择要窃取的 P\n2. 从 P 中偷走一半 G\n\n### **选择要窃取的 P**\n\n窃取的实质就是遍历 allp 中的所有 p，查看其运行队列是否有 goroutine，如果有，则取其一半到当前工作线程的运行队列\n\n为了保证公平性，遍历 allp 时并不是固定的从 allp[0]即第一个 p 开始，而是从随机位置上的 p 开始，而且遍历的顺序也随机化了，并不是现在访问了第 i 个 p 下一次就访问第 i+1 个 p，而是使用了一种伪随机的方式遍历 allp 中的每个 p，防止每次遍历时使用同样的顺序访问 allp 中的元素\n\n```\noffset := uint32(random()) % nprocs\ncoprime := 随机选取一个小于nprocs且与nprocs互质的数\nconst stealTries = 4 // 最多重试4次\nfor i := 0; i \u003c stealTries; i++ {\n    for i := 0; i \u003c nprocs; i++ {\n      p := allp[offset]\n        从p的运行队列偷取goroutine\n        if 偷取成功 {\n        break\n     }\n        offset += coprime\n        offset = offset % nprocs\n     }\n}\n```\n\n可以看到只要随机数不一样，偷取 p 的顺序也不一样，但可以保证经过 nprocs 次循环，每个 p 都会被访问到。\n\n### **从 P 中偷走一半 G**\n\n源码见 runtime/proc. Go runqsteal 函数：\n\n挑选出盗取的对象 p 之后，则调用 runqsteal 盗取 p 的运行队列中的 goroutine，runqsteal 函数再调用 runqgrap 从 p 的本地队列尾部批量偷走一半的 g\n\n为啥是偷一半的 g，可以理解为负载均衡\n\n```\nfunc runqgrab(_p_ *p, batch *[256]guintptr, batchHead uint32, stealRunNextG bool) uint32 {\n    for {\n        h := atomic.LoadAcq(\u0026_p_.runqhead) // load-acquire, synchronize with other consumers\n        t := atomic.LoadAcq(\u0026_p_.runqtail) // load-acquire, synchronize with the producer\n        n := t - h        //计算队列中有多少个goroutine\n        n = n - n/2     //取队列中goroutine个数的一半\n        if n == 0 {\n            ......\n            return ......\n        }\n        return n\n    }\n}\n```\n\n# Go hand off 机制？\n\n##  概念\n\n也称为 P 分离机制，当本线程 M 因为 G 进行的系统调用阻塞时，线程释放绑定的 P，把 P 转移给其他空闲的 M 执行，也提高了线程利用率（避免站着茅坑不拉 shi）。\n\n## 分离流程\n\n当前线程 M 阻塞时，释放 P，给其它空闲的 M 处理\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226002549.png)\n\n# Go 抢占式调度？\n\n在 1.2 版本之前，Go 的调度器仍然不支持抢占式调度，程序只能依靠 Goroutine 主动让出 CPU 资源才能触发调度，这会引发一些问题，比如：\n\n- 某些 Goroutine 可以长时间占用线程，造成其它 Goroutine 的饥饿\n- 垃圾回收器是需要 stop the world 的，如果垃圾回收器想要运行了，那么它必须先通知其它的 goroutine 停下来，这会造成较长时间的等待时间\n\n为解决这个问题：\n\n- Go 1.2 中实现了基于协作的“抢占式”调度\n- Go 1.14 中实现了基于信号的“抢占式”调度\n\n## 基于协作的抢占式调度\n\n协作式：大家都按事先定义好的规则来，比如：一个 goroutine 执行完后，退出，让出 p，然后下一个 goroutine 被调度到 p 上运行。这样做的缺点就在于是否让出 p 的决定权在 groutine 自身。一旦某个 g 不主动让出 p 或执行时间较长，那么后面的 goroutine 只能等着，没有方法让前者让出 p，导致延迟甚至饿死。\n\n非协作式: 就是由 runtime 来决定一个 goroutine 运行多长时间，如果你不主动让出，对不起，我有手段可以抢占你，把你踢出去，让后面的 goroutine 进来运行。\n\n基于协作的抢占式调度流程：\n\n- 编译器会在调用函数前插入 runtime. Morestack，让运行时有机会在这段代码中检查是否需要执行抢占调度\n- Go 语言运行时会在垃圾回收暂停程序、系统监控发现 Goroutine 运行超过 10 ms，那么会在这个协程设置一个抢占标记\n- 当发生函数调用时，可能会执行编译器插入的 runtime. Morestack，它调用的 runtime. Newstack 会检查抢占标记，如果有抢占标记就会触发抢占让出 cpu，切到调度主协程里\n\n这种解决方案只能说局部解决了“饿死”问题，只在有函数调用的地方才能插入“抢占”代码（埋点），对于没有函数调用而是纯算法循环计算的 G，Go 调度器依然无法抢占。\n\n比如，死循环等并没有给编译器插入抢占代码的机会，以下程序在 go 1.14 之前的 go 版本中，运行后会一直卡住，而不会打印 `I got scheduled!`\n\n```\npackage main\n\nimport (\n    \"fmt\"\n    \"runtime\"\n    \"time\"\n)\n\nfunc main() {\n    runtime.GOMAXPROCS(1)\n    go func() {\n        for {\n        }\n    }()\n\n    time.Sleep(time.Second)\n    fmt.Println(\"I got scheduled!\")\n}\n```\n\n为了解决这些问题，**Go 在 1.14 版本中增加了对非协作的抢占式调度的支持**，这种**抢占式调度是基于系统信号的，也就是通过向线程发送信号的方式来抢占正在运行的 Goroutine**\n\n## 基于信号的抢占式调度\n\n真正的抢占式调度是基于信号完成的，所以也称为“异步抢占”。不管协程有没有意愿主动让出 cpu 运行权，只要某个协程执行时间过长，就会发送信号强行夺取 cpu 运行权。\n\n- M 注册一个 SIGURG 信号的处理函数：sighandler\n- Sysmon 启动后会间隔性的进行监控，最长间隔 10 ms，最短间隔 20 us。如果发现某协程独占 P 超过 10 ms，会给 M 发送抢占信号\n- M 收到信号后，内核执行 sighandler 函数把当前协程的状态从_Grunning 正在执行改成 _Grunnable 可执行，把抢占的协程放到全局队列里，M 继续寻找其他 goroutine 来运行\n- 被抢占的 G 再次调度过来执行时，会继续原来的执行流\n\n抢占分为 `_Prunning` 和 `_Psyscall`，`_Psyscall` 抢占通常是由于阻塞性系统调用引起的，比如磁盘 io、cgo。`_Prunning` 抢占通常是由于一些类似死循环的计算逻辑引起的。\n\n#  Go 如何查看运行时调度信息？\n\n有 2 种方式可以查看一个程序的调度 GMP 信息，分别是 go tool trace 和 GODEBUG\n\nTrace. Go\n\n```\npackage main\n\nimport (\n    \"fmt\"\n    \"os\"\n    \"runtime/trace\"\n    \"time\"\n)\n\nfunc main() {\n\n    //创建trace文件\n    f, err := os.Create(\"trace.out\")\n    if err != nil {\n        panic(err)\n    }\n\n    defer f.Close()\n\n    //启动trace goroutine\n    err = trace.Start(f)\n    if err != nil {\n        panic(err)\n    }\n    defer trace.Stop()\n\n    //main\n    for i := 0; i \u003c 5; i++ {\n        time.Sleep(time.Second)\n        fmt.Println(\"Hello World\")\n    }\n}\n```\n\n#### []( https://youandgentleness.cn/2023/08/28/Go%E8%AF%AD%E8%A8%80%E9%9D%A2%E8%AF%95%E9%A2%98%E7%B2%BE%E8%AE%B2/#go-tool-trace \"go tool trace\") go tool trace\n\n启动可视化界面\n\n\n```\ngo run trace.go\ngo tool trace trace.out\n2022/04/22 10:44:11 Parsing trace...\n2022/04/22 10:44:11 Splitting trace...\n2022/04/22 10:44:11 Opening browser. Trace viewer is listening on http://127.0.0.1:35488\n```\n\n\n**1. 打开 ` http://127.0.0.1:35488` 查看可视化界面：**\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226002735.png)\n\n点击 `view trace` 能够看见可视化的调度流程：\n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226002746.png)\n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226002842.png)\n\n\n一共有 2 个 G 在程序中，一个是特殊的 G 0，是每个 M 必须有的一个初始化的 G，另外一个是 G 1 main goroutine (执行 main 函数的协程)，在一段时间内处于可运行和运行的状态。\n\n**2. 点击 Threads 那一行可视化的数据条，我们会看到 M 详细的信息**\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226002855.png)\n\n一共有 2 个 M 在程序中，一个是特殊的 M 0，用于初始化使用，另外一个是用于执行 G 1 的 M1\n\n**3. 点击 Proc 那一行可视化的数据条，我们会看到 P 上正在运行 goroutine 详细的信息**\n\n一共有 3 个 P 在程序中，分别是 P 0、P 1、P2\n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226002905.png)\n\n点击具体的 Goroutine 行为后可以看到其相关联的详细信息:\n\n```\nStart：开始时间\nWall Duration：持续时间\nSelf Time：执行时间\nStart Stack Trace：开始时的堆栈信息\nEnd Stack Trace：结束时的堆栈信息\nIncoming flow：输入流\nOutgoing flow：输出流\nPreceding events：之前的事件\nFollowing events：之后的事件\nAll connected：所有连接的事件\n```\n\n## GODEBUG\n\nGODEBUG 变量可以控制运行时内的调试变量。查看调度器信息，将会使用如下两个参数：\n\n- Schedtrace：设置 `schedtrace=X` 参数可以使运行时在每 X 毫秒发出一行调度器的摘要信息到标准 err 输出中。\n- Scheddetail：设置 `schedtrace=X` 和 `scheddetail=1` 可以使运行时在每 X 毫秒发出一次详细的多行信息，信息内容主要包括调度程序、处理器、OS 线程和 Goroutine 的状态。\n\n**查看基本信息**\n\n```\ngo build trace.go\nGODEBUG=schedtrace=1000 ./trace\n```\n\n```\nSCHED 0ms: gomaxprocs=8 idleprocs=6 threads=4 spinningthreads=1 idlethreads=0 runqueue=0 [1 0 0 0 0 0 0 0]\nHello World\nSCHED 1010ms: gomaxprocs=8 idleprocs=8 threads=4 spinningthreads=0 idlethreads=2 runqueue=0 [0 0 0 0 0 0 0 0]\nHello World\nSCHED 2014ms: gomaxprocs=8 idleprocs=8 threads=4 spinningthreads=0 idlethreads=2 runqueue=0 [0 0 0 0 0 0 0 0]\nHello World\nSCHED 3024ms: gomaxprocs=8 idleprocs=8 threads=4 spinningthreads=0 idlethreads=2 runqueue=0 [0 0 0 0 0 0 0 0]\nHello World\nSCHED 4027ms: gomaxprocs=8 idleprocs=8 threads=4 spinningthreads=0 idlethreads=2 runqueue=0 [0 0 0 0 0 0 0 0]\nHello World\nSCHED 5029ms: gomaxprocs=8 idleprocs=7 threads=4 spinningthreads=0 idlethreads=2 runqueue=0 [0 0 0 0 0 0 0 0]\n```\n\n\nSched：每一行都代表调度器的调试信息，后面提示的毫秒数表示启动到现在的运行时间，输出的时间间隔受 `schedtrace` 的值影响。\n\nGomaxprocs：当前的 CPU 核心数（GOMAXPROCS 的当前值）。\n\nIdleprocs：空闲的处理器数量，后面的数字表示当前的空闲数量。\n\nThreads：OS 线程数量，后面的数字表示当前正在运行的线程数量。\n\nSpinningthreads：自旋状态的 OS 线程数量。\n\nIdlethreads：空闲的线程数量。\n\nRunqueue：全局队列中中的 Goroutine 数量，而后面的[0 0 0 0 0 0 0 0] 则分别代表这 8 个 P 的本地队列正在运行的 Goroutine 数量。\n\n**查看详细信息**\n\n```\ngo build trace.go\nGODEBUG=scheddetail=1,schedtrace=1000 ./trace\n```\n\n```\nSCHED 0ms: gomaxprocs=8 idleprocs=6 threads=4 spinningthreads=1 idlethreads=0 runqueue=0 gcwaiting=0 nmidlelocked=0 stopwait=0 sysmonwait=0\n  P0: status=0 schedtick=0 syscalltick=0 m=-1 runqsize=1 gfreecnt=0 timerslen=0\n  P1: status=1 schedtick=0 syscalltick=0 m=2 runqsize=0 gfreecnt=0 timerslen=0\n  P2: status=0 schedtick=0 syscalltick=0 m=-1 runqsize=0 gfreecnt=0 timerslen=0\n  P3: status=0 schedtick=0 syscalltick=0 m=-1 runqsize=0 gfreecnt=0 timerslen=0\n  P4: status=0 schedtick=0 syscalltick=0 m=-1 runqsize=0 gfreecnt=0 timerslen=0\n  P5: status=0 schedtick=0 syscalltick=0 m=-1 runqsize=0 gfreecnt=0 timerslen=0\n  P6: status=0 schedtick=0 syscalltick=0 m=-1 runqsize=0 gfreecnt=0 timerslen=0\n  P7: status=0 schedtick=0 syscalltick=0 m=-1 runqsize=0 gfreecnt=0 timerslen=0\n  M3: p=0 curg=-1 mallocing=0 throwing=0 preemptoff= locks=1 dying=0 spinning=false blocked=false lockedg=-1\n  M2: p=1 curg=-1 mallocing=0 throwing=0 preemptoff= locks=2 dying=0 spinning=false blocked=false lockedg=-1\n  M1: p=-1 curg=-1 mallocing=0 throwing=0 preemptoff= locks=2 dying=0 spinning=false blocked=false lockedg=-1\n  M0: p=-1 curg=-1 mallocing=0 throwing=0 preemptoff= locks=1 dying=0 spinning=false blocked=false lockedg=1\n  G1: status=1(chan receive) m=-1 lockedm=0\n  G2: status=1() m=-1 lockedm=-1\n  G3: status=1() m=-1 lockedm=-1\n  G4: status=4(GC scavenge wait) m=-1 lockedm=-1\n```\n\nG\n\n```\nstatus：G 的运行状态。\nm：隶属哪一个 M。\nlockedm：是否有锁定 M。\n```\n\nG 的运行状态共涉及如下 9 种状态：\n\n|状态|值|含义|\n|---|---|---|\n|_Gidle|0|刚刚被分配，还没有进行初始化。|\n|_Grunnable|1|已经在运行队列中，还没有执行用户代码。|\n|_Grunning|2|不在运行队列里中，已经可以执行用户代码，此时已经分配了 M 和 P。|\n|_Gsyscall|3|正在执行系统调用，此时分配了 M。|\n|_Gwaiting|4|在运行时被阻止，没有执行用户代码，也不在运行队列中，此时它正在某处阻塞等待中。|\n|_Gmoribund_unused|5|尚未使用，但是在 gdb 中进行了硬编码。|\n|_Gdead|6|尚未使用，这个状态可能是刚退出或是刚被初始化，此时它并没有执行用户代码，有可能有也有可能没有分配堆栈。|\n|_Genqueue_unused|7|尚未使用。|\n|_Gcopystack|8|正在复制堆栈，并没有执行用户代码，也不在运行队列中。|\n\nM\n\n```\np：隶属哪一个 P。\ncurg：当前正在使用哪个 G。\nrunqsize：运行队列中的 G 数量。\ngfreecnt：可用的G（状态为 Gdead）。\nmallocing：是否正在分配内存。\nthrowing：是否抛出异常。\npreemptoff：不等于空字符串的话，保持 curg 在这个 m 上运行。\n```\n\nP\n\n```\nstatus：P 的运行状态。\nschedtick：P 的调度次数。\nsyscalltick：P 的系统调用次数。\nm：隶属哪一个 M。\nrunqsize：运行队列中的 G 数量。\ngfreecnt：可用的G（状态为 Gdead）\n```\n\n|状态|值|含义|\n|---|---|---|\n|_Pidle|0|刚刚被分配，还没有进行进行初始化。|\n|_Prunning|1|当 M 与 P 绑定调用 acquirep 时，P 的状态会改变为 _Prunning。|\n|_Psyscall|2|正在执行系统调用。|\n|_Pgcstop|3|暂停运行，此时系统正在进行 GC，直至 GC 结束后才会转变到下一个状态阶段。|\n|_Pdead|4|废弃，不再使用。|\n","lastmodified":"2024-02-25T17:02:23.022964011Z","tags":[]},"/GO/%E5%85%AB%E8%82%A1%E6%96%87/Map":{"title":"Map","content":"# Go Map 的查询复杂度\n\n**空间复杂度**:\n先我们不考虑因删除大量元素导致的空间浪费情况（这种情况现在 go 是留给程序员自己解决），只考虑一个持续增长状态的 map 的一个空间使用率：\n\n由于溢出桶数量超过 hash 桶数量时会触发缩容，所以最坏的情况是数据被集中在一条链上，hash 表基本是空的，这时空间浪费 O (n)。  \n最好的情况下，数据均匀散列在 hash 表上，没有元素溢出，这时最好的空间复杂度就是扩散因子决定了，当前 go 的扩散因子由全局变量决定，即 loadFactorNum/loadFactorDen = 6.5。即平均每个 hash 桶被分配到 6.5 个元素以上时，开始扩容。所以最小的空间浪费是 (8-6.5)/8 = 0.1875，即 O (0.1875n)\n\n结论：go map 的空间复杂度（指除去正常存储元素所需空间之外的空间浪费）是 O (0.1875 n) ~ O (n)之间。  \n​ 具体细节：[https://blog.csdn.net/dongjijiaoxiangqu/article/details/109643025](https://blog.csdn.net/dongjijiaoxiangqu/article/details/109643025) \n\n**时间复杂度**：\n\nGo 采用的 hash 算法应是很成熟的算法，极端情况暂不考虑。所以综合情况下 go map 的时间复杂度应为 O(1)\n\n# Map 的 key 可以是哪些类型？可以嵌套 map 吗？\n\nMap key 必须是可比较的类型，语言规范中定义了可比较的类型：boolean, numeric, string, pointer, channel, interface, 以及仅包含这些类型的 struct 和 array 。**不能作为 map key 的类型有：slice，map, function。**可以嵌套 map。\n\n# Map 怎么知道自己处于竞争状态？是 Go 编码实现的还是底层硬件实现的？\n\n代码实现的，在查找、赋值、遍历、删除的过程中都会检测写标志 flags，一旦发现写标志置位 (等于 1)，则直接 panic。赋值和删除函数载检测完标志是复位状态 (等于 0)之后，先将写标志位置位，才会进行之后的操作。\n\n# Map 的 panic 能被 recover 掉吗？了解 panic 和 recover 的机制？\n\n```\nfunc main() {\n    defer errorHandler()\n    m := map[string]int{}\n\n    go func() {\n        for {\n            m[\"x\"] = 1\n        }\n    }()\n    for {\n        _ = m[\"x\"]\n    }\n}\n\nfunc errorHandler() {\n    if r := recover(); r != nil {\n        fmt.Println(r)\n    }\n}//不能\n```\n\nMap 由于不是线程安全的，所以在遇到并发读写的时候会抛出 concurrent map read and map write 异常，从而使程序直接退出。\n\n```\nfunc mapaccess1_faststr(t *maptype, h *hmap, ky string) unsafe.Pointer {\n    ...\n    if h.flags\u0026hashWriting != 0 {\n        throw(\"concurrent map read and map write\")\n    }\n    ...\n｝\n```\n\n这里的 throw 和上面一样，最终会调用到 exit 执行退出。\n\n# Go 中两个 map 对象如何比较\n\n使用 reflect. DeepEqual 这个函数进行比较。使用 reflect. DeepEqual 有一点注意：由于使用了反射，所以有性能的损失。如果你多做一些测试，那么你会发现 reflect. DeepEqual 会比 == 慢 100 倍以上。\n\n# Map 的优缺点以及改进?\n\n**优点**：\n\n1. Map 类似其他语言中的哈希表或字典，以 key-value 形式存储数据\n\n2. Key 必须是支持==或!=比较运算的类型，不可以是函数、map 或 slice\n\n3. Map 通过 key 查找 value 比线性搜索快很多。\n\n4. Map 使用 make ()创建，支持:=这种简写方式\n\n5. 超出容量时会自动扩容，\n\n6. 当键值对不存在时自动添加，使用 delete ()删除某键值对\n\n**缺点：**\n\n并发中的 map 不是安全的\n\n# Sync. Map 怎么使用\n\n```\npackage main\n\nimport (\n    \"fmt\"\n    \"sync\"\n)\n\nfunc main() {\n    var scene sync.Map\n    // 将键值对保存到sync.Map\n    scene.Store(\"1\", 1)\n    scene.Store(\"2\", 2)\n    scene.Store(\"3\", 3)\n    // 从sync.Map中根据键取值\n    fmt.Println(scene.Load(\"1\"))\n    // 根据键删除对应的键值对\n    scene.Delete(\"1\")\n    // 遍历所有sync.Map中的键值对\n    scene.Range(func(k, v interface{}) bool {\n        fmt.Println(\"iterate:\", k, v)\n        return true\n    })\n}\n```\n\n# 如果一个 map 没申请空间，去向里面取值，会发生什么情况\n\n在 map 查询操作中，最多可以给两个变量赋值，第一个为值，第二个为 bool 类型的变量，用于指示是否存在指定的键，如果键不存在，那么第一个值为相应类型的零值。如果只指定一个变量，那么该变量仅表示改键对应的值，如果键不存在，那么该值同样为相应类型的零值\n\n```\npackage main\n\nimport \"fmt\"\n\nfunc main() {\n    var myMap map[string]int // 未初始化的 map\n    value := myMap[\"some_key\"] // 尝试获取一个键的值\n\n    fmt.Println(value)\n}\n//panic: assignment to entry in nil map\n```\n\n# Sync. Map 底层数据结构\n\n![image-20230922140118984](https://blog-1314857283.cos.ap-shanghai.myqcloud.com/images/202309221401184.png)\n\n![image-20230922140130100](https://blog-1314857283.cos.ap-shanghai.myqcloud.com/images/202309221401220.png)\n\n![image-20230922140139039](https://blog-1314857283.cos.ap-shanghai.myqcloud.com/images/202309221401144.png)\n\n![image-20230922140145882](https://blog-1314857283.cos.ap-shanghai.myqcloud.com/images/202309221401990.png)\n\n![image-20230922140150436](https://blog-1314857283.cos.ap-shanghai.myqcloud.com/images/202309221401528.png)\n\n![image-20230922140201135](https://blog-1314857283.cos.ap-shanghai.myqcloud.com/images/202309221402243.png)\n\n\n\n\n\n\n# Go map 的底层实现原理？\n\nGo 中的 map 是一个指针，占用 8 个字节，指向 hmap 结构体\n\n源码包中 `src/runtime/map.go` 定义了 hmap 的数据结构：\n\nHmap 包含若干个结构为 bmap 的数组，每个 bmap 底层都采用链表结构，bmap 通常叫其 bucket\n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240225233011.png)\n\n\n**hmap 结构体**\n\n```\n// A header for a Go map.\ntype hmap struct {\n    count     int \n    // 代表哈希表中的元素个数，调用len(map)时，返回的就是该字段值。\n    flags     uint8 \n    // 状态标志（是否处于正在写入的状态等）\n    B         uint8  \n    // buckets（桶）的对数\n    // 如果B=5，则buckets数组的长度 = 2^B=32，意味着有32个桶\n    noverflow uint16 \n    // 溢出桶的数量\n    hash0     uint32 \n    // 生成hash的随机数种子\n    buckets    unsafe.Pointer \n    // 指向buckets数组的指针，数组大小为2^B，如果元素个数为0，它为nil。\n    oldbuckets unsafe.Pointer \n    // 如果发生扩容，oldbuckets是指向老的buckets数组的指针，老的buckets数组大小是新的buckets的1/2;非扩容状态下，它为nil。\n    nevacuate  uintptr        \n    // 表示扩容进度，小于此地址的buckets代表已搬迁完成。\n    extra *mapextra \n    // 存储溢出桶，这个字段是为了优化GC扫描而设计的，下面详细介绍\n }\n```\n\n**bmap 结构体**\n\n`bmap` 就是我们常说的“桶”，一个桶里面会最多装 8 个 key，这些 key 之所以会落入同一个桶，是因为它们经过哈希计算后，哈希结果的低 B 位是相同的，关于 key 的定位我们在 map 的查询中详细说明。在桶内，又会根据 key 计算出来的 hash 值的高 8 位来决定 key 到底落入桶内的哪个位置（一个桶内最多有8个位置)。\n\n```\n// A bucket for a Go map.\ntype bmap struct {\n    tophash [bucketCnt]uint8        \n    // len为8的数组\n    // 用来快速定位key是否在这个bmap中\n    // 一个桶最多8个槽位，如果key所在的tophash值在tophash中，则代表该key在这个桶中\n}\n```\n\n\n上面 bmap 结构是静态结构，在编译过程中 `runtime.bmap` 会拓展成以下结构体：\n\n\n```\ntype bmap struct{\n    tophash [8]uint8\n    keys [8]keytype \n    // keytype 由编译器编译时候确定\n    values [8]elemtype \n    // elemtype 由编译器编译时候确定\n    overflow uintptr \n    // overflow指向下一个bmap，overflow是uintptr而不是*bmap类型，保证bmap完全不含指针，是为了减少gc，溢出桶存储到extra字段中\n}\n```\n\n\nTophash 就是用于实现快速定位 key 的位置，在实现过程中会使用 key 的 hash 值的高 8 位作为 tophash 值，存放在 bmap 的 tophash 字段中\n\nTophash 字段不仅存储 key 哈希值的高 8 位，还会存储一些状态值，用来表明当前桶单元状态，这些状态值都是小于 minTopHash 的\n\n为了避免 key 哈希值的高 8 位值和这些状态值相等，产生混淆情况，所以当 key 哈希值高 8 位若小于 minTopHash 时候，自动将其值加上 minTopHash 作为该 key 的 tophash。桶单元的状态值如下：\n\n```\nemptyRest      = 0 // 表明此桶单元为空，且更高索引的单元也是空\nemptyOne       = 1 // 表明此桶单元为空\nevacuatedX     = 2 // 用于表示扩容迁移到新桶前半段区间\nevacuatedY     = 3 // 用于表示扩容迁移到新桶后半段区间\nevacuatedEmpty = 4 // 用于表示此单元已迁移\nminTopHash     = 5 // key的tophash值与桶状态值分割线值，小于此值的一定代表着桶单元的状态，大于此值的一定是key对应的tophash值\n\nfunc tophash(hash uintptr) uint8 {\n    top := uint8(hash \u003e\u003e (goarch.PtrSize*8 - 8))\n    if top \u003c minTopHash {\n        top += minTopHash\n    }\n    return top\n}\n```\n\n**mapextra 结构体**\n\n当 map 的 key 和 value 都不是指针类型时候，bmap 将完全不包含指针，那么 gc 时候就不用扫描 bmap。Bmap 指向溢出桶的字段 overflow 是 uintptr 类型，为了防止这些 overflow 桶被 gc 掉，所以需要 mapextra. Overflow 将它保存起来。如果 bmap 的 overflow 是bmap 类型，那么 gc 扫描的是一个个拉链表，效率明显不如直接扫描一段内存(hmap.Mapextra.Overflow)\n\n```\ntype mapextra struct {\n    overflow    *[]*bmap\n    // overflow 包含的是 hmap.buckets 的 overflow 的 buckets\n    oldoverflow *[]*bma\n   // oldoverflow 包含扩容时 hmap.oldbuckets 的 overflow 的 bucket\n    nextOverflow *bmap \n     // 指向空闲的 overflow bucket 的指针\n}\n```\n\n**总结**\n\nBmap（bucket）内存数据结构可视化如下:\n\n注意到 key 和 value 是各自放在一起的，并不是 `key/value/key/value/...` 这样的形式，当 key 和 value 类型不一样的时候，key 和 value 占用字节大小不一样，使用 key/value 这种形式可能会因为内存对齐导致内存空间浪费，所以 Go 采用 key 和 value 分开存储的设计，更节省内存空间\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240225233151.png)\n\n# Go map 遍历为什么是无序的？\n\n使用 range 多次遍历 map 时输出的 key 和 value 的顺序可能不同。这是 Go 语言的设计者们**有意为之**，旨在提示开发者们，Go 底层实现并不保证 map 遍历顺序稳定，请大家不要依赖 range 遍历结果顺序\n\n主要原因有 2 点：\n\n- Map 在遍历时，并不是从固定的 0 号 bucket 开始遍历的，每次遍历，都会从一个**随机值序号的 bucket**，再从其中**随机的 cell**开始遍历\n- Map 遍历时，是按序遍历 bucket，同时按需遍历 bucket 中和其 overflow bucket 中的 cell。但是 map 在扩容后，会发生 key 的搬迁，这造成原来落在一个 bucket 中的 key，搬迁后，有可能会落到其他 bucket 中了，从这个角度看，遍历 map 的结果就不可能是按照原来的顺序了\n\nMap 本身是无序的，且遍历时顺序还会被随机化，如果想顺序遍历 map，需要对 map key 先排序，再按照 key 的顺序遍历 map。\n\n```\nfunc TestMapRange(t *testing.T) {\n    m := map[int]string{1: \"a\", 2: \"b\", 3: \"c\"}\n    t.Log(\"first range:\")\n    for i, v := range m {\n        t.Logf(\"m[%v]=%v \", i, v)\n    }\n    t.Log(\"\\nsecond range:\")\n    for i, v := range m {\n        t.Logf(\"m[%v]=%v \", i, v)\n    }\n\n    // 实现有序遍历\n    var sl []int\n    // 把 key 单独取出放到切片\n    for k := range m {\n        sl = append(sl, k)\n    }\n    // 排序切片\n    sort.Ints(sl)\n    // 以切片中的 key 顺序遍历 map 就是有序的了\n    for _, k := range sl {\n        t.Log(k, m[k])\n    }\n}\n```\n\n# Go map 为什么是非线程安全的？\n\nMap 默认是并发不安全的，同时对 map 进行并发读写时，程序会 panic，原因如下：\n\nGo 官方在经过了长时间的讨论后，认为 Go map 更应适配典型使用场景（不需要从多个 goroutine 中进行安全访问），而不是为了小部分情况（并发访问），导致大部分程序付出加锁代价（性能），决定了不支持。\n\n场景: 2 个协程同时读和写，以下程序会出现致命错误：fatal error: concurrent map writes\n\n```\npackage main\n\nimport (\n    \"fmt\"\n    \"time\"\n)\n\nfunc main() {\n    s := make(map[int]int)\n    for i := 0; i \u003c 100; i++ {\n        go func(i int) {\n            s[i] = i\n        }(i)\n    }\n    for i := 0; i \u003c 100; i++ {\n        go func(i int) {\n            fmt.Printf(\"map第%d个元素值是%d\\n\", i, s[i])\n        }(i)\n    }\n    time.Sleep(1 * time.Second)\n}\n```\n\n如果想实现 map 线程安全，有两种方式：\n\n方式一：使用读写锁 `map` + `sync.RWMutex`\n\n```\npackage main\n\nimport (\n    \"fmt\"\n    \"sync\"\n    \"time\"\n)\n\nfunc main() {\n    var lock sync.RWMutex\n    s := make(map[int]int)\n    for i := 0; i \u003c 100; i++ {\n        go func(i int) {\n            lock.Lock()\n            s[i] = i\n            lock.Unlock()\n        }(i)\n    }\n    for i := 0; i \u003c 100; i++ {\n        go func(i int) {\n            lock.RLock()\n            fmt.Printf(\"map第%d个元素值是%d\\n\", i, s[i])\n            lock.RUnlock()\n        }(i)\n    }\n    time.Sleep(1 * time.Second)\n}\n\n```\n\n方式二：使用 Go 提供的 `sync.Map`\n\n```\npackage main\n\nimport (\n    \"fmt\"\n    \"sync\"\n    \"time\"\n)\n\nfunc main() {\n    var m sync.Map\n    for i := 0; i \u003c 100; i++ {\n        go func(i int) {\n            m.Store(i, i)\n        }(i)\n    }\n    for i := 0; i \u003c 100; i++ {\n        go func(i int) {\n            v, ok := m.Load(i)\n            fmt.Printf(\"Load: %v, %v\\n\", v, ok)\n        }(i)\n    }\n    time.Sleep(1 * time.Second)\n}\n```\n\n# Go map 如何查找？\n\nGo 语言中读取 map 有两种语法：带 comma 和不带 comma。当要查询的 key 不在 map 里，带 comma 的用法会返回一个 bool 型变量提示 key 是否在 map 中；而不带 comma 的语句则会返回一个 value 类型的零值。如果 value 是 int 型就会返回 0，如果 value 是 string 类型，就会返回空字符串。\n\n```\n// 不带 comma 用法\nvalue := m[\"name\"]\nfmt.Printf(\"value:%s\", value)\n\n// 带 comma 用法\nvalue, ok := m[\"name\"]\nif ok {\n    fmt.Printf(\"value:%s\", value)\n}\n```\n\nMap 的查找通过生成汇编码可以知道，根据 key 的不同类型/返回参数，编译器会将查找函数用更具体的函数替换，以优化效率：\n\n|key 类型|查找|\n|:--|:--|\n|uint 32|mapaccess 1_fast 32 (t _maptype, h_ hmap, key uint 32) unsafe. Pointer|\n|uint 32|mapaccess 2_fast 32 (t _maptype, h_ hmap, key uint 32) (unsafe. Pointer, bool)|\n|uint 64|mapaccess 1_fast 64 (t _maptype, h_ hmap, key uint 64) unsafe. Pointer|\n|uint 64|mapaccess 2_fast 64 (t _maptype, h_ hmap, key uint 64) (unsafe. Pointer, bool)|\n|string|mapaccess 1_faststr (t _maptype, h_ hmap, ky string) unsafe. Pointer|\n|string|mapaccess 2_faststr (t _maptype, h_ hmap, ky string) (unsafe. Pointer, bool)|\n\n**查找流程**\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240225233311.png)\n\n**1. 写保护监测**\n\n函数首先会检查 map 的标志位 flags。如果 flags 的写标志位此时被置 1 了，说明有其他协程在执行“写”操作，进而导致程序 panic，这也说明了 map 不是线程安全的\n\n```\nif h.flags\u0026hashWriting != 0 {\n    throw(\"concurrent map read and map write\")\n}\n```\n\n**2. 计算 hash 值**\n\n```\nhash := t.hasher(key, uintptr(h.hash0))\n```\n\nKey 经过哈希函数计算后，得到的哈希值如下（主流 64 位机下共 64 个 bit 位），不同类型的 key 会有不同的 hash 函数\n\n```\n10010111 | 000011110110110010001111001010100010010110010101010 │ 01010\n```\n\n**3. 找到 hash 对应的 bucket**\n\nBucket 定位：**哈希值的低 B 个 bit 位**，用来定位 key 所存放的 bucket\n\n如果当前正在扩容中，并且定位到的旧 bucket 数据还未完成迁移，则使用旧的 bucket（扩容前的 bucket）\n\n```\nhash := t.hasher(key, uintptr(h.hash0))\n// 桶的个数m-1，即 1\u003c\u003cB-1,B=5时，则有0~31号桶\nm := bucketMask(h.B)\n// 计算哈希值对应的bucket\n// t.bucketsize为一个bmap的大小，通过对哈希值和桶个数取模得到桶编号，通过对桶编号和buckets起始地址进行运算，获取哈希值对应的bucket\nb := (*bmap)(add(h.buckets, (hash\u0026m)*uintptr(t.bucketsize)))\n// 是否在扩容\nif c := h.oldbuckets; c != nil {\n  // 桶个数已经发生增长一倍，则旧bucket的桶个数为当前桶个数的一半\n    if !h.sameSizeGrow() {\n        // There used to be half as many buckets; mask down one more power of two.\n        m \u003e\u003e= 1\n    }\n    // 计算哈希值对应的旧bucket\n    oldb := (*bmap)(add(c, (hash\u0026m)*uintptr(t.bucketsize)))\n    // 如果旧bucket的数据没有完成迁移，则使用旧bucket查找\n    if !evacuated(oldb) {\n        b = oldb\n    }\n}\n```\n\n**4. 遍历 bucket 查找**\n\nTophash 值定位：**哈希值的高 8 个 bit 位**，用来快速判断 key 是否已在当前 bucket 中（如果不在的话，需要去 bucket 的 overflow 中查找）\n\n用步骤 2 中的 hash 值，得到高 8 个 bit 位，也就是 `10010111`，转化为十进制，也就是**151**\n\n```\ntop := tophash(hash)\nfunc tophash(hash uintptr) uint8 {\n    top := uint8(hash \u003e\u003e (goarch.PtrSize*8 - 8))\n    if top \u003c minTopHash {\n        top += minTopHash\n    }\n    return top\n}\n```\n\n上面函数中 hash 是 64 位的，sys. PtrSize 值是 8，所以 `top := uint8(hash \u003e\u003e (sys.PtrSize*8 - 8))` 等效 `top = uint8(hash \u003e\u003e 56)`，最后 top 取出来的值就是 hash 的高8位值\n\n在 bucket 及 bucket 的 overflow 中寻找**tophash 值（HOB hash）为 151* 的槽位**，即为 key 所在位置，找到了空槽位或者 2 号槽位，这样整个查找过程就结束了，其中找到空槽位代表没找到。\n\n\n```\nfor ; b != nil; b = b.overflow(t) {\n        for i := uintptr(0); i \u003c bucketCnt; i++ {\n            if b.tophash[i] != top {\n              // 未被使用的槽位，插入\n                if b.tophash[i] == emptyRest {\n                    break bucketloop\n                }\n                continue\n            }\n            // 找到tophash值对应的的key\n            k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize))\n            if t.key.equal(key, k) {\n                e := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize))\n                return e\n            }\n        }\n    }\n```\n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240225233436.png)\n\n\n**5. 返回 key 对应的指针**\n\n如果通过上面的步骤找到了 key 对应的槽位下标 i，我们再详细分析下 key/value 值是如何获取的：\n\n```\n// keys的偏移量\ndataOffset = unsafe.Offsetof(struct{\n  b bmap\n  v int64\n}{}.v)\n\n// 一个bucket的元素个数\nbucketCnt = 8\n\n// key 定位公式\nk :=add(unsafe.Pointer(b),dataOffset+i*uintptr(t.keysize))\n\n// value 定位公式\nv:= add(unsafe.Pointer(b),dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.valuesize))\n```\n\nBucket 里 keys 的起始地址就是 unsafe.Pointer (b)+dataOffset\n\n第 i 个下标 key 的地址就要在此基础上跨过 i 个 key 的大小；\n\n而我们又知道，value 的地址是在所有 key 之后，因此第 i 个下标 value 的地址还需要加上所有 key 的偏移。\n\n# Go map 冲突的解决方式？\n\n比较常用的 Hash 冲突解决方案有链地址法和开放寻址法：\n\n**链地址法**\n\n当哈希冲突发生时，创建新**单元**，并将新单元添加到冲突单元所在链表的尾部。\n\n**开放寻址法**\n\n当哈希冲突发生时，从发生冲突的那个**单元**起，按照一定的次序，从哈希表中寻找一个空闲的单元，然后把发生冲突的元素存入到该单元。**开放寻址法需要的表长度要大于等于所需要存放的元素数量**\n\n开放寻址法有多种方式：线性探测法、平方探测法、随机探测法和双重哈希法。这里以线性探测法来帮助读者理解开放寻址法思想\n\n**线性探测法**\n\n设 `Hash(key)` 表示关键字 `key` 的哈希值，表示哈希表的槽位数（哈希表的大小）。\n\n线性探测法则可以表示为：\n\n如果 `Hash(x) % M` 已经有数据，则尝试 `(Hash(x) + 1) % M` ;\n\n如果 `(Hash(x) + 1) % M` 也有数据了，则尝试 `(Hash(x) + 2) % M` ;\n\n如果 `(Hash(x) + 2) % M` 也有数据了，则尝试 `(Hash(x) + 3) % M` ;\n\n**两种解决方案比较**\n\n对于链地址法，基于数组 + 链表进行存储，链表节点可以在需要时再创建，不必像开放寻址法那样事先申请好足够内存，因此链地址法对于内存的利用率会比开方寻址法高。链地址法对装载因子的容忍度会更高，并且适合存储大对象、大数据量的哈希表。而且相较于开放寻址法，它更加灵活，支持更多的优化策略，比如可采用红黑树代替链表。但是链地址法需要额外的空间来存储指针。\n\n对于开放寻址法，它只有数组一种数据结构就可完成存储，继承了数组的优点，对 CPU 缓存友好，易于序列化操作。但是它对内存的利用率不如链地址法，且发生冲突时代价更高。**当数据量明确、装载因子小，适合采用开放寻址法。**\n\n**总结**\n\n在发生哈希冲突时，Python 中 dict 采用的开放寻址法，Java 的 HashMap 采用的是链地址法，而 Go map 也采用链地址法解决冲突，具体就是**插入 key 到 map 中时**，当 key 定位的桶**填满 8 个元素后**（这里的单元就是桶，不是元素），将会创建一个溢出桶，并且将溢出桶插入当前桶所在链表尾部。\n\n```\nif inserti == nil {\n        // all current buckets are full, allocate a new one.\n        newb := h.newoverflow(t, b)\n        // 创建一个新的溢出桶\n        inserti = \u0026newb.tophash[0]\n        insertk = add(unsafe.Pointer(newb), dataOffset)\n        elem = add(insertk, bucketCnt*uintptr(t.keysize))\n}\n```\n\n# Go map 的负载因子为什么是 6.5？\n\n**什么是负载因子?**\n\n**负载因子（load factor），用于衡量当前哈希表中空间占用率的核心指标**，也就是每个 bucket 桶存储的平均元素个数。\n\n| 负载因子 = 哈希表存储的元素个数/桶个 |\n| ---- |\n\n另外负载因子**与扩容、迁移**等重新散列（rehash）行为有直接关系：\n\n- 在程序运行时，会不断地进行插入、删除等，会导致 bucket 不均，内存利用率低，需要迁移。\n- 在程序运行时，出现负载因子过大，需要做扩容，解决 bucket 过大的问题。\n\n负载因子是哈希表中的一个重要指标，在各种版本的哈希表实现中都有类似的东西，主要目的是**为了平衡 buckets 的存储空间大小和查找元素时的性能高低**。\n\n在接触各种哈希表时都可以关注一下，做不同的对比，看看各家的考量。\n\n**为什么是 6.5?**\n\n为什么 Go 语言中哈希表的负载因子是 6.5，为什么不是 8 ，也不是 1。这里面有可靠的数据支撑吗？\n\n**测试报告**\n\n实际上这是 Go 官方的经过认真的测试得出的数字，一起来看看官方的这份测试报告。\n\n报告中共包含 4 个关键指标，如下：\n\n|loadFactor|%overflow|bytes/entry|hitprobe|missprobe|\n|:--|:--|:--|:--|:--|\n|4.00|2.13|20.77|3.00|4.00|\n|4.50|4.05|17.30|3.25|4.50|\n|5.00|6.85|14.77|3.50|5.00|\n|5.50|10.55|12.94|3.75|5.50|\n|6.00|15.27|11.67|4.00|6.00|\n|6.50|20.90|10.79|4.25|6.50|\n|7.00|27.14|10.15|4.50|7.00|\n|7.50|34.03|9.73|4.75|7.50|\n|8.00|41.10|9.40|5.00|8.00|\n\n- LoadFactor：负载因子，也有叫装载因子。\n- %overflow：溢出率，有溢出 bukcet 的百分比。\n- Bytes/entry：平均每对 key/value 的开销字节数.\n- Hitprobe：查找一个存在的 key 时，要查找的平均个数。\n- Missprobe：查找一个不存在的 key 时，要查找的平均个数。\n\n**选择数值**\n\nGo 官方发现：**装载因子越大，填入的元素越多，空间利用率就越高，但发生哈希冲突的几率就变大。反之，装载因子越小，填入的元素越少，冲突发生的几率减小，但空间浪费也会变得更多，而且还会提高扩容操作的次数**\n\n根据这份测试结果和讨论，Go 官方取了一个相对适中的值，把 Go 中的 map 的负载因子硬编码为 6.5，这就是 6.5 的选择缘由。\n\n这意味着在 Go 语言中，**当 map 存储的元素个数大于或等于 6.5 * 桶个数时，就会触发扩容行为**。\n\n# Go map 如何扩容?\n\n**扩容时机：**\n\n在**向 map 插入新 key** 的时候，会进行条件检测，符合下面这 2 个条件，就会触发扩容\n\n```\nif !h.growing() \u0026\u0026 (overLoadFactor(h.count+1, h.B) || tooManyOverflowBuckets(h.noverflow, h.B)) {\n  hashGrow(t, h)\n  goto again // Growing the table invalidates everything, so try again\n}\n\n// 判断是否在扩容\nfunc (h *hmap) growing() bool {\n    return h.oldbuckets != nil\n}\n```\n\n**扩容条件：**\n\n**条件 1：超过负载**\n\nMap 元素个数 \u003e 6.5 * 桶个数\n\n```\nfunc overLoadFactor(count int, B uint8) bool {\n   return count \u003e bucketCnt \u0026\u0026 uintptr(count) \u003e loadFactor*bucketShift(B)\n}\n\n/*\n其中 \n\nbucketCnt = 8，一个桶可以装的最大元素个数\nloadFactor = 6.5，负载因子，平均每个桶的元素个数\nbucketShift(B): 桶的个数\n*/\n```\n\n**条件 2：溢出桶太多**\n\n当桶总数 \u003c 2 ^ 15 时，如果溢出桶总数 \u003e= 桶总数，则认为溢出桶过多。\n\n当桶总数 \u003e= 2 ^ 15 时，直接与 2 ^ 15 比较，当溢出桶总数 \u003e= 2 ^ 15 时，即认为溢出桶太多了。\n\n```\nfunc tooManyOverflowBuckets(noverflow uint16, B uint8) bool {\n    // If the threshold is too low, we do extraneous work.\n    // If the threshold is too high, maps that grow and shrink can hold on to lots of unused memory.\n    // \"too many\" means (approximately) as many overflow buckets as regular buckets.\n    // See incrnoverflow for more details.\n    if B \u003e 15 {\n        B = 15\n    }\n    // The compiler doesn't see here that B \u003c 16; mask B to generate shorter shift code.\n    return noverflow \u003e= uint16(1)\u003c\u003c(B\u002615)\n}\n```\n\n对于条件 2，其实算是对条件 1 的补充。因为在负载因子比较小的情况下，有可能 map 的查找和插入效率也很低，而第 1 点识别不出来这种情况。\n\n表面现象就是负载因子比较小比较小，即 map 里元素总数少，但是桶数量多（真实分配的桶数量多，包括大量的溢出桶）。比如不断的增删，这样会造成 overflow 的 bucket 数量增多，但负载因子又不高，达不到第 1 点的临界值，就不能触发扩容来缓解这种情况。这样会造成桶的使用率不高，值存储得比较稀疏，查找插入效率会变得非常低，因此有了第 2 扩容条件。\n\n**扩容机制：**\n\n**双倍扩容**：针对条件 1，新建一个 buckets 数组，新的 buckets 大小是原来的 2 倍，然后旧 buckets 数据搬迁到新的 buckets。该方法我们称之为**双倍扩容**\n\n**等量扩容：**针对条件 2，并不扩大容量，buckets 数量维持不变，重新做一遍类似双倍扩容的搬迁动作，把松散的键值对重新排列一次，使得同一个 bucket 中的 key 排列地更紧密，节省空间，提高 bucket 利用率，进而保证更快的存取。该方法我们称之为**等量扩容**。\n\n**扩容函数：**\n\n上面说的 `hashGrow ()` 函数实际上并没有真正地“搬迁”，它只是分配好了新的 buckets，并将老的 buckets 挂到了 oldbuckets 字段上。真正搬迁 buckets 的动作在 `growWork ()` 函数中，而调用 `growWork ()` 函数的动作是在 mapassign 和 mapdelete 函数中。也就是**插入或修改、删除 key 的时候，都会尝试进行搬迁 buckets 的工作**。先检查 oldbuckets 是否搬迁完毕，具体来说就是检查 oldbuckets 是否为 nil\n\n```\nfunc hashGrow(t *maptype, h *hmap) {\n   // 如果达到条件 1，那么将B值加1，相当于是原来的2倍\n   // 否则对应条件 2，进行等量扩容，所以 B 不变\n     bigger := uint8(1)\n     if !overLoadFactor(h.count+1, h.B) {\n         bigger = 0\n         h.flags |= sameSizeGrow\n     }\n   // 记录老的buckets\n    oldbuckets := h.buckets\n  // 申请新的buckets空间\n    newbuckets, nextOverflow := makeBucketArray(t, h.B+bigger, nil)\n  // 注意\u0026^ 运算符，这块代码的逻辑是转移标志位\n    flags := h.flags \u0026^ (iterator | oldIterator)\n    if h.flags\u0026iterator != 0 {\n        flags |= oldIterator\n    }\n    // 提交grow (atomic wrt gc)\n    h.B += bigger\n    h.flags = flags\n    h.oldbuckets = oldbuckets\n    h.buckets = newbuckets\n  // 搬迁进度为0\n    h.nevacuate = 0\n  // overflow buckets 数为0\n    h.noverflow = 0\n\n  // 如果发现hmap是通过extra字段 来存储 overflow buckets时\n    if h.extra != nil \u0026\u0026 h.extra.overflow != nil {\n        if h.extra.oldoverflow != nil {\n            throw(\"oldoverflow is not nil\")\n        }\n        h.extra.oldoverflow = h.extra.overflow\n        h.extra.overflow = nil\n    }\n    if nextOverflow != nil {\n        if h.extra == nil {\n            h.extra = new(mapextra)\n        }\n        h.extra.nextOverflow = nextOverflow\n    }\n}\n```\n\n由于 map 扩容需要将原有的 key/value 重新搬迁到新的内存地址，如果 map 存储了数以亿计的 key-value，一次性搬迁将会造成比较大的延时，因此 Go map 的扩容采取了一种称为**“渐进式”**的方式，原有的 key 并不会一次性搬迁完毕，每次最多只会搬迁 2 个 bucket。\n\n\n```\nfunc growWork(t *maptype, h *hmap, bucket uintptr) {\n    // 为了确认搬迁的 bucket 是我们正在使用的 bucket\n    // 即如果当前key映射到老的bucket1，那么就搬迁该bucket1。\n    evacuate(t, h, bucket\u0026h.oldbucketmask())\n    // 如果还未完成扩容工作，则再搬迁一个bucket。\n    if h.growing() {\n        evacuate(t, h, h.nevacuate)\n    }\n}\n```\n\n\n# Go map 和 sync. Map 谁的性能好，为什么？\n\nGo 语言的 `sync. Map` 支持并发读写，采取了 “空间换时间” 的机制，冗余了两个数据结构，分别是：read 和 dirty\n\n```\ntype Map struct {\n   mu Mutex\n   read atomic.Value // readOnly\n   dirty map[interface{}]*entry\n   misses int\n}\n```\n\n**对比原始 map：**\n\n和原始 map+RWLock 的实现并发的方式相比，减少了加锁对性能的影响。它做了一些优化：可以无锁访问 read map，而且会优先操作 read map，倘若只操作 read map 就可以满足要求，那就不用去操作 write map (dirty)，所以在某些特定场景中它发生锁竞争的频率会远远小于 map+RWLock 的实现方式\n\n**优点：**\n\n适合读多写少的场景\n\n**缺点：**\n\n写多的场景，会导致 read map 缓存失效，需要加锁，冲突变多，性能急剧下降","lastmodified":"2024-02-25T17:02:23.022964011Z","tags":[]},"/GO/%E5%85%AB%E8%82%A1%E6%96%87/Mutex":{"title":"Mutex","content":" \n\n\n# Mutex 几种状态\n\n![image-20230921213238958](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticimage-20230921213238958.png)\n\n# RWMutex 实现，RWMutex 注意事项\n\n通过记录 readerCount 读锁的数量来进⾏控制，当有⼀个写锁的时候，会将读锁数量设置为负数 1\u003c\u003c30。⽬的是让新进⼊的读锁等待写锁之后释放通知读锁。同样的写锁也会等等待之前的读锁都释放完毕，才会开始进⾏后续的操作。而等写锁释放完之后，会将值重新加上 1\u003c\u003c30, 并通知刚才新进⼊的读锁 (rw. ReaderSem)，两者互相限制。\n\n![image-20230624162219175](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticimage-20230624162219175.png)\n\n# Go 当中同步锁有什么特点？作用是什么\n\n当⼀个 Goroutine（协程）获得了 Mutex 后，其他 Goroutine（协程）就只能乖乖的等待，除非该 goroutine 释放了该 Mutex RWMutex 在读锁占⽤的情况下，会阻止写，但不阻止读 RWMutex 在写锁占用情况下，会阻止任何其他 goroutine（⽆论读和写）进来，整个锁相当于由该 goroutine 独占同步锁的作用是保证资源在使用时的独有性，不会因为并发而导致数据错乱，保证系统的稳定性。\n\n# 获取不到锁会一直等待吗？\n\n会。  \n在 2016 年 Go 1.9 中 Mutex 增加了饥饿模式，让锁变得更公平，不公平的等待时间限制在 1 毫秒，并且修复了一个大 Bug：总是把唤醒的 goroutine 放在等待队列的尾部，会导致出现不公平的等待时间。那什么时候会进入饥饿模式？1 毫秒，一旦等待者等待时间超过这个时间阈值，就可能会进入饥饿模式，优先让等待着先获取到锁。有饥饿模式自然就有正常模式了，这里就不展开了。你只需要记住，Mutex 锁不会容忍一个 goroutine 被落下，永远没有机会获取锁。Mutex 尽可能地让等待较长的 goroutine 更有机会获取到锁。\n\n# 如何实现一个 timeout 的锁\n\n\n```\npackage main\n\nimport (\n\t\"fmt\"\n\t\"sync\"\n\t\"sync/atomic\"\n\t\"time\"\n)\n\ntype ChanMutex chan struct{}\n\nfunc NewTryLock() ChanMutex {\n\tch := make(chan struct{}, 1)\n\treturn ch\n}\nfunc (m *ChanMutex) Lock() {\n\tch := (chan struct{})(*m)\n\tch \u003c- struct{}{}\n}\nfunc (m *ChanMutex) Unlock() {\n\tch := (chan struct{})(*m)\n\tselect {\n\tcase \u003c-ch:\n\tdefault:\n\t\tpanic(\"unlock of unlocked mutex\")\n\t}\n}\nfunc (m *ChanMutex) TryLockWithTimeOut(d time.Duration) bool {\n\tch := (chan struct{})(*m)\n\tt := time.NewTimer(d)\n\tselect {\n\tcase \u003c-t.C:\n\t\treturn false\n\tcase ch \u003c- struct{}{}:\n\t\tt.Stop()\n\t\treturn true\n\t}\n}\nfunc (m *ChanMutex) TryLock() bool {\n\tch := (chan struct{})(*m)\n\tselect {\n\tcase ch \u003c- struct{}{}:\n\t\treturn true\n\tdefault:\n\t\treturn false\n\t}\n}\n\nfunc main() {\n\tn1 := int64(0)\n\tn2 := int64(0)\n\tc := NewTryLock()\n\n\twg := sync.WaitGroup{}\n\tfor i := 0; i \u003c 10000; i++ {\n\t\twg.Add(1)\n\t\tgo func() {\n\t\t\tif c.TryLock() {\n\t\t\t\tn1++\n\t\t\t\tc.Unlock()\n\t\t\t} else {\n\t\t\t\tatomic.AddInt64(\u0026n2, 1)\n\t\t\t}\n\t\t\twg.Done()\n\t\t}()\n\t}\n\twg.Wait()\n\n\tfmt.Printf(\"total: %v, success: %v, fail: %v\\n\", n1+n2, n1, n2)\n}\n```\n\n\n\n\n# Go 互斥锁的实现原理？\n\nGo sync包提供了两种锁类型：互斥锁sync.Mutex 和 读写互斥锁sync.RWMutex，都属于悲观锁。\n\n## 概念\n\nMutex是互斥锁，当一个 goroutine 获得了锁后，其他 goroutine 不能获取锁（只能存在一个写者或读者，不能同时读和写）\n\n## 使用场景\n\n多个线程同时访问临界区，为保证数据的安全，锁住一些共享资源， 以防止并发访问这些共享数据时可能导致的数据不一致问题。\n\n获取锁的线程可以正常访问临界区，未获取到锁的线程等待锁释放后可以尝试获取锁\n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240225235022.png)\n\n## 底层实现结构\n\n互斥锁对应的是底层结构是sync.Mutex结构体，，位于 src/sync/mutex.go中\n\n\n```\ntype Mutex struct {  \n     state int32  \n     sema  uint32\n }\n```\n\n\nstate表示锁的状态，有锁定、被唤醒、饥饿模式等，并且是用state的二进制位来标识的，不同模式下会有不同的处理方式\n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240225235050.png)\n\n\nsema表示信号量，mutex阻塞队列的定位是通过这个变量来实现的，从而实现goroutine的阻塞和唤醒\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240225235107.png)\n\n\n```\naddr = \u0026sema\nfunc semroot(addr *uint32) *semaRoot {  \n   return \u0026semtable[(uintptr(unsafe.Pointer(addr))\u003e\u003e3)%semTabSize].root  \n}\nroot := semroot(addr)\nroot.queue(addr, s, lifo)\nroot.dequeue(addr)\n\nvar semtable [251]struct {  \n   root semaRoot  \n   ...\n}\n\ntype semaRoot struct {  \n  lock  mutex  \n  treap *sudog // root of balanced tree of unique waiters.  \n  nwait uint32 // Number of waiters. Read w/o the lock.  \n}\n\ntype sudog struct {\n    g *g  \n    next *sudog  \n    prev *sudog\n    elem unsafe.Pointer // 指向sema变量\n    waitlink *sudog // g.waiting list or semaRoot  \n    waittail *sudog // semaRoot\n    ...\n}\n```\n## 操作\n\n锁的实现一般会依赖于原子操作、信号量，通过atomic 包中的一些原子操作来实现锁的锁定，通过信号量来实现线程的阻塞与唤醒\n\n###  **加锁**\n\n通过原子操作cas加锁，如果加锁不成功，根据不同的场景选择自旋重试加锁或者阻塞等待被唤醒后加锁\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240225235208.png)\n\n```\nfunc (m *Mutex) Lock() {\n    // Fast path: 幸运之路，一下就获取到了锁\n    if atomic.CompareAndSwapInt32(\u0026m.state, 0, mutexLocked) {\n        return\n    }\n    // Slow path：缓慢之路，尝试自旋或阻塞获取锁\n    m.lockSlow()\n}\n```\n\n### **解锁**\n\n通过原子操作add解锁，如果仍有goroutine在等待，唤醒等待的goroutine\n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240225235306.png)\n\n\n```\nfunc (m *Mutex) Unlock() {  \n   // Fast path: 幸运之路，解锁\n   new := atomic.AddInt32(\u0026m.state, -mutexLocked)  \n   if new != 0 {  \n            // Slow path：如果有等待的goroutine，唤醒等待的goroutine\n            m.unlockSlow()\n   }  \n}\n```\n\n### **注意点：**\n\n- 在 Lock() 之前使用 Unlock() 会导致 panic 异常\n- 使用 Lock() 加锁后，再次 Lock() 会导致死锁（不支持重入），需Unlock()解锁后才能再加锁\n- 锁定状态与 goroutine 没有关联，一个 goroutine 可以 Lock，另一个 goroutine 可以 **Unlock**\n\n# Go 互斥锁正常模式和饥饿模式的区别？\n\n在Go一共可以分为两种抢锁的模式，一种是**正常模式**，另外一种是**饥饿模式**。\n\n## 正常模式(非公平锁)\n\n在刚开始的时候，是处于正常模式（Barging），也就是，当一个G1持有着一个锁的时候，G2会自旋的去尝试获取这个锁\n\n当**自旋超过4次**还没有能获取到锁的时候，这个G2就会被加入到获取锁的等待队列里面，并阻塞等待唤醒\n\n正常模式下，所有等待锁的 goroutine 按照 FIFO(先进先出)顺序等待。唤醒的goroutine 不会直接拥有锁，而是会和新请求锁的 goroutine 竞争锁。新请求锁的 goroutine 具有优势：它正在 CPU 上执行，而且可能有好几个，所以刚刚唤醒的 goroutine 有很大可能在锁竞争中失败，长时间获取不到锁，就会切换到饥饿模式\n\n## 饥饿模式(公平锁)\n\n当一个 goroutine 等待锁时间超过 1 毫秒时，它可能会遇到饥饿问题。 在版本1.9中，这种场景下Go Mutex 切换到饥饿模式（handoff），解决饥饿问题。\n\n```\nstarving = runtime_nanotime()-waitStartTime \u003e 1e6\n```\n\n正常模式下，所有等待锁的 goroutine 按照 FIFO(先进先出)顺序等待。唤醒的goroutine 不会直接拥有锁，而是会和新请求锁的 goroutine 竞争锁。新请求锁的 goroutine 具有优势：它正在 CPU 上执行，而且可能有好几个，所以刚刚唤醒的 goroutine 有很大可能在锁竞争中失败，长时间获取不到锁，就会切换到饥饿模式\n\n那么也不可能说永远的保持一个饥饿的状态，总归会有吃饱的时候，也就是总有那么一刻Mutex会回归到正常模式，那么回归正常模式必须具备的条件有以下几种：\n\n1. G的执行时间小于1ms\n2. 等待队列已经全部清空了\n\n当满足上述两个条件的任意一个的时候，Mutex会切换回正常模式，而Go的抢锁的过程，就是在这个正常模式和饥饿模式中来回切换进行的。\n\n```\ndelta := int32(mutexLocked - 1\u003c\u003cmutexWaiterShift)  \nif !starving || old\u003e\u003emutexWaiterShift == 1 {  \n    delta -= mutexStarving\n}\natomic.AddInt32(\u0026m.state, delta)\n```\n\n## 总结\n\n对于两种模式，正常模式下的性能是最好的，goroutine 可以连续多次获取锁，饥饿模式解决了取锁公平的问题，但是性能会下降，其实是性能和公平的 一个平衡模式。\n\n# Go 互斥锁允许自旋的条件？\n\n线程没有获取到锁时常见有2种处理方式：\n\n- 一种是没有获取到锁的线程就一直循环等待判断该资源是否已经释放锁，这种锁也叫做**自旋锁**，它不用将线程阻塞起来， 适用于并发低且程序执行时间短的场景，缺点是cpu占用较高\n- 另外一种处理方式就是把自己阻塞起来，会**释放CPU给其他线程**，内核会将线程置为「睡眠」状态，等到锁被释放后，内核会在合适的时机唤醒该线程，适用于高并发场景，缺点是有线程上下文切换的开销\n\nGo语言中的Mutex实现了自旋与阻塞两种场景，当满足不了自旋条件时，就会进入阻塞\n\n**允许自旋的条件：**\n\n1. 锁已被占用，并且锁不处于饥饿模式。\n2. 积累的自旋次数小于最大自旋次数（active_spin=4）。\n3. cpu 核数大于 1。\n4. 有空闲的 P。\n5. 当前 goroutine 所挂载的 P 下，本地待运行队列为空。\n\n```\nif old\u0026(mutexLocked|mutexStarving) == mutexLocked \u0026\u0026 runtime_canSpin(iter) {  \n    ...\n    runtime_doSpin()   \n    continue  \n}\n\n\nfunc sync_runtime_canSpin(i int) bool {  \n    if i \u003e= active_spin \n    || ncpu \u003c= 1 \n    || gomaxprocs \u003c= int32(sched.npidle+sched.nmspinning)+1 {  \n          return false  \n     }  \n   if p := getg().m.p.ptr(); !runqempty(p) {  \n      return false  \n }  \n   return true  \n}\n```\n\n**自旋：**\n\n```\nfunc sync_runtime_doSpin() {\n    procyield(active_spin_cnt)\n}    \n```\n\n如果可以进入自旋状态之后就会调用 `runtime_doSpin` 方法进入自旋， `doSpin` 方法会调用 `procyield(30)` 执行30次 `PAUSE` 指令，什么都不做，但是会消耗CPU时间\n\n# Go 读写锁的实现原理？\n\n## 概念\n\n读写互斥锁RWMutex，是对Mutex的一个扩展，当一个 goroutine 获得了读锁后，其他 goroutine可以获取读锁，但不能获取写锁；当一个 goroutine 获得了写锁后，其他 goroutine既不能获取读锁也不能获取写锁（只能存在一个写者或多个读者，可以同时读）\n\n## 使用场景\n\n**读**多于**写**的情况（既保证线程安全，又保证性能不太差）\n\n## 底层实现结构\n\n互斥锁对应的是底层结构是sync.RWMutex结构体，，位于 src/sync/rwmutex.go中\n\n```\ntype RWMutex struct {\n    w           Mutex  // 复用互斥锁\n    writerSem   uint32 // 信号量，用于写等待读\n    readerSem   uint32 // 信号量，用于读等待写\n    readerCount int32  // 当前执行读的 goroutine 数量\n    readerWait  int32  // 被阻塞的准备读的 goroutine 的数量\n}\n```\n\n## **操作:**\n\n\n```\nfunc (rw *RWMutex) RLock() // 加读锁\nfunc (rw *RWMutex) RUnlock() // 释放读锁\nfunc (rw *RWMutex) Lock() // 加写锁\nfunc (rw *RWMutex) Unlock() // 释放写锁\n```\n\n### **加读锁**\n\n```\nfunc (rw *RWMutex) RLock() {\n// 为什么readerCount会小于0呢？往下看发现writer的Lock()会对readerCount做减法操作（原子操作）\n  if atomic.AddInt32(\u0026rw.readerCount, 1) \u003c 0 {\n    // A writer is pending, wait for it.\n    runtime_Semacquire(\u0026rw.readerSem)\n  }\n}\n```\n\n`atomic.AddInt32(\u0026rw.readerCount, 1)` 调用这个原子方法，对当前在读的数量加1，如果返回负数，那么说明当前有其他写锁，这时候就调用 `runtime_SemacquireMutex` 休眠当前goroutine 等待被唤醒\n\n### **释放读锁**\n\n解锁的时候对正在读的操作减1，如果返回值小于 0 那么说明当前有在写的操作，这个时候调用 `rUnlockSlow` 进入慢速通道\n\n```\nfunc (rw *RWMutex) RUnlock() {\n    if r := atomic.AddInt32(\u0026rw.readerCount, -1); r \u003c 0 {\n        rw.rUnlockSlow(r)\n    }\n}\n```\n\n被阻塞的准备读的 goroutine 的数量减1，readerWait 为 0，就表示当前没有正在准备读的 goroutine 这时候调用 `runtime_Semrelease` 唤醒写操作\n\n```\nfunc (rw *RWMutex) rUnlockSlow(r int32) {\n    // A writer is pending.\n    if atomic.AddInt32(\u0026rw.readerWait, -1) == 0 {\n        // The last reader unblocks the writer.\n        runtime_Semrelease(\u0026rw.writerSem, false, 1)\n    }\n}\n```\n\n\n### **加写锁**\n\n\n```\nconst rwmutexMaxReaders = 1 \u003c\u003c 30\n\nfunc (rw *RWMutex) Lock() {\n    // First, resolve competition with other writers.\n    rw.w.Lock()\n    // Announce to readers there is a pending writer.\n    r := atomic.AddInt32(\u0026rw.readerCount, -rwmutexMaxReaders) + rwmutexMaxReaders\n    // Wait for active readers.\n    if r != 0 \u0026\u0026 atomic.AddInt32(\u0026rw.readerWait, r) != 0 {\n        runtime_Semacquire(\u0026rw.writerSem)\n    }\n}\n```\n\n首先调用互斥锁的 lock，获取到互斥锁之后，如果计算之后当前仍然有其他 goroutine 持有读锁，那么就调用 `runtime_SemacquireMutex` 休眠当前的 goroutine 等待所有的读操作完成\n\n这里readerCount 原子性加上一个很大的负数，是防止后面的协程能拿到读锁，阻塞读\n\n### **释放写锁**\n\n```\nfunc (rw *RWMutex) Unlock() {\n    // Announce to readers there is no active writer.\n    r := atomic.AddInt32(\u0026rw.readerCount, rwmutexMaxReaders)\n    // Unblock blocked readers, if any.\n    for i := 0; i \u003c int(r); i++ {\n        runtime_Semrelease(\u0026rw.readerSem, false)\n    }\n    // Allow other writers to proceed.\n    rw.w.Unlock()\n}\n```\n\n解锁的操作，会先调用 `atomic.AddInt32(\u0026rw.readerCount, rwmutexMaxReaders)` 将恢复之前写入的负数，然后根据当前有多少个读操作在等待，循环唤醒\n\n### 注意点\n\n- 读锁或写锁在 Lock() 之前使用 Unlock() 会导致 panic 异常\n- 使用 Lock() 加锁后，再次 Lock() 会导致死锁（不支持重入），需Unlock()解锁后才能再加锁\n- 锁定状态与 goroutine 没有关联，一个 goroutine 可以 RLock（Lock），另一个 goroutine 可以 RUnlock（Unlock）\n\n## 互斥锁和读写锁的区别\n\n- 读写锁区分读者和写者，而互斥锁不区分\n- 互斥锁同一时间只允许一个线程访问该对象，无论读写；读写锁同一时间内只允许一个写者，但是允许多个读者同时读对象。\n\n# Go 可重入锁如何实现？\n\n## 概念\n\n可重入锁又称为递归锁，是指在同一个线程在外层方法获取锁的时候，在进入该线程的内层方法时会自动获取锁，不会因为之前已经获取过还没释放再次加锁导致死锁\n\n## 为什么 Go 语言中没有可重入锁？\n\nMutex 不是可重入的锁。Mutex 的实现中没有记录哪个 goroutine 拥有这把锁。理论上，任何 goroutine 都可以随意地 Unlock 这把锁，所以没办法计算重入条件，并且Mutex 重复Lock会导致死锁。\n\n## 如何实现可重入锁？\n\n实现一个可重入锁需要这两点：\n\n- 记住持有锁的线程\n- 统计重入的次数\n\n```\npackage main\n\nimport (\n    \"bytes\"\n    \"fmt\"\n    \"runtime\"\n    \"strconv\"\n    \"sync\"\n    \"sync/atomic\"\n)\n\ntype ReentrantLock struct {\n    sync.Mutex\n    recursion int32 // 这个goroutine 重入的次数\n    owner     int64 // 当前持有锁的goroutine id\n}\n\n// Get returns the id of the current goroutine.\nfunc GetGoroutineID() int64 {\n    var buf [64]byte\n    var s = buf[:runtime.Stack(buf[:], false)]\n    s = s[len(\"goroutine \"):]\n    s = s[:bytes.IndexByte(s, ' ')]\n    gid, _ := strconv.ParseInt(string(s), 10, 64)\n    return gid\n}\n\nfunc NewReentrantLock() sync.Locker {\n    res := \u0026ReentrantLock{\n        Mutex:     sync.Mutex{},\n        recursion: 0,\n        owner:     0,\n    }\n    return res\n}\n\n// ReentrantMutex 包装一个Mutex,实现可重入\ntype ReentrantMutex struct {\n    sync.Mutex\n    owner     int64 // 当前持有锁的goroutine id\n    recursion int32 // 这个goroutine 重入的次数\n}\n\nfunc (m *ReentrantMutex) Lock() {\n    gid := GetGoroutineID()\n    // 如果当前持有锁的goroutine就是这次调用的goroutine,说明是重入\n    if atomic.LoadInt64(\u0026m.owner) == gid {\n        m.recursion++\n        return\n    }\n    m.Mutex.Lock()\n    // 获得锁的goroutine第一次调用，记录下它的goroutine id,调用次数加1\n    atomic.StoreInt64(\u0026m.owner, gid)\n    m.recursion = 1\n}\n\nfunc (m *ReentrantMutex) Unlock() {\n    gid := GetGoroutineID()\n    // 非持有锁的goroutine尝试释放锁，错误的使用\n    if atomic.LoadInt64(\u0026m.owner) != gid {\n        panic(fmt.Sprintf(\"wrong the owner(%d): %d!\", m.owner, gid))\n    }\n    // 调用次数减1\n    m.recursion--\n    if m.recursion != 0 { // 如果这个goroutine还没有完全释放，则直接返回\n        return\n    }\n    // 此goroutine最后一次调用，需要释放锁\n    atomic.StoreInt64(\u0026m.owner, -1)\n    m.Mutex.Unlock()\n}\n\nfunc main() {\n    var mutex = \u0026ReentrantMutex{}\n    mutex.Lock()\n    mutex.Lock()\n    fmt.Println(111)\n    mutex.Unlock()\n    mutex.Unlock()\n}\n```\n\n# Go 原子操作有哪些？\n\nGo atomic包是最轻量级的锁（也称无锁结构），可以在不形成临界区和创建互斥量的情况下完成并发安全的值替换操作，不过这个包只支持int32/int64/uint32/uint64/uintptr这几种数据类型的一些基础操作（增减、交换、载入、存储等）\n\n## 概念\n\n原子操作仅会由一个独立的CPU指令代表和完成。原子操作是无锁的，常常直接通过CPU指令直接实现。 事实上，其它同步技术的实现常常依赖于原子操作。\n\n## 使用场景\n\n当我们想要对**某个变量**并发安全的修改，除了使用官方提供的 `mutex`，还可以使用 sync/atomic 包的原子操作，它能够保证对变量的读取或修改期间不被其他的协程所影响。\n\natomic 包提供的原子操作能够确保任一时刻只有一个goroutine对变量进行操作，善用 atomic 能够避免程序中出现大量的锁操作。\n\n## 常见操作\n\n- 增减Add\n- 载入Load\n- 比较并交换CompareAndSwap\n- 交换Swap\n- 存储Store\n\natomic 操作的对象是一个地址，你需要把可寻址的变量的地址作为参数传递给方法，而不是把变量的值传递给方法\n\n下面将分别介绍这些操作：\n\n### **增减操作**\n\n此类操作的前缀为 `Add`\n\n```\nfunc AddInt32(addr *int32, delta int32) (new int32)\n\nfunc AddInt64(addr *int64, delta int64) (new int64)\n\nfunc AddUint32(addr *uint32, delta uint32) (new uint32)\n\nfunc AddUint64(addr *uint64, delta uint64) (new uint64)\n\nfunc AddUintptr(addr *uintptr, delta uintptr) (new uintptr)\n```\n\n需要注意的是，第一个参数必须是指针类型的值，通过指针变量可以获取被操作数在内存中的地址，从而施加特殊的CPU指令，确保同一时间只有一个goroutine能够进行操作。\n\n使用举例：\n\n```\nfunc add(addr *int64, delta int64) {\n    atomic.AddInt64(addr, delta) //加操作\n    fmt.Println(\"add opts: \", *addr)\n}\n```\n\n### **载入操作**\n\n此类操作的前缀为 `Load`\n\n```\nfunc LoadInt32(addr *int32) (val int32)\n\nfunc LoadInt64(addr *int64) (val int64)\n\nfunc LoadPointer(addr *unsafe.Pointer) (val unsafe.Pointer)\n\nfunc LoadUint32(addr *uint32) (val uint32)\n\nfunc LoadUint64(addr *uint64) (val uint64)\n\nfunc LoadUintptr(addr *uintptr) (val uintptr)\n\n// 特殊类型： Value类型，常用于配置变更\nfunc (v *Value) Load() (x interface{}) {}\n```\n\n载入操作能够保证原子的读变量的值，当读取的时候，任何其他CPU操作都无法对该变量进行读写，其实现机制受到底层硬件的支持。\n\n使用示例:\n\n```\nfunc load(addr *int64) {\n    fmt.Println(\"load opts: \", atomic.LoadInt64(\u0026opts))\n}\n```\n\n### **比较并交换**\n\n此类操作的前缀为 `CompareAndSwap`, 该操作简称 CAS，可以用来实现乐观锁\n\n```\nfunc CompareAndSwapInt32(addr *int32, old, new int32) (swapped bool)\n\nfunc CompareAndSwapInt64(addr *int64, old, new int64) (swapped bool)\n\nfunc CompareAndSwapPointer(addr *unsafe.Pointer, old, new unsafe.Pointer) (swapped bool)\n\nfunc CompareAndSwapUint32(addr *uint32, old, new uint32) (swapped bool)\n\nfunc CompareAndSwapUint64(addr *uint64, old, new uint64) (swapped bool)\n\nfunc CompareAndSwapUintptr(addr *uintptr, old, new uintptr) (swapped bool)\n```\n\n该操作在进行交换前首先确保变量的值未被更改，即仍然保持参数 `old` 所记录的值，满足此前提下才进行交换操作。CAS的做法类似操作数据库时常见的乐观锁机制。\n\n需要注意的是，当有大量的goroutine 对变量进行读写操作时，可能导致CAS操作无法成功，这时可以利用for循环多次尝试。\n\n使用示例：\n\n```\nfunc compareAndSwap(addr *int64, oldValue int64, newValue int64) {\n    if atomic.CompareAndSwapInt64(addr, oldValue, newValue) {\n        fmt.Println(\"cas opts: \", *addr)\n        return\n    }\n}\n```\n\n### **交换**\n\n此类操作的前缀为 `Swap`：\n\n```\nfunc SwapInt32(addr *int32, new int32) (old int32)\n\nfunc SwapInt64(addr *int64, new int64) (old int64)\n\nfunc SwapPointer(addr *unsafe.Pointer, new unsafe.Pointer) (old unsafe.Pointer)\n\nfunc SwapUint32(addr *uint32, new uint32) (old uint32)\n\nfunc SwapUint64(addr *uint64, new uint64) (old uint64)\n\nfunc SwapUintptr(addr *uintptr, new uintptr) (old uintptr)\n```\n\n相对于CAS，明显此类操作更为暴力直接，并不管变量的旧值是否被改变，直接赋予新值然后返回背替换的值。\n\n```\nfunc swap(addr *int64, newValue int64) {\n    atomic.SwapInt64(addr, newValue)\n    fmt.Println(\"swap opts: \", *addr)\n}\n```\n\n### **存储**\n\n此类操作的前缀为 `Store`：\n\n```\nfunc StoreInt32(addr *int32, val int32)\n\nfunc StoreInt64(addr *int64, val int64)\n\nfunc StorePointer(addr *unsafe.Pointer, val unsafe.Pointer)\n\nfunc StoreUint32(addr *uint32, val uint32)\n\nfunc StoreUint64(addr *uint64, val uint64)\n\nfunc StoreUintptr(addr *uintptr, val uintptr)\n\n// 特殊类型： Value类型，常用于配置变更\nfunc (v *Value) Store(x interface{})\n```\n\n此类操作确保了写变量的原子性，避免其他操作读到了修改变量过程中的脏数据。\n\n```\nfunc store(addr *int64, newValue int64) {\n    atomic.StoreInt64(addr, newValue)\n    fmt.Println(\"store opts: \", *addr)\n}\n```\n\n# Go 原子操作和锁的区别？\n\n- 原子操作由底层硬件支持，而锁是基于原子操作+信号量完成的。若实现相同的功能，前者通常会更有效率\n- 原子操作是单个指令的互斥操作；互斥锁/读写锁是一种数据结构，可以完成临界区（多个指令）的互斥操作，扩大原子操作的范围\n- 原子操作是无锁操作，属于乐观锁；说起锁的时候，一般属于悲观锁\n- 原子操作存在于各个指令/语言层级，比如“机器指令层级的原子操作”，“汇编指令层级的原子操作”，“Go语言层级的原子操作”等。\n- 锁也存在于各个指令/语言层级中，比如“机器指令层级的锁”，“汇编指令层级的锁”，“Go语言层级的锁”等\n","lastmodified":"2024-02-25T17:02:23.022964011Z","tags":[]},"/GO/%E5%85%AB%E8%82%A1%E6%96%87/goroutine":{"title":"goroutine","content":"\n\n\n\n# Go goroutine 的底层实现原理？\n\n## 概念\n\nGoroutine 可以理解为一种 Go 语言的协程（轻量级线程），是 Go 支持高并发的基础，属于用户态的线程，由 Go runtime 管理而不是操作系统。\n\n## 底层数据结构\n\n\n```\ntype g struct {\n    goid    int64 // 唯一的goroutine的ID\n    sched gobuf // goroutine切换时，用于保存g的上下文\n    stack stack // 栈\n  gopc        // pc of go statement that created this goroutine\n    startpc    uintptr // pc of goroutine function\n    ...\n}\n\ntype gobuf struct {\n    sp   uintptr // 栈指针位置\n    pc   uintptr // 运行到的程序位置\n    g    guintptr // 指向 goroutine\n    ret  uintptr  // 保存系统调用的返回值\n    ...\n}\n\ntype stack struct {\n    lo uintptr // 栈的下界内存地址\n    hi uintptr // 栈的上界内存地址\n}\n```\n\n最终有一个 runtime. G 对象放入调度队列\n\n## 状态流转\n\n| 状态 |  | 含义 |\n| ---- | ---- | ---- |\n| 空闲中 | Gidle | G 刚刚新建, 仍未初始化 |\n| 待运行 | Grunnable | 就绪状态，G 在运行队列中, 等待 M 取出并运行 |\n| 运行中 | Grunning | M 正在运行这个 G, 这时候 M 会拥有一个 P |\n| 系统调用中 | Gsyscall | M 正在运行这个 G 发起的系统调用, 这时候 M 并不拥有 P |\n| 等待中 | Gwaiting | G 在等待某些条件完成, 这时候 G 不在运行也不在运行队列中 (可能在 channel 的等待队列中) |\n| 已中止 | Gdead | G 未被使用, 可能已执行完毕 |\n| 栈复制中 | Gcopystack | G 正在获取一个新的栈空间并把原来的内容复制过去 (用于防止 GC 扫描) |\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226000754.png)\n\n## 创建\n\n通过 `go` 关键字调用底层函数 `runtime.newproc()` 创建一个 `goroutine`\n\n当调用该函数之后，goroutine 会被设置成 `runnable` 状态\n\n```\nfunc main() {\n   go func() {\n    fmt.Println(\"func routine\")\n   }()\n   fmt.Println(\"main goroutine\")\n}\n```\n\n创建好的这个 goroutine 会新建一个自己的栈空间，同时在 G 的 sched 中维护栈地址与程序计数器这些信息。\n\n每个 G 在被创建之后，都会被优先放入到本地队列中，如果本地队列已经满了，就会被放入到全局队列中。\n\n## 运行\n\nGoroutine 本身只是一个数据结构，真正让 goroutine 运行起来的是**调度器**。Go 实现了一个用户态的调度器（GMP 模型），这个调度器充分利用现代计算机的多核特性，同时让多个 goroutine 运行，同时 goroutine 设计的很轻量级，调度和上下文切换的代价都比较小。\n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226000930.png)\n\n\n\n**调度时机：**\n\n- 新起一个协程和协程执行完毕\n- 会阻塞的系统调用，比如文件 io、网络 io\n- Channel、mutex 等阻塞操作\n- Time. Sleep\n- 垃圾回收之后\n- 主动调用 runtime.Gosched ()\n- 运行过久或系统调用过久等等\n\n每个 M 开始执行 P 的本地队列中的 G 时，goroutine 会被设置成 `running` 状态\n\n如果某个 M 把本地队列中的 G 都执行完成之后，然后就会去全局队列中拿 G，这里需要注意，每次去全局队列拿 G 的时候，都需要上锁，避免同样的任务被多次拿。\n\n如果全局队列都被拿完了，而当前 M 也没有更多的 G 可以执行的时候，它就会去其他 P 的本地队列中拿任务，这个机制被称之为 work stealing 机制，每次会拿走一半的任务，向下取整，比如另一个 P 中有 3 个任务，那一半就是一个任务。\n\n当全局队列为空，M 也没办法从其他的 P 中拿任务的时候，就会让自身进入自选状态，等待有新的 G 进来。最多只会有 GOMAXPROCS 个 M 在自旋状态，过多 M 的自旋会浪费 CPU 资源。\n\n## 阻塞\n\nchannel 的读写操作、等待锁、等待网络数据、系统调用等都有可能发生阻塞，会调用底层函数 `runtime.gopark()`，会让出 CPU 时间片，让调度器安排其它等待的任务运行，并在下次某个时候从该位置恢复执行。\n\n当调用该函数之后，goroutine 会被设置成 `waiting` 状态\n\n## 唤醒\n\n处于 waiting 状态的 goroutine，在调用 `runtime.goready()` 函数之后会被唤醒，唤醒的 goroutine 会被重新放到 M 对应的上下文 P 对应的 runqueue 中，等待被调度。\n\n当调用该函数之后，goroutine 会被设置成 `runnable` 状态\n\n## 退出\n\n当 goroutine 执行完成后，会调用底层函数 `runtime.Goexit()`\n\n当调用该函数之后，goroutine 会被设置成 `dead` 状态\n\n# Go goroutine 和线程的区别?\n\n| goroutine | 线程 |  |\n| :--: | ---- | ---- |\n| 内存占用 | 创建一个 goroutine 的栈内存消耗为 2 KB，实际运行过程中，如果栈空间不够用，会自动进行扩容 | 创建一个线程的栈内存消耗为 1 MB |\n| 创建和销毀 | goroutine 因为是由 Go runtime 负责管理的，创建和销毁的消耗非常小，是用户级。 | 线程创建和销毀都会有巨大的消耗，因为要和操作系统打交道，是内核级的，通常解决的办法就是线程池 |\n| 切换 | goroutines 切换只需保存三个寄存器：PC、SP、BP goroutine 的切换约为 200 ns，相当于 2400-3600 条指令。 | 当线程切换时，需要保存各种寄存器，以便恢复现场。线程切换会消耗 1000-1500 ns，相当于 12000-18000 条指令。 |\n\n# Go goroutine 泄露的场景?\n\n## 泄露原因\n\n- Goroutine 内进行 channel/mutex 等读写操作被一直阻塞。\n- Goroutine 内的业务逻辑进入死循环，资源一直无法释放。\n- Goroutine 内的业务逻辑进入长时间等待，有不断新增的 Goroutine 进入等待\n\n## 泄露场景\n\n如果输出的 goroutines 数量是在不断增加的，就说明存在泄漏\n\n**nil channel**\n\nChannel 如果忘记初始化，那么无论你是读，还是写操作，都会造成阻塞。\n\n```\nfunc main() {\n    fmt.Println(\"before goroutines: \", runtime.NumGoroutine())\n    block1()\n    time.Sleep(time.Second * 1)\n    fmt.Println(\"after goroutines: \", runtime.NumGoroutine())\n}\n\nfunc block1() {\n    var ch chan int\n    for i := 0; i \u003c 10; i++ {\n        go func() {\n            \u003c-ch\n        }()\n    }\n}\n```\n\n输出结果：\n\n```\nbefore goroutines:  1\nafter goroutines:  11\n```\n\n**发送不接收**\n\nChannel 发送数量超过 channel 接收数量，就会造成阻塞\n\n```\nfunc block2() {\n    ch := make(chan int)\n    for i := 0; i \u003c 10; i++ {\n        go func() {\n            ch \u003c- 1\n        }()\n    }\n}\n```\n\n**接收不发送**\n\nChannel 接收数量超过 channel 发送数量，也会造成阻塞\n\n```\nfunc block3() {\n    ch := make(chan int)\n    for i := 0; i \u003c 10; i++ {\n        go func() {\n            \u003c-ch\n        }()\n    }\n}\n```\n\n**http request body 未关闭**\n\n`resp.Body.Close()` 未被调用时，goroutine 不会退出\n\n```\nfunc requestWithNoClose() {\n    _, err := http.Get(\"https://www.baidu.com\")\n    if err != nil {\n        fmt.Println(\"error occurred while fetching page, error: %s\", err.Error())\n    }\n}\n\nfunc requestWithClose() {\n    resp, err := http.Get(\"https://www.baidu.com\")\n    if err != nil {\n        fmt.Println(\"error occurred while fetching page, error: %s\", err.Error())\n        return\n    }\n    defer resp.Body.Close()\n}\n\nfunc block4() {\n    for i := 0; i \u003c 10; i++ {\n        wg.Add(1)\n        go func() {\n                defer wg.Done()\n                requestWithNoClose()\n        }()\n    }\n}\n\nvar wg = sync.WaitGroup{}\n\nfunc main() {\n    block4()\n    wg.Wait()\n}\n```\n\n一般发起 http 请求时，需要确保关闭 body\n\n```\ndefer resp.Body.Close()\n```\n\n**互斥锁忘记解锁**\n\n第一个协程获取 `sync.Mutex` 加锁了，但是他可能在处理业务逻辑，又或是忘记 `Unlock` 了。\n\n因此导致后面的协程想加锁，却因锁未释放被阻塞了\n\n```\nfunc block5() {\n    var mutex sync.Mutex\n    for i := 0; i \u003c 10; i++ {\n        go func() {\n            mutex.Lock()\n        }()\n    }\n}\n```\n\n**sync. WaitGroup 使用不当**\n\n由于 `wg.Add` 的数量与 `wg.Done` 数量并不匹配，因此在调用 `wg.Wait` 方法后一直阻塞等待\n\n```\nfunc block6() {\n    var wg sync.WaitGroup\n    for i := 0; i \u003c 10; i++ {\n        go func() {\n            wg.Add(2)\n            wg.Done()\n            wg.Wait()\n        }()\n    }\n}\n```\n\n## 如何排查\n\n单个函数：调用 `runtime.NumGoroutine` 方法来打印执行代码前后 Goroutine 的运行数量，进行前后比较，就能知道有没有泄露了。\n\n生产/测试环境：使用 `PProf` 实时监测 Goroutine 的数量\n\n# Go 如何查看正在执行的 goroutine 数量?\n\n## 程序中引入 pprof package\n\n在程序中引入 pprof package：\n\n```\nimport _ \"net/http/pprof\"\n```\n\n程序中开启 HTTP 监听服务：\n\n```\npackage main\n\nimport (\n    \"net/http\"\n    _ \"net/http/pprof\"\n)\n\nfunc main() {\n\n    for i := 0; i \u003c 100; i++ {\n        go func() {\n            select {}\n        }()\n    }\n\n    go func() {\n        http.ListenAndServe(\"localhost:6060\", nil)\n    }()\n\n    select {}\n}\n```\n\n## 分析 goroutine 文件\n\n在命令行下执行：\n\n```\ngo tool pprof -http=:1248 http://127.0.0.1:6060/debug/pprof/goroutine\n```\n\n会自动打开浏览器页面如下图所示\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240226001403.png)\n\n\n在图中可以清晰的看到 goroutine 的数量以及调用关系，可以看到有 103 个 goroutine\n\n# Go 如何控制并发的 goroutine 数量?\n\n## **为什么要控制 goroutine 并发的数量？**\n\n在开发过程中，如果不对 goroutine 加以控制而进行滥用的话，可能会导致服务整体崩溃。比如耗尽系统资源导致程序崩溃，或者 CPU 使用率过高导致系统忙不过来。\n\n## **用什么方法控制 goroutine 并发的数量？**\n\n**有缓冲 channel**\n\n利用缓冲满时发送阻塞的特性\n\n```\npackage main\n\nimport (\n    \"fmt\"\n    \"runtime\"\n    \"time\"\n)\n\nvar wg = sync.WaitGroup{}\n\nfunc main() {\n    // 模拟用户请求数量\n    requestCount := 10\n    fmt.Println(\"goroutine_num\", runtime.NumGoroutine())\n    // 管道长度即最大并发数\n    ch := make(chan bool, 3)\n    for i := 0; i \u003c requestCount; i++ {\n        wg.Add(1)\n        ch \u003c- true\n        go Read(ch, i)\n    }\n\n     wg.Wait()\n}\n\nfunc Read(ch chan bool, i int) {\n    fmt.Printf(\"goroutine_num: %d, go func: %d\\n\", runtime.NumGoroutine(), i)\n    \u003c-ch\n    wg.Done()\n}\n```\n\n输出结果：默认最多不超过 3（4-1）个 goroutine 并发执行\n\n\n```\ngoroutine_num 1\ngoroutine_num: 4, go func: 1\ngoroutine_num: 4, go func: 3\ngoroutine_num: 4, go func: 2\ngoroutine_num: 4, go func: 0\ngoroutine_num: 4, go func: 4\ngoroutine_num: 4, go func: 5\ngoroutine_num: 4, go func: 6\ngoroutine_num: 4, go func: 8\ngoroutine_num: 4, go func: 9\ngoroutine_num: 4, go func: 7\n```\n\n\n**无缓冲 channel**\n\n任务发送和执行分离，指定消费者并发协程数\n\n```\npackage main\n\nimport (\n    \"fmt\"\n    \"runtime\"\n    \"sync\"\n)\n\nvar wg = sync.WaitGroup{}\n\nfunc main() {\n    // 模拟用户请求数量\n    requestCount := 10\n    fmt.Println(\"goroutine_num\", runtime.NumGoroutine())\n    ch := make(chan bool)\n    for i := 0; i \u003c 3; i++ {\n        go Read(ch, i)\n    }\n\n    for i := 0; i \u003c requestCount; i++ {\n        wg.Add(1)\n        ch \u003c- true\n    }\n\n    wg.Wait()\n}\n\nfunc Read(ch chan bool, i int) {\n    for _ = range ch {\n        fmt.Printf(\"goroutine_num: %d, go func: %d\\n\", runtime.NumGoroutine(), i)\n        wg.Done()\n    }\n}\n```\n\n\n\n\n\n\n# 开五个协程，全部执行一个函数，怎么保证协程执行完全部打印\n\n```\npackage main\n\nimport (\n\t\"fmt\"\n\t\"sync\"\n)\n\nfunc main() {\n\tvar wg sync.WaitGroup\n\twg.Add(5) // 设置等待的协程数量\n\n\tfor i := 0; i \u003c 5; i++ {\n\t\tgo func(i int) {\n\t\t\tdefer wg.Done() // 每个协程执行完成后调用 wg.Done() 减少计数\n\n\t\t\t// 执行你的函数\n\t\t\t// 这里可以替换为你的具体函数逻辑\n\t\t\tfmt.Println(\"执行协程\", i)\n\t\t}(i)\n\t}\n\twg.Wait() // 等待所有协程执行完成\n\tfmt.Println(\"所有协程执行完毕\")\n}\n```\n\n# 用 Channel 和两个协程实现数组相加\n\n```\npackage main\nimport \"fmt\"\n\n//用channel和两个goroutine实现数组相加\nfunc add(a, b []int) []int {\n\tch := make(chan int)\n\tc := make([]int,len(a))\n\tgo func() {\n\t\tfor _,v := range a{\n\t\t\tch \u003c- v\n\t\t}\n\t}()\n\tgo func() {\n\t\tfor i,t := range b{\n\t\t\ttemp := \u003c- ch\n\t\t\tc[i] = temp+t\n\t\t}\n\t}()\n\treturn c\n}\n\nfunc main()  {\n\ta := []int{2,4,6,8}\n\tb := []int{1,3,5,7}\n\tans := add(a,b)\n\tfmt.Println(ans)\n}\n```\n\n# 2 个协程交替打印字母和数字\n\n```\npackage main\n\nimport (\n\t\"fmt\"\n)\n\nfunc main() {\n\tlimit := 26\n\n\tnumChan := make(chan int, 1)\n\tcharChan := make(chan int, 1)\n\tmainChan := make(chan int, 1)\n\tcharChan \u003c- 1\n\n\tgo func() {\n\t\tfor i := 0; i \u003c limit; i++ {\n\t\t\t\u003c-charChan\n\t\t\tfmt.Printf(\"%c\\n\", 'a'+i)\n\t\t\tnumChan \u003c- 1\n\n\t\t}\n\t}()\n\tgo func() {\n\t\tfor i := 0; i \u003c limit; i++ {\n\t\t\t\u003c-numChan\n\t\t\tfmt.Println(i)\n\t\t\tcharChan \u003c- 1\n\n\t\t}\n\t\tmainChan \u003c- 1\n\t}()\n\t\u003c-mainChan\n\tclose(charChan)\n\tclose(numChan)\n\tclose(mainChan)\n}\n```\n\n# 为什么不要大量使用 goroutine\n\n1、过多会占有太多的 cpu 资源和内存，可能使系统资源耗尽\n\n2、因为 GMP, M 和 P 都是有数量限制的，如果调度队列过长，也会影响性能；\n\n3、频繁 GC 也会影响性能；\n\n4、内存占用, 不好管理，容易资源泄漏或者死锁\n\n# Golang 中除了加 Mutex 锁以外还有哪些方式安全读写共享变量？\n\nGolang 中 Goroutine 可以通过 Channel 进行安全读写共享变量。\n\n# Golang Panic 子 Goroutine 发生 panic，主进程会 panic 吗？\n\n虽然 Goroutine 能够实现高并发，但是如果某个 Goroutine panic 了，而且这个 Goroutine 里面没有捕获 recover，那么整个进程就会挂掉。\n\n# 并行 goroutine 如何实现\n\n通过设置最大的可同时使用的 CPU 核数，例如同时执行两个 goroutine, 设置 runtime.GOMAXPROCS (2), 用来实现 goroutine 并行。\n\n# 协程中参数直接使用，和传参的区别是什么，为什么会造成这种结果\n\n以一个例子说明\n\n**直接使用**\n\n```\nfunc main() {\n    wg := sync.WaitGroup{}\n    for i := 0; i \u003c 10; i++ {\n        wg.Add(1)\n        go func(ctx,func(ctx context.Context) {\n            fmt.Println(i)\n            wg.Done()\n    \t})\n\n    }\n    wg.Wait()\n}\n```\n\n执行输出结果\n\n\n```\n10 10 10 10 10 10 10 10 10 10\n```\n\n\n**传参使用**\n\n```\nfunc main() {\n    wg := sync.WaitGroup{}\n    for i := 0; i \u003c 10; i++ {\n    wg.Add(1)\n    go func(ctx,func(ctx context.Context) {\n        fmt.Println(i)\n        wg.Done()\n        })(i)\n    }\n   wg.Wait()\n}\n```\n\n执行输出结果\n\n\n```\n0 9 3 4 5 6 7 8 1 2\n```\n\n\n产生这种结果的原因是，对于一部协程来说，函数在执行异步执行注册时，该函数并未真正开始执行注册时只在 goroutine 的栈中保存了变量 i 的内存地址，而一旦开始执行函数时才会去读取变量 i 的值，而这时变量 i 的值已经自增到了 10，改进的方案就是在注册异步执行函数的时候，把变量的值也一并传递获取，或者吧当前变量 i 的值赋值给一个不会改变的临时变量中，在函数中使用该临时变量而不是直接使用 i\n\n# Go 中用 for 遍历多次执行 goroutine 会存在什么问题\n\n程序会 panic: too many open files  \n解决的方法: 通过带缓冲的 channel 和 sync. Waitgroup 控制协程并发量。\n\n# Go 里面一个协程能保证绑定在一个内核线程上面的。\n\n协程是用户级的线程，对内核是透明的，系统并不知道协程的存在，并且协程是非抢占式调度，无法实现公平的任务调用，通常只进行协作式调度，需要协程自己主动把控制权转让出去之后，其他协程才能被执行到。  \nGo Scheduler 会把 goroutine 调度到逻辑处理器上运行，逻辑处理器会一对一的绑定到操作系统的线程。当 goroutine 可以运行时，会被放入一个逻辑处理器的待执行队列中；当 goroutine 遇到长时间执行或执行了一个阻塞的系统调用时（如打开文件），Go Scheduler 会将这个逻辑处理器与线程分离，并将另一个线程绑定到这个逻辑处理器，之后从待执行队列中选择下一个 goroutine 来运行，原来的 goroutine 保存到待执行队列等待调用（逻辑处理器是不动的）。\n\n# 协程池的使用\n\n```\nvar (\n    ctx = gctx.New()\n)\n\nfunc main() {\n    wg := sync.WaitGroup{}\n    for i := 0; i \u003c 10; i++ {\n        wg.Add(1)\n        v := i\n        grpool.Add(ctx, func(ctx context.Context) {\n            fmt.Println(v)\n            wg.Done()\n        })\n    }\n    wg.Wait()\n}\n```\n\n**自主实现**\n\n```\npackage main\n\nimport (\n  \"fmt\"\n  \"runtime\"\n  \"sync\"\n  \"time\"\n)\n\n// Task 任务接口\ntype Task interface {\n  Execute()\n}\n\n// Pool 协程池\ntype Pool struct {\n  TaskChannel chan Task // 任务队列\n}\n\n// NewPool 创建一个协程池\nfunc NewPool(cap ...int) *Pool {\n  // 获取 worker 数量\n  var n int\n  if len(cap) \u003e 0 {\n    n = cap[0]\n  }\n  if n == 0 {\n    n = runtime.NumCPU()\n  }\n\n  p := \u0026Pool{\n    TaskChannel: make(chan Task),\n  }\n\n  // 创建指定数量 worker 从任务队列取出任务执行\n  for i := 0; i \u003c n; i++ {\n    go func() {\n      for task := range p.TaskChannel {\n        task.Execute()\n      }\n    }()\n  }\n  return p\n}\n\n// Submit 提交任务\nfunc (p *Pool) Submit(t Task) {\n  p.TaskChannel \u003c- t\n}\n\n// EatFood 吃饭任务\ntype EatFood struct {\n  wg *sync.WaitGroup\n}\n\nfunc (e *EatFood) Execute() {\n  defer e.wg.Done()\n  fmt.Println(\"eat cost 3 seconds\")\n  time.Sleep(3 * time.Second)\n}\n\n// WashFeet 洗脚任务\ntype WashFeet struct {\n  wg *sync.WaitGroup\n}\n\nfunc (w *WashFeet) Execute() {\n  defer w.wg.Done()\n  fmt.Println(\"wash feet cost 3 seconds\")\n  time.Sleep(3 * time.Second)\n}\n\n// WatchTV 看电视任务\ntype WatchTV struct {\n  wg *sync.WaitGroup\n}\n\nfunc (w *WatchTV) Execute() {\n  defer w.wg.Done()\n  fmt.Println(\"watch tv cost 3 seconds\")\n  time.Sleep(3 * time.Second)\n}\n\nfunc main() {\n  p := NewPool()\n  var wg sync.WaitGroup\n  wg.Add(3)\n  task1 := \u0026EatFood{\n    wg: \u0026wg,\n  }\n  task2 := \u0026WashFeet{\n    wg: \u0026wg,\n  }\n  task3 := \u0026WatchTV{\n    wg: \u0026wg,\n  }\n  p.Submit(task1)\n  p.Submit(task2)\n  p.Submit(task3)\n  // 等待所有任务执行完成\n  wg.Wait()\n}\n```\n\n#  Go 源码：协程栈\n\n[https://segmentfault.com/a/1190000019570427](https://segmentfault.com/a/1190000019570427) \n\n# Go 如何关闭 goroutine\n\n1. 关闭 channel\n\n第一种方法，就是借助 channel 的 close 机制来完成对 goroutine 的精确控制。  \n在 Go 语言的 channel 中，channel 接受数据有两种方法：  \nMsg := \u003c-ch  \nMsg, ok := \u003c-ch  \n这两种方式对应着不同的 runtime 方法，我们可以利用其第二个参数进行判别，当关闭 channel 时，就根据其返回结果跳出。\n\n2. 定期轮询 channel\n\n第二种方法，是更为精细的方法，其结合了第一种方法和类似信号量的处理方式。  \n而 goroutine 的关闭是不知道什么时候发生的，因此在 Go 语言中会利用 for-loop 结合 select 关键字进行监听，再进行完毕相关的业务处理后，再调用 close 方法正式关闭 channel。  \n若程序逻辑比较简单结构化，也可以不调用 close 方法，因为 goroutine 会自然结束，也就不需要手动关闭了。\n\n3. 使用 context\n\n可以借助 Go 语言的上下文（context）来做 goroutine 的控制和关闭。  \n在 context 中，我们可以借助 ctx. Done 获取一个只读的 channel，类型为结构体。可用于识别当前 channel 是否已经被关闭，其原因可能是到期，也可能是被取消了。  \n因此 context 对于跨 goroutine 控制有自己的灵活之处，可以调用 context. WithTimeout 来根据时间控制，也可以自己主动地调用 cancel 方法来手动关闭。\n\n# 父 goroutine 退出，如何使得子 goroutine 也退出？\n\n父子协程的退出分为两种情况：\n\n- 当父协程是 main 协程时，父协程退出，父协程下的所有子协程也会跟着退出；\n- 当父协程不是 main 协程时，父协程退出，父协程下的所有子协程并不会跟着退出（子协程直到自己的所有逻辑执行完或者是 main 协程结束才结束）\n\n这时候就需要使子协程退出，`context` 就登场了：  \n`context` 主要用于父子任务之间的同步取消信号，本质上是一种协程调度的方式。\n\n```\ntype Context interface {\n \n    Deadline() (deadline time.Time, ok bool)\n \n    Done() \u003c-chan struct{}\n \n    Err() error\n \n    Value(key interface{}) interface{}\n}\n```\n\nContext. Context 是 Go 语言在 1.7 版本中引入标准库的接口，该接口定义了四个需要实现的方法，其中包括：\n\n1. Deadline — 返回 context. Context 被取消的时间，也就是完成工作的截止日期；\n2. Done — 返回一个 Channel，这个 Channel 会在当前工作完成或者上下文被取消后关闭，多次调用 Done 方法会返回同一个 Channel；\n    1. Err — 返回 context. Context 结束的原因，它只会在 Done 方法对应的 Channel 关闭时返回非空的值；\n    2. 如果 context. Context 被取消，会返回 Canceled 错误；\n3. 如果 context. Context 超时，会返回 DeadlineExceeded 错误；\n4. Value — 从 context. Context 中获取键对应的值，对于同一个上下文来说，多次调用 Value 并传入相同的 Key 会返回相同的结果，该方法可以用来传递请求特定的数据；\n\n# 一个线程打印奇数一个线程打印偶数交替打印\n\n```\npackage main\n \nimport (\n    \"fmt\"\n    \"time\"\n)\n \nvar num = 100\n \nfunc goroutine1(p chan int) {\n    for i := 1; i \u003c= num; i++ {\n        p \u003c- i\n        if i%2 == 1 {\n            fmt.Println(\"goroutine-1:\", i)\n        }\n    }\n}\n \nfunc goroutine2(p chan int) {\n    for i := 1; i \u003c= num; i++ {\n        \u003c-p\n        if i%2 == 0 {\n            fmt.Println(\"goroutine-2:\", i)\n        }\n    }\n}\n \nfunc main() {\n    msg := make(chan int)\n \n    go goroutine1(msg)\n    go goroutine2(msg)\n \n    time.Sleep(time.Second * 1)\n```\n\n# Goroutine 和 kernel thread 之间是什么关系？\n\n在进程被划分为更小的线程后，线程成为了**最小的调度单元**，也是在 CPU 上**执行的最小单元**\n\n操作系统将内存空间划分为**内核空间**和**用户空间**，\n\n由于**用户级线程**一般使用线程库来模拟线程且**对操作系统保持透明**，因此对操作系统而言只能调度内核空间中的**内核级线程**\n\n内核级线程 **kernel thread** 简称 **KSE**\n\n由此可以将内核级线程视作用户级线程上 CPU 运行的**机会**\n\n![none](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticnone.png)\n\n对于传统的内核级线程和用户线程，有**一对一**、**一对多**和**多对多**三种模型\n\n对于同一进程内的用户级线程切换，不需要切换上下文也无需额外开销\n\n对于不同进程内的用户级线程切换，要切换进程的上下文，开销较大\n\n![image-20220417135413988](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticimage-20220417135413988.png)\n\n在 go 中使用 goroutine，而 goroutine 是 go 中实现的**用户级线程**\n\n因此一般来看 go 中的线程调度应该如左图所示\n\n在 go 中使用 GMP 模型，其中 P (processor) 专门管理一个 goroutine 的队列，实际情况如右图所示\n\n![none](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticnone-1.png)\n\n总结：goroutine 依靠 kernel thread 执行\n\n#  协程实现顺序打印 123\n\n```\npackage main\n\nimport \"fmt\"\n\nvar one = make(chan struct{}, 1)\nvar two = make(chan struct{}, 1)\nvar three = make(chan struct{}, 1)\nvar done = make(chan struct{})\n\nfunc PrintOne() {\n\tdefer close(one)\n\tfor i := 0; i \u003c 10; i++ {\n\t\t\u003c-three\n\t\tfmt.Println(\"1\")\n\t\tone \u003c- struct{}{}\n\t}\n}\nfunc PrintTwo() {\n\tdefer close(two)\n\tfor i := 0; i \u003c 10; i++ {\n\t\t\u003c-one\n\t\tfmt.Println(\"2\")\n\t\ttwo \u003c- struct{}{}\n\t}\n}\n\nfunc PrintThere() {\n\tdefer close(three)\n\tfor i := 0; i \u003c 10; i++ {\n\t\t\u003c-two\n\t\tfmt.Println(\"3\")\n\t\tthree \u003c- struct{}{}\n\t}\n\tdone \u003c- struct{}{}\n}\n\nfunc main() {\n\tdefer close(done)\n\tthree \u003c- struct{}{}\n\tgo PrintOne()\n\tgo PrintTwo()\n\tgo PrintThere()\n\t\u003c-done\n}\n```\n\n# 两个协程交替打印 1 到 20\n\n```\npackage main\n\nimport (\n\t\"fmt\"\n\t\"sync\"\n\t\"time\"\n)\n\n\nfunc main() {\n\twg := \u0026sync.WaitGroup{}\n\tch1 := make(chan int)\n\tch2 := make(chan int)\n\n\twg.Add(2)\n\tgo say(wg, ch2, ch1)\n\tgo say1(wg, ch1, ch2)\n\twg.Wait()\n\ttime.Sleep(1 * time.Second)\n}\n\nfunc say(wg *sync.WaitGroup, ch2 chan int, ch1 chan int) {\n\tdefer wg.Done()\n\tfor i := 1; i \u003c= 10; i++ {\n\t\tch2 \u003c- 2*i - 1\n\t\tfmt.Println(\u003c-ch1)\n\t}\n}\n\nfunc say1(wg *sync.WaitGroup, ch1 chan int, ch2 chan int) {\n\tdefer wg.Done()\n\tfor i := 1; i \u003c= 10; i++ {\n\t\tfmt.Println(\u003c-ch2)\n\t\tch1 \u003c- 2 * i\n\t}\n}\n```\n\n# 两个协程交替打印一个数组，使数组中的数据按顺序输出\n\n```\npackage main\n\nimport (\n\t\"fmt\"\n\t\"sync\"\n)\n\nvar wg sync.WaitGroup\n\nfunc worker1(ch chan struct{}, data chan interface{}) {\n\tdefer wg.Done()\n\n\tfor {\n\t\tselect {\n\t\tcase \u003c-ch:\n\t\t\ttmp := \u003c-data\n\t\t\t//更清楚看见输出！\n\t\t\ttime.Sleep(time.Second * 1)\n\t\t\tfmt.Printf(\"%v \", tmp)\n\t\t\tch \u003c- struct{}{} //发送信号\n\t\tdefault:\n\t\t}\n\t}\n}\n\nfunc worker2(ch chan struct{}, data chan interface{}) {\n\tdefer wg.Done()\n\tch \u003c- struct{}{} // 先发送信号\n\n\tfor {\n\t\tselect {\n\t\tcase \u003c-ch:\n\t\t\ttmp := \u003c-data\n\t\t\ttime.Sleep(time.Second * 1) \n\t\t\tfmt.Printf(\"%v \", tmp)\n\t\t\tch \u003c- struct{}{} //发送信号\n\t\tdefault:\n\t\t}\n\t}\n}\n\nfunc main() {\n\tdone := make(chan struct{})\n\tdata := make(chan interface{})\n\twg.Add(1)\n\tgo func() {\n\t\tdefer wg.Done()\n\t\t/*s1 := []int{1, 2, 3, 4, 5, 6}*/\n\t\ts1 := []string{\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"}\n\t\tfor _, v := range s1 {\n\t\t\tdata \u003c- v\n\t\t}\n\t}()\n\twg.Add(2)\n\tgo worker1(done, data)\n\tgo worker2(done, data)\n\n\twg.Wait()\n}\n```\n","lastmodified":"2024-02-25T17:02:23.022964011Z","tags":[]},"/GO/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B9%B6%E5%8F%91%E5%8E%9F%E8%AF%AD/%E9%98%9F%E5%88%97%E6%A0%85%E6%A0%8F%E5%92%8CSTM":{"title":"队列、栅栏和STM","content":"","lastmodified":"2024-02-25T17:02:23.022964011Z","tags":[]},"/GO/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B9%B6%E5%8F%91%E5%8E%9F%E8%AF%AD/Leader%E9%80%89%E4%B8%BE%E4%BA%92%E6%96%A5%E9%94%81%E5%92%8C%E8%AF%BB%E5%86%99%E9%94%81":{"title":"Leader选举互斥锁和读写锁","content":"","lastmodified":"2024-02-25T17:02:23.022964011Z","tags":[]},"/GO/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C/atomic":{"title":"atomic","content":"","lastmodified":"2024-02-25T17:02:23.022964011Z","tags":[]},"/GO/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E5%9F%BA%E7%A1%80%E5%B9%B6%E5%8F%91%E5%8E%9F%E8%AF%AD/Cond":{"title":"Cond","content":"","lastmodified":"2024-02-25T17:02:23.022964011Z","tags":[]},"/GO/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E5%9F%BA%E7%A1%80%E5%B9%B6%E5%8F%91%E5%8E%9F%E8%AF%AD/Context":{"title":"Context","content":"","lastmodified":"2024-02-25T17:02:23.022964011Z","tags":[]},"/GO/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E5%9F%BA%E7%A1%80%E5%B9%B6%E5%8F%91%E5%8E%9F%E8%AF%AD/Mutex":{"title":"Mutex","content":"","lastmodified":"2024-02-25T17:02:23.022964011Z","tags":[]},"/GO/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E5%9F%BA%E7%A1%80%E5%B9%B6%E5%8F%91%E5%8E%9F%E8%AF%AD/Once":{"title":"Once","content":"","lastmodified":"2024-02-25T17:02:23.022964011Z","tags":[]},"/GO/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E5%9F%BA%E7%A1%80%E5%B9%B6%E5%8F%91%E5%8E%9F%E8%AF%AD/Pool":{"title":"Pool","content":"","lastmodified":"2024-02-25T17:02:23.022964011Z","tags":[]},"/GO/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E5%9F%BA%E7%A1%80%E5%B9%B6%E5%8F%91%E5%8E%9F%E8%AF%AD/RWMutex":{"title":"RWMutex","content":"","lastmodified":"2024-02-25T17:02:23.022964011Z","tags":[]},"/GO/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E5%9F%BA%E7%A1%80%E5%B9%B6%E5%8F%91%E5%8E%9F%E8%AF%AD/WaitGroup":{"title":"WaitGroup","content":"","lastmodified":"2024-02-25T17:02:23.022964011Z","tags":[]},"/GO/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E5%9F%BA%E7%A1%80%E5%B9%B6%E5%8F%91%E5%8E%9F%E8%AF%AD/map":{"title":"map","content":"","lastmodified":"2024-02-25T17:02:23.022964011Z","tags":[]},"/GO/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E5%BC%80%E7%AF%87%E8%AF%8D":{"title":"开篇词","content":"\n参考 https://time.geekbang.org/column/article/294849\n\n# 为啥选择 Go\n\n* Go 的简单高效\n* 并发编程的便利性\n* GO 生态圈微服务框架的发展\n\n# 学习 Go 并发编程的困难\n\n* 无从下手\n* 最优解选择困难\n* 并发任务编排困难\n* 程序 panic 或者死锁排查困难\n* 负责并发问题处理困难 \n\n#  提升 GO 并发编程能力\n\n![image.png](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statistic20240107213310.png)\n## 知识主线\n* 基础并发原语\n\t* [Mutex](GO/并发编程/基础并发原语/Mutex.md) \n\t* [RWMutex](GO/并发编程/基础并发原语/RWMutex.md) \n\t* [WaitGroup](GO/并发编程/基础并发原语/WaitGroup.md) \n\t* [Cond](GO/并发编程/基础并发原语/Cond.md) \n\t* [Once](GO/并发编程/基础并发原语/Once.md) \n\t* [map](GO/并发编程/基础并发原语/map.md) \n\t* [Pool](GO/并发编程/基础并发原语/Pool.md) \n\t* [Context](GO/并发编程/基础并发原语/Context.md) \n* 原子操作 \n\t* [atomic](GO/并发编程/原子操作/atomic.md) \n* Channel \n\t* [channel](GO/并发编程/Channel/channel.md) \n* 扩展并发原语\n\t* [Semaphore-信号量](GO/并发编程/扩展并发原语/Semaphore-信号量.md) \n\t* [SingleFlight 和 CyclicBarrier-请求合并和循环栅栏](GO/并发编程/扩展并发原语/SingleFlight%20和%20CyclicBarrier-请求合并和循环栅栏.md) \n* 分布式并发原语\n\t* [Leader选举互斥锁和读写锁](GO/并发编程/分布式并发原语/Leader选举互斥锁和读写锁.md) \n\t* [队列、栅栏和STM](GO/并发编程/分布式并发原语/队列、栅栏和STM.md) \n\n## 学习主线\n\n* 基础用法 \n\t* Go 中有一个大的方向，就是任务编排用 Channel，共享资源保护用传统并发原语。\n* 实现原理 \n* 易错场景 \n* 知名项目中的 bug \n\n## 掌握武器 \n\n* 建立丰富的并发原语库\n* 熟系每一种并发原语的实现机制和适用场景\n* 创造自己需要的并发原语","lastmodified":"2024-02-25T17:02:23.022964011Z","tags":[]},"/GO/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E6%89%A9%E5%B1%95%E5%B9%B6%E5%8F%91%E5%8E%9F%E8%AF%AD/%E5%88%86%E7%BB%84%E6%93%8D%E4%BD%9C":{"title":"分组操作","content":"","lastmodified":"2024-02-25T17:02:23.022964011Z","tags":[]},"/GO/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E6%89%A9%E5%B1%95%E5%B9%B6%E5%8F%91%E5%8E%9F%E8%AF%AD/Semaphore-%E4%BF%A1%E5%8F%B7%E9%87%8F":{"title":"Semaphore-信号量","content":"","lastmodified":"2024-02-25T17:02:23.022964011Z","tags":[]},"/GO/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/%E6%89%A9%E5%B1%95%E5%B9%B6%E5%8F%91%E5%8E%9F%E8%AF%AD/SingleFlight-%E5%92%8C-CyclicBarrier-%E8%AF%B7%E6%B1%82%E5%90%88%E5%B9%B6%E5%92%8C%E5%BE%AA%E7%8E%AF%E6%A0%85%E6%A0%8F":{"title":"SingleFlight 和 CyclicBarrier-请求合并和循环栅栏","content":"","lastmodified":"2024-02-25T17:02:23.022964011Z","tags":[]},"/GO/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/Channel/channel":{"title":"channel","content":"","lastmodified":"2024-02-25T17:02:23.022964011Z","tags":[]},"/Java/Spring/Spring-cloud/spring-cloud-alibaba":{"title":"spring cloud alibaba","content":"* 官网  [spring cloud alibaba ](https://sca.aliyun.com/zh-cn/)\n* ","lastmodified":"2024-02-25T17:02:23.026964Z","tags":[]},"/Java/netty/%E4%BC%A0%E8%BE%93%E5%92%8CChannel":{"title":"传输和Channel","content":"在某些时候，你需要支撑比预期多很多的并发连接。如果你随后尝试从阻塞传输切换到非阻塞传输，那么你可能会因为这两种网络 API 的截然不同而遇到问题。\n\n**Netty 为它所有的传输实现提供了一个通用 API，这使得这种转换比你直接使用 JDK 所能够达到的简单得多。**\n\n# 传输方式\n\n- OIO\n    \n- NIO\n    \n- AIO\n    \n\n  \n\n# Channel\n\n传输 API 的核心是 interface Channel，它被用于所有的 I/O 操作\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-670.png)\n\n- 每个 Channel 都将会被分配一个 ChannelPipeline 和 ChannelConfig。\n    \n    - ChannelConfig 包含了该 Channel 的所有配置设置，并且支持热更新。由于特定的传输可能 具有独特的设置，所以它可能会实现一个 ChannelConfig 的子类型。\n        \n- 由于 Channel 是独一无二的，所以为了保证顺序将 Channel 声明为 java.lang.Comparable 的一个子接口\n    \n- ChannelPipeline **持有所有将应用于入站和出站数据以及事件的 ChannelHandler实例**，这些 ChannelHandler 实现了应用程序用于处理状态变化以及数据处理的逻辑\n    \n    - ChannelHandler 的典型用途包括：\n        \n        -  将数据从一种格式转换为另一种格式；\n            \n        -  提供异常的通知；\n            \n        -  提供 Channel 变为活动的或者非活动的通知；\n            \n        -  提供当 Channel 注册到 EventLoop 或者从 EventLoop 注销时的通知；\n            \n        -  提供有关用户自定义事件的通知。\n            \n- 也可以利用 Channel 的其他方法\n    \n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-668.png)\n\nNetty 的 **Channel 实现是线程安全的.**\n\n# NIO\n\n  \n\nNIO 提供了一个所有 I/O 操作的全异步的实现。\n\n选择器背后的基本概念是充当一个注册表，在那里你将可以请求在 Channel 的状态发生变化时得到通知。可能的状态变化有：\n\n-  新的 Channel 已被接受并且就绪；\n    \n-  Channel 连接已经完成；\n    \n-  Channel 有已经就绪的可供读取的数据；\n    \n-  Channel 可用于写数据。\n    \n\n**选择器运行在一个检查状态变化并对其做出相应响应的线程上，在应用程序对状态的改变做出响应之后，选择器将会被重置**，并将重复这个过程\n\n的常量值代表了由class java.nio.channels.SelectionKey定义的位模式。这些位模式可以组合起来定义一组应用程序正在请求通知的状态变化集。\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-669.png)\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-667.png)\n\n# 零拷贝\n\n零拷贝（zero-copy）是一种目前只有在使用 NIO 和 Epoll 传输时才可使用的特性**。它使你可以快速 高效地将数据从文件系统移动到网络接口，而不需要将其从内核空间复制到用户空间，**其在像 FTP 或者 HTTP 这样的协议中可以显著地提升性能。但是，并不是所有的操作系统都支持这一特性。特别地，它对于实现了数据加密或者压缩的文件系统是不可用的——只能传输文件的原始内容。","lastmodified":"2024-02-25T17:02:23.026964Z","tags":[]},"/Java/netty/%E7%BC%96%E8%A7%A3%E7%A0%81%E5%99%A8":{"title":"编解码器","content":"每个网络应用程序都必须定义如何解析在\n\n- **两个节点之间来回传输的原始字节**\n    \n- **其和目标应用程序的数据格式做相互转换**\n    \n\n  \n\n- 编码器是将消息转换为适合于传输的格式（最有可能的就是字节流）；\n    \n- 而对应的解码器则是将网络字节流转换回应用程序的消息格式\n    \n\n  \n\n# 解码器\n\n因为解码器是负责将入站数据从一种格式转换到另一种格式的，所以知道 Netty 的解码器实现了 **ChannelInboundHandler** 也不会让你感到意外。\n\n我们将研究 Netty 所提供的解码器类，并提供关于何时以及如何使用它们的具 体示例。这些类覆盖了两个不同的用例：\n\n- 将字节解码为消息——**ByteToMessageDecoder 和 ReplayingDecoder；**\n    \n- 将一种消息类型解码为另一种——**MessageToMessageDecoder**\n    \n\n  \n\n## ByteToMessageDecoder\n\n将字节解码为消息（或者另一个字节序列）是一项如此常见的任务，以至于 Netty 为它提供了一个抽象的基类：ByteToMessageDecoder\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-750.png)\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-745.png)\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-748.png)\n\n虽然 ByteToMessageDecoder 使得可以很简单地实现这种模式，但是你可能会发现，**在调用 readInt()方法前不得不验证所输入的 ByteBuf 是否具有足够的数据有点繁琐**。在下一节中，\n\n我们将讨论 ReplayingDecoder，它是一个特殊的解码器，以少量的开销消除了这个步骤\n\n  \n\n## ReplayingDecoder\n\nReplayingDecoder扩展了ByteToMessageDecoder类（如代码清单 10-1 所示），使得我们不必调用 readableBytes()方法，它通过使用一个自定义的ByteBuf实现 ，\n\nReplayingDecoderByteBuf，包装传入的ByteBuf实现了这一点，其将在内部执行该调用\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-750.png)\n\n- ByteBuf中提取的int将会被添加到List中。**如果没有足够的字节可用，这个readInt()方法的实现将会抛出一个Error**\n    \n- 并不是所有的 ByteBuf 操作都被支持，如果调用了一个不被支持的方法，将会抛出一个 UnsupportedOperationException；\n    \n- ReplayingDecoder 稍慢于 ByteToMessageDecoder。\n    \n\n  \n\n## MessageToMessageDecoder\n\n```Go\npublic abstract class MessageToMessageDecoder\u003cI\u003e extends ChannelInboundHandlerAdapter\n```\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-750.png)\n\n  \n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-745.png)\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-745.png)\n\n## TooLongFrameException 类\n\n由于 Netty 是一个异步框架，所以需要在字节可以解码之前在内存中缓冲它们。因此，不能让解码器缓冲大量的数据以至于耗尽可用的内存.Netty 提供了TooLongFrameException 类，其将由解码器在帧超出指定的大小限制时抛出。\n\nByteToMessageDecoder 是如何使用 TooLongFrameException 来通知 ChannelPipeline 中的其他 ChannelHandler 发生了帧大小溢出的。\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-745.png)\n\n  \n\n# 编码器\n\n编码器实现了 ChannelOutboundHandler，并将出站数据从一种格式转换为另一种格式，\n\n-  将消息编码为字节；\n    \n-  将消息编码为消息 ①\n    \n\n我们将首先从抽象基类 MessageToByteEncoder 开始来对这些类进行考察。\n\n## MessageToByteEncoder\n\n使 用 MessageToByteEncoder 将消息转化为字节\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-744.png)\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-745.png)\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-743.png)\n\n## MessageToMessageEncoder\n\n数据将如何从一种消息编码为另一种\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-745.png)\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-745.png)\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-726.png)\n\n  \n\n  \n\n# 抽象的编解码\n\n们一直将解码器和编码器作为单独的实体讨论，但是你有时将会发现在同一个类中管理入站和出站数据和消息的转换是很有用的。\n\n这些类同时实现了 ChannelInboundHandler 和 ChannelOutboundHandler 接口。\n\n  \n\n## ByteToMessageCodec\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-728.png)\n\n## MessageToMessageCodec\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-727.png)\n\n## CombinedChannelDuplexHandler\n\n结合一个解码器和编码器可能会对可重用性造成影响。但是，有一 种方法既能够避免这种惩罚，又不会牺牲将一个解码器和一个编码器作为一个单独的单元部署所带来的便利性。CombinedChannelDuplexHandler 提供了这个解决方案\n\n```Go\npublic class CombinedChannelDuplexHandler \u003cI extends ChannelInboundHandler, O extends ChannelOutboundHandler\u003e\n```\n\n这个类充当了 ChannelInboundHandler 和 ChannelOutboundHandler（该类的类型 参数 I 和 O）的容器。\n\n通过提供分别继承了解码器类和编码器类的类型，我们可以实现一个编解码器，**而又不必直接扩展抽象的编解码器类**\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-745.png)\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-745.png)\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-745.png)","lastmodified":"2024-02-25T17:02:23.026964Z","tags":[]},"/Java/netty/1.-%E6%A6%82%E5%BF%B5%E5%92%8C%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84":{"title":"1. 概念和体系结构","content":"# IO 模型\n\n[IO模型详解](https://jovbd87bon.feishu.cn/wiki/wikcnlmBPltNAH5jI0rrD6bpNWf)\n\n  \n\n  \n\n# Java 网络编程\n\n最早期的 Java API（java.net）只支持由本地系统套接字库提供的所谓的阻塞函数\n\n```Java\n//  创建一个新的 ServerSocket，用以 监听指定端口上的连接请求\nServerSocket serverSocket = new ServerSocket(portNumber); \n// 对accept 阻塞，知道创建一个\nSocket clientSocket = serverSocket.accept(); \nBufferedReader in = new BufferedReader(new InputStreamReader(clientSocket.getInputStream())); \nPrintWriter out = new PrintWriter(clientSocket.getOutputStream(), true); \nString request, response; \nwhile ((request = in.readLine()) != null) { \n    if (\"Done\".equals(request)) { \n        break; \n    } \n    response = processRequest(request); \n    out.println(response); \n} \n```\n\n  \n\n# Java Nio\n\n本地套接字库很早就提供了非阻塞调用， 其为网络资源的利用率提供了相当多的控制：\n\n- 可以使用 setsockopt()方法配置套接字，以便读/写调用在没有数据的时候立即返回， 也就是说，如果是一个阻塞调用应该已经被阻塞了① ；\n    \n- 可以使用操作系统的事件通知 API②注册一组非阻塞套接字，以确定它们中是否有任何的套接字已经有数据可供读写。\n    \n\nJava 对于非阻塞 I/O 的支持是在 2002 年引入的，位于 JDK 1.4 的 java.nio 包中\n\n  \n\n## 选择器\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-657.png)\n\nclass java.nio.channels.Selector 是 Java 的非阻塞 I/O 实现的关键。它使用了事件通知 API\n\n以确定在一组非阻塞套接字中有哪些已经就绪能够进 行 I/O 相关的操作。**因为可以在任何的时间检查任意**\n\n**的读操作或者写操作的完成状态，一个单一的线程便可以处理多个并发的连接。**\n\n与阻塞 I/O 模型相比，这种模型提供了更好的资源管理：\n\n- 使用较少的线程便可以处理许多连接，因此也减少了内存管理和上下文切换所带来开销；\n    \n- 当没有 I/O 操作需要处理的时候，线程也可以被用于其他任务。\n    \n\n  \n\n# Netty\n\n在网络编程领域，Netty是Java的卓越框架。 它驾驭了Java高级API的能力，并将其隐藏在一个易于使用的API之后。\n\nNetty 的关键特性\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-665.png)\n\n## Netty 的主要构件块\n\n- Channel；\n    \n- 回调；\n    \n- Future；\n    \n- 事件和 ChannelHandler。\n    \n\n这些构建块代表了不同类型的构造：资源、逻辑以及通知\n\n  \n\n### Channel\n\nChannel 是 Java NIO 的一个基本构造。\n\n\u003e 它代表一个到实体（如一个硬件设备、一个文件、一个网络套接字或者一个能够执行一个或者多个不同的I/O操作的程序组件）的开放连接，如读操作和写操作 ①\n\n**把 Channel 看作是传入（入站）或者传出（出站）数据的载体。因此，它可以被打开或者被关闭，连接或者断开连接。**\n\n### 回调\n\n一个回调其实就是一个方法，**一个指向已经被提供给另外一个方法的方法的引用**。\n\nNetty 在内部使用了回调来处理事件；当一个回调被触发时，相关的事件可以被一个 interface ChannelHandler 的实现处理。\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-663.png)\n\n当一个新的连接已经被建立时，ChannelHandler 的 channelActive()回调方法将会被调用，并将打印出一条信息。\n\n  \n\n### Future\n\nFuture 提供了另一种在操作完成时通知应用程序的方式。这个对象可以看作是一个异步操作的结果的占位符；它将在未来的某个时刻完成，并提供对其结果的访问\n\n- JDK 预置了 interface java.util.concurrent.Future，但是其所提供的实现，只 允许手动检查对应的操作是否已经完成，或者一直阻塞直到它完成。这是非常繁琐的，\n    \n- 所以 Netty 提供了它自己的实现——ChannelFuture，用于在执行异步操作的时候使用\n    \n\n  \n\n- ChannelFuture提供了几种额外的方法，这些方法使得我们能够注册一个或者多个 ChannelFutureListener实例。监听器的回调方法operationComplete()，将会在对应的操作完成时被调用\n    \n- 每个 Netty 的出站 I/O 操作都将返回一个 ChannelFuture；也就是说，它们都不会阻塞。正如我们前面所提到过的一样，Netty 完全是异步和事件驱动的\n    \n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-656.png)\n\n  \n\nChannel 回调的用法\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-662.png)\n\n### 事件和ChannelHandler\n\nNetty 使用不同的事件来通知我们状态的改变或者是操作的状态。这使得我们能够基于已经 =发生的事件来触发适当的动作。\n\nNetty 是一个网络编程框架，所以事件是按照它们与入站或出站数据流的相关性进行分类的。\n\n  \n\n可能由**入站**数据或者相关的状态更改而触发的事件包括：\n\n-  连接已被激活或者连接失活；\n    \n-  数据读取；\n    \n-  用户事件；\n    \n-  错误事件。\n    \n\n**出站事件**是未来将会触发的某个动作的操作结果，这些动作包括：\n\n-  打开或者关闭到远程节点的连接；\n    \n-  将数据写到或者冲刷到套接字。\n    \n\n每个事件都可以被分发给 ChannelHandler 类中的某个用户实现的方法。这是一个很好的将事件驱动范式直接转换为应用程序构件块的例子。\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-664.png)\n\n  \n\n## Netty 的组件和设计\n\n- 首先，它的基于 Java NIO 的异步的和事件驱动的实现，保证了高负载下应用程序 性能的最大化和可伸缩性。\n    \n- 其次，Netty 也包含了一组设计模式，将应用程序逻辑从网络层解耦，简化了开发过程，同时也最大限度地提高了可测试性、模块化以及代码的可重用性。\n    \n\n### Channel\n\nNetty 的 Channel 接 口所提供的 API，大大地降低了直接使用 Socket 类的复杂性。其基本的构造是 class Socket。\n\nChannel 也是拥有许多 预定义的、专门化实现的广泛类层次结构的根，下面是一个简短的部分清单：\n\n- EmbeddedChannel；\n    \n- LocalServerChannel；\n    \n- NioDatagramChannel；\n    \n- NioSctpChannel；\n    \n- NioSocketChannel。\n    \n\n### EventLoop\n\nEventLoop 定义了 Netty 的核心抽象，用于处理连接的生命周期中所发生的事件\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-659.png)\n\nChannel、EventLoop、Thread 以及 EventLoopGroup 之间的关系\n\n- 一个 EventLoopGroup 包含一个或者多个 EventLoop；\n    \n- 一个 EventLoop 在它的生命周期内只和一个 Thread 绑定；\n    \n- 所有由 EventLoop 处理的 I/O 事件都将在它专有的 Thread 上被处理；\n    \n- 一个 Channel 在它的生命周期内只注册于一个 EventLoop；\n    \n- 一个 EventLoop 可能会被分配给一个或多个 Channel。\n    \n\n### ChannelFuture\n\n- Netty 中所有的 I/O 操作都是异步的。因为一个操作可能不会立即返回，所以我们需要一种用于在之后的某个时间点确定其结果的方法。\n    \n- Netty 提供了 ChannelFuture 接口，其 addListener()方法注册了一个 ChannelFutureListener，以便在某个操作完成时（无论是否成功）得到通知。\n    \n\n### ChannelHandler\n\n- 从应用程序开发人员的角度来看，Netty 的主要组件是 ChannelHandler，它充当了所有处理入站和出站数据的应用程序逻辑的容器\n    \n- 事实上，ChannelHandler 可专 门用于几乎任何类型的动作，例如将数据从一种格式转换为另外一种格式，或者处理转换过程中所抛出的异常。\n    \n\n### ChannaelPipeline\n\n- ChannelPipeline 提供了 ChannelHandler 链的容器，并**定义了用于在该链上传播入站和出站事件**流的 API\n    \n- 当 Channel 被创建时，它会被自动地分配到它专属的 ChannelPipeline。\n    \n- ChannelHandler 安装到 ChannelPipeline 中的过程如下所示\n    \n    - 一个ChannelInitializer的实现被注册到了ServerBootstrap中 ① ；\n        \n    - 当 ChannelInitializer.initChannel()方法被调用时，ChannelInitializer将在 ChannelPipeline 中安装一组自定义的 ChannelHandler；\n        \n    - ChannelInitializer **将它自己从 ChannelPipeline 中移除**。\n        \n\n  \n\n从 ChannelHandler 派生的 ChannelInboundHandler 和 ChannelOutboundHandler 接口\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-661.png)\n\n  \n\n- 上面的接口使得事件流经 ChannelPipeline 是 ChannelHandler 的工作，它们是在应用程序的**初始化或者引导阶段被安装的**。\n    \n- 这些对象接收事件、执行它们所实现的处理逻辑，并将数据传递给链中的下一个 ChannelHandler。\n    \n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-658.png)\n\n- 它们的执行顺序是由它们被添加的顺序所决定的。实际上，被我们称为 ChannelPipeline 的是这些 ChannelHandler 的编排顺序\n    \n- 虽然 ChannelInboundHandle 和 ChannelOutboundHandle 都扩展自 ChannelHandler，但是 Netty 能区分 ChannelInboundHandler 实现和 ChannelOutboundHandler 实现，并确保数据只会在具有相同定向类型的两个 ChannelHandler 之间传递。\n    \n- 在 Netty 中，有**两种发送消息的方式。**\n    \n    - 你可以**直接写到 Channel** 中，会导致消息**从Channe-lPipeline 的尾端开始流动**\n        \n    - 也可以写到和 ChannelHandler相关联的**ChannelHandlerContext对象**中将导致消息从 **ChannelPipeline 中的下一个 ChannelHandler 开始流动。**\n        \n\n  \n\n#### 适配器\n\nNetty 以适配器类的形式提供了大量默认的 ChannelHandler 实现，\n\n- 其旨在简化应用程序处理逻辑的开发过程。\n    \n- 你已经看到了，ChannelPipeline中的每个ChannelHandler 将负责把事件转发到链中的下一个 ChannelHandler。这些适配器类（及它们的子类）将自动 执行这个操作，所以你可以只重写那些你想要特殊处理的方法和事件。\n    \n- 常用的适配器\n    \n    -  ChannelHandlerAdapter\n        \n    -  ChannelInboundHandlerAdapter\n        \n    -  ChannelOutboundHandlerAdapter\n        \n    -  ChannelDuplexHandler\n        \n\n  \n\n#### 编解码器\n\n- 通常来说，这些基类的名称将类似于 ByteToMessageDecoder 或 MessageToByteEncoder。\n    \n- 对于特殊的类型，你可能会发现类似于 ProtobufEncoder 和 ProtobufDecoder 这样的名称——预置的用来支持 Google 的 Protocol Buffers。\n    \n- 严格地说，其他的处理器也可以完成编码器和解码器的功能。但是，正如有用来简化ChannelHandler 的创建的适配器类一样，所有由 Netty 提供的编码器/解码器适配器类都实现 ChannelOutboundHandler 或者 ChannelInboundHandler 接口。\n    \n\n  \n\n#### SimpleChannelInboundHandler\n\n- 最常见的情况是，你的应用程序会利用一个 ChannelHandler 来接收解码消息，并对该数据应用业务逻辑。\n    \n- 要创建一个这样的 ChannelHandler,你只需要扩展基类 `SimpleChannelInboundHandler\u003cT\u003e`，其中 T 是你要处理的消息的 Java 类型 。\n    \n    - 在这种类型的 ChannelHandler 中，最重要的方法是 channelRead0(ChannelHandlerContext,T)**。除了要求不要阻塞当前的 I/O 线程之外**，其具体实现完全取决于你\n        \n\n### BootStrap\n\nNetty 的引导类为应用程序的网络层配置提供了容器，\n\n- 这涉及将一个进程绑定到某个指定的端口，ServerBootStrap\n    \n- 或者将一个进程连接到另一个运行在某个指定主机的指定端口上的进程,BootStrap\n    \n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-660.png)\n\n引导一个客户端只需要一个 EventLoopGroup，但是一个ServerBootstrap 则需要两个（也可以是同一个实例）。为什么呢？\n\n因为服务器需要两组不同的 Channel。\n\n- 第一组将只包含一个 ServerChannel，代表服务器自身的已绑定到某个本地端口的正在监听的套接字。\n    \n- 而第二组将包含所有已创建的用来处理传 入客户端连接（**对于每个服务器已经接受的连接都有一个**）的 Channel。\n    \n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-666.png)","lastmodified":"2024-02-25T17:02:23.026964Z","tags":[]},"/Java/netty/BootStrap":{"title":"BootStrap","content":"\n简单来说，**引导一个应用程序是指对它进行配置，并使它运行起来的过程**—尽管该过程的具体细节可能并不如它的定义那样简单，尤其是对于一个网络应用程序来说\n\n  \n\nNetty处理引导的方式**使你的应用程序和网络层相隔离**，无论它是客户端还是服务器\n\n  \n\n# BootStrap类\n\n引导类的层次结构包括一个抽象的父类和两个具体的引导子类\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-699.png)\n\n相对于将具体的引导类分别看作用于服务器和客户端的引导来说，记住它们的本意是用来支撑不同的应用程序的功能的将有所裨益。\n\n- 服务器致力于使用一个父 Channel 来接受来自客户端的连接，并创建子 Channel 以用于它们之间的通信\n    \n- 而客户端将最可能只需要一个单独的、没有父 Channel 的 Channel 来用于所有的网络交互\n    \n\n  \n\n两种应用程序类型之间通用的引导步骤由 AbstractBootstrap 处理，而特定于客户端或者服务器的引导步骤则分别由 Bootstrap 或 ServerBootstrap 处理\n\n  \n\nAbstractBootstrap 类的完整声明是：\n\n```Go\npublic abstract class AbstractBootstrap \u003cB extends AbstractBootstrap\u003cB,C\u003e,C extends Channel\u003e\n```\n\n在这个签名中，子类型 B 是其父类型的一个类型参数，**因此可以返回到运行时实例的引用以支持方法的链式调用**\n\n其子类的声明如下：\n\n```Go\npublic class Bootstrap extends AbstractBootstrap\u003cBootstrap,Channel\u003e\n\npublic class ServerBootstrap extends AbstractBootstrap\u003cServerBootstrap,ServerChannel\u003e\n```\n\n  \n\n# 引导客户端和无连接协议\n\n**Bootstrap 类被用于客户端或者使用了无连接协议的应用程序中**\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-732.png)\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-708.png)\n\n## BootStrap\n\nBootstrap 类负责为客户端和使用无连接协议的应用程序创建 Channel\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-709.png)\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-734.png)\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-703.png)\n\n## Channel 和 EventLoopGroup 的兼容性\n\n你可以从包名以及与其相对应 的类名的前缀看到，对于 NIO 以及 OIO 传输两者来说，都有相关的 EventLoopGroup 和Channel 实现。\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-733.png)\n\n不能混用具有不同前缀的组件，如 NioEventLoopGroup 和 OioSocketChannel，会导致 IllegalStateException，\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-710.png)\n\n# 引导服务端\n\n  \n\n## ServerBootStrap\n\n  \n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-702.png)\n\n列出了一些bootStrap不存在的方法：childHandler()、 childAttr()和 childOption()。这些调用支持特别用于服务器应用程序的操作。具体来说， **ServerChannel 的实现负责创建子 Channel，这些子 Channel 代表了已被接受的连接。**负责引导 ServerChannel 的 ServerBootstrap 提供了这些方法，以简化将设置应用到已被接受的子 Channel 的 ChannelConfig 的任务\n\n- ServerBootstrap 在 bind()方法被调用时创建了一个 ServerChannel， 且该 ServerChannel 管理了多个子 Channel。\n    \n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-704.png)\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-700.png)\n\n  \n\n# 从Channel引导客户端\n\n我们都在引导的过程中调用了 handler()或者 childHandler()方法来添加单个的 ChannelHandler。\n\n通过在 ChannelPipeline 中将它们链接在一起来部署尽可能多的 ChannelHandler。\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-707.png)\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-706.png)\n\n  \n\n# 使用Netty的ChannelOption属性\n\n可以使用 option()方法来将 ChannelOption 应用到引\n\n在某些常用的属性和数据不可用时，Netty 提供了 AttributeMap 抽象（一个由 Channel 和引导类提供的集合）以及 `AttributeKey\u003cT\u003e`（一 个用于插入和获取属性值的泛型类）。\n\n使用这些工具，便可以安全地将任何类型的数据项与客户端和服务器 Channel（包含 ServerChannel 的子 Channel）相关联了。\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-705.png)\n\n# 引导DataGramChannel\n\nNetty 提供了各种 DatagramChannel 的实现。唯一区别就是，**不再调用 connect()方法，而是只调用 bind()方法**\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-701.png)\n\n# 关闭\n\n- 引导使你的应用程序启动并且运行起来，但是迟早你都需要优雅地将它关闭\n    \n- 最重要的是，你需要关闭 EventLoopGroup，它将处理任何挂起的事件和任务，并且随后释放所有活动的线程。\n    \n- 这就是调用 EventLoopGroup.shutdownGracefully()方法的作用。\n    \n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-729.png)","lastmodified":"2024-02-25T17:02:23.026964Z","tags":[]},"/Java/netty/ByteBuf":{"title":"ByteBuf","content":"网络数据的基本单位总是字节。Java NIO 提供了 ByteBuffer 作为它的字节容器，但是这个类使用起来过于复杂，而且也有些繁琐。\n\nNetty 的 ByteBuffer 替代品是 ByteBuf，一个强大的实现，既解决了 JDK API 的局限性，又为网络应用程序的开发者提供了更好的 API。\n\n# ByteBuf 的优点\n\nNetty 的数据处理 API 通过两个组件暴露——abstract class ByteBuf 和 interface ByteBufHolder。\n\n下面是一些 ByteBuf API 的优点：\n\n 它可以被用户自定义的缓冲区类型扩展；\n\n 通过内置的复合缓冲区类型实现了透明的零拷贝；\n\n 容量可以按需增长（类似于 JDK 的 StringBuilder）；\n\n 在读和写这两种模式之间切换不需要调用 ByteBuffer 的 flip()方法；\n\n 读和写使用了不同的索引；\n\n 支持方法的链式调用；\n\n# ByteBuf 如何工作\n\n**ByteBuf 维护了两个不同的索引：一个用于读取，一个用于写入**。当你从 ByteBuf 读取时， 它的 readerIndex 将会被递增已经被读取的字节数。同样地，当你写入 ByteBuf 时，它的 writerIndex 也会被递增。\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-671.png)\n\nreaderIndex 达到 和 writerIndex 同样的值时, 试图读取超出该点的数据将会触发一个 IndexOutOfBoundsException。\n\n  \n\n# ByteBuf 的使用模式\n\n## 堆缓冲区\n\n最常用的 ByteBuf 模式是将数据存储在 **JVM 的堆空间**中，这种模式被称为**支撑数组** （backing array），它能在**没有使用池化的情况下提供快速的分配和释放**\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-673.png)\n\n## 直接缓冲区\n\nNIO 在 JDK 1.4 中引入的 ByteBuffer 类允许 JVM 实现通过本地调 用来分配内存。这主要是为了避**免在每次调用本地 I/O 操作之前（或者之后）将缓冲区的内容复 制到一个中间缓冲区（或者从中间缓冲区把内容复制到缓冲区）。**\n\n直接缓冲区的主要缺点是，相对于基于堆的缓冲区，**它们的分配和释放都较为昂贵。**\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-679.png)\n\n## 符合缓冲区\n\n它为**多个 ByteBuf 提供一个聚合视图。**在这里你可以根据需要添加或者删除 ByteBuf 实例，这是一个 JDK 的 ByteBuffer 实现完全缺失的特性。\n\nNetty 通过一个 ByteBuf 子类——**CompositeByteBuf——实现了这个模式**，它提供了一个将多个**缓冲区表示为单个合并缓冲区的虚拟表示**。\n\n为了举例说明，让我们考虑一下一个由两部分——头部和主体——组成的将通过 HTTP 协议 传输的消息。**这两部分由应用程序的不同模块产生，将会在消息被发送的时候组装**。该应用程序 可以选择为多个消息重用相同的消息主体。当这种情况发生时，对于每个消息都将会创建一个新的头部。\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-683.png)\n\n- 使用ByteBuffer 的符合缓冲区模式\n    \n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-684.png)\n\n- 使用 **CompositeByteBuf** 的复合缓冲区模式\n    \n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-684.png)\n\n- 访问 **CompositeByteBuf** 中的数据\n    \n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-687.png)\n\n  \n\n# 字节级操作\n\n## 随机访问索引\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-672.png)\n\n那些需要一个索引值参数的方法（的其中）之一来访问数据既不会改变readerIndex 也不会改变 writerIndex。\n\n  \n\n## 顺序访问索引\n\n虽然 ByteBuf 同时具有读索引和写索引，\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-677.png)\n\n## 可丢弃字节\n\n记为可丢弃字节的分段包含了已经被读过的字节。通过调用 discardReadBytes()方法，可以丢弃它们并回收空间\n\n  \n\n## 可读字节\n\nByteBuf 的可读字节分段存储了实际数据。新分配的、包装的或者复制的缓冲区的默认的\n\nreaderIndex 值为 0。任何名称以 read 或者 skip 开头的操作都将检索或者跳过位于当前\n\nreaderIndex 的数据，并且将它增加已读字节数。\n\n  \n\n## 可写字节\n\n可写字节分段是指一个拥有未定义内容的、写入就绪的内存区域。新分配的缓冲区的 writerIndex 的默认值为 0。任何名称以 write 开头的操作都将从当前的 writerIndex 处 开始写数据，并将它增加已经写入的字节数。如果写操作的目标也是 ByteBuf，并且没有指定源索引的值，则源缓冲区的 readerIndex 也同样会被增加相同的大小。这个调用如下所示：\n\nwriteBytes(ByteBuf dest);\n\n  \n\n## 读写操作\n\n正如我们所提到过的，有两种类别的读/写操作：\n\n get()和 set()操作，从给定的索引开始，并且保持索引不变；\n\n read()和 write()操作，从给定的索引开始，并且会根据已经访问过的字节数对索\n\n引进行调整\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-685.png)\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-675.png)\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-680.png)\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-686.png)\n\n## 其他操作\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-674.png)\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-681.png)\n\n  \n\n# ByteBufHolder\n\n- 除了实际的数据负载之外，我们还需要**存储各种属性值**。 为了处理这种常见的用例，Netty 提供了 ByteBufHolder\n    \n- ByteBufHolder 也为 Netty 的 高级特性提供了支持，如缓冲区池化，其中可以从池中借用 ByteBuf，并且在需要时自动释放\n    \n- ByteBufHolder 只有几种用于访问底层数据和引用计数的方法\n    \n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-676.png)\n\n  \n\n# ByteBuf分配\n\n## 按需分配ByteBufAllocator\n\n，Netty 通过 interface ByteBufAllocator 实现了 （ByteBuf 的）**池化**，它可以用来分配我们所描述过的任意类型的 ByteBuf 实例\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-682.png)\n\n可以通过 Channel（每个都可以有一个不同的 ByteBufAllocator 实例）或者绑定到 ChannelHandler 的 ChannelHandlerContext 获取一个到 ByteBufAllocator 的引用。\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-686.png)\n\nNetty提供了两种ByteBufAllocator的实现：PooledByteBufAllocator和UnpooledByteBufAllocator。\n\n- PooledByteBufAllocator，池化了ByteBuf的实例以提高性能并最大限度地减少内存碎片\n    \n- UnpooledByteBufAllocator，非池化ByteBuf实例，并且在每次它被调用时都会返回一个新的实例\n    \n\n**Netty默认使用了PooledByteBufAllocator**，但这可以很容易地通过ChannelConfig API或者在引导你的应用程序时指定一个不同的分配器来更改\n\n  \n\n## Unpooled 缓冲区\n\n你未能获取一个到 ByteBufAllocator 的引用。对于这种情况，Netty 提供了一个简单的称为 Unpooled 的工具类，它提供了静态的辅助方法来创建未池化的 ByteBuf 实例。\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-678.png)\n\n## ByteBufUtil\n\nByteBufUtil 提供了用于操作 ByteBuf 的静态的辅助方法。因为这个 API 是通用的，并\n\n且和池化无关，所以这些方法已然在分配类的外部实现\n\n  \n\n# 引用计数\n\nNetty 在第 4 版中为 ByteBuf 和 ByteBufHolder 引入了引用计数技术，它们都实现了 interface ReferenceCounted。\n\n它主要涉及跟踪到某个特定对象的活动引用的数量。一个 ReferenceCounted 实现的实例将通常以活动的引用计数为 1 作为开始。\n\n只要引用计数大于 0，就能保证对象不会被释放。当活动引用的数量减少到 0 时，该实例就会被释放\n\n引用计数对于池化实现（如 PooledByteBufAllocator）来说是至关重要的，它降低了内存分配的开销。","lastmodified":"2024-02-25T17:02:23.026964Z","tags":[]},"/Java/netty/ChannelHandlerChannelPipelineChannelContext":{"title":"ChannelHandler、ChannelPipeline、ChannelContext","content":"当我们在本章中探讨 Netty 的数据流以及处理组件\n\n在 ChannelPipeline 中将 ChannelHandler 链接在一起以组织处理逻辑。我们将会研究涉及这些类的各种用例，以及一个重要的关系—ChannelHandlerContext\n\n  \n\n# ChannelHandler\n\n  \n\n## Channel 的生命周期\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-731.png)\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-731.png)\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-689.png)\n\n  \n\nChannelHandler的生命周期\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-731.png)\n\n  \n\nNetty定义了两个重要的ChannelHandler\n\n-  ChannelInboundHandler——处理入站数据以及各种状态变化；\n    \n-  ChannelOutboundHandler——处理出站数据并且允许拦截所有的操作。\n    \n\n  \n\n## ChannelInBoundHandler接口\n\nChannelInBoundHandler的生命周期方法。这些方法将会在数据被接收时或者与其对应的 Channel 状态发生改变时被调用。\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-721.png)\n\n当某个 ChannelInboundHandler 的实现重写 channelRead()方法时，它将负责显式地释放与池化的 ByteBuf 实例相关的内存。Netty 为此提供了一个实用方法 ReferenceCountUtil.release()\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-711.png)\n\n一个更加简单的方式是使用 SimpleChannelInboundHandler\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-722.png)\n\n由于 SimpleChannelInboundHandler 会自动释放资源，所以你不应该存储指向任何消 息的引用供将来使用\n\n## ChannelOutboundHandler\n\n出站操作和数据将由 ChannelOutboundHandler 处理。它的方法将被 Channel、ChannelPipeline 以及 ChannelHandlerContext 调用。\n\nChannelOutboundHandler 的一个强大的功能**是可以按需推迟操作或者事件**，这使得可以通过一些复杂的方法来处理请求。例如，如果到远程节点的写入被暂停了，那么你可以推迟冲刷操作并在稍后继续\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-714.png)\n\n  \n\n\u003e **ChannelPromise**与**ChannelFuture** ChannelOutboundHandler中的大部分方法都需要一个\n\u003e \n\u003e ChannelPromise参数，以便在操作完成时得到通知。ChannelPromise是ChannelFuture的一个\n\u003e \n\u003e 子类，其定义了一些可写的方法，如setSuccess()和setFailure()，从而使ChannelFuture不\n\u003e \n\u003e 可变\n\n  \n\n## 适配器\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-723.png)\n\n## 资源管理\n\n- 每当通过调用 ChannelInboundHandler.channelRead()或者 ChannelOutboundHandler.write()方法来处理数据时，你都需要确保没有任何的资源泄漏。\n    \n- Netty 使用引用计数来处理池化的 ByteBuf。所以在完全使用完某个ByteBuf 后，**调整其引用计数是很重要的**\n    \n\n  \n\nNetty提供了class ResourceLeakDetector①，它将对你应用程序的缓冲区分配做大约 1%的采样来检测内存泄露\n\nNetty的泄露级别\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-713.png)\n\n消费并释放入站消息\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-737.png)\n\n丢弃并释放出站消息\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-731.png)\n\n  \n\n# ChannelPipeline\n\n\u003e - ChannelPipeline 保存了与 Channel 相关联的 ChannelHandler；\n\u003e     \n\u003e - ChannelPipeline 可以根据需要，通过添加或者删除 ChannelHandler 来动态地修改；\n\u003e     \n\u003e - ChannelPipeline 有着丰富的 API 用以被调用，以响应入站和出站事件。\n\u003e     \n\n  \n\n- 每一个新创建的 Channel 都将会被分配一个新的 ChannelPipeline。这项关联是永久性的；\n    \n- Channel 既不能附加另外一个 ChannelPipeline，也不能分离其当前的\n    \n- 根据事件的起源，事件将会被 ChannelInboundHandler 或者 ChannelOutboundHandler处理，随后，通过调用 ChannelHandlerContext 实现，它将被转发给同一超类型的下一个 ChannelHandler\n    \n\n  \n\n\u003e ChannelHandlerContext使得ChannelHandler能够和它的ChannelPipeline以及其他的ChannelHandler 交互，\n\u003e \n\u003e - ChannelHandler 可以通知其所属的 ChannelPipeline 中的下一 个ChannelHandler，\n\u003e     \n\u003e - 甚至可以动态修改它所属的ChannelPipeline\n\u003e     \n\n  \n\n了一个典型的同时具有入站和出站 ChannelHandler 的 ChannelPipeline 的布 局，并且印证了我们之前的关于 ChannelPipeline 主要由一系列的 ChannelHandler 所组成的说法。\n\n  \n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-718.png)\n\n- ChannelPipeline 还提供了通过 ChannelPipeline 本身传播事件的方法。\n    \n    - 如果一个入站事件被触发，它将被从 ChannelPipeline 的头部开始一直被传播到 Channel Pipeline 的尾端\n        \n    - 一个出站 I/O 事件将从 ChannelPipeline 的最右边开始，然后向左传播。\n        \n- 在 ChannelPipeline 传播事件时，它会测试 ChannelPipeline 中的下一个 ChannelHandler 的类型是否和事件的运动方向相匹配。\n    \n    - 如果不匹配，ChannelPipeline 将跳过该ChannelHandler 并前进到下一个，直到它找到和该事件所期望的方向相匹配的为止。\n        \n\n  \n\n## 修改ChannelPipeline\n\nChannelHandler 可以通过添加、删除或者替换其他的 ChannelHandler 来实时地修改ChannelPipeline 的布局。\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-697.png)\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-749.png)\n\n  \n\n## ChannelHandler 的阻塞和执行\n\n- 通常 ChannelPipeline 中的每一个 ChannelHandler 都是通过它的 EventLoop（I/O 线程）来处 理传递给它的事件的。所以**至关重要的是不要阻塞这个线程**，因为这会对整体的 I/O 处理产生负面的影响。\n    \n- 但有时可能需要与那些使用阻塞 API 的遗留代码进行交互。对于这种情况，ChannelPipeline 有一些接受一个 EventExecutorGroup 的 add()方法。如果一个事件被传递给一个自定义的 EventExecutorGroup，它将被包含在这个 EventExecutorGroup 中的某个 **EventExecutor** 所处理，**从而被从该 Channel 本身的 EventLoop 中移除**。对于这种用例，Netty 提供了一个叫 DefaultEventExecutorGroup 的默认实现。\n    \n\n## 其他获取ChannelHandler的方法\n\n还有别的通过类型或者名称来访问 ChannelHandler 的方法\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-731.png)\n\n## 触发事件\n\n入站操作，用于通知 ChannelInboundHandler 在 ChannelPipeline 中所发生的事件\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-712.png)\n\nChannelPipeline API 的出站操作。\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-719.png)\n\n  \n\n# ChannelHandlerContext\n\n- ChannelHandlerContext 代表了 ChannelHandler 和 ChannelPipeline 之间的关联，每当有 ChannelHandler 添加到 ChannelPipeline 中时，都会创建 ChannelHandlerContext\n    \n- ChannelHandlerContext 的主要功能是管理它所关联的 ChannelHandler 和在 同一个 ChannelPipeline 中的其他 ChannelHandler 之间的交互\n    \n\n  \n\nChannelHandlerContext 有很多的方法，其中一些方法也存在于 Channel 和 ChannelPipeline 本身上，但是有一点重要的不同。\n\n- 如果调用 Channel 或者 ChannelPipeline 上的这些方法，它们将沿着整个 ChannelPipeline 进行传播\n    \n- 而调用位于 ChannelHandlerContext 上的相同方法，则将从当前所关联的 ChannelHandler 开始，并且**只会传播给位于该 ChannelPipeline 中的下一个能够处理该事件的 ChannelHandler**\n    \n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-698.png)\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-731.png)\n\n当使用 ChannelHandlerContext 的 API 的时候，请牢记以下两点：\n\n-  ChannelHandlerContext 和 ChannelHandler 之间的关联（绑定）是永远不会改变的，所以缓存对它的引用是安全的；\n    \n-  如同我们在本节开头所解释的一样，相对于其他类的同名方法，ChannelHandleContext 的方法将产生更短的事件流，应该尽可能地利用这个特性来获得最大的性能\n    \n\n## 使用\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-730.png)\n\n  \n\n### **ChannelHandlerContext** 访问 **Channel**\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-741.png)\n\n### 通过 **ChannelHandlerContext** 访问 **ChannelPipeline**\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-715.png)\n\n- 虽然被调用的 Channel 或 ChannelPipeline 上的 write()方法将**一直传播事件通过整个 ChannelPipeline**，\n    \n- 但是在 ChannelHandler 的级别上，事件从一个 ChannelHandler 到下一个 ChannelHandler 的移动是由ChannelHandlerContext 上的调用完成的\n    \n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-716.png)\n\n### 调用 **ChannelHandlerContext** 的 **write()**方法\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-731.png)\n\n消息将从下一个 ChannelHandler 开始流经 ChannelPipeline，绕过了所有前面的 ChannelHandler\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-736.png)\n\n### 可共享的ChannelHandler\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-738.png)\n\n  \n\n# 异常处理\n\n## 处理入站点异常\n\n- 如果在处理入站事件的过程中有异常被抛出，那么它将从它在 ChannelInboundHandler里被触发的那一点开始流经 ChannelPipeline\n    \n- 要想处理这种类型的入站异常，你需要在你的 ChannelInboundHandler 实现中重写下面的方法\n    \n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-742.png)\n\n- ChannelHandler.exceptionCaught()的默认实现是简单地将当前异常转发给 ChannelPipeline 中的下一个 ChannelHandler；\n    \n- 如果异常到达了 ChannelPipeline 的尾端，它将会被记录为未被处理；\n    \n- 要想定义自定义的处理逻辑，你需要重写 exceptionCaught()方法。然后你需要决定是否需要将该异常传播出去。\n    \n\n  \n\n## 处理出站异常\n\n用于处理出站操作中的正常完成以及异常的选项，都基于以下的通知机制。\n\n- 每个出站操作都将返回一个 ChannelFuture。注册到 ChannelFuture 的 ChannelFutureListener 将在操作完成时被通知该操作是成功了还是出错了\n    \n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-720.png)\n\n- 几乎所有的 ChannelOutboundHandler 上的方法都会传入一个 ChannelPromise 的实例。作为 ChannelFuture 的子类，ChannelPromise 也可以被分配用于异步通知的监听器。但是，ChannelPromise 还具有提供立即通知的可写方法：\n    \n    - ChannelPromise setSuccess();\n        \n    - ChannelPromise setFailure(Throwable cause)\n        \n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-690.png)","lastmodified":"2024-02-25T17:02:23.026964Z","tags":[]},"/Java/netty/EventLoop-%E5%92%8C%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B":{"title":"EventLoop 和线程模型","content":"# 常见的线程模型\n\n基本的线程池化模式\n\n- 从池的空闲线程列表中选择一个 Thread，并且指派它去运行一个已提交的任务（一个 Runnable 的实现）；\n    \n- 当任务完成时，将该 Thread 返回给该列表，使其可被重用\n    \n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-717.png)\n\n虽然池化和重用线程相对于简单地为每个任务都创建和销毁线程是一种进步，但是它并不能消除由上下文切换所带来的开销\n\n# EventLoop\n\n运行任务来**处理在连接的生命周期内发生的事件是任何网络框架的基本功能**。与之相应的编程上的构造通常被称为**事件循环**—一个 Netty 使用了 interface io.netty.channel.EventLoop 来适配的术语。\n\n  \n\nNetty 的 EventLoop 是协同设计的一部分，它采用了两个基本的 API：并发和网络编程。\n\n- 首先，io.netty.util.concurrent 包构建在 JDK 的 java.util.concurrent 包上，用来提供线程执行器。\n    \n- 其次，io.netty.channel 包中的类，为了与 Channel 的事件进行交互，扩展了这些接口/类\n    \n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-691.png)\n\n线程的关系\n\n- 在这个模型中，一个 EventLoop 将由一个永远都不会改变的 Thread 驱动\n    \n- 同时任务 （Runnable 或者 Callable）可以直接提交给 EventLoop 实现，以立即执行或者调度执行。\n    \n- 根据配置和可用核心的不同，可能会创建多个 EventLoop 实例用以优化资源的使用，\n    \n- 并且单个 EventLoop 可能会被指派用于服务多个 Channel\n    \n- netty的EventLoop在继承了ScheduledExecutorService的同时，只定 义了一个方法，parent(),用于返回到当前EventLoopGroup的引用。\n    \n\n```Go\npublic interface EventLoop extends EventExecutor, EventLoopGroup { \n    @Override \n    EventLoopGroup parent(); \n}\n```\n\n  \n\n## Netty4 中的I/O和事件处理\n\nI/O 操作触发的事件将流经安装了一个或者多个 ChannelHandler 的 ChannelPipeline。**传播这些事件的方法调用可以随后被 ChannelHandler 所拦截，并且可以按需地处理事件**\n\n- 在Netty 4 中，所有的I/O操作和事件都由已经被分配给了EventLoop的那个Thread来处理\n    \n\n不同于 Netty 3 中所使用的模型\n\n  \n\n## Netty3 中的I/O操作\n\n在以前的版本中\n\n- 所使用的线程模型只保证了入站（之前称为上游）事件会在所谓的 I/O 线程（对应于 Netty 4 中的 EventLoop）中执行。\n    \n- 所有的出站（下游）事件都由调用线程处理，其可能是 I/O 线程也可能是别的线程\n    \n\n  \n\n已经被发现**是有问题的**， **因为需要在 ChannelHandler 中对出站事件进行仔细的同步。简而言之，不可能保证多个线程不会在同一时刻尝试访问出站事件**\n\n  \n\nNetty 4 中所采用的线程模型，通过在**同一个线程中处理某个给定的 EventLoop 中所产生的所有事件**，解决了这个问题。这提供了一个更加简单的执行体系架构，并且消除了在多个 ChannelHandler 中进行同步的需要（除了任何可能需要在多个 Channel 中共享的）\n\n  \n\n# 任务调度\n\n  \n\n偶尔，你将需要调度一个任务**以便稍后（延迟）执行或者周期性地执行**。例如，你可能想要注册一个在客户端已经**连接了 5 分钟之后触发的任务。**\n\n  \n\nJDK 的任务调度\n\n- 在 Java 5 之前，任务调度是建立在 java.util.Timer 类之上的，其使用了一个后台 Thread，并且具有与标准线程相同的限制。、\n    \n- 随后，JDK 提供了 java.util.concurrent 包，它定义了 interface ScheduledExecutorService。表 7-1 展示了 java.util.concurrent.Executors的相关工厂方法。\n    \n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-724.png)\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-746.png)\n\n  \n\n## EventLoop调度任务\n\nNetty 通 过 Channel 的 EventLoop 实现任务调度解决了这一问题\n\n  \n\n- 使用EventLoop调度任务\n    \n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-692.png)\n\n- 使用 **EventLoop** 调度周期性的任务\n    \n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-695.png)\n\n- 使用 **ScheduledFuture** 取消任务\n    \n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-725.png)\n\n  \n\n# 实现细节\n\n## 线程管理\n\nNetty线程模型的卓越性能取决于对于当前执行的Thread的身份的确定 ，**它是否是分配给当前Channel以及它的EventLoop的那一个线程，**\n\n- 如果（当前）调用线程正是支撑 EventLoop 的线程，那么所提交的代码块将会被（直接执行）\n    \n- 否则，EventLoop 将调度该任务以便稍后执行，**并将它放入到内部队列中**。当 EventLoop 下次处理它的事件时，它会执行队列中的那些任务/事件。这也就解释了任何的\n    \n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-696.png)\n\n  \n\n- 每个 EventLoop 都有它自已的任务队列，独立于任何其他的 EventLoop\n    \n- “永 远不要将一个长时间运行的任务放入到执行队列中，因为它将阻塞需要在同一线程上执行的任何其他任务。”如果必须要进行阻塞调用或者执行长时间运行的任务，我们建议使用一个专门的EventExecutor\n    \n\n## EventLoop线程的分配\n\n服务于 Channel 的 I/O 和事件的 EventLoop 包含在 EventLoopGroup 中。根据不同的传输实现，EventLoop 的创建和分配方式也不同\n\n#### 异步传输\n\n异步传输实现**只使用了少量的 EventLoop**（以及和它们相关联的 Thread），而且在当前的线程模型中，**它们可能会被多个 Channel 所共享**，这使得可以通过**尽可能少量的 Thread 来支撑大量的 Channel**，而不是每个 Channel 分配一个 Thread\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-693.png)\n\n- EventLoopGroup 负责为**每个新创建的 Channel 分配一个 EventLoop**。\n    \n    - 在当前实现中，使用顺序循环（round-robin）的方式进行分配以获取一个均衡的分布，并且相同的 **EventLoop可能会被分配给多个 Channel。**（这一点在将来的版本中可能会改变。）\n        \n- 一旦一个 Channel 被分配给一个 EventLoop，它将在它的整个生命周期中都使用这个 EventLoop（以及相关联的 Thread）\n    \n- EventLoop 的分配方式对 ThreadLocal 的使用的影响。因为一个EventLoop 通常会被用于支撑多个 Channel，所以对于所有相关联的 Channel 来说， ThreadLocal 都将是一样的\n    \n\n  \n\n#### 阻塞传输\n\n用于像 OIO（旧的阻塞 I/O）这样的其他传输的设计略有不同\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticasynccode-694.png)\n\n这里每一个 Channel 都将被分配给一个 EventLoop（以及它的 Thread）。如果你开发的应用程序使用过 java.io 包中的阻塞 I/O 实现，你可能就遇到过这种模型\n\n但是，正如同之前一样，得到的保证是**每个 Channel 的 I/O 事件都将只会被一个 Thread** （用于支撑该 Channel 的 EventLoop 的那个 Thread）处理。","lastmodified":"2024-02-25T17:02:23.026964Z","tags":[]},"/Obsidian/%E4%BD%BF%E7%94%A8quartz%E5%8F%91%E5%B8%83obsidian-vault":{"title":"使用quartz发布obsidian  vault","content":"","lastmodified":"2024-02-25T17:02:23.03496398Z","tags":[]},"/Obsidian/Front-Matter":{"title":"Front Matter","content":"\n\n使用 Front Matter 可以保存 note 待元数据，推荐使用 Hugo 的配置 [Front matter | Hugo (gohugo.io)](https://gohugo.io/content-management/front-matter/)\n\n","lastmodified":"2024-02-25T17:02:21.450967896Z","tags":["Obsidian"]},"/Obsidian/Obsidian-plugin":{"title":"Obsidian-plugin","content":"\n* [advanced-table](https://github.com/tgrosinger/advanced-tables-obsidian)\n* [banners](https://github.com/noatpad/obsidian-banners)\n* [calendar](https://github.com/liamcain/obsidian-calendar-plugin)\n* [commander](https://github.com/phibr0/obsidian-commander)\n* [dataview](https://github.com/blacksmithgu/obsidian-dataview)\n* [emoji-shortcodes](https://github.com/phibr0/obsidian-emoji-shortcodes)\n* [emoji-toolbar](https://github.com/oliveryh/obsidian-emoji-toolbar)\n* [excel-to-markdown-table](https://github.com/ganesshkumar/obsidian-excel-to-markdown-table)\n* [homepage](https://github.com/mirnovov/obsidian-homepage)\n* [hover-editor](https://github.com/nothingislost/obsidian-hover-editor)\n* [icon-folder)](https://github.com/FlorianWoelki/obsidian-icon-folder)\n* [icons](https://github.com/visini/obsidian-icons-plugin)\n* [image-toolkit](https://github.com/sissilab/obsidian-image-toolkit)\n* [minimal-settings](https://github.com/kepano/obsidian-minimal-settings)\n* [obsidian-git](https://github.com/denolehov/obsidian-git)\n* [recent-files](https://github.com/tgrosinger/recent-files-obsidian)\n* [settings-search](https://github.com/javalent/settings-search)\n* [style-settings](https://github.com/mgmeyers/obsidian-style-settings)\n* [tag-wrangler](https://github.com/pjeby/tag-wrangler)\n* [excalidraw](https://github.com/zsviczian/obsidian-excalidraw-plugin)","lastmodified":"2024-02-25T17:02:21.450967896Z","tags":["Obsidian"]},"/Obsidian/dataview":{"title":"dataview","content":"\n\n# 官方地址\n\n* [代码仓库](https://github.com/blacksmithgu/obsidian-dataview)\n* [文档地址](https://blacksmithgu.github.io/obsidian-dataview/)\n\n# 其他教程\n*  [Obsidian DataView 入门保姆级引导手册](https://zhuanlan.zhihu.com/p/614881764)\n\n# 元数据\n\n元数据是一系列的键值对,可以给笔记，可以给note,list item ,task 添加元数据\n\n## 如何添加元数据\n\n### Frontmatter\n\n* frontmatter 是markdown的一种扩展，可以使用yaml 来添加元数据\n\n```\n --- \n alias: \"document\" \n last-reviewed: 2021-08-17 \n thoughts: \n\t rating: 8 \n\t reviewable: false \n ---\n```\n\n###  inline fields\n* 使用方法为在文件的任意位置添加\n```text\n\nBasic Field:: Some random Value \n**Bold Field**:: Nice!\n  \n```\n\n* 如果你需要标注list itme 或者 task 需要使用中括号\n```\n- [ ] Send an mail to David about the deadline [due:: 2022-04-05].\n```\n\n\n# 另外还有隐含的元数据\n\n## page 中的元数据\n\n\n[# Metadata on Pages](https://blacksmithgu.github.io/obsidian-dataview/annotation/metadata-pages/)\n\n\n| Field Name       | Data Type      | Description                                                                                                                                                                   |\n|------------------|----------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| file.name        | Text           | The file name as seen in Obsidians sidebar.                                                                                                                                   |\n| file.folder      | Text           | The path of the folder this file belongs to.                                                                                                                                  |\n| file.path        | Text           | The full file path, including the files name.                                                                                                                                 |\n| file.ext         | Text           | The extension of the file type; generally md.                                                                                                                                 |\n| file.link        | Link           | A link to the file.                                                                                                                                                           |\n| file.size        | Number         | The size (in bytes) of the file.                                                                                                                                              |\n| file.ctime       | Date with Time | The date that the file was created.                                                                                                                                           |\n| file.cday        | Date           | The date that the file was created.                                                                                                                                           |\n| file.mtime       | Date with Time | The date that the file was last modified.                                                                                                                                     |\n| file.mday        | Date           | The date that the file was last modified.                                                                                                                                     |\n| file.tags        | List           | A list of all unique tags in the note. Subtags are broken down by each level, so #Tag/1/A will be stored in the list as [#Tag, #Tag/1, #Tag/1/A].                             |\n| file.etags       | List           | A list of all explicit tags in the note; unlike file.tags, does not break subtags down, i.e. [#Tag/1/A]                                                                       |\n| file.inlinks     | List           | A list of all incoming links to this file, meaning all files that contain a link to this file.                                                                                |\n| file.outlinks    | List           | A list of all outgoing links from this file, meaning all links the file contains.                                                                                             |\n| file.aliases     | List           | A list of all aliases for the note as defined via the YAML frontmatter.                                                                                                       |\n| file.tasks       | List           | A list of all tasks (I.e., \\| [ ] some task) in this file.                                                                                                                    |\n| file.lists       | List           | A list of all list elements in the file (including tasks); these elements are effectively tasks and can be rendered in task views.                                            |\n| file.frontmatter | List           | Contains the raw values of all frontmatter in form of key \\| value text values; mainly useful for checking raw frontmatter values or for dynamically listing frontmatter keys. |\n| file.day         | Date           | Only available if the file has a date inside its file name (of form yyyy-mm-dd or yyyymmdd), or has a Date field/inline field.                                                |\n| file.starred     | Boolean        | if this file has been starred via the Obsidian Core Plugin \"Starred Files\".                                                                                                   |\n\n\n## 列表和任务中的元数据\n\n[# Metadata on Tasks and Lists](https://blacksmithgu.github.io/obsidian-dataview/annotation/metadata-tasks/)\n\n| Field name     | Data Type | Description                                                                                                                                                                                                                                                                                               |\n|----------------|-----------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| status         | Text      | The completion status of this task, as determined by the character inside the [ ] brackets. Generally a space \" \" for incomplete tasks and a \"x\" for complete tasks, but allows for plugins which support alternative task statuses.                                                                      |\n| checked        | Boolean   | Whether or not this task status is empty, meaning it has a space in its [ ] brackets                                                                                                                                                                                                                      |\n| completed      | Boolean   | Whether or not this specific task has been completed; this does not consider the completionnon-completion of any child tasks. A task is explicitly considered \"completed\" if it has been marked with an 'x'. If you use a custom status, i.e. [-], checked will be true, whereas completed will be false. |\n| fullyCompleted | Boolean   | Whether or not this task and all of its subtasks are completed.                                                                                                                                                                                                                                           |\n| text           | Text      | The plain text of this task, including any metadata field annotations.                                                                                                                                                                                                                                    |\n| visual         | Text      | The text of this task, which is rendered by Dataview. It can be modified to render arbitary text.                                                                                                                                                                                                         |\n| line           | Number    | The line of the file this task shows up on.                                                                                                                                                                                                                                                               |\n| lineCount      | Number    | The number of Markdown lines that this task takes up.                                                                                                                                                                                                                                                     |\n| path           | Text      | The full path of the file this task is in. Equals to file.path for pages                                                                                                                                                                                                                                  |\n| section        | Link      | link to the section this task is contained in.                                                                                                                                                                                                                                                            |\n| tags           | List      | Any tags inside of the text task.                                                                                                                                                                                                                                                                         |\n| outlinks       | List      | Any links defined in this task.                                                                                                                                                                                                                                                                           |\n| link           | Link      | link to the closest linkable block near this task; useful for making links which go to the task.                                                                                                                                                                                                          |\n| children       | List      | ny subtasks or sublists of this task.                                                                                                                                                                                                                                                                     |\n| task           | Boolean   | If true, this is a task; otherwise, it is a regular list element.                                                                                                                                                                                                                                         |\n| annotated      | Boolean   | True if the task text contains any metadata fields, false otherwise.                                                                                                                                                                                                                                      |\n| parent         | Number    | The line number of the task above this task, if present; will be null if this is a root-level task.                                                                                                                                                                                                       |\n| blockId        | Text      | The block ID of this task / list element, if one has been defined with the ^blockId syntax; otherwise null.                                                                                                                                                                                               |\n\n\n# DQL\n\n比较类似于sql, 可是实现以下的功能\n\n- Choosing an **output format** of your output (the [Query Type](https://blacksmithgu.github.io/obsidian-dataview/queries/query-types/))\n- Fetch pages **from a certain [source](https://blacksmithgu.github.io/obsidian-dataview/reference/sources/)**, i.e. a tag, folder or link\n- **Filtering pages/data** by simple operations on fields, like comparison, existence checks, and so on\n- **Transforming fields** for displaying, i.e. with calculations or splitting up multi-value fields\n- **Sorting** results based on fields\n- **Grouping** results based on fields\n- **Limiting** your result count\n\n## 查询语法\n\n```text\n```dataview \n\t\u003cQUERY-TYPE\u003e \u003cfields\u003e \n\tFROM \u003csource\u003e \n\t\u003cDATA-COMMAND\u003e \u003cexpression\u003e \n\t\u003cDATA-COMMAND\u003e \u003cexpression\u003e \n\t...\n```\n```\t\n```\n\n\n## 输出类型\n\n* **TABLE**: A table of results with one row per result and one or many columns of **field data**.\n* **LIST**: A bullet point list of **pages** which match the query. You can output one field for each page alongside their file links.\n* **TASK**: An interactive task list of **tasks** that match the given query.\n* **CALENDAR**: A calendar view displaying each hit via a dot on its referred date.\n\n\n```text\nLists all pages in your vault as a bullet point list\n\t```dataview \n\tLIST \n\t```\n\t\nLists all tasks (completed or not) in your vault \n\t```dataview \n\tTASK \n\t```\n\t\nRenders a Calendar view where each page is represented as a dot on its creation date. \n\t```dataview \n\tCALENDAR file.cday \n\t```\n\t\nShows a table with all pages of your vault, their field value of due, the files' tags and an average of the values of multi-value field working-hours \n\t```dataview \n\tTABLE due, file.tags AS \"tags\", average(working-hours)\n\t ```\n\n```\n\n\n## 数据来源\n\n* tags\n* folders\n* note\n* lint\n\n```\nLists all pages inside the folder Books and its sub folders \n\t```dataview \n\tLIST FROM \"Books\" \n\t``` \n\t\nLists all pages that include the tag #status/open or #status/wip \n\t```dataview \n\tLIST FROM #status/open OR #status/wip \n\t``` \n\t\nLists all pages that have either the tag #assignment and are inside folder \"30 School\" (or its sub folders), or are inside folder \"30 School/32 Homeworks\" and are linked on the page School Dashboard Current To Dos \n\n\t```dataview \n\tLIST FROM (#assignment AND \"30 School\") OR (\"30 School/32 Homeworks\" AND outgoing([[School Dashboard Current To Dos]])) \n\t```\n\n```\n\n\n## Filter, sort, group or limit results\n\n* ***FROM** like explained [above](https://blacksmithgu.github.io/obsidian-dataview/queries/structure/#choose-your-source).\n*  **WHERE**: Filter notes based on information **inside** notes, the meta data fields.\n*  **SORT**: Sorts your results depending on a field and a direction.\n*  **GROUP BY**: Bundles up several results into one result row per group.\n*  **LIMIT**: Limits the result count of your query to the given number.\n*  **FLATTEN**: Splits up one result into multiple results based on a field or calculation.\n\n\n```\nLists all pages that have a metadata field `due` and where `due` is before today \n\n\t```dataview \n\tLIST WHERE due AND due \u003c date(today) \n\t``` \nLists the 10 most recently created pages in your vault that have the tag #status/open \n\t```dataview \n\tLIST FROM #status/open SORT file.ctime DESC LIMIT 10 \n\t``` \nLists the 10 oldest and incompleted tasks of your vault as an interactive task list, grouped by their containing file and sorted from oldest to newest file. \n\t```dataview \n\tTASK WHERE !completed SORT created ASC LIMIT 10 GROUP BY file.link SORT rows.file.ctime ASC \n\t```\n\n\n```","lastmodified":"2024-02-25T17:02:21.450967896Z","tags":["Obsidian"]},"/Obsidian/excalidraw":{"title":"excalidraw","content":"\n*  [代码仓库](https://github.com/zsviczian/obsidian-excalidraw-plugin)\n* note 中插入excalidraw 语法\n\n```\n![[excalidraw]]\n```","lastmodified":"2024-02-25T17:02:21.450967896Z","tags":["Obsidian"]},"/Obsidian/obsidian-overview":{"title":"obsidian overview","content":"\n# 主页内容\n\nobsidian 相关内容，包括插件\n\n\n# 结构\n\n","lastmodified":"2024-02-25T17:02:21.450967896Z","tags":["Obsidian"]},"/Obsidian/publish":{"title":"publish","content":"\n\n\n[obsidian 目前最完美的免费发布方案 渐进式教程 by oldwinter](https://publish.obsidian.md/chinesehelp/01+2021%E6%96%B0%E6%95%99%E7%A8%8B/obsidian+%E7%9B%AE%E5%89%8D%E6%9C%80%E5%AE%8C%E7%BE%8E%E7%9A%84%E5%85%8D%E8%B4%B9%E5%8F%91%E5%B8%83%E6%96%B9%E6%A1%88+%E6%B8%90%E8%BF%9B%E5%BC%8F%E6%95%99%E7%A8%8B+by+oldwinter#%E5%87%A0%E4%B8%AA%E5%8F%91%E5%B8%83%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94)","lastmodified":"2024-02-25T17:02:21.450967896Z","tags":["Obsidian"]},"/Obsidian/template":{"title":"template","content":"\n* *[模板的使用方法](https://publish.obsidian.md/help-zh/%E6%8F%92%E4%BB%B6/%E6%A8%A1%E6%9D%BF)\n* 默认存放的文件夹 `/template`\n\n","lastmodified":"2024-02-25T17:02:21.450967896Z","tags":["Obsidian"]},"/awesome/JavaGuide-%E7%9F%A5%E8%AF%86%E6%98%9F%E7%90%83%E4%BC%98%E8%B4%A8%E4%B8%BB%E9%A2%98%E6%B1%87%E6%80%BB":{"title":"JavaGuide 知识星球优质主题汇总","content":"为了避免这里成为知识杂货铺，我会对严格筛选入选的优质主题。  \n  \n更新日期：2023-06-11  \n  \n\n面试  \n  \n●[Java面试常见问题总结（2023最新版）](https://t.zsxq.com/0eRq7EJPy)  \n●[一位 HR 分享的求职建议](https://t.zsxq.com/0dSKX0jkK)  \n●[面试和简历上的一些大忌](https://t.zsxq.com/0eOgYt3qU)  \n●项目：  \n○[如何回答项目遇到什么困难，如何解决这类问题](https://t.zsxq.com/0dduy9CeQ)  \n○[项目太简单怎么办?](https://t.zsxq.com/0eV4BksDb)  \n○[商城项目到底能不能做？](https://t.zsxq.com/0eBcCNhbB)  \n  \n\n安抚心态  \n  \n如果你陷入精神内耗或者自我怀疑，不然看看下面这些内容：  \n  \n●[编程找工作现状 - 哔哩哔哩](https://t.zsxq.com/0edKnfcZW)  \n  \n\n技术资源  \n  \n学习路线：[Java 系统学习路线](https://t.zsxq.com/0dupYAEaq)  \n  \n总结 ：  \n  \n●[Java 后端开发常用的技术书籍+原创面试资料 PDF 版本](https://t.zsxq.com/0bWeUrBVq)  \n●[JavaGuide 网站总结的八股文合集  - 念神](https://t.zsxq.com/0biGG9UlX)  \n●[Java 后端常见知识点思维导图分享 - 吴不卷](https://t.zsxq.com/0bHk3wEDs)  \n  \n常用技术：  \n  \n●[SpringBoot 学习资源推荐](https://t.zsxq.com/0eEGBV1Md)  \n●[单测技术选型+学习资源推荐](https://t.zsxq.com/0d7jOz9Vm)  \n●[Redis 学习资源推荐](https://t.zsxq.com/0dwd4ONZ9)  \n●[Elasticsearch 学习资源推荐](https://t.zsxq.com/0dEWEThKR)  \n●[Kafka、RocketMQ、RabbitMQ 学习资源推荐](https://t.zsxq.com/0bEDFwgon)  \n●[分布式学习资源推荐（偏理论方向）](https://t.zsxq.com/0euwZ8uiP)  \n●[Git 学习资源推荐](https://t.zsxq.com/0bTheL01q)  \n●[《阿里开发者手册 - Redis 专题》PDF 文档](https://t.zsxq.com/0bEiLJIVW)  \n  \n\n代码质量  \n  \n●[24 个写出漂亮代码的小技巧](https://t.zsxq.com/0foGrZIc7)  \n●[程序员“起名”头痛根治指南](https://t.zsxq.com/0d8ODCefj)  \n●[5天带你读完《Effective Java》](https://t.zsxq.com/0dIkpk8AV)  \n●[提高代码质量的书籍和文章推荐](https://t.zsxq.com/0dWEHSiBW)  \n●[一个练习重构的开源教程](https://t.zsxq.com/0d221QNao)  \n●[分享3本对于提高代码质量有实际帮助的书籍](https://t.zsxq.com/0dFLaE2Lp)（《编写可读代码的艺术》、《Clean Code》、《The Clean Coder》）  \n  \n\n进阶攻略  \n  \n●[如何撰写一份令人赞叹的软件专利技术交底书？](https://articles.zsxq.com/id_2kdw0o0ovc44.html)  \n●[校招生如何参与开源项目？如何获得开源经历？](https://articles.zsxq.com/id_q0g14e71eqc3.html)  \n●[一些读书心得和看书做笔记的经验](https://t.zsxq.com/0cpx9pkIE)  \n●[一个关于提升学习能力和效率的视频](https://t.zsxq.com/0c2OboF1Q)（收益匪浅）  \n●[如何有效提升专注力？](https://t.zsxq.com/0eIuSBARU)  \n●[快速熟悉业务逻辑并付诸落地的建议 - 念神](https://t.zsxq.com/0cGu9HjPQ)  \n●[给初级 Java 工程师的一些学习建议 - 念神](https://t.zsxq.com/0ckNvT31a)  \n●[项目技术选型的建议](https://t.zsxq.com/0ciPGdBoZ)（听了一个技术选型分享之后的一些心得体会）  \n●[使用 Google 搜索的实用建议](https://t.zsxq.com/0c0K3zPRk)  \n●[不要把自己局限在技术上!](https://t.zsxq.com/0cdHCFWNw) （重视技术能力，但你的世界不能仅仅只有技术）  \n●[给一些想要换职业方向的朋友一些客观的建议](https://t.zsxq.com/0crTLD2hY)  \n●[如何做编程知识投资及减少知识失效的影响](https://t.zsxq.com/0ccagnzao) （感触很深的一篇文章，强烈推荐阅读）  \n●[碎片化知识可能会带来的坏处](https://t.zsxq.com/0cdfq7iR4)（碎片化知识泛滥的时代，应该注意其对自身的影响）  \n  \n\n开源项目  \n  \n●[一个简易版的IoC的轮子（球友自制，附笔记）](https://t.zsxq.com/0eCVtaUND)  \n●[Java 语言手写的一款简易版 Git（球友自制）](https://t.zsxq.com/0ekLd7XaX)  \n●[基于 SpringBoot 的国密前后端分离快速开发平台](https://t.zsxq.com/0b3wlSfjS)  \n●[《高并发的哲学原理》开源图书](https://t.zsxq.com/0bmQXO4bf)  \n●[zyplayer-doc：适合团队和个人使用的WIKI文档管理工具，同时还包含数据库文档、Api接口文档。](https://t.zsxq.com/0bcfjG15v)  \n●[《深入理解 Java 虚拟机》阅读笔记，基于第二版（目前最新版是第三版）](https://t.zsxq.com/0b1CDmh5H)  \n●[think：一款开源知识管理工具，支持创建知识库、多人协作、分享知识库、绘制思维导图、添加附加附件等功能](https://wx.zsxq.com/dweb2/index/group/48418884588288)  \n●[ip2region：高性能离线IP地址定位库，10微秒级别的查询效率，开箱即用，提供了多种主流编程语言（如 Go，Java，Python）的 xdb 数据生成和查询客户端 API。](https://t.zsxq.com/0b6BYX1rp)  \n●[novel：一套基于时下最新 Java 技术栈 Spring Boot 3 + Vue 3 开发的前后端分离学习型小说项目](https://t.zsxq.com/0b71m4luD)  \n●[lu-raft-kv：分布式 KV 存储轮子](https://t.zsxq.com/0baOCvT01)  \n●[MYDB：简易版数据库](https://t.zsxq.com/0b0d5pFHt)  \n●[mini-spring-cloud：手写的简化版的 Spring Cloud](https://t.zsxq.com/0bai0TuJX)  \n●[SurveyKing：号称功能最强大的调查问卷系统和考试系统](https://t.zsxq.com/0bJaH3GSP)  \n●[cs-self-learning：计算机自学指南](https://t.zsxq.com/0biDtoOF7)  \n●[upupor：小众但是功能强大的开源社区](https://t.zsxq.com/0bZrBeqMg)  \n●[Easy-Es： Elasticsearch 工具库](https://t.zsxq.com/0bWdejp6D)  \n  \n\n工具网站  \n  \n●[两个巨好用的 Linux 命令网站](https://t.zsxq.com/0eKkOJPDA)  \n●[GitHub Web IDE：直接通过多种在线 IDE 打开Github项目](https://t.zsxq.com/0eDXSZsBw)","lastmodified":"2024-02-25T17:02:23.03496398Z","tags":[]},"/elastic/KQL":{"title":"KQL","content":"\nKibana  Query Language\n\n\nhttps://juejin.cn/post/7003201901382598686\n\n\nhttps://www.elastic.co/guide/en/kibana/7.14/kuery-query.html#kuery-query\n\n\n","lastmodified":"2024-02-25T17:02:23.038963969Z","tags":[]},"/lua/%E7%94%A8Go%E5%AE%9E%E7%8E%B0Lua/%E5%89%8D%E8%A8%80":{"title":"前言","content":"\n# 参考资料\n\n*  *[自己动手实现Lua:虚拟机、编译器和标准库](https://weread.qq.com/web/bookDetail/40032ae07164852040038d3)\n* 《Programming in Lua, Fourth Edition》\n* 《Lua 5.3 Reference Manual》\n* 《The Evolution of Lua》\n* 《The Implementation of Lua 5.0》\n* 《A No-Frills Introduction to Lua 5.1 VM Instructions》\n* 《Lua 5.3 Bytecode Reference》\n\n\n\n# 关于 Lua 的语法\n\n* [lua基础](lua/lua基础.md)\n* [Lua高级](lua/Lua高级.md)\n\n\n# 参考代码\n\n* [自己动手实现Lua:虚拟机、编译器和标准库](https://weread.qq.com/web/bookDetail/40032ae07164852040038d3) 的随书代码 [luago-book](https://github.com/zxh0/luago-book)\n\n## 我的代码\n\n* [golua](https://github.com/googoo-s/golua)\n\n\n\n\n\n","lastmodified":"2024-02-25T17:02:23.038963969Z","tags":[]},"/lua/%E7%94%A8Go%E5%AE%9E%E7%8E%B0Lua/1.%E4%BA%8C%E8%BF%9B%E5%88%B6Chunk":{"title":"1.二进制Chunk","content":"\n# 什么是二进制 chunk\nLua 脚本并.不是直接被 Lua 解释器解释执行，而是类似 Java 语言那样，先由 Lua 编译器编译为字节码，然后再交给 Lua 虚拟机去执行\n\nLua 字节码需要一个载体，这个载体就是二进制 chunk，对 Java 虚拟机比较熟悉的读者可以把二进制 chunk 看作 Lua 版的 class 文件\n\n\n#  lunc 命令\n\n\nLuac 命令主要有两个用途：\n\n* 第一，作为编译器，把 Lua 源文件编译成二进制 chunk 文件：\n* 第二，作为反编译器，分析二进制 chunk，将信息输出到控制台\n\n\n```\n➜  will ~ luac\nC:\\Program Files (x86)\\Lua\\5.1\\luac.exe: no input files given\nusage: C:\\Program Files (x86)\\Lua\\5.1\\luac.exe [options] [filenames].\nAvailable options are:\n  -        process stdin\n  -l       list\n  -o name  output to file 'name' (default is \"luac.out\")\n  -p       parse only\n  -s       strip debug information\n  -v       show version information\n  --       stop handling options\n```\n\n## 编译 lua 源文件\n\n将一个或者多个文件名作为参数调用 luac 命令就可以编译指定的 Lua 源文件，如果编译成功，在当前目录下会出现 luac. Out 文件，里面的内容就是对应的二进制 chunk\n\n\n```\n$ luac hello_world.lua              # 生成luac.out\n$ luac -o hw.luac hello_world.lua   # 生成hw.luac\n$ luac -s hello_world.lua           # 不包含调试信息\n$ luac -p hello_world.lua           # 只进行语法检查\n```\n\n\n## Luac 的简单工作原理\n\n\nLua 编译器以函数为单位进行编译，每一个函数都会被 Lua 编译器编译为一个内部结构，这个结构叫作“原型”（Prototype）。原型主要包含 6 部分内容，分别是：\n\n* 函数基本信息（包括参数数量、局部变量数量等）\n* 字节码\n* 常量表\n* Upvalue 表\n* 调式信息\n* 子函数原型列表\n\n**函数原型是一种递归结构**，并且 Lua 源码中函数的嵌套关系会直接反映在编译后的原型里\n\n对于脚本，**Lua 编译器会自动为我们的脚本添加一个 main 函数**（后文称其为主函数），并且把整个程序都放进这个函数里，然后再以它为起点进行编译，那么自然就把整个程序都编译出来了\n\n\n综上所述，函数原型和二进制 chunk 的内部结构\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticPasted%20image%2020230805015642.png)\n\n\n## 反编译二进制 chunk \n\n\nLuc 命令兼具编译和反编译功能，使用“-l”选项可以将 luac 切换到反编译模式。正如 javap 命令是查看 class 文件的利器，luac 命令搭配“-l”选项则是查看二进制 chunk 的利器\n\n\n以前面编译出来的 hello_world. Luac 文件为例，其反编译输出如下。\n\n\n```\n$ luac -l hello_world.luac\n\nmain \u003chello_world.lua:0,0\u003e (4 instructions at 0x7fb4dbc030f0)\n0+ params, 2 slots, 1 upvalue, 0 locals, 2 constants, 0 functions\n\t1    [1]GETTABUP  0 0-1 ; _ENV \"print\"\n\t2    [1]LOADK      1-2       ; \"Hello, World! \"\n\t3    [1]CALL       0 2 1\n\t4    [1]RETURN     0 1\n```\n\n\n由于“Hello, World! ”程序只有一条打印语句，所以编译出来的二进制 chunk 里也只有一个主函数原型（没有子函数），因此反编译输出里也只有主函数信息\n\n\n多函数的 lua\n\n```\nfunction foo()\n\tfunction bar() end\nend\n```\n\n反编译结果，反编译输出中会依次包含 main、foo 和 bar 函数的信息，如下所示。\n\n\n```\n$ luac -l foo_bar.lua\n\nmain \u003cfoo_bar.lua:0,0\u003e (3 instructions at 0x7fc43fc02b20)\n0+ params, 2 slots, 1 upvalue, 0 locals, 1 constant, 1 function\n\t1  [4] CLOSURE    0 0     ; 0x7fc43fc02cc0\n\t2  [1] SETTABUP  0-1 0 ; _ENV \"foo\"\n\t3  [4] RETURN     0 1\n\nfunction \u003cfoo_bar.lua:1,4\u003e (3 instructions at 0x7fc43fc02cc0)\n0 params, 2 slots, 1 upvalue, 0 locals, 1 constant, 1 function\n\t1  [3] CLOSURE    0 0     ; 0x7fc43fc02e40\n\t2  [2] SETTABUP  0-1 0 ; _ENV \"bar\"\n\t3  [4] RETURN     0 1\n\nfunction \u003cfoo_bar.lua:2,3\u003e (1 instruction at 0x7fc43fc02e40)\n0 params, 2 slots, 0 upvalues, 0 locals, 0 constants, 0 functions\n\t1  [3] RETURN     0 1\n\n```\n\n\n反编译打印出的函数信息包含两个部分：\n\n* 前面两行是函数基本信息，\n\t* 第一行\n\t\t* 如果以 main 开头，说明这是编译器为我们生成的主函数，以 function 开头，说明这是一个普通函数\n\t\t* 接着是定义函数的源文件名和函数在文件里的**起止行号**（对于主函数，起止行号都是 0），然后是指令数量和函数地址。\n\t* 第二行依次给出\n\t\t* 函数的固定参数数量（如果有+号，表示这是一个 vararg 函数）\n\t\t* 运行函数所必要的寄存器数量\n\t\t* upvalue 数量\n\t\t* 局部变量数量\n\t\t* 常量数量\n\t\t* 子函数数量\n* 后面是指令列表。每一条都包含\n\t* 指令序号\n\t* 对应行号\n\t* 操作码 \n\t* 操作数\n\t* 分号后面是 luac 根据指令操作数生成的注释，以便于我们理解指令\n\n## 二进制 chunk 的格式\n\n和 Java 的 class 文件类似，Lua 的二进制 chunk 本质上也是一个字节流\n\n* 二进制 chunk 格式（包括 Lua 虚拟机指令）属于 Lua 虚拟机内部实现细节，并没有标准化，也没有任何官方文档对其进行说明，一切以 Lua 官方实现的源代码为准\n* **二进制 chunk 格式的设计没有考虑跨平台的需求**，使用超过一个字节表示的数据，必须要考虑大小端（Endianness）问题。\n\t* Lua 官方实现的做法比较简单：编译 Lua 脚本时，**直接按照本机的大小端方式**生成二进制 chunk 文件，当加载二进制 chunk 文件时，会探测被加载文件的大小端方式，如果和本机不匹配，就拒绝加载\n* 二进制 chunk 格式的设计也没有考虑不同 Lua 版本之间的兼容问题\n\t* 编译 Lua 脚本时，直接按照当时的 Lua 版本生成二进制 chunk 文件，当加载二进制 chunk 文件时，会检测被加载文件的版本号，如果和当前 Lua 版本不匹配，则拒绝加载\n* 二进制 chunk 格式并没有被刻意设计得很紧凑\n\t* lua 脚本预编译成二进制 chunk 的主要目的是为了获得更快的加载速度，所以这也不是什么大问题。\n\n### 数据类型 \n\n在讨论二进制 chunk 格式时，我们称这种被编码为一个或多个字节的信息单位为数据类型\n由于 Lua 官方实现是用 C 语言编写的，所以 **C 语言的一些数据类型（比如 size_t）会直接反映在二进制 chunk 的格式**里\n\n二进制 chunk 内部使用的数据类型大致可以分为**数字、字符串和列表**三种。\n\n\n#### 数字\n\n数字类型主要包括**字节、C 语言整型（后文简称 cint）、C 语言 size_t 类型（简称 size_t）、Lua 整数、Lua 浮点数**五种\n\n* 字节类型用来存放一些比较小的整数值，比如 Lua 版本号、函数的参数个数等；\n* cint 类型主要用来表示列表长度；\n* size_t 则主要用来表示长字符串长度；\n* Lua 整数和 Lua 浮点数则主要在常量表里出现，记录 Lua 脚本中出现的整数和浮点数字面量\n\n数字类型在二进制 chunk 里都按照固定长度存储。除字节类型外，其余四种数字类型都会占用多个字节，具体占用几个字节则会记录在头部里\n\nLua 官方实现（64 位平台）里对应的 C 语言类型、在本书中使用的 Go 语言类型，以及占用的字节数\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticPasted%20image%2020230805155327.png)\n\n\n#### 字符串\n\n字符串在二进制 chunk 里，其实就是一个**字节数组**。\n\n\n因为字符串长度是不固定的，所以需要把字节数组的长度也记录到二进制 chunk 里。**作为优化，字符串类型又可以进一步分为短字符串和长字符串两种，具体有三种情况**\n\n\n* 对于 NULL 字符串，只用 0 x 00 表示就可以了。\n* 对于长度小于等于 253（0 xFD）的字符串，**先使用一个字节记录长度+1**，然后是字节数组。\n* 对于长度大于等于 254（0 xFE）的字符串，**第一个字节是 0 xFF，后面跟一个 size_t 记录长度+1**，最后是字节数组。\n\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticPasted%20image%2020230805155714.png)\n\n\n#### 列表\n\n在二进制 chunk 内部，**指令表、常量表、子函数原型表等信息都是按照列表的方式存储的**。\n\n* 用一个 cint 类型记录列表长度，\n* 然后紧接着存储 n 个列表元素，\n* 至于列表元素如何存储那就要具体情况具体分析了\n\n### 总体结果\n\n总体而言，二进制 chunk 分为头部和主函数原型两部分\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticPasted%20image%2020230805015642.png)\n\n\n定义结构体 binaryChunk \n\n\n```\ntype binaryChunk struct {\n    // 头部\n    header\n    // 主函数upvalues 和闭包有关\n    sizeUpvalues byte\n    // 主函数原型\n    mainFunc *Prototype\n}\n```\n\n### 头部\n\n\n```\ntype header struct {\n\t// 签名，相对于Java的模式,主要起快速识别文件格式的作用\n\tsignature [4]byte\n\t// 版本号，记录二进制chunk文件所对应的Lua版本号\n\tversion byte\n\t// 格式号，如果和虚拟机本身的格式号不匹配，就拒绝加载该文件\n\tformat          byte\n\t// LUAC_DATA 格式号之后的6个字节在Lua官方实现里叫作LUAC_DATA。\n\t// 其中前两个字节是0x1993，这是Lua 1.0发布的年份；\n\t// 后四个字节依次是回车符（0x0D）、换行符（0x0A）、替换符（0x1A）和另一个换行符\n\t// 6个字节主要起进一步校验的作用。如果Lua虚拟机在加载二进制chunk时发现这6个字节和预期的不一样，就会认为文件已经损坏，拒绝加载\n\tluacData        [6]byte\n\t// 接下来的5个字节分别记录cint、size_t、Lua虚拟机指令、Lua整数和Lua浮点数这5种数据类型在二进制chunk里占用的字节数\n\tcintSize        byte\n\tsizetSize       byte\n\tinstructionSize byte\n\tluaIntegerSize  byte\n\tluaNumberSize   byte\n\t// LUAC_INT， n个字节存放Lua整数值0x5678，存储这个Lua整数的目的是为了检测二进制chunk的大小端方式\n\tluacInt         int64\n\t// LUAC_NUM，头部的最后n个字节存放Lua浮点数370.5，头部的最后n个字节存放Lua浮点数370.5\n\tluacNum         float64\n}\n```\n\n### 函数原型\n\n\n函数原型主要包含函数基本信息、指令表、常量表、upvalue 表、子函数原型表以及调试信息；\n\n* 基本信息\n\t* 源文件名、起止行号、固定参数个数、是否是 vararg 函数以及运行函数所必要的寄存器数量；\n\t* 调试信息又包括行号表、局部变量表以及 upvalue 名列表。\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticPasted%20image%2020230805162248.png)\n\n```\ntype Prototype struct {\n\t// 源文件名，只有在主函数原型里，该字段才真正有值，在其他嵌套的函数原型里，该字段存放空字符串\n\tSource string\n\t// Prototype,用于记录原型对应的函数在源文件中的起止行号。如果是普通的函数，起止行号都应该大于0；\n\t//  如果是主函数，则起止行号都是0\n\tLineDefined     uint32\n\tLastLineDefined uint32\n\t// 函数固定参数个数。这里的固定参数，是相对于变长参数（Vararg）而言的\n\tNumParams byte\n\t// 用来记录函数是否为Vararg函数，即是否有变长参数\n\tIsVararg byte\n\t// 记录的是寄存器数量。Lua编译器会在编译函数时将这个数量计算好，并以字节类型保存在函数原型\n\tMaxStackSize byte\n\t// 函数基本信息之后是指令表\n\tCode []uint32\n\t// 指令表之后是常量表。常量表用于存放Lua代码里出现的字面量，包括nil、布尔值、整数、浮点数和字符串五种。\n\t// 每个常量都以1字节tag开头，用来标识后续存储的是哪种类型的常量值。常量tag值,tag类型为TAG_NIL，TAG_BOOLEAN，，\n\tConstants []interface{}\n\t// Upvalues 占有两个字节\n\tUpvalues []Upvalue\n\t// 子函数原型表\n\tProtos []*Prototype\n\t// 行号表 子函数原型表之后是行号表，其中行号按cint类型存储。行号表中的行号和指令表中的指令一一对应\n\tLineInfo []uint32\n\t// 号表之后是局部变量表，用于记录局部变量名，\n\t// 表中每个元素都包含变量名（按字符串类型存储）和起止指令索引（按cint类型存储\n\tLocVars []LocVar\n\t// 数原型的最后一部分内容是Upvalue名列表。该列表中的元素（按字符串类型存储）\n\t// 和前面Upvalue表中的元素一一对应，分别记录每个Upvalue在源代码中的名字\n\tUpvalueNames []string\n}\n\ntype LocVar struct {\n\tVarName string\n\tStartPC uint32\n\tEndPC   uint32\n}\n\n\n// Upvalue 和闭包相关\ntype Upvalue struct {\n\tInstack byte\n\tInx     byte\n}\n\n// 常量类型\nconst (\n\tTAG_NIL       = 0x00\n\tTAG_BOOLEAN   = 0x01\n\tTAG_NUMBER    = 0x03\n\tTAG_INTEGER   = 0x13\n\tTAG_SHORT_STR = 0x04\n\tTAG_LONG_STR  = 0x14\n)\n\n```\n\n## 解析二进制 chunk\n\n在 `binary_chunk.go` 中定义了 chunk 的解析函数`Undump`\n\n```\nfunc Undump(data []byte) * Prototype {\n\treader := \u0026reader{data}\n\treader.checkHeader()\n\treader.readByte()\n\t\n\treader.readProto(\"\")\n}\n```\n\n解析 chunk 主要看 reader ，定义 ` binchunk/reader.go`\n\n\n```\npackage binchunk\n\nimport \"encoding/binary\"\nimport \"math\"\n\ntype reader struct {\n\tdata []byte\n}\n```\n\n### 读取基本数据类型\n\n定义了 7 种读取数据类型的方法\n\n\n```\n// readByte 从字节流里读取一个字节\nfunc (self *reader) readByte() byte \n// readUint32 使用小端方式从字节流里读取一个cint存储类型（占4个字节，映射为Go语言uint32类型）的整数\nfunc (self *reader) readUint32() uint32 \n// readUint64 使用小端方式从字节流里读取一个cint存储类型（占4个字节，映射为Go语言uint32类型）的整数\nfunc (self *reader) readUint64() uint64 \n// readLuaInteger 从字节流里读取一个Lua整数（占8个字节，映射为Go语言int64类型\nfunc (self *reader) readLuaInteger() int64 \n// readLuaNumber 从字节流里读取一个Lua浮点数（占8个字节，映射为Go语言float64类型）\nfunc (self *reader) readLuaNumber() float64 \n// readString()方法从字节流里读取字符串（映射为Go语言string类型）\nfunc (self *reader) readString() string \n// readBytes()方法从字节流里读取n个字节\nfunc (self *reader) readBytes(n uint) []byte \n\n```\n\n### 检查头部\n\nCheckHeader ()方法从字节流里读取并检查二进制 chunk 头部的各个字段，如果发现某个字段和期望不符，则调用 panic 函数终止加载\n\n\n### 读取函数原型\n\nReadProto ()方法从字节流里读取函数原型","lastmodified":"2024-02-25T17:02:23.038963969Z","tags":[]},"/lua/%E7%94%A8Go%E5%AE%9E%E7%8E%B0Lua/2.%E6%8C%87%E4%BB%A4%E9%9B%86":{"title":"2.指令集","content":"\n\n# 指令集介绍\n\n按照实现方式，虚拟机大致可以分为两类：\n\n* 基于栈（Stack Based）。 \n\t* Java 虚拟机、. NET CLR、Python 虚拟机，以及在第 2 章中提到过的 Ruby YARV 虚拟机都是基于栈的虚拟机；\n* 基于寄存器（Register Based）。\n\t* 以及本书讨论的 Lua 虚拟机则是基于寄存器的虚拟机\n\n\n如同真实机器有一套指令集（Instruction Set）一样，虚拟机也有自己的指令集：\n\n* 基于栈的虚拟机需要使用 PUSH 类指令往栈顶推入值，使用 POP 类指令从栈顶弹出值, 其他指令则是对栈顶值进行操作，因此**指令集相对比较大，**\n* 其他指令则是对栈顶值进行操作，因此指令集相对比较大，但是由于需要把寄存器地址编码进指令里，**所以指令的平均长度比较长**。\n\n\n按照指令长度是否固定，指令集可以分为**定长（Fixed-width）指令集**和**变长（Variable-width）指令集**两种\n\n* Java 虚拟机使用的是变长指令集，指令长度从 1 到多个字节不 \n* Lua 虚拟机采用的则是定长指令集，每条指令占 4 个字节（共 32 比特），\n\t* 其中 6 比特用于操作码（Opcode），\n\t* 其余 26 比特用于操作数（Operand）\n\n\nLua 5.3 一共定义了 47 条指令，按照作用，这些指令大致可以分为 6 大类\n\n* 常量加载指令、\n* 运算符相关指令、\n* 循环和跳转指令、\n* 函数调用相关指令、\n* 表操作指令以及 \n* Upvalue 操作指令 \n\n\n#  指令编码格式\n\n## 编码模式\n\n条 Lua 虚拟机指令占用 4 个字节，共 32 个比特（可以用 Go 语言 uint 32 类型表示），\n\n*  6 个比特用于操作码，\n* 高 26 个比特用于操作数\n\nLua 虚拟机指令可以分为四类，分别对应四种编码模式（Mode）: \n\n* iABC\n\t* 可以携带 A、B、C 三个操作数，分别占用 8、9、9 个比特\n\t* 有 39 条使用 iABC 模式\n* iABx、\n\t* 可以携带 A 和 Bx 两个操作数，分别占用 8 和 18 个比特\n\t*  3 条使用 iABx 指令\n* iAsBx、\n\t* 可以携带 A 和 sBx 两个操作数，分别占用 8 和 18 个比特\n\t* 4 条使用 iAsBx 模式\n* iAx \n\t* 只携带一个操作数，占用全部的 26 个比特\n\t* 1 条使用 iAx 格式（实际上这条指令并不是真正的指令，只是用来扩展其他指令操作数的）\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticPasted%20image%2020230806010858.png)\n\n### 操作码\n\n\n由于 Lua 虚拟机指令使用 6 个比特表示操作码，所以最多只能有 64 条指令\n\n\n操作码从 0 开始，到 46 截止。\n\n定义如下\n\n\n```\nconst (\n\tOP_MOVE = iota\n\tOP_LOADK\n\tOP_LOADKX\n\tOP_LOADBOOL\n\tOP_LOADNIL\n\tOP_GETUPVAL\n\tOP_GETTABUP\n\tOP_GETTABLE\n\tOP_SETTABUP\n\tOP_SETUPVAL\n\tOP_SETTABLE\n\tOP_NEWTABLE\n\tOP_SELF\n\tOP_ADD\n\tOP_SUB\n\tOP_MUL\n\tOP_MOD\n\tOP_POW\n\tOP_DIV\n\tOP_IDIV\n\tOP_BAND\n\tOP_BOR\n\tOP_BXOR\n\tOP_SHL\n\tOP_SHR\n\tOP_UNM\n\tOP_BNOT\n\tOP_NOT\n\tOP_LEN\n\tOP_CONCAT\n\tOP_JMP\n\tOP_EQ\n\tOP_LT\n\tOP_LE\n\tOP_TEST\n\tOP_TESTSET\n\tOP_CALL\n\tOP_TAILCALL\n\tOP_RETURN\n\tOP_FORLOOP\n\tOP_FORPREP\n\tOP_TFORCALL\n\tOP_TFORLOOP\n\tOP_SETLIST\n\tOP_CLOSURE\n\tOP_VARARG\n\tOP_EXTRAARG\n)\n```\n\n### 操作数\n\n操作数是指令的参数，每条指令（因编码模式而异）可以携带 1 到 3 个操作数。\n\n* 其中操作数 A 主要用来表示目标寄存器索引，\n* 其他操作数按照其表示的信息，可以粗略分为四种类型：\n\t* OpArgN\n\t\t* 不表示任何信息，也就是说不会被使用。比如 MOVE 指令（iABC 模式）只使用 A 和 B 操作数，不使用 C 操作数（OpArgN 类型\n\t* OpArgU\n\t\t* 操作数也可能表示布尔值、整数值、upvalue 索引、子函数索引等，这些情况都可以归到 OpArgU 类型里\n\t* OpArgR\n\t\t* 在 iABC 模式下表示寄存器索引，\n\t\t* 在 iAsBx 模式下表示跳转偏移\n\t* OpArgK \n\t\t* 表示常量表索引或者寄存器索引\n\t\t* 第一种情况是 LOADK 指令（iABx 模式，用于将常量表中的常量加载到寄存器中），该指令的 Bx 操作数表示**常量表索引**，如果用 Kst (N)表示常量表访问，则 LOADK 指令可以表示为伪代码 R (A) := Kst (Bx)\n\t\t* 第二种情况是部分 iABC 模式指令，**这些指令的 B 或 C 操作数既可以表示常量表索引也可以表示寄存器索引**，以加法指令 ADD 为例，如果用 RK (N)表示常量表或者寄存器访问，则该指令可以表示为伪代码 R (A):= RK (B)+RK (C)。\n\n\n### 指令表 \n\nLua 官方实现把每一条指令的基本信息（包括编码模式、是否设置寄存器 A、操作数 B 和 C 的使用类型等）都编码成了一个字节。\n\n我们也对其进行模仿，只不过把字节换成结构体，\n\n\n```\n\ntype opcode struct {\n\t// operator is a test (next instruction must be a jump)\n\ttestFlag byte\n\t// 是否设置寄存器A\n\tsetAFlag byte\n\t// 操作数B使用类型\n\targBMode byte\n\t//  操作数C使用类型\n\targCMode byte\n\t// 操作模式\n\topMode byte\n\tname   string\n}\n```\n\n所有的指令\n\n```\nvar opcodes = []opcode{\n\t//T A    B       C     mode  \t   name\n\t{0, 1, OpArgR, OpArgN, IABC, \"MOVE     \"},\n\t{0, 1, OpArgK, OpArgN, IABx, \"LOADK    \"},\n\t{0, 1, OpArgN, OpArgN, IABx, \"LOADKX  \"},\n\t{0, 1, OpArgU, OpArgU, IABC, \"LOADBOOL\"},\n\t{0, 1, OpArgU, OpArgN, IABC, \"LOADNIL \"},\n\t{0, 1, OpArgU, OpArgN, IABC, \"GETUPVAL\"},\n\t{0, 1, OpArgU, OpArgK, IABC, \"GETTABUP\"},\n\t{0, 1, OpArgR, OpArgK, IABC, \"GETTABLE\"},\n\t{0, 0, OpArgK, OpArgK, IABC, \"SETTABUP\"},\n\t{0, 0, OpArgU, OpArgN, IABC, \"SETUPVAL\"},\n\t{0, 0, OpArgK, OpArgK, IABC, \"SETTABLE\"},\n\t{0, 1, OpArgU, OpArgU, IABC, \"NEWTABLE\"},\n\t{0, 1, OpArgR, OpArgK, IABC, \"SELF     \"},\n\t{0, 1, OpArgK, OpArgK, IABC, \"ADD      \"},\n\t{0, 1, OpArgK, OpArgK, IABC, \"SUB      \"},\n\t{0, 1, OpArgK, OpArgK, IABC, \"MUL      \"},\n\t{0, 1, OpArgK, OpArgK, IABC, \"MOD      \"},\n\t{0, 1, OpArgK, OpArgK, IABC, \"POW      \"},\n\t{0, 1, OpArgK, OpArgK, IABC, \"DIV      \"},\n\t{0, 1, OpArgK, OpArgK, IABC, \"IDIV     \"},\n\t{0, 1, OpArgK, OpArgK, IABC, \"BAND     \"},\n\t{0, 1, OpArgK, OpArgK, IABC, \"BOR      \"},\n\t{0, 1, OpArgK, OpArgK, IABC, \"BXOR     \"},\n\t{0, 1, OpArgK, OpArgK, IABC, \"SHL      \"},\n\t{0, 1, OpArgK, OpArgK, IABC, \"SHR      \"},\n\t{0, 1, OpArgR, OpArgN, IABC, \"UNM      \"},\n\t{0, 1, OpArgR, OpArgN, IABC, \"BNOT     \"},\n\t{0, 1, OpArgR, OpArgN, IABC, \"NOT      \"},\n\t{0, 1, OpArgR, OpArgN, IABC, \"LEN      \"},\n\t{0, 1, OpArgR, OpArgR, IABC, \"CONCAT  \"},\n\t{0, 0, OpArgR, OpArgN, IAsBx, \"JMP      \"},\n\t{1, 0, OpArgK, OpArgK, IABC, \"EQ       \"},\n\t{1, 0, OpArgK, OpArgK, IABC, \"LT       \"},\n\t{1, 0, OpArgK, OpArgK, IABC, \"LE       \"},\n\t{1, 0, OpArgN, OpArgU, IABC, \"TEST     \"},\n\t{1, 1, OpArgR, OpArgU, IABC, \"TESTSET \"},\n\t{0, 1, OpArgU, OpArgU, IABC, \"CALL     \"},\n\t{0, 1, OpArgU, OpArgU, IABC, \"TAILCALL\"},\n\t{0, 0, OpArgU, OpArgN, IABC, \"RETURN  \"},\n\t{0, 1, OpArgR, OpArgN, IAsBx, \"FORLOOP \"},\n\t{0, 1, OpArgR, OpArgN, IAsBx, \"FORPREP \"},\n\t{0, 0, OpArgN, OpArgU, IABC, \"TFORCALL\"},\n\t{0, 1, OpArgR, OpArgN, IAsBx, \"TFORLOOP\"},\n\t{0, 0, OpArgU, OpArgU, IABC, \"SETLIST \"},\n\t{0, 1, OpArgU, OpArgN, IABx, \"CLOSURE \"},\n\t{0, 1, OpArgU, OpArgN, IABC, \"VARARG  \"},\n\t{0, 0, OpArgU, OpArgU, IAx, \"EXTRAARG\"},\n}\n\n```\n\n## 指令解码\n\n定义 Instruction 类型表示指令，定义五个方法，用于解码指令\n\n\n```\nype Instruction uint32\n  \n\n// Opcode()方法从指令中提取操作F\nfunc (self Instruction) Opcode() int {\n// ABC()方法从iABC模式指令中提取参数\nfunc (self Instruction) ABC() (a, b, c int) {\n// ABx()方法从iABx模式指令中提取参数，\nfunc (self Instruction) ABx() (a, bx int) {\n// AsBx()方法从iAsBx模式指令中提取参数\nfunc (self Instruction) AsBx() (a, sbx int) {\n// Ax()方法从iAx模式指令中提取参数\nfunc (self Instruction) Ax() int{\n```\n\n\nPcode ()、ABC ()、ABx ()、Ax ()这 4 个方法比较简单，只使用位移和逻辑与运算符从指令中提取信息\n\n\nSBx 操作数（共 18 个比特）表示的是**有符号整数**。有很多种方式可以把有符号整数编码成比特序列，比如 **2 的补码**（Two's Complement）等。Lua 虚拟机这里采用了一种叫作**偏移二进制码（Offset Binary，也叫作 Excess-K）的编码模式。**\n\n\u003e **偏移二进制码（Offset Binary，也叫作 Excess-K）\n\u003e 如果把 sBx 解释成无符号整数时它的值是 x，那么解释成有符号整数时它的值就是 x-K。那么 K 是什么呢？K 取 sBx 所能表示的最大无符号整数值的一半。也就是上面代码中的 MAXARG_sBx\n\n\n\n```\nconst MAXARG_Bx = 1\u003c\u003c18-1 // 2^18-1 = 262143 const MAXARG_sBx = MAXARG_Bx \u003e\u003e 1 // 262143 / 2 = 131071\n```\n","lastmodified":"2024-02-25T17:02:23.038963969Z","tags":[]},"/lua/%E7%94%A8Go%E5%AE%9E%E7%8E%B0Lua/3.lua-API":{"title":"3.lua API","content":"\nLua 核心是以库（Library）的形式被实现的，其他应用程序只需要链接 Lua 库就可以使用 Lua 提供的 API 轻松获得脚本执行能力\n\n\u003e  Lua 发布版包含的两个命令行程序，也就是我们已经很熟悉的 lua 和 luac，实际上就是 Lua 库的两个特殊的宿主程序。\n\n\n# Lua API 介绍\n\n官方 Lua 使用 Clean C（其语法是 C 和 C++语言的子集）编写，Lua API 主要是指一系列以“lua_”开头的 C 语言函数（也可能是宏定义，后文统称为函数）。\n\n\n**Lua state 的发展**\n\n1. 最开始 Lua 解释器的状态是完全隐藏在 API 后面的，散落在各种全局变量里。\n\n2. 由于某些宿主环境（比如 Web 服务器）需要同时使用多个 Lua 解释器实例 Lua 3.1 引入了 lua_State 结构体，对解释器状态进行了封装，从而使得用户可以在多个解释器实例之间切换。\n\n3. Lua 4.0 对 API 进行了重新设计，引入了虚拟栈的概念，并且让 lua_State 结构体从幕后走到了前台。\n\n4. 用户使用 lua_newstate ()函数创建 lua_State 实例，其他函数则用于操作 lua_State 实例。\n\n\nLua API、Lua State 以及宿主程序之间的关系如图 4-1 所示\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticPasted%20image%2020230806021610.png)\n\nLua State 是 Lua API 非常核心的一个概念，在本章，我们暂时先把 **Lua State 理解成一个不那么纯粹的栈（Stack )**, 之所以不够纯粹，是因为这个栈也可以通过索引直接进行访问\n\n\n## Lua 栈\n\n\nLua State 是 Lua API 非常核心的概念，全部的 API 函数都是围绕 Lua State 进行操作，而 Lua State 内部封装的最为基础的一个状态就是**虚拟栈（后面我们称其为 Lua 栈**）\n\n\n\nLua 栈是宿主语言（对于官方 Lua 来说是 C 语言，本次是Go 语言）和 Lua 语言进行沟通的桥梁，Lua API 函数有很大一部分是专门用来操作 Lua 栈的。宿主语言、Lua 语言、Lua 栈之间的关系如图4-2所示。\n\n![](https://googoo-s.oss-cn-chengdu.aliyuncs.com/statisticPasted%20image%2020230806022038.png)","lastmodified":"2024-02-25T17:02:23.038963969Z","tags":[]},"/lua/Lua%E9%AB%98%E7%BA%A7":{"title":"Lua高级","content":"\n# 元表\n\n元表 _(metatable)_ 的**表现行为类似于 C++ 语言中的操作符重载**，例如我们可以重载 \"__add\" 元方法 _(metamethod)_，来计算两个 Lua 数组的并集；或者重载 \"__index\" 方法，来定义我们自己的 Hash 函数。Lua 提供了两个十分重要的用来处理元表的方法\n\n- setmetatable(table, metatable)：此方法用于为一个表设置元表。\n    \n- getmetatable(table)：此方法用于获取表的元表对象\n    \n\n设置元表\n\n```Lua\nlocal mytable = {}\nlocal mymetatable = {}\nsetmetatable(mytable, mymetatable)\n```\n\n  \n\n## **修改表的操作符行为**\n\n  \n\n通过重载 \"__add\" 元方法来计算集合的并集实例\n\n```Lua\nlocal set1 = {10, 20, 30}   -- 集合\nlocal set2 = {20, 40, 50}   -- 集合\n\n-- 将用于重载__add的函数，注意第一个参数是self\nlocal union = function (self, another)\n    local set = {}\n    local result = {}\n\n    -- 利用数组来确保集合的互异性\n    for i, j in pairs(self) do set[j] = true end\n    for i, j in pairs(another) do set[j] = true end\n\n    -- 加入结果集合\n    for i, j in pairs(set) do table.insert(result, i) end\n    return result\nend\nsetmetatable(set1, {__add = union}) -- 重载 set1 表的 __add 元方法\n\nlocal set3 = set1 + set2\nfor _, j in pairs(set3) do\n    io.write(j..\" \")               --\u003eoutput：30 50 20 40 10\nend\n```\n\n除了加法可以被重载之外，Lua 提供的所有操作符都可以被重载：\n| 元方法        | 含义                                                                         |\n|------------|----------------------------------------------------------------------------|\n| \"__add    | #NAME?                                                                     |\n| \"__sub   | - 操作 其行为类似于 \"add\" 操作                                                       |\n| \"__mul    | * 操作 其行为类似于 \"add\" 操作                                                       |\n| \"__div   | / 操作 其行为类似于 \"add\" 操作                                                       |\n| \"__mod   | % 操作 其行为类似于 \"add\" 操作                                                       |\n| \"__pow    | ^ （幂）操作 其行为类似于 \"add\" 操作                                                    |\n| \"__unm\"   | 一元 - 操作                                                                    |\n| \"__concat\" | .. （字符串连接）操作                                                               |\n| \"__len\"    | # 操作                                                                       |\n| \"__eq\"     | == 操作 函数 getcomphandler 定义了 Lua 怎样选择一个处理器来作比较操作 仅在两个对象类型相同且有对应操作相同的元方法时才起效 |\n| \"__lt\"     | \u003c 操作                                                                       |\n| \"__le\"     | \u003c= 操作                                                                      |\n\n\n除了操作符之外，如下元方法也可以被重载，下面会依次解释使用方法：\n\n|   |   |\n|---|---|\n|元方法|含义|\n|\"__index\"|取下标操作用于访问 table[key]|\n|\"__newindex\"|赋值给指定下标 table[key] = value|\n|\"__tostring\"|转换成字符串|\n|\"__call\"|当 Lua 调用一个值时调用|\n|\"__mode\"|用于弱表(week table)|\n|\"__metatable\"|用于保护metatable不被访问|\n\n## **__index 元方法**\n\n```Lua\nmytable = setmetatable({key1 = \"value1\"},   --原始表\n{__index = function(self, key)            --重载函数\n    if key == \"key2\" then\n        return \"metatablevalue\"\n    end\nend\n})\n\nprint(mytable.key1,mytable.key2)  --\u003e output：value1 metatablevalue\n```\n\n关于 __index 元方法，有很多比较高阶的技巧，例如：__index 的元方法不需要非是一个函数，他也可以是一个表。\n\n```Lua\nt = setmetatable({[1] = \"hello\"}, {__index = {[2] = \"world\"}})\nprint(t[1], t[2])   --\u003ehello wor\n```\n\n## **__tostring 元方法**\n\n  \n\n与 Java 中的 toString() 函数类似，可以实现自定义的字符串转换。\n\n```Lua\narr = {1, 2, 3, 4}\narr = setmetatable(arr, {__tostring = function (self)\n    local result = '{'\n    local sep = ''\n    for _, i in pairs(self) do\n        result = result ..sep .. i\n        sep = ', '\n    end\n    result = result .. '}'\n    return result\nend})\nprint(arr)  --\u003e {1, 2, 3, 4}\n```\n\n## **__call 元方法**\n\n__call 元方法的功能类似于 C++ 中的仿函数，使得普通的表也可以被调用。\n\n  \n\n```Lua\nfunctor = {}\nfunction func1(self, arg)\n    print (\"called from\", arg)\nend\nsetmetatable(functor, {__call = func1})\n\nfunctor(\"functor\")  --\u003e called from functor\nprint(functor)      --\u003e output：0x00076fc8 （后面这串数字可能不一样）\n```\n\n## **__metatable 元方法**\n\n假如我们想保护我们的对象使其使用者既看不到也不能修改 metatables。我**们可以对 metatable 设置了 __metatable 的值，getmetatable 将返回这个域的值，而调用 setmetatable 将会出错**：\n\n```Lua\nbject = setmetatable({}, {__metatable = \"You cannot access here\"})\n\nprint(getmetatable(Object)) --\u003e You cannot access heresetmetatable(Object, {})    --\u003e 引发编译器报错\n```\n\n  \n\n# 面向对象\n\n## 类\n\n在 Lua 中，我们可以使用表和函数实现面向对象。**将函数和相关的数据放置于同一个表中就形成了一个对象。**\n\n```Plaintext\nlocal _M = {}\n\nlocal mt = { __index = _M }\n\nfunction _M.deposit (self, v)\n    self.balance = self.balance + v\nend\n\nfunction _M.withdraw (self, v)\n    if self.balance \u003e v then\n        self.balance = self.balance - v\n    else\n        error(\"insufficient funds\")\n    end\nend\n\nfunction _M.new (self, balance)\n    balance = balance or 0\n    return setmetatable({balance = balance}, mt)\nend\n\nreturn _M\n```\n\n引用\n\n```Lua\nlocal account = require(\"account\")\n\nlocal a = account:new()\na:deposit(100)\n\nlocal b = account:new()\nb:deposit(50)\n\nprint(a.balance)  --\u003e output: 100\nprint(b.balance)  --\u003e output: 50\n```\n\n上面这段代码 \"setmetatable({balance = balance}, mt)\"，其中 mt 代表 `{ __index = _M }` ，这句话值得注意。根据我们在元表这一章学到的知识，我们明白，setmetatable 将 `_M` 作为新建表的原型，所以在自己的表内找不到 'deposit'、'withdraw' 这些方法和变量的时候，便会到 __index 所指定的 _M 类型中去寻找。\n\n  \n\n## 继承\n\n继承可以用元表实现，它提供了在父类中查找存在的方法和变量的机制。在 Lua 中是不推荐使用继承方式完成构造的，这样做引入的问题可能比解决的问题要多，下面一个是字符串操作类库，给大家演示一下。\n\n```Lua\n---------- s_base.lualocal _M = {}\n\nlocal mt = { __index = _M }\n\nfunction _M.upper (s)return string.upper(s)\nendreturn _M\n\n---------- s_more.lualocal s_base = require(\"s_base\")\n\nlocal _M = {}\n_M = setmetatable(_M, { __index = s_base })\n\n\nfunction _M.lower (s)return string.lower(s)\nendreturn _M\n\n---------- test.lualocal s_more = require(\"s_more\")\n\nprint(s_more.upper(\"Hello\"))   -- output: HELLOprint(s_more.lower(\"Hello\"))   -- output: hello\n```\n\n  \n\n## 成员私有性\n\n在动态语言中引入成员私有性并没有太大的必要，反而会显著增加运行时的开销，毕竟这种检查无法像许多静态语言那样在编译期完成。下面的技巧把对象作为各方法的 upvalue，本身是很巧妙的，但会让子类继承变得困难，同时构造函数动态创建了函数，会导致构造函数无法被 JIT 编译。\n\n在 Lua 中，成员的私有性，使用类似于函数闭包的形式来实现。在我们之前的银行账户的例子中，我们使用一个工厂方法来创建新的账户实例，通过工厂方法对外提供的闭包来暴露对外接口。而不想暴露在外的例如 balance 成员变量，则被很好的隐藏起来。\n\n```Lua\nfunction newAccount (initialBalance)\n    local self = {balance = initialBalance}\n    local withdraw = function (v)\n        self.balance = self.balance - v\n    end\n    local deposit = function (v)\n        self.balance = self.balance + v\n    end\n    local getBalance = function () \n        return self.balance \n    end\n    \n    return {\n        withdraw = withdraw,\n        deposit = deposit,\n        getBalance = getBalance\n    }\nend\n\na = newAccount(100)\na.deposit(100)\nprint(a.getBalance()) --\u003e 200print(a.balance)      --\u003e nil\n```\n\n  \n\n# 局部变量\n\nLua 的设计有一点很奇怪，**在一个 block 中的变量，如果之前没有定义过，那么认为它是一个全局变量**，**而不是这个 block 的局部变量**。这一点和别的语言不同。**容易造成不小心覆盖了全局同名变量的错误**。\n\n## **定义**\n\nLua 中的局部变量要用 local 关键字来显式定义，不使用 local 显式定义的变量就是全局变量\n\n```Lua\ng_var = 1         -- global var\nlocal l_var = 2   -- local var\n```\n\n## **作用域**\n\n**局部变量的生命周期是有限的，它的作用域仅限于声明它的块（block）**。一个块是一个控制结构的执行体、或者是一个函数的执行体再或者是一个程序块（chunk）。\n\n```Lua\nx = 10\nlocal i = 1         -- 程序块中的局部变量 i\n\nwhile i \u003c=x do\n    local x = i * 2   -- while 循环体中的局部变量 x\n    print(x)          -- output： 2, 4, 6, 8, ...\n    i = i + 1\nend\n\nif i \u003e 20 then\n    local x           -- then 中的局部变量 x\n    x = 20\n    print(x + 2)      -- 如果i \u003e 20 将会打印 22，此处的 x 是局部变量\nelse\n    print(x)          -- 打印 10，这里 x 是全局变量\nend\n\nprint(x)            -- 打印 10\n```\n\n  \n\n## 使用局部变量的好处\n\n  \n\n1. 局部变量可以避免因为命名问题污染了全局环境\n    \n2. local 变量的访问比全局变量更快\n    \n3. 由于局部变量出了作用域之后生命周期结束，这样可以被垃圾回收器及时释放\n    \n\n  \n\n  \n\n## 检测模块的函数使用局部变量\n\nfoo.lua\n\n```Lua\nlocal _M = { _VERSION = '0.01' }\n\nfunction _M.add(a, b)     --两个number型变量相加\n    return a + b\nend\n\nfunction _M.update_A()    --更新变量值\n    A = 365               -- A 是全局变量\nend\n\nreturn _M\n```\n\nuse_foo.lua\n\n```Lua\nA = 360     --定义全局变量\n\nlocal foo = require(\"foo\")\n\nlocal b = foo.add(A, A)\nprint(\"b = \", b)\n\nfoo.update_A()\nprint(\"A = \", A)\n```\n\n因为A 是全局变量，改变了A的值\n\nLua 上下文中应当严格避免使用自己定义的全局变量。**可以使用一个 lj-releng 工具来扫描 Lua 代码，定位使用 Lua 全局变量的地方**。lj-releng 的相关链接：[https://github.com/openresty/openresty-devel-utils/blob/master/lj-releng](https://github.com/openresty/openresty-devel-utils/blob/master/lj-releng)\n\nWindows 用户把 lj-releng 文件所在的目录的绝对路径添加进 PATH 环境变量。然后进入你自己的 Lua 文件所在的工作目录，得到如下结果：\n\n```Lua\n#  lj-releng\nfoo.lua: 0.01 (0.01)\nChecking use of Lua global variables in file foo.lua...\nop no.  line  instruction args  ; code\n2  [8] SETGLOBAL 0 -1  ; A\nChecking line length exceeding 80...\nWARNING: No \"_VERSION\" or \"version\" field found in `use_foo.lua`.\nChecking use of Lua global variables in file use_foo.lua...\nop no.  line  instruction args  ; code\n2  [1] SETGLOBAL 0 -1  ; A\n7  [4] GETGLOBAL 2 -1  ; A\n8  [4] GETGLOBAL 3 -1  ; A\n18 [8] GETGLOBAL 4 -1  ; A\n```\n\n当然，更推荐采用 **luacheck 来检查项目中全局变量，之后的“代码静态分析”一节，我们还会讲到如何使用 luacheck**。\n\n  \n\n# 判断数组的大小\n\n- table.getn(t) 等价于 t 但**计算的是数组元素，不包括 hash 键值**。而且数组是以第一个 nil 元素来判断数组结束。\n    \n- `#` 只计算 array 的元素个数，它实际上调用了对象的 metatable 的 `__len` 函数。对于有 `__len` 方法的函数返回函数返回值，不然就返回数组成员数目\n    \n- _Lua_ 内部实际采用哈希表和数组分别保存键值对、普通值，所以不推荐混合使用这两种赋值方式。\n    \n- Lua 数组中允许 nil 值的存在，但是数组默认结束标志却是 nil。这类比于 C 语言中的字符串，字符串中允许 '\\0' 存在，但当读到 '\\0' 时，就认为字符串已经结束了。\n    \n- 初始化是例外，在 Lua 相关源码中，初始化数组时首先判断数组的长度，若长度大于 0 ，并且最后一个值不为 nil，返回包括 nil 的长度；若最后一个值为 nil，则返回截至第一个非 nil 值的长度。\n    \n- **如果你要删除一个数组中的元素，请使用 remove 函数，而不是用 nil 赋值**\n    \n\n```Lua\n-- test.lua\nlocal tblTest1 = { 1, a = 2, 3 }\nprint(\"Test1 \" .. #(tblTest1))\n\nlocal tblTest2 = { 1, nil }\nprint(\"Test2 \" .. #(tblTest2))\n\nlocal tblTest3 = { 1, nil, 2 }\nprint(\"Test3 \" .. #(tblTest3))\n\nlocal tblTest4 = { 1, nil, 2, nil }\nprint(\"Test4 \" .. #(tblTest4))\n\nlocal tblTest5 = { 1, nil, 2, nil, 3, nil }\nprint(\"Test5 \" .. #(tblTest5))\n\nlocal tblTest6 = { 1, nil, 2, nil, 3, nil, 4, nil }\nprint(\"Test6 \" .. #(tblTest6))\n```\n\n我们分别使用 Lua 和 LuaJIT 来执行一下：\n\n```Lua\n➜ luajit test.lua\nTest1 2\nTest2 1\nTest3 1\nTest4 1\nTest5 1\nTest6 1\n\n➜ lua test.lua\nTest1 2\nTest2 1\nTest3 3\nTest4 1\nTest5 3\nTest6 1\n```\n\n这一段的输出结果，就是这么 **匪夷所思**。不要在 Lua 的 table 中使用 nil 值，**如果一个元素要删除，直接 remove，不要用 nil 去代替**。\n\n  \n\n# 非空判断\n\n  \n\n有时候不小心引用了一个没有赋值的变量，这时它的值默认为 nil。如果对一个 nil 进行索引的话，会导致异常。\n\n```Plaintext\nlocal person = {name = \"Bob\", sex = \"M\"}\n\n-- do something\nperson = nil\n-- do something\nprint(person.name)\n```\n\n会报错\n\n```Lua\nstdin:1:attempt to index global 'person' (a nil value)\nstack traceback:\n   stdin:1: in main chunk\n   [C]: ?\n```\n\n在实际的工程代码中，我们很难这么轻易地发现我们引用了 nil 变量。因此，在很多情况下我们在访问一些 table 型变量时，需要先判断该变量是否为 nil，例如将上面的代码改成\n\n```Lua\nlocal person = {name = \"Bob\", sex = \"M\"}\n\n-- do something\nperson = nil\n-- do something\nif person ~= nil and person.name ~= nil then\n    print(person.name)\nelse\n-- do somethingend\n```\n\n对于简单类型的变量，我们可以用 _if (var == nil) then_ 这样的简单句子来判断。**但是对于 table 型的 Lua 对象，就不能这么简单判断它是否为空了。一个 table 型变量的值可能是** **`{}`**，这时它不等于 nil。我们来看下面这段代码：\n\n```Lua\nlocal next = next\nlocal a = {}\nlocal b = {name = \"Bob\", sex = \"Male\"}\nlocal c = {\"Male\", \"Female\"}\nlocal d = nil\n\nprint(#a)\nprint(#b)\nprint(#c)\n--print(#d)    -- error\n\nif a == nil then\n    print(\"a == nil\")\nend\n\nif b == nil then\n    print(\"b == nil\")\nend\n\nif c == nil then\n    print(\"c == nil\")\nend\n\nif d== nil then\n    print(\"d == nil\")\nend\n\nif next(a) == nil then\n    print(\"next(a) == nil\")\nend\n\nif next(b) == nil then\n    print(\"next(b) == nil\")\nend\n\nif next(c) == nil then\n    print(\"next(c) == nil\")\nend\n```\n\n输出\n\n```Lua\n0\n0\n2\nd == nil\nnext(a) == nil\n```\n\n因此，我们要判断一个 table 是否为 `{}`，不能采用 `#table == 0` 的方式来判断。可以用下面这样的方法来判断：\n\n```Plaintext\nfunction isTableEmpty(t)\n    return t == nil or next(t) == nil\nend\n```\n\n注意：**`next`** **指令是不能被 LuaJIT 的 JIT 编译优化，并且 LuaJIT 貌似没有明确计划支持这个指令优化，在不是必须的情况下，尽量少用。**\n\n  \n\n# 正则表达式\n\n同时存在两套正则表达式规范：_Lua_ 语言的规范和 `ngx.re.*` 的规范，即使您对 _Lua_ 语言中的规范非常熟悉，我们仍不建议使用 _Lua_ 中的正则表达式。\n\n- 一是因为 _Lua_ 中正则表达式的性能并不如 `ngx.re.*` 中的正则表达式优秀；\n    \n- 二是 _Lua_ 中的正则表达式并不符合 _POSIX_ 规范，而 `ngx.re.*` 中实现的是标准的 _POSIX_ 规范，后者明显更具备通用性。\n    \n\n`ngx.re.*` 中的 `o` 选项，指明该参数，被编译的 Pattern 将会在工作进程中缓存，并且被当前工作进程的每次请求所共享。Pattern 缓存的上限值通过 `lua_regex_cache_max_entries` 来修改，它的默认值为1024。\n\n`ngx.re.*` 中的 `j` 选项，指明该参数，如果使用的 PCRE 库支持 JIT，OpenResty 会在编译 Pattern 时启用 JIT。启用 JIT 后正则匹配会有明显的性能提升。较新的平台，自带的 PCRE 库均支持 JIT。如果系统自带的 PCRE 库不支持 JIT，出于性能考虑，最好自己编译一份 libpcre.so，然后在编译 OpenResty 时链接过去。要想验证当前 PCRE 库是否支持 JIT，可以这么做\n\n1. 编译 OpenResty 时在 `./configure` 中指定 `--with-debug` 选项\n    \n2. 在 `error_log` 指令中指定日志级别为 `debug`\n    \n3. 运行正则匹配代码，查看日志中是否有 `pcre JIT compiling result: 1`\n    \n\n即使运行在不支持 JIT 的 OpenResty 上，加上 `j` 选项也不会带来坏的影响。在 OpenResty 官方的 Lua 库中，正则匹配至少都会带上 `jo` 这两个选项。\n\n```Lua\nlocation /test {\n    content_by_lua_block {\n        local regex = [[\\d+]]\n\n        -- 参数 \"j\" 启用 JIT 编译，参数 \"o\" 是开启缓存必须的\n        local m = ngx.re.match(\"hello, 1234\", regex, \"jo\")\n        if m then\n            ngx.say(m[0])\n        else\n            ngx.say(\"not matched!\")\n        end\n    }\n}\n```\n\n#### **Lua 正则简单汇总**\n\n_Lua_ 中正则表达式语法上最大的区别，_Lua_ 使用 _'%'_ 来进行转义，而其他语言的正则表达式使用 _'\\'_ 符号来进行转义。其次，_Lua_ 中并不使用 _'?'_ 来表示非贪婪匹配，而是定义了不同的字符来表示是否是贪婪匹配。定义如下：\n\n|符号|匹配次数|匹配模式|\n|---|---|---|\n|+|匹配前一字符 1 次或多次|非贪婪|\n|`*`|匹配前一字符 0 次或多次|贪婪|\n|-|匹配前一字符 0 次或多次|非贪婪|\n|?|匹配前一字符 0 次或1次|仅用于此，不用于标识是否贪婪|\n\n|符号|匹配模式|\n|---|---|\n|.|任意字符|\n|%a|字母|\n|%c|控制字符|\n|%d|数字|\n|%l|小写字母|\n|%p|标点字符|\n|%s|空白符|\n|%u|大写字母|\n|%w|字母和数字|\n|%x|十六进制数字|\n|%z|代表 0 的字符|\n\n  \n\n# 虚变量\n\n当一个方法返回多个值时，有些返回值有时候用不到，要是声明很多变量来一一接收，显然不太合适（不是不能）。**Lua 提供了一个虚变量(dummy variable)的概念， 按照****[惯例](https://www.lua.org/pil/1.3.html)****以一个下划线（“_”）来命名，用它来表示丢弃不需要的数值，仅仅起到占位的作用。**\n\n  \n\n## 返回值\n\n```Lua\n-- string.find (s,p) 从string 变量s的开头向后匹配 string\n-- p，若匹配不成功，返回nil，若匹配成功，返回第一次匹配成功\n-- 的起止下标。\n\nlocal start, finish = string.find(\"hello\", \"he\") --start 值为起始下标，finish\n--值为结束下标\nprint ( start, finish )                          --输出 1   2\n\nlocal start = string.find(\"hello\", \"he\")      -- start值为起始下标\nprint ( start )                               -- 输出 1\n\n\nlocal _,finish = string.find(\"hello\", \"he\")   --采用虚变量（即下划线），接收起\n--始下标值，然后丢弃，finish接收\n--结束下标值\nprint ( finish )                              --输出 2\nprint ( _ )    \n```\n\n  \n\n## 迭代\n\n```Lua\n-- test.lua 文件\nlocal t = {1, 3, 5}\n\nprint(\"all  data:\")\nfor i,v in ipairs(t) do\n    print(i,v)\nend\n\nprint(\"\")\nprint(\"part data:\")\nfor _,v in ipairs(t) do\n    print(v)\nend\n```\n\n输出\n\n```Lua\n# luajit test.lua\nall  data:\n1   1\n2   3\n3   5\n\npart data:\n1\n3\n5\n```\n\n# **抵制使用 module() 定义模块**\n\n旧式的模块定义方式是通过 `module(\"filename\"[,package.seeall])*` 来显式声明一个包，现在官方不推荐再使用这种方式\n\n这种方式将会返回一个由 `filename` 模块函数组成的 `table`，并且还会定义一个包含该 `table` 的全局变量。\n\n  \n\n1. `package.seeall` 这种方式破坏了模块的高内聚，原本引入 \"filename\" 模块只想调用它的 _foobar()_ 函数，但是它却可以读写全局属性，例如 `\"filename.os\"`。\n    \n2. `module` 函数压栈操作引发的副作用，污染了全局环境变量。例如 `module(\"filename\")` 会创建一个 `filename` 的 `table`，并将这个 `table` 注入全局环境变量中，这样使得没有引用它的文件也能调用 `filename` 模块的方法。\n    \n\n  \n\n推荐的模块定义\n\n```Lua\n-- square.lua 长方形模块\nlocal _M = {}           -- 局部的变量\n_M._VERSION = '1.0'     -- 模块版本\n\nlocal mt = { __index = _M }\n\nfunction _M.new(self, width, height)\n    return setmetatable({ width=width, height=height }, mt)\nend\n\nfunction _M.get_square(self)\n    return self.width * self.height\nend\n\nfunction _M.get_circumference(self)\n    return (self.width + self.height) * 2\nend\n\nreturn _M\n```\n\n使用\n\n```Lua\nlocal square = require \"square\"\nlocal s1 = square:new(1, 2)\nprint(s1:get_square())          --output: 2\nprint(s1:get_circumference())   --output: 6\n```\n\n另一个跟 Lua 的 module 模块相关需要注意的点是，当 lua_code_cache on 开启时，require 加载的模块是会被缓存下来的，这样我们的模块就会以最高效的方式运行，直到被显式地调用如下语句（这里有点像模块卸载）：\n\n```Plaintext\npackage.loaded[\"square\"] = nil\n```\n\n  \n\n## 调用函数前先定义函数\n\nLua 里面的函数必须放在调用的代码之前，下面的代码是一个常见的错误：\n\n```Lua\n-- test.lua 文件local i = 100\ni = add_one(i)\n\nfunction add_one(i)\n    return i + 1\nend\n```\n\n因此在函数定义之前使用函数相当于在变量赋值之前使用变量，Lua 世界对于没有赋值的变量，默认都是 nil，所以这里也就产生了一个 nil 的错误。\n\n  \n\n# 点号操作符和冒号操作符的区别\n\n```Plaintext\nlocal str = \"abcde\"\n\nprint(\"case 1:\", str:sub(1, 2))\nprint(\"case 2:\", str.sub(str, 1, 2))\n```\n\n输出\n\n```Lua\ncase 1: ab\ncase 2: ab\n```\n\n- **冒号操作会带入一个** **`self`** **参数，用来代表** **`自己`****。**\n    \n- 而点号操作，只是 `内容` 的展开。\n    \n\n在函数定义时，使用冒号将默认接收一个 `self` 参数，而使用点号则需要显式传入 `self` 参数\n\n示例代码：\n\n```Plaintext\nobj = { x = 20 }\n\nfunction obj:fun1()\n    print(self.x)\nend\n```\n\n等价于\n\n```Plaintext\nobj = { x = 20 }\n\nfunction obj.fun1(self)\n    print(self.x)\nend\n```\n\n# module的缺点\n\n由于 `lua_code_cache off` 情况下，缓存的代码会伴随请求完结而释放。module 的最大好处缓存这时候是无法发挥的，所以本章的内容都是基于 `lua_code_cache on` 的情况下。\n\n先看看下面代码：\n\n```Plaintext\nlocal ngx_socket_tcp = ngx.socket.tcp           -- ①\n\nlocal _M = { _VERSION = '0.06' }                -- ②\nlocal mt = { __index = _M }                     -- ③\n\nfunction _M.new(self)\n    local sock, err = ngx_socket_tcp()          -- ④\n    if not sock then\n        return nil, err\n    end\n    return setmetatable({ sock = sock }, mt)    -- ⑤\nend\n\nfunction _M.set_timeout(self, timeout)\n    local sock = self.sock\n    if not sock then\n        return nil, \"not initialized\"\n    end\n\n    return sock:settimeout(timeout)\nend\n\n-- ... 其他功能代码，这里简略\n\nreturn _M\n```\n\n1. 对于比较底层的模块，内部使用到的非本地函数，都需要 local 本地化，这样做的好处：\n    \n    1. 避免命名冲突：防止外部是 `require(...)` 的方法调用造成全局变量污染\n        \n    2. 访问局部变量的速度比全局变量更快、更快、更快（重要事情说三遍）\n        \n\n  \n\n2. 每个基础模块最好有自己 `_VERSION` 标识，方便后期利用 `_VERSION` 完成热代码部署等高级特性，也便于使用者对版本有整体意识。\n    \n3. 其实 `_M` 和 `mt` 对于不同的请求实例（require 方法得到的对象）是相同的，因为 module 会被缓存到全局环境中。所以在这个位置千万不要放单请求内个性信息，例如 ngx.ctx 等变量。\n    \n4. **这里需要实现的是给每个实例绑定不同的 tcp 对象**，后**面 setmetatable 确保了每个实例拥有自己的 socket 对象，所以必须放在 new 函数中**。如果放在 ③ 的下面，那么这时候所有的不同实例内部将绑定了同一个 socket 对象。\n    \n\n```Plaintext\nlocal mt = { __index = _M }                     -- ③\nlocal sock = ngx_socket_tcp()                   -- ④ 错误的\n\nfunction _M.new(self)\n    return setmetatable({ sock = sock }, mt)    -- ⑤\nend\n```\n\n5. Lua 的 module 有两种类型：\n    \n    1. 支持面向对象痕迹可以保留私有属性；静态方法提供者，没有任何私有属性。\n        \n    2. 真正起到区别作用的就是 setmetatable 函数，是否有自己的个性元表，最终导致两种不同的形态。\n        \n\n# FFI\n\nhttps://moonbingbing.gitbooks.io/openresty-best-practices/content/lua/FFI.html\n\nFFI 库，是 LuaJIT 中最重要的一个扩展库。它允许从纯 Lua 代码调用外部 C 函数，使用 C 数据结构。\n\n  \n\nFFI 库最大限度的省去了使用 C 手工编写繁重的 `Lua/C` 绑定的需要。不需要学习一门独立/额外的绑定语言——它解析普通 C 声明。这样可以从 C 头文件或参考手册中，直接剪切，粘贴。它的任务就是绑定很大的库，但不需要捣鼓脆弱的绑定生成器。\n\nFFI 紧紧的整合进了 LuaJIT（几乎不可能作为一个独立的模块）。`JIT` 编译器在 C 数据结构上所产生的代码，等同于一个 C 编译器应该生产的代码。在 `JIT` 编译过的代码中，调用 C 函数，可以被内连处理，不同于基于 `Lua/C API` 函数调用。\n\n  \n\n## **ffi 库 词汇**\n\n|   |   |\n|---|---|\n|noun|Explanation|\n|cdecl|A definition of an abstract C type(actually, is a lua string)|\n|ctype|C type object|\n|cdata|C data object|\n|ct|C type format, is a template object, may be cdecl, cdata, ctype|\n|cb|callback object|\n|VLA|An array of variable length|\n|VLS|A structure of variable length|\n\n## **ffi.* API**\n\n**功能：** _Lua ffi 库的 API，与 LuaJIT 不可分割。_\n\n毫无疑问，在 `lua` 文件中使用 `ffi` 库的时候，必须要有下面的一行。\n\n```Plaintext\nlocal ffi = require \"ffi\"\n```\n\n# JIT\n\n看一下 LuaJIT 官方的解释：LuaJIT is a Just-In-Time Compilerfor the Lua programming language。\n\n**LuaJIT 的运行时环境包括一个用手写汇编实现的 Lua 解释器和一个可以直接生成机器代码的 JIT 编译器**\n\n- 一开始的时候，Lua 字节码总是被 LuaJIT 的解释器解释执行。LuaJIT 的解释器会在执行字节码时同时记录一些运行时的统计信息，比如每个 Lua 函数调用入口的实际运行次数，还有每个 Lua 循环的实际执行次数。\n    \n- 当这些次数超过某个预设的阈值时，便认为对应的 Lua 函数入口或者对应的 Lua 循环足够的“热”，这时便会触发 JIT 编译器开始工作。\n    \n- JIT 编译器会从热函数的入口或者热循环的某个位置开始尝试编译对应的 Lua 代码路径。编译的过程是把 LuaJIT 字节码先转换成 LuaJIT 自己定义的中间码（IR），然后再生成针对目标体系结构的机器码（比如 x86_64 指令组成的机器码）\n    \n- 如果当前 Lua 代码路径上的所有的操作都可以被 JIT 编译器顺利编译，则这条编译过的代码路径便被称为一个“trace”，在物理上对应一个 `trace` 类型的 GC 对象（即参与 Lua GC 的对象）。\n    \n\n  \n\nJIT 编译器不支持的原语被称为 **NYI（Not Yet Implemented）原语**。比较完整的 NYI 列表在这篇文档里面：\n\n```Plaintext\nhttp://wiki.luajit.org/NYI\n```\n\n所谓“让更多的 Lua 代码被 JIT 编译”，其实就是帮助更多的 Lua 代码路径能为 JIT 编译器所接受。这一般通过两种途径来实现：\n\n1. 调整对应的 Lua 代码，**避免使用 NYI 原语**。\n    \n2. 增强 JIT 编译器，让越来越多的 NYI 原语能够被编译。\n    \n\n## **可以被 JIT 编译的元操作**\n\n下面给大家列一下截止到目前已经可以被 JIT 编译的元操作。 其他还有 IO、Bit、FFI、Coroutine、OS、Package、Debug、JIT 等分类，使用频率相对较低，这里就不罗列了，可以参考官网：[http://wiki.luajit.org/NYI](http://wiki.luajit.org/NYI)。\n\n### **基础库的支持情况**\n\n|   |   |   |\n|---|---|---|\n|函数|编译?|备注|\n|assert|yes||\n|collectgarbage|no||\n|dofile|never||\n|error|never||\n|getfenv|2.1 partial|只有 getfenv(0) 能编译|\n|getmetatable|yes||\n|ipairs|yes||\n|load|never||\n|loadfile|never||\n|loadstring|never||\n|next|no||\n|pairs|no||\n|pcall|yes||\n|print|no||\n|rawequal|yes||\n|rawget|yes||\n|rawlen (5.2)|yes||\n|rawset|yes||\n|select|partial|第一个参数是静态变量的时候可以编译|\n|setfenv|no||\n|setmetatable|yes||\n|tonumber|partial|不能编译非10进制，非预期的异常输入|\n|tostring|partial|只能编译：字符串、数字、布尔、nil 以及支持 __tostring元方法的类型|\n|type|yes||\n|unpack|no||\n|xpcall|yes||\n\n### **字符串库**\n\n|   |   |   |\n|---|---|---|\n|函数|编译?|备注|\n|string.byte|yes||\n|string.char|2.1||\n|string.dump|never||\n|string.find|2.1 partial|只有字符串样式查找（没有样式）|\n|string.format|2.1 partial|不支持 %p 或 非字符串参数的 %s|\n|string.gmatch|no||\n|string.gsub|no||\n|string.len|yes||\n|string.lower|2.1||\n|string.match|no||\n|string.rep|2.1||\n|string.reverse|2.1||\n|string.sub|yes||\n|string.upper|2.1||\n\n### **表**\n\n|   |   |   |\n|---|---|---|\n|函数|编译?|备注|\n|table.concat|2.1||\n|table.foreach|no|2.1: 内部编译，但还没有外放|\n|table.foreachi|2.1||\n|table.getn|yes||\n|table.insert|partial|只有 push 操作|\n|table.maxn|no||\n|table.pack (5.2)|no||\n|table.remove|2.1|部分，只有 pop 操作|\n|table.sort|no||\n|table.unpack (5.2)|no||\n\n### **math 库**\n\n|   |   |   |\n|---|---|---|\n|函数|编译?|备注|\n|math.abs|yes||\n|math.acos|yes||\n|math.asin|yes||\n|math.atan|yes||\n|math.atan2|yes||\n|math.ceil|yes||\n|math.cos|yes||\n|math.cosh|yes||\n|math.deg|yes||\n|math.exp|yes||\n|math.floor|yes||\n|math.fmod|no||\n|math.frexp|no||\n|math.ldexp|yes||\n|math.log|yes||\n|math.log10|yes||\n|math.max|yes||\n|math.min|yes||\n|math.modf|yes||\n|math.pow|yes||\n|math.rad|yes||\n|math.random|yes||\n|math.randomseed|no||\n|math.sin|yes||\n|math.sinh|yes||\n|math.sqrt|yes||\n|math.tan|yes||\n|math.tanh|yes||","lastmodified":"2024-02-25T17:02:23.038963969Z","tags":["lua"]},"/lua/lua%E5%9F%BA%E7%A1%80":{"title":"lua基础","content":"\n\n# Lua 简介\n\nLua 是一个小巧的脚本语言。是巴西里约热内卢天主教大学（Pontifical Catholic University of Rio de Janeiro）里的一个研究小组并于 1993 年开发。**其设计目的是为了嵌入应用程序中，从而为应用程序提供灵活的扩展和定制功能**。Lua 由标准 C 编写而成，几乎在所有操作系统和平台上都可以编译、运行。Lua 并没有提供强大的库，这是由它的定位决定的。所以 Lua 不适合作为开发独立应用程序的语言。**Lua 有一个同时进行的 JIT 项目，提供在特定平台上的即时编译功能**。\n\n- **Lua 脚本可以很容易的被 C/C++ 代码调用，也可以反过来调用 C/C++ 的函数，这使得 Lua 在应用程序中可以被广泛应用**。\n    \n- **不仅仅作为扩展脚本，也可以作为普通的配置文件，代替 XML、ini 等文件格式，并且更容易理解和维护**。\n    \n- 标准 Lua 5.1 解释器由标准 C 编写而成，代码简洁优美，几乎在所有操作系统和平台上都可以编译和运行；\n    \n- 一个完整的标准 Lua 5.1 解释器不足 200 KB。而本书推荐使用的 LuaJIT 2 的代码大小也只有不足 500 KB\n    \n- 同时也支持大部分常见的体系结构。在目前所有脚本语言引擎中，LuaJIT 2 实现的速度应该算是最快的之一。这一切都决定了 Lua 是作为嵌入式脚本的最佳选择。\n    \n\nLua 语言的各个版本是不相兼容的。因此本书只介绍 Lua 5.1 语言，这是为标准 Lua 5.1 解释器和 LuaJIT 2 所共同支持的。LuaJIT 支持的对 Lua 5.1 向后兼容的 Lua 5.2 和 Lua 5.3 的特性，我们也会在方便的时候予以介绍。\n\n  \n\n# Lua 环境搭建\n\n[http://openresty.org](http://openresty.org/)\n\n  \n\n## Helloworld\n\n```Go\n# cat hello.lua\nprint(\"hello world\")\n# luajit hello.lua\nhello world\n```\n\n  \n\n# 基本数据类型\n\n  \n\n```Go\nprint(type(\"helloworld\"))\nprint(type('helloworld'))\nprint(type('true'))\nprint(type(1))\nprint(type(2.1))\nprint(type(nil))\nfunction hello()\n    print(\"hello\")\nend\nprint(type(hello))\n```\n\n输出\n\n```Go\nstring\nstring\nstring\nnumber\nnumber\nnil\nfunction\n```\n\n## Nil\n\nNil 是一种类型，Lua 将 nil 用于表示“无效值”。\n\n- 一个变量在第一次赋值前的默认值是 nil，\n    \n- 将 nil 赋予给一个全局变量就等同于删除它。\n    \n\n```Go\nlocal num\nprint(num)        --\u003eoutput:nil\n\nnum = 100\nprint(num)        --\u003eoutput:100\n```\n\n## Boolean (布尔)\n\n布尔类型，可选值 true/false；\n\n- Lua 中 nil 和 false 为“假”\n    \n- 其它所有值均为“真”。比如 0 和空字符串就是“真”；\n    \n\n```Go\nlocal a = true\nlocal b = 0\nlocal c = nil\nif a then\n    print(\"a\")        --\u003eoutput:a\nelse\n    print(\"not a\")    --这个没有执行\nend\n\nif b then\n    print(\"b\")        --\u003eoutput:b\nelse\n    print(\"not b\")    --这个没有执行\nend\n\nif c then\n    print(\"c\")        --这个没有执行\nelse\n    print(\"not c\")    --\u003eoutput:not c\nend\n```\n\n## **number（数字）**\n\nNumber 类型用于表示实数，和 C/C++ 里面的 double 类型很类似。可以使用数学函数 math. Floor（向下取整）和 math. Ceil（向上取整）进行取整操作。\n\n一般地，Lua 的 number 类型就是用双精度浮点数来实现的。值得一提的是，LuaJIT 支持所谓的“dual-number”（双数）模式，\n\n- 即 **LuaJIT 会根据上下文用整型来存储整数，而用双精度浮点数来存放浮点数。**\n    \n\n```Go\nlocal order = 3.99\nlocal score = 98.01\nprint(math.floor(order))   --\u003eoutput:3\nprint(math.ceil(score))    --\u003eoutput:99\nprint(9223372036854775807LL - 1)  --\u003eoutput:9223372036854775806LL\n```\n\n## String（字符串）\n\nLua 中有三种方式表示字符串:\n\n1. 使用一对匹配的单引号。例：'hello'。\n    \n2. 使用一对匹配的双引号。例：\"abclua\"。\n    \n3. 字符串还可以用一种长括号（即 [[ ]]）括起来的方式定义\n    \n    1. 我们把两个正的方括号（即[[）间插入 n 个等号定义为第 n 级正长括号。\n        \n    2. 0 级正的长括号写作 [[ ，一级正的长括号写作 [=[\n        \n    3. 反的长括号也作类似定义；举个例子，4 级反的长括号写作 ]====]\n        \n    4. **一个长字符串可以由任何一级的正的长括号开始，而由第一个碰到的同级反的长括号结束**。整个词法分析过程将**不受分行限制，不处理任何转义符，并且忽略掉任何不同级别的长括号**\n        \n\n  \n\n```Plaintext\nlocal str1 = 'hello world'\nlocal str2 = \"hello lua\"\nlocal str3 = [[\"add\\name\",'hello']]\nlocal str4 = [=[string have a [[]].]=]\nlocal str5 = [=[asdfasd]=]\n\nprint(str1)    --\u003eoutput:hello world\nprint(str2)    --\u003eoutput:hello lua\nprint(str3)    --\u003eoutput:\"add\\name\",'hello'\nprint(str4)    --\u003eoutput:string have a [[]].\nprint(str5)    --\u003eoutput:asdfasd\n```\n\n在 Lua 实现中，Lua 字符串一般都会经历一个“内化”（intern）的过程，**即两个完全一样的 Lua 字符串在 Lua 虚拟机中只会存储一份**。每一个 Lua 字符串在创建时都会**插入到 Lua 虚拟机内部的一个全局的哈希表**中\n\n1. 创建相同的 Lua 字符串并不会引入新的动态内存分配操作，所以相对便宜（但仍有全局哈希表查询的开销），\n    \n2. 内容相同的 Lua 字符串不会占用多份存储空间，\n    \n3. 已经创建好的 Lua 字符串之间进行相等性比较时是 `O(1)` 时间度的开销，而不是通常见到的 `O(n)`.\n    \n\n## Table (表)\n\nTable 类型实现了一种抽象的“关联数组”。“关联数组”是一种具有特殊索引方式的数组，\n\n- 索引通常是**字符串（string）或者 number 类型，但也可以是除** **`nil`** **以外的任意类型的值**\n    \n\n```Go\n\nlocal corp = {\n    web = \"www.google.com\",   --索引为字符串，key = \"web\",\n    --            value = \"www.google.com\"\n    telephone = \"12345678\",   --索引为字符串\n    staff = {\"Jack\", \"Scott\", \"Gary\"}, --索引为字符串，值也是一个表\n    100876,              --相当于 [1] = 100876，此时索引为数字\n    --      key = 1, value = 100876\n    100191,              --相当于 [2] = 100191，此时索引为数字\n    [10] = 360,          --直接把数字索引给出\n    [\"city\"] = \"Beijing\" --索引为字符串\n}\n\nprint(corp.web)               --\u003eoutput:www.google.com\nprint(corp[\"web\"])               --\u003eoutput:www.google.com\nprint(corp[\"telephone\"])      --\u003eoutput:12345678\nprint(corp[2])                --\u003eoutput:100191\nprint(corp[\"city\"])           --\u003eoutput:\"Beijing\"\nprint(corp.staff[1])          --\u003eoutput:Jack\nprint(corp[\"staff\"][1])          --\u003eoutput:Jack\nprint(corp[10])               --\u003eoutput:360\n```\n\n在内部实现上，table 通常实现为一个哈希表、一个数组、或者两者的混合。具体的实现为何种形式，动态依赖于具体的 table 的键分布特点。\n\n## Function (函数)\n\n在 Lua 中，**函数** 也是一种数据类型，函数可以存储在变量中，可以通过参数传递给其他函数，还可以作为其他函数的返回值\n\n```Go\nlocal function foo()\n    print(\"in the function\")\n    --dosomething()\n    local x = 10\n    local y = 20\n    return x + y\nend\n\nlocal a = foo    --把函数赋给变量\n\nprint(a())\n\n--output:\n--in the function\n--30\n\nfunction foo()\nend\n--等价于\n\nfoo = function ()\nend\n\nlocal function foo()\nend\n-- 等价于\n\nlocal foo = function ()\nend\n```\n\n  \n\n# 表达式\n\n## 算术运算符\n\n|            |      |\n| ---------- | ---- |\n| 算术运算符 | 说明 |\n| +          | 加法 |\n| -          | 减法 |\n| *          | 乘法 |\n| /          | 除法 |\n| ^          | 指数 |\n| %          | 取模 |\n\n```Go\nprint(1 + 2)       --\u003e打印 3\nprint(5 / 10)      --\u003e打印 0.5。 这是Lua不同于c语言的\nprint(5.0 / 10)    --\u003e打印 0.5。 浮点数相除的结果是浮点数\n-- print(10 / 0)   --\u003e注意除数不能为0，计算的结果会出错\nprint(2 ^ 10)      --\u003e打印 1024。 求2的10次方\n\nlocal num = 1357\nprint(num % 2)       --\u003e打印 1\nprint((num % 2) == 1) --\u003e打印 true。 判断num是否为奇数\n```\n\n## 关系运算符\n\n  \n\n|            |          |\n| ---------- | -------- |\n| 关系运算符 | 说明     |\n| \u003c          | 小于     |\n| \u003e          | 大于     |\n| \u003c=         | 小于等于 |\n| \u003e=         | 大于等于 |\n| ==         | 等于     |\n| ~=         | 不等于   |\n\n  \n\n```Go\nprint(1 \u003c 2)    --\u003e打印 true\nprint(1 == 2)   --\u003e打印 false\nprint(1 ~= 2)   --\u003e打印 true\nlocal a, b = true, false\nprint(a == b)  --\u003e打印 false\n```\n\n- 在使用“==”做等于判断时，要注意对于 table, userdate 和函数， Lua 是作引用比较的。也就是说，只有当两个变量引用同一个对象时，才认为它们相等\n    \n\n```Go\nlocal a = { x = 1, y = 0}\nlocal b = { x = 1, y = 0}\nif a == b then\n    print(\"a==b\")\nelse\n    print(\"a~=b\")\nend\n---output:\na~=b\n```\n\n- Lua 字符串总是会被“内化”，即相同内容的字符串只会被保存一份，因此 Lua 字符串之间的相等性比较可以简化为其内部存储地址的比较。\n    \n- 这意味着 Lua 字符串的相等性比较总是为 O (1)\n    \n\n## 逻辑运算符\n\n|            |        |\n| ---------- | ------ |\n| 逻辑运算符 | 说明   |\n| and        | 逻辑与 |\n| or         | 逻辑或 |\n| not        | 逻辑非 |\n\n在 c 语言中，and 和 or 只得到两个值 1 和 0，其中 1 表示真，0 表示假。而 Lua 中 and 的执行过程是这样的：\n\n- `a and b` 如果 a 为 nil，则返回 a，否则返回 b;\n    \n- `a or b` 如果 a 为 nil，则返回 b，否则返回 a。\n    \n- **所有逻辑操作符将 false 和 nil 视作假，其他任何值视作真，对于 and 和 or，“短路求值”，对于 not，永远只返回 true 或者 false。**\n    \n\n```Go\nlocal c = nil\nlocal d = 0\nlocal e = 100\nprint(c and d)  --\u003e打印 nil\nprint(c and e)  --\u003e打印 nil\nprint(d and e)  --\u003e打印 100\nprint(c or d)   --\u003e打印 0\nprint(c or e)   --\u003e打印 100\nprint(not c)    --\u003e打印 true\nprint(not d)    --\u003e打印 false\n```\n\n## 字符串连接\n\nLua 中连接两个字符串，可以使用操作符“..”（两个点）\n\n- 如果其任意一个操作数是数字的话，Lua 会将这个数字转换成字符串。\n    \n- 注意，连接操作符只会创建一个新字符串，而不会改变原操作数\n    \n- 也可以使用 string 库函数 `string.format` 连接字符串\n    \n\n```Go\nprint(\"Hello \" .. \"World\")    --\u003e打印 Hello Worldprint(0 .. 1)                 --\u003e打印 01\n\nstr1 = string.format(\"%s-%s\",\"hello\",\"world\")\nprint(str1)              --\u003e打印 hello-world\n\nstr2 = string.format(\"%d-%s-%.2f\",123,\"world\",1.21)\nprint(str2)              --\u003e打印 123-world-1.21\n```\n\n于 Lua 字符串本质上是只读的，**因此字符串连接运算符几乎总会创建一个新的（更大的）字符串**。这意味着如果有很多这样的连接操作（比如在循环中使用 .. 来拼接最终结果），则性能损耗会非常大。在这种情况下，推荐使用 table 和 `table.concat()` 来进行很多字符串的拼接\n\n```Go\nlocal pieces = {}\nfor i, elem in ipairs(my_list) do\n    pieces[i] = my_process(elem)\nend\nlocal res = table.concat(pieces)\n```\n\n上面的例子还可以使用 LuaJIT 独有的 `table.new` 来恰当地初始化 `pieces` 表的空间，以避免该表的动态生长。\n\n## 优先级\n\n| f               |     |\n| --------------- | --- |\n| ^               |     |\n| not # -         |     |\n| * / %           |     |\n| + -             |     |\n| ..              |     |\n| \u003c \u003e \u003c= \u003e= == ~= |     |\n| and             |     |\n| or              |     |\n  \n\n```Go\nlocal a, b = 1, 2\nlocal x, y = 3, 4\nlocal i = 10\nlocal res = 0\nres = a + i \u003c b/2 + 1  --\u003e等价于res =  (a + i) \u003c ((b/2) + 1)\nres = 5 + x^2*8        --\u003e等价于res =  5 + ((x^2) * 8)\nres = a \u003c y and y \u003c=x  --\u003e等价于res =  (a \u003c y) and (y \u003c= x)\n```\n\n  \n\n# 控制结构\n\n## If-else\n\n### **单个 if 分支型**\n\n```Go\nx = 10\nif x \u003e 0 then\n    print(\"x is a positive number\")\nend\n```\n\n### **两个分支 if-else 型**\n\n```Go\nx = 10\nif x \u003e 0 then\n    print(\"x is a positive number\")\nelse\n    print(\"x is a non-positive number\")\nend\n```\n\n### 多个分支的 if-elseif-else\n\n```Go\n\nscore = 90\nif score == 100 then\n    print(\"Very good!Your score is 100\")\nelseif score \u003e= 60 then\n    print(\"Congratulations, you have passed it,your score greater or equal to 60\")\n    --此处可以添加多个elseif\nelse\n    print(\"Sorry, you do not pass the exam! \")\nend\n```\n\n与 C 语言的不同之处是 else 与 if 是连在一起的，若将 else 与 if 写成 \"else if\" 则相当于在 else 里嵌套另一个 if 语句，如下代码：\n\n```Go\nscore = 0\nif score == 100 then\n    print(\"Very good!Your score is 100\")\nelseif score \u003e= 60 then\n    print(\"Congratulations, you have passed it,your score greater or equal to 60\")\nelse\n    if score \u003e 0 then\n        print(\"Your score is better than 0\")\n    else\n        print(\"My God, your score turned out to be 0\")\n    end --与上一示例代码不同的是，此处要添加一个end\nend\n```\n\n## While\n\n```Go\nwhile 表达式 do\n    --body\nend\n```\n\n  \n\n## Repeat\n\nLua 中的 repeat 控制结构类似于其他语言（如：C++ 语言）中的 do-while，但是控制方式是刚好相反的。简单点说，**执行 repeat 循环体后，直到 until 的条件为真时才结束**\n\n```Lua\n-- 以下代码会死循环\nx = 10\nrepeat\n    print(x)\nuntil false\n```\n\n  \n\n## For\n\n### **for 数字型**\n\n```Lua\nfor var = begin, finish, step do\n    --body\nend\n```\n\n1. Var 从 begin 变化到 finish，每次变化都以 step 作为步长递增 var\n    \n2. Begin、finish、step 三个表达式只会在循环开始时执行一次\n    \n3. 第三个表达式 step 是可选的，默认为 1\n    \n4. 控制变量 var 的作用域仅在 for 循环内，需要在外面控制，则需将值赋给一个新的变量\n    \n5. 循环过程中不要改变控制变量的值，那样会带来不可预知的影响\n    \n\n```Lua\nfor i = 1, 5 do\n    print(i)\nend\n-- output:\n1\n2\n3\n4\n5\n\nfor i = 1, 10, 2 do\n    print(i)\nend\n-- output:\n1\n3\n5\n7\n9\n```\n\n## For 泛型\n\n泛型 for 循环通过一个迭代器（iterator）函数来遍历所有值：\n\n```Lua\n-- 打印数组a的所有值local a = {\"a\", \"b\", \"c\", \"d\"}\nfor i, v in ipairs(a) do\n    print(\"index:\", i, \" value:\", v)\nend\n-- output:\nindex:  1  value: a\nindex:  2  value: b\nindex:  3  value: c\nindex:  4  value: d\n```\n\nLua 的基础库提供了 **ipairs，这是一个用于遍历数组的迭代器函数**。在每次循环中，i 会被赋予一个索引值，同时 v 被赋予一个对应于该索引的数组元素值。\n\n```Lua\n-- 打印table t中所有的\nkeyfor k in pairs(t) do\n    print(k)\nend\n```\n\n通过不同的迭代器，几乎可以遍历所有的东西，而且写出的代码极具可读性。标准库提供了几种迭代器，包括用于迭代文件中每行的（io. Lines）、迭代 table 元素的（pairs）、迭代数组元素的（ipairs）、迭代字符串中单词的（string. Gmatch）\n\n泛型 for 循环与数字型 for 循环有两个相同点：\n\n1. 循环变量是循环体的局部变量；\n    \n2. 决不应该对循环变量作任何赋值。\n    \n\n在 LuaJIT 2.1 中，**`ipairs()`** **内建函数是可以被 JIT 编译的，而** **`pairs()`** **则只能被解释执行。因此在性能敏感的场景，应当合理安排数据结构，避免对哈希表进行遍历**\n\n  \n\n## Break\n\n语句 `break` 用来终止 `while`、`repeat` 和 `for` 三种循环的执行，并跳出当前循环体，继续执行当前循环之后的语句\n\n```Lua\n-- 计算最小的x,使从1到x的所有数相加和大于100\nsum = 0\ni = 1while true do\n    sum = sum + i\n    if sum \u003e 100 then\n        break\n    end\n    i = i + 1\nend\nprint(\"The result is \" .. i)  \n--\u003eoutput:The result is 14\n```\n\n## Return\n\n  \n\n`return` 主要用于从函数中返回结果，或者用于简单的结束一个函数的执行。\n\n```Lua\nlocal function add(x, y)\n    return x + y\n    --print(\"add: I will return the result \" .. (x + y))\n    --因为前面有个return，若不注释该语句，则会报错\nend\n\nlocal function is_positive(x)\n    if x \u003e 0 then\n        return x .. \" is positive\"\n    else\n        return x .. \" is non-positive\"\n    end\n\n    --由于return只出现在前面显式的语句块，所以此语句不注释也不会报错\n    --，但是不会被执行，此处不会产生输出\n    print(\"function end!\")\nend\n\nlocal sum = add(10, 20)\nprint(\"The sum is \" .. sum)  --\u003eoutput:The sum is 30\nlocal answer = is_positive(-10)\nprint(answer)                --\u003eoutput:-10 is non-positive\n```\n\n  \n\n## Goto\n\n有了 `goto`，我们可以实现 `continue` 的功能：\n\n```Lua\nfor i=1, 3 do\n    if i \u003c= 2 then\n        print(i, \"yes continue\")\n        goto continue\n    end\n    print(i, \" no continue\")\n\n    ::continue::\n    print([[i'm end]])\nend\n```\n\n输出结果\n\n```Lua\n$ luajit test.lua\n1   yes continue\ni'm end\n2   yes continue\ni'm end\n3    no continue\ni'm end\n```\n\n# 函数\n\n## 定义\n\n```Lua\nfunction function_name (arc)  -- arc 表示参数列表，函数的参数列表可以为空\n    -- body\nend\n```\n\n上面的语法定义了一个全局函数，名为 `function_name`. 全局函数本质上就是函数类型的值赋给了一个全局变量，即上面的语法等价于\n\n```Lua\nfunction_name = function (arc)\n     -- body\nend\n```\n\n由于全局变量一般会污染全局名字空间，同时也有性能损耗（即查询全局环境表的开销），因此我们应当尽量使用“局部函数”，其记法是类似的，只是开头加上 `local` 修饰符：\n\n```Lua\nlocal function function_name (arc)\n    -- body\nend\n```\n\n定义函数\n\n1. 利用名字来解释函数、变量的目的，使人通过名字就能看出来函数、变量的作用。\n    \n2. 每个函数的长度要尽量控制在一个屏幕内，一眼可以看明白。\n    \n3. 让代码自己说话，不需要注释最好。\n    \n\n  \n\n由于函数定义等价于变量赋值，我们也可以把函数名替换为某个 Lua 表的某个字段，例如\n\n```Lua\nlocal foo = {}\nfunction foo.pr()\n    print(\"ssss\")\nend\n\nfoo.pr()\n```\n\n  \n\n## 参数\n\n### 按值传递\n\n**Lua 函数的参数大部分是按值传递的**。**当函数参数是 table 类型时，传递进来的是实际参数的引用**\n\n值传递就是调用函数时，实参把它的值通过赋值运算传递给形参，然后形参的改变和实参就没有关系了。在这个过程中，实参是通过它在参数表中的位置与形参匹配起来的。\n\n```Lua\nlocal function swap(a, b) --定义函数swap,函数内部进行交换两个变量的值\n    local temp = a\n    a = b\n    b = temp\n    print(a, b)\nend\n\nlocal x = \"hello\"\nlocal y = 20\nprint(x, y)\nswap(x, y)    --调用swap函数\nprint(x, y)   --调用swap函数后，x和y的值并没有交换\n\n--\u003eoutput\nhello 20\n20  hello\nhello 20\n```\n\n在调用函数的时候，**若形参个数和实参个数不同时，Lua 会自动调整实参个数**。调整规则：\n\n- 若实参个数大于形参个数，从左向右，多余的实参被忽略；\n    \n- 若实参个数小于形参个数，从左向右，**没有被实参初始化的形参会被初始化为 nil**\n    \n\n```Lua\nlocal function fun1(a, b)       --两个形参，多余的实参被忽略掉\n    print(a, b)\nend\n\nlocal function fun2(a, b, c, d) --四个形参，没有被实参初始化的形参，用nil初始化\n    print(a, b, c, d)\nend\n\nlocal x = 1\nlocal y = 2\nlocal z = 3\n\nfun1(x, y, z)         -- z被函数fun1忽略掉了，参数变成 x, y\nfun2(x, y, z)         -- 后面自动加上一个nil，参数变成 x, y, z, nil\n\n--\u003eoutput\n1   2\n1   2   3   nil\n```\n\n### 变长参数\n\n其实 Lua 还支持变长参数。若形参为 `...`，表示该函数可以接收不同长度的参数。访问参数的时候也要使用 `...`\n\n```Lua\n\nlocal function func( ... )                -- 形参为 ... ,表示函数采用变长参数\n\n    local temp = {...}                     -- 访问的时候也要使用 ...\n    local ans = table.concat(temp, \" \")    -- 使用 table.concat 库函数对数\n    -- 组内容使用 \" \" 拼接成字符串。\n    print(ans)\nend\n\nfunc(1, 2)        -- 传递了两个参数\nfunc(1, 2, 3, 4)  -- 传递了四个参数\n\n--\u003eoutput\n1 2\n\n1 2 3 4\n```\n\n### **具名参数**\n\nLua 还支持通过名称来指定实参，这时候要把所有的实参组织到一个 table 中，并将这个 table 作为唯一的实参传给函数。\n\n```Lua\nlocal function change(arg) -- change 函数，改变长方形的长和宽，使其各增长一倍\n  arg.width = arg.width * 2\n  arg.height = arg.height * 2return arg\nendlocal rectangle = { width = 20, height = 15 }\nprint(\"before change:\", \"width  =\", rectangle.width,\n                        \"height =\", rectangle.height)\nrectangle = change(rectangle)\nprint(\"after  change:\", \"width  =\", rectangle.width,\n                        \"height =\", rectangle.height)\n\n--\u003eoutput\nbefore change: width = 20  height =  15\nafter  change: width = 40  height =  30\n```\n\n  \n\n### 按引用传递\n\n**当函数参数是 table 类型时，传递进来的是实际参数的引用**，此时在函数内部对该 table 所做的修改，会直接对调用者所传递的实际参数生效，而无需自己返回结果和让调用者进行赋值\n\n```Plaintext\nfunction change(arg) --change函数，改变长方形的长和宽，使其各增长一倍\n  arg.width = arg.width * 2  --表arg不是表rectangle的拷贝，他们是同一个表\n  arg.height = arg.height * 2end                  -- 没有return语句了local rectangle = { width = 20, height = 15 }\nprint(\"before change:\", \"width = \", rectangle.width,\n                        \" height = \", rectangle.height)\nchange(rectangle)\nprint(\"after change:\", \"width = \", rectangle.width,\n                       \" height =\", rectangle.height)\n\n--\u003e output\nbefore change: width = 20  height = 15\nafter  change: width = 40  height = 30\n```\n\n## 函数返回值\n\nLua 具有一项与众不同的特性，允许函数返回多个值。\n\n```Lua\nlocal function swap(a, b)   \n    -- 定义函数 swap，实现两个变量交换值\n    return b, a              \n    -- 按相反顺序返回变量的值\nend\n\nlocal x = 1\nlocal y = 20\nx, y = swap(x, y)           -- 调用 swap 函数\nprint(x, y)                 --\u003e output   20     1\n```\n\n  \n\n当函数返回值的个数和接收返回值的变量的个数不一致时，Lua 也会自动调整参数个数调整规则：\n\n- 若返回值个数大于接收变量的个数，多余的返回值会被忽略掉；\n    \n- 若返回值个数小于参数个数，从左向右，没有被返回值初始化的变量会被初始化为 nil。\n    \n\n```Lua\nfunction init()             \n    --init 函数 返回两个值 1 和 \"lua\"\n    return 1, \"lua\"\nend\n\nx = init()\nprint(x)\n\nx, y, z = init()\nprint(x, y, z)\n\n--output\n1\n1 lua nil\n```\n\n  \n\n当一个函数有一个以上返回值，且函数调用不是一个列表表达式的最后一个元素，那么函数调用只会产生一个返回值, 也就是第一个返回值。\n\n```Lua\nlocal function init()       -- init 函数 返回两个值 1 和 \"lua\"\n    return 1, \"lua\"\nend\n\nlocal x, y, z = init(), 2   -- init 函数的位置不在最后，此时只返回 1\nprint(x, y, z)              --\u003eoutput  1  2  nil\n\nlocal a, b, c = 2, init()   -- init 函数的位置在最后，此时返回 1 和 \"lua\"\nprint(a, b, c)              --\u003eoutput  2  1  lua\n```\n\n函数调用的实参列表也是一个列表表达式。考虑下面的例子：\n\n```Lua\nlocal function init()\n    return 1, \"lua\"\nend\n\nprint(init(), 2)   --\u003eoutput  1  2\nprint(2, init())   --\u003eoutput  2  1  lua\n```\n\n如果你确保只取函数返回值的第一个值，可以使用括号运算符\n\n```Lua\nlocal function init()\n    return 1, \"lua\"\nend\nprint((init()), 2)   --\u003eoutput  1  2\nprint(2, (init()))   --\u003eoutput  2  1\n```\n\n**值得一提的是，如果实参列表中某个函数会返回多个值，同时调用者又没有显式地使用括号运算符来筛选和过滤，则这样的表达式是不能被 LuaJIT 2 所 JIT 编译的，而只能被解释执行。**\n\n  \n\n  \n\n# 全动态函数调用\n\n调用回调函数，并把一个数组参数作为回调函数的参数。\n\n```Lua\nlocal args = {...} or {}\nmethod_name(unpack(args, 1, table.maxn(args)))\n```\n\n```Lua\nlocal function run(x, y)\n    print('run', x, y)\nend\n\nlocal function attack(targetId)\n    print('targetId', targetId)\nend\n\nlocal function do_action(method, ...)\n    local args = {...} or {}\n    method(unpack(args, 1, table.maxn(args)))\nend\n\ndo_action(run, 1, 2)         -- output: run 1 2\ndo_action(attack, 1111)      -- output: targetId    1111\n```\n\n  \n\n# 模块\n\n从 Lua 5.1 语言添加了对模块和包的支持。一**个 Lua 模块的数据结构是用一个 Lua 值（通常是一个 Lua 表或者 Lua 函数）**。**一个 Lua 模块代码就是一个会返回这个 Lua 值的代码块**\n\n- 可以使用内建函数 `require()` 来加载和缓存模块。\n    \n- 简单的说，一个代码模块就是一个程序库，可以通过 `require` 来加载。**模块加载后的结果通过是一个 Lua table**\n    \n- **这个表就像是一个命名空间**，其内容就是模块中导出的所有东西，**比如函数和变量**。`require` 函数会返回 Lua 模块加载后的结果，即用于表示该 Lua 模块的 Lua 值。\n    \n\n  \n\n  \n\nLua 提供了一个名为 `require` 的函数用来加载模块。**要加载一个模块，只需要简单地调用** **`require`** **\"file\" 就可以了，file 指模块所在的文件名**。这个调用会返回一个由模块函数组成的 table，并且还会定义一个包含该 table 的全局变量。\n\n在 Lua 中创建一个模块最简单的方法是：**创建一个 table，并将所有需要导出的函数放入其中，最后返回这个 table 就可以了。相当于将导出的函数作为 table 的一个字段，在 Lua 中函数是第一类值，提供了天然的优势。**\n\n- 创建 my. Lua\n    \n\n```Lua\nlocal _M = {}\n\nlocal function get_name()\n    return \"Lucy\"\n    end\nfunction _M.greeting()\n    print(\"hello \" .. get_name())\nend\n\nreturn _M\n```\n\n- 把下面代码保存在文件 main. Lua 中，然后执行 main. Lua，调用上述模块。\n    \n\n```Lua\nlocal my_module = require(\"my\")\nmy_module.greeting()     --\u003eoutput: hello Lucy\n```\n\n  \n\n\u003e - 对于需要导出给外部使用的公共模块，处于安全考虑，**是要避免全局变量的出现**。我们可以使用 lj-releng 或 luacheck 工具完成全局变量的检测。至于如何做，到后面再讲。\n\u003e     \n\u003e - 另一个要注意的是，由于在 LuaJIT 中，**require 函数内不能进行上下文切换**，**所以不能够在模块的顶级上下文中调用 cosocket 一类的 API**。否则会报 `attempt to yield across C-call boundary` 错误。\n\u003e     \n\n  \n\n# String\n\nLua 字符串总是由字节构成的。Lua 核心并不尝试理解具体的字符集编码（比如 GBK 和 UTF-8 这样的多字节字符编码）\n\nLua 字符串内部用来标识各个组成字节的下标是从 1 开始的，这不同于像 C 和 Perl 这样的编程语言。这样数字符串位置的时候再也不用调整，对于非专业的开发者来说可能也是一个好事情，**string.Sub (str, 3, 7) 直接表示从第三个字符开始到第七个字符（含）为止的子串。**\n\n## **string.Byte (s [, i [, j ]])**\n\n返回字符 s[i]、s[i + 1]、s[i + 2]、······、s[j] 所对应的 ASCII 码\n\n```Lua\nprint(string.byte(\"abc\", 1, 3))\nprint(string.byte(\"abc\", 3)) -- 缺少第三个参数，第三个参数默认与第二个相同，此时为 3\nprint(string.byte(\"abc\"))    -- 缺少第二个和第三个参数，此时这两个参数都默认为 1\n\n--\u003eoutput\n97    98    99\n99\n97\n```\n\n## **string. Char (...)**\n\n接收 0 个或更多的整数（整数范围：0~255），返回这些整数所对应的 ASCII 码字符组成的字符串。当参数为空时，默认是一个 0。\n\n```Lua\nprint(string.char(96, 97, 98))\nprint(string.char())        -- 参数为空，默认是一个0，-- 你可以用string.byte(string.char())测试一下print(string.char(65, 66))\n\n--\u003e output\n`ab\n\nAB\n```\n\n## **string.Upper (s)**\n\n接收一个字符串 s，返回一个把所有小写字母变成大写字母的字符串。\n\n```Lua\nprint(string.upper(\"Hello Lua\"))  --\u003eoutput  HELLO LUA\n```\n\n## **string.Lower (s)**\n\n接收一个字符串 s，返回一个把所有大写字母变成小写字母的字符串。\n\n```Lua\nprint(string.lower(\"Hello Lua\"))  --\u003eoutput   hello lua\n```\n\n## **string.Len (s)**\n\n接收一个字符串，返回它的长度。\n\n```Lua\nprint(string.len(\"hello lua\")) --\u003eoutput  9\n```\n\n使用此函数是不推荐的。应当总是使用 `#` 运算符来获取 Lua 字符串的长度\n\n## **string.Find (s, p [, init [, plain]])**\n\n在 s 字符串中第一次匹配 p 字符串。若匹配成功，则返回 p 字符串在 s 字符串中出现的开始位置和结束位置；若匹配失败，则返回 nil,\n\n第三个参数第三个参数 init 默认为 1，并且可以为负整数，\n\n当 init 为负数时，表示从 s 字符串的 string.Len (s) + init + 1 索引处开始向后匹配字符串 p 。\n\n第四个参数默认为 false，当其为 true 时，只会把 p 看成一个字符串对待。\n\n```Lua\nlocal find = string.find\nprint(find(\"abc cba\", \"ab\"))\nprint(find(\"abc cba\", \"ab\", 2))     -- 从索引为2的位置开始匹配字符串：ab\nprint(find(\"abc cba\", \"ba\", -1))    -- 从索引为7的位置开始匹配字符串：ba\nprint(find(\"abc cba\", \"ba\", -3))    -- 从索引为5的位置开始匹配字符串：ba\nprint(find(\"abc cba\", \"(%a+)\", 1))  -- 从索引为1处匹配最长连续且只含字母的字符串\nprint(find(\"abc cba\", \"(%a+)\", 1, true)) --从索引为1的位置开始匹配字符串：(%a+)\n\n--\u003eoutput\n1   2\nnil\nnil\n6   7\n1   3   abc\nnil\n```\n\n## **string.Format (formatstring, ...)**\n\n按照格式化参数 formatstring，返回后面 `...` 内容的格式化版本\n\n```Plaintext\nprint(string.format(\"%.4f\", 3.1415926))     -- 保留4位小数\nprint(string.format(\"%d %x %o\", 31, 31, 31))-- 十进制数31转换成不同进制\nd = 29; m = 7; y = 2015                     -- 一行包含几个语句，用；分开\nprint(string.format(\"%s %02d/%02d/%d\", \"today is:\", d, m, y))\n\n--\u003eoutput\n3.1416\n31 1f 37\ntoday is: 29/07/2015\n```\n\n## **string.Match (s, p [, init])**\n\n在字符串 s 中匹配（模式）字符串 p，若匹配成功，则返回目标字符串中与模式匹配的子串；否则返回 nil。第三个参数 init 默认为 1，并且可以为负整数，当 init 为负数时，表示从 s 字符串的 string.Len (s) + init + 1 索引处开始向后匹配字符串 p。\n\n```Lua\nprint(string.match(\"hello lua\", \"lua\"))\nprint(string.match(\"lua lua\", \"lua\", 2))  --匹配后面那个luaprint(string.match(\"lua lua\", \"hello\"))\nprint(string.match(\"today is 27/7/2015\", \"%d+/%d+/%d+\"))\n\n--\u003eoutput\nlua\nlua\nnil27/7/2015\n```\n\n## **string.Gmatch (s, p)**\n\n返回一个迭代器函数，通过这个迭代器函数可以遍历到在字符串 s 中出现模式串 p 的所有地方。\n\n```Lua\ns = \"hello world from Lua\"\nfor w in string.gmatch(s, \"%a+\") do  --匹配最长连续且只含字母的字符串\n    print(w)\nend\n\n--\u003eoutput\nhello\nworld\nfrom\nLua\n\n\nt = {}\ns = \"from=world, to=Lua\"\nfor k, v in string.gmatch(s, \"(%a+)=(%a+)\") do  --匹配两个最长连续且只含字母的\n    t[k] = v                                    --字符串，它们之间用等号连接\nend\nfor k, v in pairs(t) do\n    print (k,v)\nend\n\n--\u003eoutput\nto      Lua\nfrom    worl\n```\n\n## **string.Rep (s, n)**\n\n返回字符串 s 的 n 次拷贝。\n\n```Lua\nprint(string.rep(\"abc\", 3)) \n\n--拷贝3次\"abc\"--\u003eoutput  abcabcabc\n```\n\n## **string.Sub (s, i [, j])**\n\n返回字符串 s 中，索引 i 到索引 j 之间的子字符串。当 j 缺省时，默认为 -1，也就是字符串 s 的最后位置。I 可以为负数。当索引 i 在字符串 s 的位置在索引 j 的后面时，将返回一个空字符串。\n\n```Lua\nprint(string.sub(\"Hello Lua\", 4, 7))\nprint(string.sub(\"Hello Lua\", 2))\nprint(string.sub(\"Hello Lua\", 2, 1))    --看到返回什么了吗print(string.sub(\"Hello Lua\", -3, -1))\n\n--\u003eoutput\nlo L\nello Lua\n\nLua\n```\n\n## **string.Gsub (s, p, r [, n])**\n\n将目标字符串 s 中所有的子串 p 替换成字符串 r。可选参数 n，表示限制替换次数。返回值有两个，第一个是被替换后的字符串，第二个是替换了多少次。\n\n```Plaintext\nprint(string.gsub(\"Lua Lua Lua\", \"Lua\", \"hello\"))\nprint(string.gsub(\"Lua Lua Lua\", \"Lua\", \"hello\", 2)) --指明第四个参数--\u003eoutput\nhello hello hello   3\nhello hello Lua     2\n```\n\n## **string. Reverse (s)**\n\n接收一个字符串 s，返回这个字符串的反转\n\n```Lua\nprint(string.reverse(\"Hello Lua\"))  --\u003e output: auL olleH\n```\n\n  \n\n# Table\n\n## **下标从 1 开始**\n\n数组下标从 1 开始计数。\n\n而 Lua 最初设计是一种类似 XML 的数据描述语言，所以索引（index）反应的是数据在里面的位置，而不是偏移量。\n\n  \n\n在初始化一个数组的时候，**若不显式地用键值对方式赋值，则会默认用数字作为下标**，从 1 开始。由于在 _Lua_ 内部实际采用哈希表和数组分别保存键值对、普通值，所以不推荐混合使用这两种赋值方式\n\n```Lua\nlocal color={first=\"red\", \"blue\", third=\"green\", \"yellow\"}\nprint(color[\"first\"])                 --\u003e output: red\nprint(color[1])                       --\u003e output: blue\nprint(color[\"third\"])                 --\u003e output: green\nprint(color[2])                       --\u003e output: yellow\nprint(color[3])                       --\u003e output: nil\n```\n\n- **当我们把 table 当作栈或者队列使用的时候，容易犯错，追加到 table 的末尾用的是** **`s[#s+1] = something`****, 而不是** **`s[#s] = something`**\n    \n- 而且如果这个 something 是一个 nil 的话**，会导致这一次压栈（或者入队列）没有存入任何东西**， s 的值没有变\n    \n- 如果 `s = { 1, 2, 3, 4, 5, 6 }`，你令 `s[4] = nil`， s 会令你“匪夷所思”地变成 3。\n    \n\n## **table. Getn 获取长度**\n\n取长度操作符写作一元操作 。字符串的长度是它的字节数（就是以一个字符一个字节计算的字符串长度）\n\n- 对于常规的数组，里面从 1 到 n 放着一些非空的值的时候，它的长度就精确的为 n，即最后一个值的下标\n    \n- 如果数组有一个“空洞”（**就是说，nil 值被夹在非空值之间**），**那么 t 可能是指向任何一个是 nil 值的前一个位置的下标**\n    \n- 这也就说明对于有“空洞”的情况，table 的长度存在一定的 **不可确定性**\n    \n\n```Lua\nlocal tblTest1 = { 1, a = 2, 3 }\nprint(\"Test1 \" .. table.getn(tblTest1))\n\nlocal tblTest2 = { 1, nil }\nprint(\"Test2 \" .. table.getn(tblTest2))\n\nlocal tblTest3 = { 1, nil, 2 }\nprint(\"Test3 \" .. table.getn(tblTest3))\n\nlocal tblTest4 = { 1, nil, 2, nil }\nprint(\"Test4 \" .. table.getn(tblTest4))\n\nlocal tblTest5 = { 1, nil, 2, nil, 3, nil }\nprint(\"Test5 \" .. table.getn(tblTest5))\n\nlocal tblTest6 = { 1, nil, 2, nil, 3, nil, 4, nil }\nprint(\"Test6 \" .. table.getn(tblTest6))\n```\n\n我们使用 Lua 5.1 和 LuaJIT 2.1 分别执行这个用例，结果如下：\n\n```Lua\n# lua test.lua\nTest1 2\nTest2 1\nTest3 3\nTest4 1\nTest5 3\nTest6 1\n# luajit test.lua\nTest1 2\nTest2 1\nTest3 1\nTest4 1\nTest5 1\nTest6 1\n```\n\n不要在 Lua 的 table 中使用 nil 值，**如果一个元素要删除，直接 remove，不要用 nil 去代替**。\n\n## **table. Concat (table [, sep [, i [, j ] ] ])**\n\n对于元素是 string 或者 number 类型的表 table，返回 `table[i]..sep..table[i+1] ··· sep..table[j]` 连接成的字符串。填充字符串 sep 默认为空白字符串。起始索引位置 i 默认为 1，结束索引位置 j 默认是 table 的长度。\n\n```Lua\nlocal a = {1, 3, 5, \"hello\" }\nprint(table.concat(a))              -- output: 135hello\nprint(table.concat(a, \"|\"))         -- output: 1|3|5|hello\nprint(table.concat(a, \" \", 4, 2))   -- output:\nprint(table.concat(a, \" \", 2, 4))   -- output: 3 5 hello\n```\n\n## **table. Insert (table, [pos ,] value)**\n\n在（数组型）表 table 的 pos 索引位置插入 value，其它元素向后移动到空的地方。Pos 的默认值是表的长度加一，即默认是插在表的最后\n\n```Lua\nlocal a = {1, 8}             --a[1] = 1,a[2] = 8\ntable.insert(a, 1, 3)   --在表索引为1处插入3\nprint(a[1], a[2], a[3])\ntable.insert(a, 10)    --在表的最后插入10\nprint(a[1], a[2], a[3], a[4])\n\n--\u003eoutput\n3    1    8\n3    1    8    10\n```\n\n## **table. Maxn (table)**\n\n返回（数组型）表 table 的最大索引编号；如果此表没有正的索引编号，返回 0。\n\n```Lua\nlocal a = {}\na[-1] = 10\nprint(table.maxn(a))\na[5] = 10\nprint(table.maxn(a))\n\n--\u003eoutput05\n```\n\n## **table. Remove (table [, pos])**\n\n在表 table 中删除索引为 pos（pos 只能是 number 型）的元素，并返回这个被删除的元素，它后面所有元素的索引值都会减一。Pos 的默认值是表的长度，即默认是删除表的最后一个元素。\n\n```Lua\nlocal a = { 1, 2, 3, 4}\nprint(table.remove(a, 1)) --删除速索引为1的元素print(a[1], a[2], a[3], a[4])\n\nprint(table.remove(a))   --删除最后一个元素print(a[1], a[2], a[3], a[4])\n\n--\u003eoutput12    3    4    nil42    3    nil    nil\n```\n\n## **table. Sort (table [, comp])**\n\n按照给定的比较函数 comp 给表 table 排序，也就是从 table[1] 到 table[n]，这里 n 表示 table 的长度。比较函数有两个参数，如果希望第一个参数排在第二个的前面，就应该返回 true，否则返回 false。如果比较函数 comp 没有给出，默认从小到大排序。\n\n```Lua\n\nlocal function compare(x, y) --从大到小排序\n    return x \u003e y         --如果第一个参数大于第二个就返回true，否则返回false\nend\n\nlocal a = { 1, 7, 3, 4, 25}\ntable.sort(a)           --默认从小到大排序\nprint(a[1], a[2], a[3], a[4], a[5])\ntable.sort(a, compare) --使用比较函数进行排序\nprint(a[1], a[2], a[3], a[4], a[5])\n\n--\u003eoutput\n1    3    4    7    25\n25    7    4    3    1\n```\n\n## 其他\n\nLuaJIT 2.1 新增加的 `table.new` 和 `table.clear` 函数是非常有用的。前者主要用来预分配 Lua table 空间，后者主要用来高效的释放 table 空间，并且它们都是可以被 JIT 编译的\n\n  \n\n# 日期时间\n\n函数 time、date 和 difftime 提供了所有的日期和时间功能。\n\n在 OpenResty 的世界里，不推荐使用这里的标准时间函数，因为这些函数通常会引发不止一个昂贵的系统调用，同时无法为 LuaJIT JIT 编译，对性能造成较大影响。推荐使用 ngx_lua 模块提供的带缓存的时间接口，如 `ngx.today`, `ngx.time`, `ngx.utctime`, `ngx.localtime`, `ngx.now`, `ngx.http_time`，以及 `ngx.cookie_time` 等。\n\n  \n\n## **os. Time ([table])**\n\n如果不使用参数 table 调用 time 函数，\n\n- 它会返回当前的时间和日期（它表示从某一时刻到现在的秒数）。\n    \n- 如果用 table 参数，它会返回一个数字，表示该 table 中所描述的日期和时间（它表示从某一时刻到 table 中描述日期和时间的秒数）。Table 的字段如下：\n    \n\n|          |                            |\n| -------- | -------------------------- |\n| 字段名称 | 取值范围                   |\n| year     | 四位数字                   |\n| month    | 1--12                      |\n| day      | 1--31                      |\n| hour     | 0--23                      |\n| min      | 0--59                      |\n| sec      | 0--61                      |\n| isdst    | boolean（true 表示夏令时） |\n\n对于 time 函数，如果参数为 table，那么 table 中必须含有 year、month、day 字段。其他字缺省时段默认为中午（12:00:00）。\n\n\u003e 示例代码：（地点为北京）\n\n```Plaintext\nprint(os.time())    --\u003eoutput  1438243393\na = { year = 1970, month = 1, day = 1, hour = 8, min = 1 }\nprint(os.time(a))   --\u003eoutput  60\n```\n\n## **os. Difftime (t 2, t 1)**\n\n返回 t 1 到 t 2 的时间差，单位为秒。\n\n\u003e 示例代码:\n\n```Plaintext\nlocal day1 = { year = 2015, month = 7, day = 30 }\nlocal t1 = os.time(day1)\n\nlocal day2 = { year = 2015, month = 7, day = 31 }\nlocal t2 = os.time(day2)\nprint(os.difftime(t2, t1))   --\u003eoutput  86400\n```\n\n## **os. Date ([format [, time]])**\n\n把一个表示日期和时间的数值，转换成更高级的表现形式。\n\n- 其第一个参数 format 是一个格式化字符串，描述了要返回的时间形式。\n    \n- 第二个参数 time 就是日期和时间的数字表示，缺省时默认为当前的时间。\n    \n- 使用格式字符 \"*t\"，创建一个时间表。\n    \n\n\u003e 示例代码：\n\n```Plaintext\nlocal tab1 = os.date(\"*t\")  --返回一个描述当前日期和时间的表\nlocal ans1 = \"{\"\nfor k, v in pairs(tab1) do  --把tab1转换成一个字符串\n    ans1 = string.format(\"%s %s = %s,\", ans1, k, tostring(v))\nend\n\nans1 = ans1 .. \"}\"\nprint(\"tab1 = \", ans1)\n\n\nlocal tab2 = os.date(\"*t\", 360)  --返回一个描述日期和时间数为360秒的表\nlocal ans2 = \"{\"\nfor k, v in pairs(tab2) do      --把tab2转换成一个字符串\n    ans2 = string.format(\"%s %s = %s,\", ans2, k, tostring(v))\nend\n\nans2 = ans2 .. \"}\"\nprint(\"tab2 = \", ans2)\n\n--\u003eoutput\ntab1 = { hour = 17, min = 28, wday = 5, day = 30, month = 7, year = 2015, sec = 10, yday = 211, isdst = false,}\ntab2 = { hour = 8, min = 6, wday = 5, day = 1, month = 1, year = 1970, sec = 0, yday = 1, isdst = false,}\n```\n\n该表中除了使用到了 time 函数参数 table 的字段外，这还提供了星期（wday，星期天为 1）和一年中的第几天（yday，一月一日为 1）。除了使用 \"*t\" 格式字符串外，如果使用带标记（见下表）的特殊字符串，os. Date 函数会将相应的标记位以时间信息进行填充，得到一个包含时间的字符串。表如下：\n\n|          |                                           |\n| -------- | ----------------------------------------- |\n| 格式字符 | 含义                                      |\n| %a       | 一星期中天数的简写（例如：Wed）           |\n| %A       | 一星期中天数的全称（例如：Wednesday）     |\n| %b       | 月份的简写（例如：Sep）                   |\n| %B       | 月份的全称（例如：September）             |\n| %c       | 日期和时间（例如：07/30/15 16:57:24）     |\n| %d       | 一个月中的第几天[01 ~ 31]                 |\n| %H       | 24 小时制中的小时数[00 ~ 23]              |\n| %I       | 12 小时制中的小时数[01 ~ 12]              |\n| %j       | 一年中的第几天[001 ~ 366]                 |\n| %M       | 分钟数[00 ~ 59]                           |\n| %m       | 月份数[01 ~ 12]                           |\n| %p       | “上午（am）”或“下午（pm）”                |\n| %S       | 秒数[00 ~ 59]                             |\n| %w       | 一星期中的第几天[1 ~ 7 = 星期天 ~ 星期六] |\n| %x       | 日期（例如：07/30/15）                    |\n| %X       | 时间（例如：16:57:24）                    |\n| %y       | 两位数的年份[00 ~ 99]                     |\n| %Y       | 完整的年份（例如：2015）                  |\n| %%       | 字符'%'                                   |\n\n\u003e 示例代码：\n\n```Plaintext\nprint(os.date(\"today is %A, in %B\"))\nprint(os.date(\"now is %x %X\"))\n\n--\u003eoutput\ntoday is Thursday, in July\nnow is 07/30/15 17:39:22\n```\n\n  \n\n# 数学库\n\nUa 数学库由一组标准的数学函数构成。数学库的引入丰富了 Lua 编程语言的功能，同时也方便了程序的编写。常用数学函数见下表：\n\n|               asd           |                                                                                        sdfa                                                                                                      | \n| ------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| 函数名                   | 函数功能                                                                                                                                                                                     |\n| math.Rad (x)             | 角度 x 转换成弧度                                                                                                                                                                            |\n| math.Deg (x)             | 弧度 x 转换成角度                                                                                                                                                                            |\n| math.Max (x, ...)        | 返回参数中值最大的那个数，参数必须是 number 型                                                                                                                                               |\n| math.Min (x, ...)        | 返回参数中值最小的那个数，参数必须是 number 型                                                                                                                                               |\n| math. Random ([m [, n]]) | 不传入参数时，返回一个在区间[0,1)内均匀分布的伪随机实数；只使用一个整数参数 m 时，返回一个在区间[1, m]内均匀分布的伪随机整数；使用两个整数参数时，返回一个在区间[m, n]内均匀分布的伪随机整数 |\n| math. Randomseed (x)     | 为伪随机数生成器设置一个种子 x，相同的种子将会生成相同的数字序列                                                                                                                             |\n| math.Abs (x)             | 返回 x 的绝对值                                                                                                                                                                              |\n| math.Fmod (x, y)         | 返回 x 对 y 取余数                                                                                                                                                                           |\n| math.Pow (x, y)          | 返回 x 的 y 次方                                                                                                                                                                             |\n| math.Sqrt (x)            | 返回 x 的算术平方根                                                                                                                                                                          |\n| math.Exp (x)             | 返回自然数 e 的 x 次方                                                                                                                                                                       |\n| math.Log (x)             | 返回 x 的自然对数                                                                                                                                                                            |\n| math. Log 10 (x)         | 返回以 10 为底，x 的对数                                                                                                                                                                     |\n| math.Floor (x)           | 返回最大且不大于 x 的整数                                                                                                                                                                    |\n| math.Ceil (x)            | 返回最小且不小于 x 的整数                                                                                                                                                                    |\n| math. Pi                 | 圆周率                                                                                                                                                                                       |\n| math.Sin (x)             | 求弧度 x 的正弦值                                                                                                                                                                            |\n| math.Cos (x)             | 求弧度 x 的余弦值                                                                                                                                                                            |\n| math.Tan (x)             | 求弧度 x 的正切值                                                                                                                                                                            |\n| math.Asin (x)            | 求 x 的反正弦值                                                                                                                                                                              |\n| math.Acos (x)            | 求 x 的反余弦值                                                                                                                                                                              |\n| math.Atan (x)            | 求 x 的反正切值                                                                                                                                                                              |\n\n```Lua\nprint(math.pi)           --\u003eoutput  3.1415926535898\nprint(math.rad(180))     --\u003eoutput  3.1415926535898\nprint(math.deg(math.pi)) --\u003eoutput  180\n\nprint(math.sin(1))       --\u003eoutput  0.8414709848079\nprint(math.cos(math.pi)) --\u003eoutput  -1\nprint(math.tan(math.pi / 4))  --\u003eoutput  1\n\nprint(math.atan(1))      --\u003eoutput  0.78539816339745\nprint(math.asin(0))      --\u003eoutput  0\n\nprint(math.max(-1, 2, 0, 3.6, 9.1))     --\u003eoutput  9.1\nprint(math.min(-1, 2, 0, 3.6, 9.1))     --\u003eoutput  -1\n\nprint(math.fmod(10.1, 3))   --\u003eoutput  1.1\nprint(math.sqrt(360))      --\u003eoutput  18.97366596101\n\nprint(math.exp(1))         --\u003eoutput  2.718281828459\nprint(math.log(10))        --\u003eoutput  2.302585092994\nprint(math.log10(10))      --\u003eoutput  1\n\nprint(math.floor(3.1415))  --\u003eoutput  3\nprint(math.ceil(7.998))    --\u003eoutput  8\n```\n\n使用 `math.random()` 函数获得伪随机数时，如果不使用 `math.randomseed()` 设置伪随机数生成种子或者设置相同的伪随机数生成种子，那么得得到的伪随机数序列是一样的。\n\n```Lua\nmath.randomseed (100) --把种子设置为100\nprint(math.random())         --\u003eoutput  0.0012512588885159\nprint(math.random(100))      --\u003eoutput  57\nprint(math.random(100, 360)) --\u003eoutput  150\n```\n\n稍等片刻，再次运行上面的代码。\n\n```Lua\nmath.randomseed (100) --把种子设置为100\nprint(math.random())         --\u003eoutput  0.0012512588885159\nprint(math.random(100))      --\u003eoutput  57\nprint(math.random(100, 360)) --\u003eoutput  150\n```\n\n两次运行的结果一样。为了避免每次程序启动时得到的都是相同的伪随机数序列，通常是使用当前时间作为种子。\n\n\u003e 修改上例中的代码：\n\n```Lua\nmath.randomseed (os.time())   --把100换成os.time()\nprint(math.random())          --\u003eoutput 0.88369396038697\nprint(math.random(100))       --\u003eoutput 66\nprint(math.random(100, 360))  --\u003eoutput 228\n```\n\n稍等片刻，再次运行上面的代码。\n\n```Plaintext\nmath.randomseed (os.time())   --把100换成os.time()\nprint(math.random())          --\u003eoutput 0.88946195867794\nprint(math.random(100))       --\u003eoutput 68\nprint(math.random(100, 360))  --\u003eoutput 129\n```\n\n  \n\n# 文件\n\nLua I/O 库提供两种不同的方式处理文件：隐式文件描述，显式文件描述。\n\n这些文件 I/O 操作，**在 OpenResty 的上下文中对事件循环是会产生阻塞效应**。OpenResty 比较擅长的是高并发网络处理，在这个环境中，任何文件的操作，都将阻塞其他并行执行的请求。**实际中的应用，在 OpenResty 项目中应尽可能让网络处理部分、文件 I/0 操作部分相互独立，不要揉和在一起**。\n\n## **隐式文件描述**\n\n设置一个默认的输入或输出文件，然后在这个文件上进行所有的输入或输出操作。所有的操作函数由 io 表提供。\n\n\u003e 打开已经存在的 `test1.txt` 文件，并读取里面的内容\n\n```Plaintext\nfile = io.input(\"test1.txt\")    -- 使用 io.input() 函数打开文件repeat\n    line = io.read()            -- 逐行读取内容，文件结束时返回nil\n    if nil == line then\n        break\n    end\n    print(line)\nuntil (false)\n\nio.close(file)                  -- 关闭文件--\u003e output\nmy test file\nhello\nlua\n```\n\n\u003e 在 `test1.txt` 文件的最后添加一行 \"hello world\"\n\n```Plaintext\nfile = io.open(\"test1.txt\", \"a+\")   -- 使用 io.open() 函数，以添加模式打开文件\nio.output(file)                     -- 使用 io.output() 函数，设置默认输出文件\nio.write(\"\\nhello world\")           -- 使用 io.write() 函数，把内容写到文件\nio.close(file)\n```\n\n在相应目录下打开 `test1.txt` 文件，查看文件内容发生的变化。\n\n## **显式文件描述**\n\n使用 file: XXX () 函数方式进行操作, 其中 file 为 io.Open () 返回的文件句柄。\n\n\u003e 打开已经存在的 test 2. Txt 文件，并读取里面的内容\n\n```Plaintext\nfile = io.open(\"test2.txt\", \"r\")    -- 使用 io.open() 函数，以只读模式打开文件\n\nfor line in file:lines() do         -- 使用 file:lines() 函数逐行读取文件\n    print(line)\nend\n\nfile:close()\n\n--\u003eoutput\nmy test2\nhello lua\n```\n\n\u003e 在 test 2. Txt 文件的最后添加一行 \"hello world\"\n\n```Plaintext\nfile = io.open(\"test2.txt\", \"a\")  -- 使用 io.open() 函数，以添加模式打开文件\nfile:write(\"\\nhello world\")       -- 使用 file:write() 函数，在文件末尾追加内容\nfile:close()\n```\n\n在相应目录下打开 `test2.txt` 文件，查看文件内容发生的变化。\n\n## **文件操作函数**\n\n#### **io. Open (filename [, mode])**\n\n按指定的模式 mode，打开一个文件名为 `filename` 的文件，成功则返回文件句柄，失败则返回 nil 加错误信息。模式：\n\n|      |                                                |                     | \n| ---- | ---------------------------------------------- | ------------------- |\n| 模式 | 含义                                           | 文件不存在时        |\n| \"r\"  | 读模式 (默认)                                  | 返回 nil 加错误信息 |\n| \"w\"  | 写模式                                         | 创建文件            |\n| \"a\"  | 添加模式                                       | 创建文件            |\n| \"r+\" | 更新模式，保存之前的数据                       | 返回 nil 加错误信息 |\n| \"w+\" | 更新模式，清除之前的数据                       | 创建文件            |\n| \"a+\" | 添加更新模式，保存之前的数据, 在文件尾进行添加 | 创建文件            |\n\n模式字符串后面可以有一个 'b'，用于在某些系统中打开二进制文件。\n\n注意 \"w\" 和 \"wb\" 的区别\n\n- \"w\" 表示文本文件。某些文件系统 (如 Linux 的文件系统)认为 0 x 0 A 为文本文件的换行符，Windows 的文件系统认为 0 x 0 D 0 A 为文本文件的换行符。为了兼容其他文件系统（如从 Linux 拷贝来的文件），Windows 的文件系统在写文件时，会在文件中 0 x 0 A 的前面加上 0 x 0 D。使用 \"w\"，其属性要看所在的平台。\n    \n- \"wb\" 表示二进制文件。文件系统会按纯粹的二进制格式进行写操作，因此也就不存在格式转换的问题。（Linux 文件系统下 \"w\" 和 \"wb\" 没有区别）\n    \n\n#### **file: close ()**\n\n关闭文件。注意：当文件句柄被垃圾收集后，文件将自动关闭。句柄将变为一个不可预知的值。\n\n#### **io. Close ([file])**\n\n关闭文件，和 file: close () 的作用相同。没有参数 file 时，关闭默认输出文件。\n\n#### **file: flush ()**\n\n把写入缓冲区的所有数据写入到文件 file 中。\n\n#### **io. Flush ()**\n\n相当于 file: flush ()，把写入缓冲区的所有数据写入到默认输出文件。\n\n#### **io. Input ([file])**\n\n当使用一个文件名调用时，打开这个文件（以文本模式），并设置文件句柄为默认输入文件；当使用一个文件句柄调用时，设置此文件句柄为默认输入文件；当不使用参数调用时，返回默认输入文件句柄。\n\n#### **file: lines ()**\n\n返回一个迭代函数, 每次调用将获得文件中的一行内容, 当到文件尾时，将返回 nil，但不关闭文件。\n\n#### **io. Lines ([filename])**\n\n打开指定的文件 filename 为读模式并返回一个迭代函数, 每次调用将获得文件中的一行内容, 当到文件尾时，将返回 nil，并自动关闭文件。若不带参数时 io.Lines () 等价于 io.Input (): lines () 读取默认输入设备的内容，结束时不关闭文件。\n\n#### **io. Output ([file])**\n\n类似于 io. Input，但操作在默认输出文件上。\n\n#### **file: read (...)**\n\n按指定的格式读取一个文件。按每个格式将返回一个字符串或数字, 如果不能正确读取将返回 nil，若没有指定格式将指默认按行方式进行读取。格式：\n\n|        |                                                                                                        |\n| ------ | ------------------------------------------------------------------------------------------------------ |\n| 格式   | 含义                                                                                                   |\n| \"*n\"   | 读取一个数字                                                                                           |\n| \"*a\"   | 从当前位置读取整个文件。若当前位置为文件尾，则返回空字符串                                             |\n| \"*l\"   | 读取下一行的内容。若为文件尾，则返回 nil。(默认)                                                       |\n| number | 读取指定字节数的字符。若为文件尾，则返回 nil。如果 number 为 0, 则返回空字符串，若为文件尾, 则返回 nil |\n\n#### **io. Read (...)**\n\n相当于 io.Input ():read\n\n#### **io. Type (obj)**\n\n检测 obj 是否一个可用的文件句柄。如果 obj 是一个打开的文件句柄，则返回 \"file\" 如果 obj 是一个已关闭的文件句柄，则返回 \"closed file\" 如果 obj 不是一个文件句柄，则返回 nil。\n\n#### **file: write (...)**\n\n把每一个参数的值写入文件。参数必须为字符串或数字，若要输出其它值，则需通过 tostring 或 string. Format 进行转换。\n\n#### **io. Write (...)**\n\n相当于 io.Output (): write。\n\n#### **file: seek ([whence] [, offset])**\n\n设置和获取当前文件位置，成功则返回最终的文件位置 (按字节，相对于文件开头), 失败则返回 nil 加错误信息。缺省时，whence 默认为 \"cur\"，offset 默认为 0 。参数 whence：\n\n|        |                     |\n| ------ | ------------------- |\n| whence | 含义                |\n| \"set\"  | 文件开始            |\n| \"cur\"  | 文件当前位置 (默认) |\n| \"end\"  | 文件结束            |\n\n#### **file: setvbuf (mode [, size])**\n\n设置输出文件的缓冲模式。模式：\n\n|        |                                                              |\n| ------ | ------------------------------------------------------------ |\n| 模式   | 含义                                                         |\n| \"no\"   | 没有缓冲，即直接输出                                         |\n| \"full\" | 全缓冲，即当缓冲满后才进行输出操作 (也可调用 flush 马上输出) |\n| \"line\" | 以行为单位，进行输出                                         |\n\n最后两种模式，size 可以指定缓冲的大小（按字节），忽略 size 将自动调整为最佳的大小。","lastmodified":"2024-02-25T17:02:23.038963969Z","tags":["lua"]}}