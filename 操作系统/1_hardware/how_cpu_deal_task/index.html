<!doctype html><html lang=en><head><meta charset=utf-8><meta name=description content="2.5 CPU 是如何执行任务的？ 你清楚下面这几个问题吗？
 有了内存，为什么还需要 CPU Cache？ CPU 是怎么读写数据的？ 如何让 CPU 能读取数据更快一些？ CPU 伪共享是如何发生的？又该如何避免？ CPU 是如何调度任务的？如果你的任务对响应要求很高，你希望它总是能被先调度，这该怎么办？ &mldr;  这篇，我们就来回答这些问题。"><meta property="og:title" content><meta property="og:description" content="2.5 CPU 是如何执行任务的？ 你清楚下面这几个问题吗？
 有了内存，为什么还需要 CPU Cache？ CPU 是怎么读写数据的？ 如何让 CPU 能读取数据更快一些？ CPU 伪共享是如何发生的？又该如何避免？ CPU 是如何调度任务的？如果你的任务对响应要求很高，你希望它总是能被先调度，这该怎么办？ &mldr;  这篇，我们就来回答这些问题。"><meta property="og:type" content="website"><meta property="og:image" content="https://googoo-s.github.io/icon.png"><meta property="og:url" content="https://googoo-s.github.io/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1_hardware/how_cpu_deal_task/"><meta property="og:width" content="200"><meta property="og:height" content="200"><meta name=twitter:card content="summary"><meta name=twitter:title content><meta name=twitter:description content="2.5 CPU 是如何执行任务的？ 你清楚下面这几个问题吗？
 有了内存，为什么还需要 CPU Cache？ CPU 是怎么读写数据的？ 如何让 CPU 能读取数据更快一些？ CPU 伪共享是如何发生的？又该如何避免？ CPU 是如何调度任务的？如果你的任务对响应要求很高，你希望它总是能被先调度，这该怎么办？ &mldr;  这篇，我们就来回答这些问题。"><meta name=twitter:image content="https://googoo-s.github.io/icon.png"><title>googoo-s 😄😸😎</title><meta name=viewport content="width=device-width,initial-scale=1"><link rel="shortcut icon" type=image/png href=https://googoo-s.github.io//icon.png><link href=https://googoo-s.github.io/styles.19109a40042e9f0e72e952fda4442a34.min.css rel=stylesheet><link href=https://googoo-s.github.io/styles/_light_syntax.86a48a52faebeaaf42158b72922b1c90.min.css rel=stylesheet id=theme-link><script src=https://googoo-s.github.io/js/darkmode.953af745b0f9342644d632fc167f3727.min.js></script>
<script src=https://googoo-s.github.io/js/util.00639692264b21bc3ee219733d38a8be.min.js></script>
<link rel=preload href=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css as=style onload='this.onload=null,this.rel="stylesheet"' integrity=sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js integrity=sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/contrib/copy-tex.min.js integrity=sha384-ww/583aHhxWkz5DEVn6OKtNiIaLi2iBRNZXfJRiY1Ai7tnJ9UXpEsyvOITVpTl4A crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/@floating-ui/core@1.2.1></script>
<script src=https://cdn.jsdelivr.net/npm/@floating-ui/dom@1.2.1></script>
<script defer src=https://googoo-s.github.io/js/popover.aa9bc99c7c38d3ae9538f218f1416adb.min.js></script>
<script defer src=https://googoo-s.github.io/js/code-title.ce4a43f09239a9efb48fee342e8ef2df.min.js></script>
<script defer src=https://googoo-s.github.io/js/clipboard.2913da76d3cb21c5deaa4bae7da38c9f.min.js></script>
<script defer src=https://googoo-s.github.io/js/callouts.7723cac461d613d118ee8bb8216b9838.min.js></script>
<script>const SEARCH_ENABLED=!1,LATEX_ENABLED=!0,PRODUCTION=!0,BASE_URL="https://googoo-s.github.io/",fetchData=Promise.all([fetch("https://googoo-s.github.io/indices/linkIndex.0be9ea5cc5a709de699463fae2ac30a8.min.json").then(e=>e.json()).then(e=>({index:e.index,links:e.links})),fetch("https://googoo-s.github.io/indices/contentIndex.0d1fcd0ce55147328e47ced9d4063f41.min.json").then(e=>e.json())]).then(([{index:e,links:t},n])=>({index:e,links:t,content:n})),render=()=>{const e=new URL(BASE_URL),t=e.pathname,n=window.location.pathname,s=t==n;addCopyButtons(),addTitleToCodeBlocks(),addCollapsibleCallouts(),initPopover("https://googoo-s.github.io",!0);const o=document.getElementById("footer");if(o){const e=document.getElementById("graph-container");if(!e)return requestAnimationFrame(render);e.textContent="";const t=s&&!0;drawGraph("https://googoo-s.github.io",t,[{"/moc":"#4388cc"}],t?{centerForce:1,depth:-1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.5,linkDistance:1,opacityScale:3,repelForce:1,scale:1.4}:{centerForce:1,depth:1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.6,linkDistance:1,opacityScale:3,repelForce:2,scale:1.2})}var i=document.getElementsByClassName("mermaid");i.length>0&&import("https://unpkg.com/mermaid@9/dist/mermaid.esm.min.mjs").then(e=>{e.default.init()});function a(n){const e=n.target,t=e.className.split(" "),s=t.includes("broken"),o=t.includes("internal-link");plausible("Link Click",{props:{href:e.href,broken:s,internal:o,graph:!1}})}const r=document.querySelectorAll("a");for(link of r)link.className.includes("root-title")&&link.addEventListener("click",a,{once:!0})},init=(e=document)=>{addCopyButtons(),addTitleToCodeBlocks(),renderMathInElement(e.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],macros:{'’':"'"},throwOnError:!1})}</script><script type=module>
    import { attachSPARouting } from "https:\/\/googoo-s.github.io\/js\/router.d6fe6bd821db9ea97f9aeefae814d8e7.min.js"
    attachSPARouting(init, render)
  </script><script defer data-domain=googoo-s.github.io src=https://plausible.io/js/script.js></script>
<script>window.plausible=window.plausible||function(){(window.plausible.q=window.plausible.q||[]).push(arguments)}</script></head><body><div id=search-container><div id=search-space><input autocomplete=off id=search-bar name=search type=text aria-label=Search placeholder="Search for something..."><div id=results-container></div></div></div><script src=https://cdn.jsdelivr.net/npm/flexsearch@0.7.21/dist/flexsearch.bundle.js integrity="sha256-i3A0NZGkhsKjVMzFxv3ksk0DZh3aXqu0l49Bbh0MdjE=" crossorigin=anonymous defer></script>
<script defer src=https://googoo-s.github.io/js/full-text-search.e6e2e0c213187ca0c703d6e2c7a77fcd.min.js></script><div class=singlePage><header><h1 id=page-title><a class=root-title href=https://googoo-s.github.io/>googoo-s 😄😸😎</a></h1><div class=spacer></div><div id=search-icon><p>Search</p><svg tabindex="0" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search Icon</title><desc id="desc">Icon to open search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"/><circle cx="8" cy="8" r="7"/></g></svg></div><div class=darkmode><input class=toggle id=darkmode-toggle type=checkbox tabindex=-1>
<label id=toggle-label-light for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="dayIcon" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35"><title>Light Mode</title><path d="M6 17.5C6 16.672 5.328 16 4.5 16h-3C.672 16 0 16.672.0 17.5S.672 19 1.5 19h3C5.328 19 6 18.328 6 17.5zM7.5 26c-.414.0-.789.168-1.061.439l-2 2C4.168 28.711 4 29.086 4 29.5 4 30.328 4.671 31 5.5 31c.414.0.789-.168 1.06-.44l2-2C8.832 28.289 9 27.914 9 27.5 9 26.672 8.329 26 7.5 26zm10-20C18.329 6 19 5.328 19 4.5v-3C19 .672 18.329.0 17.5.0S16 .672 16 1.5v3C16 5.328 16.671 6 17.5 6zm10 3c.414.0.789-.168 1.06-.439l2-2C30.832 6.289 31 5.914 31 5.5 31 4.672 30.329 4 29.5 4c-.414.0-.789.168-1.061.44l-2 2C26.168 6.711 26 7.086 26 7.5 26 8.328 26.671 9 27.5 9zM6.439 8.561C6.711 8.832 7.086 9 7.5 9 8.328 9 9 8.328 9 7.5c0-.414-.168-.789-.439-1.061l-2-2C6.289 4.168 5.914 4 5.5 4 4.672 4 4 4.672 4 5.5c0 .414.168.789.439 1.06l2 2.001zM33.5 16h-3c-.828.0-1.5.672-1.5 1.5s.672 1.5 1.5 1.5h3c.828.0 1.5-.672 1.5-1.5S34.328 16 33.5 16zM28.561 26.439C28.289 26.168 27.914 26 27.5 26c-.828.0-1.5.672-1.5 1.5.0.414.168.789.439 1.06l2 2C28.711 30.832 29.086 31 29.5 31c.828.0 1.5-.672 1.5-1.5.0-.414-.168-.789-.439-1.061l-2-2zM17.5 29c-.829.0-1.5.672-1.5 1.5v3c0 .828.671 1.5 1.5 1.5s1.5-.672 1.5-1.5v-3C19 29.672 18.329 29 17.5 29zm0-22C11.71 7 7 11.71 7 17.5S11.71 28 17.5 28 28 23.29 28 17.5 23.29 7 17.5 7zm0 18c-4.136.0-7.5-3.364-7.5-7.5s3.364-7.5 7.5-7.5 7.5 3.364 7.5 7.5S21.636 25 17.5 25z"/></svg></label><label id=toggle-label-dark for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="nightIcon" viewBox="0 0 100 100" style="enable-background='new 0 0 100 100'"><title>Dark Mode</title><path d="M96.76 66.458c-.853-.852-2.15-1.064-3.23-.534-6.063 2.991-12.858 4.571-19.655 4.571C62.022 70.495 50.88 65.88 42.5 57.5 29.043 44.043 25.658 23.536 34.076 6.47c.532-1.08.318-2.379-.534-3.23-.851-.852-2.15-1.064-3.23-.534-4.918 2.427-9.375 5.619-13.246 9.491-9.447 9.447-14.65 22.008-14.65 35.369.0 13.36 5.203 25.921 14.65 35.368s22.008 14.65 35.368 14.65c13.361.0 25.921-5.203 35.369-14.65 3.872-3.871 7.064-8.328 9.491-13.246C97.826 68.608 97.611 67.309 96.76 66.458z"/></svg></label></div></header><article><p class=meta>Last updated
Unknown</p><ul class=tags></ul><aside class=mainTOC><details><summary>Table of Contents</summary><nav id=TableOfContents><ol><li><a href=#25-cpu-是如何执行任务的>2.5 CPU 是如何执行任务的？</a><ol><li><a href=#cpu-如何读写数据的>CPU 如何读写数据的？</a><ol><li><a href=#分析伪共享的问题>分析伪共享的问题</a></li><li><a href=#避免伪共享的方法>避免伪共享的方法</a></li></ol></li><li><a href=#cpu-如何选择线程的>CPU 如何选择线程的？</a><ol><li><a href=#调度类>调度类</a></li><li><a href=#完全公平调度>完全公平调度</a></li><li><a href=#cpu-运行队列>CPU 运行队列</a></li><li><a href=#调整优先级>调整优先级</a></li></ol></li><li><a href=#总结>总结</a></li><li><a href=#关注作者>关注作者</a></li></ol></li></ol></nav></details></aside><a href=#25-cpu-是如何执行任务的><h1 id=25-cpu-是如何执行任务的><span class=hanchor arialabel=Anchor># </span>2.5 CPU 是如何执行任务的？</h1></a><p>你清楚下面这几个问题吗？</p><ul><li>有了内存，为什么还需要 CPU Cache？</li><li>CPU 是怎么读写数据的？</li><li>如何让 CPU 能读取数据更快一些？</li><li>CPU 伪共享是如何发生的？又该如何避免？</li><li>CPU 是如何调度任务的？如果你的任务对响应要求很高，你希望它总是能被先调度，这该怎么办？</li><li>&mldr;</li></ul><p>这篇，我们就来回答这些问题。</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%e6%93%8d%e4%bd%9c%e7%b3%bb%e7%bb%9f/CPU%e4%bc%aa%e5%85%b1%e4%ba%ab/%e6%8f%90%e7%ba%b2.png width=auto alt></p><hr><a href=#cpu-如何读写数据的><h2 id=cpu-如何读写数据的><span class=hanchor arialabel=Anchor># </span>CPU 如何读写数据的？</h2></a><p>先来认识 CPU 的架构，只有理解了 CPU 的 架构，才能更好地理解 CPU 是如何读写数据的，对于现代 CPU 的架构图如下：</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%e6%93%8d%e4%bd%9c%e7%b3%bb%e7%bb%9f/CPU%e4%bc%aa%e5%85%b1%e4%ba%ab/CPU%e6%9e%b6%e6%9e%84.png width=auto alt></p><p>可以看到，一个 CPU 里通常会有多个 CPU 核心，比如上图中的 1 号和 2 号 CPU 核心，并且每个 CPU 核心都有自己的 L1 Cache 和 L2 Cache，而 L1 Cache 通常分为 dCache（数据缓存） 和 iCache（指令缓存），L3 Cache 则是多个核心共享的，这就是 CPU 典型的缓存层次。</p><p>上面提到的都是 CPU 内部的 Cache，放眼外部的话，还会有内存和硬盘，这些存储设备共同构成了金字塔存储层次。如下图所示：</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%e6%93%8d%e4%bd%9c%e7%b3%bb%e7%bb%9f/%e5%ad%98%e5%82%a8%e7%bb%93%e6%9e%84/%e5%ad%98%e5%82%a8%e5%99%a8%e7%9a%84%e5%b1%82%e6%ac%a1%e5%85%b3%e7%b3%bb%e5%9b%be.png width=auto alt></p><p>从上图也可以看到，从上往下，存储设备的容量会越大，而访问速度会越慢。至于每个存储设备的访问延时，你可以看下图的表格：</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%e6%93%8d%e4%bd%9c%e7%b3%bb%e7%bb%9f/%e5%ad%98%e5%82%a8%e7%bb%93%e6%9e%84/%e5%ad%98%e5%82%a8%e5%99%a8%e6%88%90%e6%9c%ac%e7%9a%84%e5%af%b9%e6%af%94.png width=auto alt></p><p>你可以看到， CPU 访问 L1 Cache 速度比访问内存快 100 倍，这就是为什么 CPU 里会有 L1~L3 Cache 的原因，目的就是把 Cache 作为 CPU 与内存之间的缓存层，以减少对内存的访问频率。</p><p>CPU 从内存中读取数据到 Cache 的时候，并不是一个字节一个字节读取，而是一块一块的方式来读取数据的，这一块一块的数据被称为 CPU Cache Line（缓存块），所以 <strong>CPU Cache Line 是 CPU 从内存读取数据到 Cache 的单位</strong>。</p><p>至于 CPU Cache Line 大小，在 Linux 系统可以用下面的方式查看到，你可以看我服务器的 L1 Cache Line 大小是 64 字节，也就意味着 <strong>L1 Cache 一次载入数据的大小是 64 字节</strong>。</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%e6%93%8d%e4%bd%9c%e7%b3%bb%e7%bb%9f/CPU%e7%bc%93%e5%ad%98/%e6%9f%a5%e7%9c%8bCPULine%e5%a4%a7%e5%b0%8f.png width=auto alt></p><p>那么对数组的加载， CPU 就会加载数组里面连续的多个数据到 Cache 里，因此我们应该按照物理内存地址分布的顺序去访问元素，这样访问数组元素的时候，Cache 命中率就会很高，于是就能减少从内存读取数据的频率， 从而可提高程序的性能。</p><p>但是，在我们不使用数组，而是使用单独的变量的时候，则会有 Cache 伪共享的问题，Cache 伪共享问题上是一个性能杀手，我们应该要规避它。</p><p>接下来，就来看看 Cache 伪共享是什么？又如何避免这个问题？</p><p>现在假设有一个双核心的 CPU，这两个 CPU 核心并行运行着两个不同的线程，它们同时从内存中读取两个不同的数据，分别是类型为 <code>long</code> 的变量 A 和 B，这个两个数据的地址在物理内存上是<strong>连续</strong>的，如果 Cahce Line 的大小是 64 字节，并且变量 A 在 Cahce Line 的开头位置，那么这两个数据是位于<strong>同一个 Cache Line 中</strong>，又因为 CPU Cache Line 是 CPU 从内存读取数据到 Cache 的单位，所以这两个数据会被同时读入到了两个 CPU 核心中各自 Cache 中。</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%e6%93%8d%e4%bd%9c%e7%b3%bb%e7%bb%9f/CPU%e4%bc%aa%e5%85%b1%e4%ba%ab/%e5%90%8c%e4%b8%80%e4%b8%aa%e7%bc%93%e5%ad%98%e8%a1%8c.png width=auto alt></p><p>我们来思考一个问题，如果这两个不同核心的线程分别修改不同的数据，比如 1 号 CPU 核心的线程只修改了 变量 A，或 2 号 CPU 核心的线程的线程只修改了变量 B，会发生什么呢？</p><a href=#分析伪共享的问题><h3 id=分析伪共享的问题><span class=hanchor arialabel=Anchor># </span>分析伪共享的问题</h3></a><p>现在我们结合保证多核缓存一致的 MESI 协议，来说明这一整个的过程，如果你还不知道 MESI 协议，你可以看我这篇文章「
<a href=https://mp.weixin.qq.com/s/PDUqwAIaUxNkbjvRfovaCg rel=noopener>10 张图打开 CPU 缓存一致性的大门</a>」。</p><p>①. 最开始变量 A 和 B 都还不在 Cache 里面，假设 1 号核心绑定了线程 A，2 号核心绑定了线程 B，线程 A 只会读写变量 A，线程 B 只会读写变量 B。</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%e6%93%8d%e4%bd%9c%e7%b3%bb%e7%bb%9f/CPU%e4%bc%aa%e5%85%b1%e4%ba%ab/%e5%88%86%e6%9e%90%e4%bc%aa%e5%85%b1%e4%ba%ab1.png width=auto alt></p><p>②. 1 号核心读取变量 A，由于 CPU 从内存读取数据到 Cache 的单位是 Cache Line，也正好变量 A 和 变量 B 的数据归属于同一个 Cache Line，所以 A 和 B 的数据都会被加载到 Cache，并将此 Cache Line 标记为「独占」状态。</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%e6%93%8d%e4%bd%9c%e7%b3%bb%e7%bb%9f/CPU%e4%bc%aa%e5%85%b1%e4%ba%ab/%e5%88%86%e6%9e%90%e4%bc%aa%e5%85%b1%e4%ba%ab2.png width=auto alt></p><p>③. 接着，2 号核心开始从内存里读取变量 B，同样的也是读取 Cache Line 大小的数据到 Cache 中，此 Cache Line 中的数据也包含了变量 A 和 变量 B，此时 1 号和 2 号核心的 Cache Line 状态变为「共享」状态。</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%e6%93%8d%e4%bd%9c%e7%b3%bb%e7%bb%9f/CPU%e4%bc%aa%e5%85%b1%e4%ba%ab/%e5%88%86%e6%9e%90%e4%bc%aa%e5%85%b1%e4%ba%ab3.png width=auto alt></p><p>④. 1 号核心需要修改变量 A，发现此 Cache Line 的状态是「共享」状态，所以先需要通过总线发送消息给 2 号核心，通知 2 号核心把 Cache 中对应的 Cache Line 标记为「已失效」状态，然后 1 号核心对应的 Cache Line 状态变成「已修改」状态，并且修改变量 A。</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%e6%93%8d%e4%bd%9c%e7%b3%bb%e7%bb%9f/CPU%e4%bc%aa%e5%85%b1%e4%ba%ab/%e5%88%86%e6%9e%90%e4%bc%aa%e5%85%b1%e4%ba%ab4.png width=auto alt></p><p>⑤. 之后，2 号核心需要修改变量 B，此时 2 号核心的 Cache 中对应的 Cache Line 是已失效状态，另外由于 1 号核心的 Cache 也有此相同的数据，且状态为「已修改」状态，所以要先把 1 号核心的 Cache 对应的 Cache Line 写回到内存，然后 2 号核心再从内存读取 Cache Line 大小的数据到 Cache 中，最后把变量 B 修改到 2 号核心的 Cache 中，并将状态标记为「已修改」状态。</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%e6%93%8d%e4%bd%9c%e7%b3%bb%e7%bb%9f/CPU%e4%bc%aa%e5%85%b1%e4%ba%ab/%e5%88%86%e6%9e%90%e4%bc%aa%e5%85%b1%e4%ba%ab5.png width=auto alt></p><p>所以，可以发现如果 1 号和 2 号 CPU 核心这样持续交替的分别修改变量 A 和 B，就会重复 ④ 和 ⑤ 这两个步骤，Cache 并没有起到缓存的效果，虽然变量 A 和 B 之间其实并没有任何的关系，但是因为同时归属于一个 Cache Line ，这个 Cache Line 中的任意数据被修改后，都会相互影响，从而出现 ④ 和 ⑤ 这两个步骤。</p><p>因此，这种因为多个线程同时读写同一个 Cache Line 的不同变量时，而导致 CPU Cache 失效的现象称为<strong>伪共享（<em>False Sharing</em>）</strong>。</p><a href=#避免伪共享的方法><h3 id=避免伪共享的方法><span class=hanchor arialabel=Anchor># </span>避免伪共享的方法</h3></a><p>因此，对于多个线程共享的热点数据，即经常会修改的数据，应该避免这些数据刚好在同一个 Cache Line 中，否则就会出现为伪共享的问题。</p><p>接下来，看看在实际项目中是用什么方式来避免伪共享的问题的。</p><p>在 Linux 内核中存在 <code>__cacheline_aligned_in_smp</code> 宏定义，是用于解决伪共享的问题。</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%e6%93%8d%e4%bd%9c%e7%b3%bb%e7%bb%9f/CPU%e4%bc%aa%e5%85%b1%e4%ba%ab/__cacheline_aligned.png width=auto alt></p><p>从上面的宏定义，我们可以看到：</p><ul><li>如果在多核（MP）系统里，该宏定义是 <code>__cacheline_aligned</code>，也就是 Cache Line 的大小；</li><li>而如果在单核系统里，该宏定义是空的；</li></ul><p>因此，针对在同一个 Cache Line 中的共享的数据，如果在多核之间竞争比较严重，为了防止伪共享现象的发生，可以采用上面的宏定义使得变量在 Cache Line 里是对齐的。</p><p>举个例子，有下面这个结构体：</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%e6%93%8d%e4%bd%9c%e7%b3%bb%e7%bb%9f/CPU%e4%bc%aa%e5%85%b1%e4%ba%ab/struct_test.png width=auto alt></p><p>结构体里的两个成员变量 a 和 b 在物理内存地址上是连续的，于是它们可能会位于同一个 Cache Line 中，如下图：</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%e6%93%8d%e4%bd%9c%e7%b3%bb%e7%bb%9f/CPU%e4%bc%aa%e5%85%b1%e4%ba%ab/struct_ab.png width=auto alt></p><p>所以，为了防止前面提到的 Cache 伪共享问题，我们可以使用上面介绍的宏定义，将 b 的地址设置为 Cache Line 对齐地址，如下：</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%e6%93%8d%e4%bd%9c%e7%b3%bb%e7%bb%9f/CPU%e4%bc%aa%e5%85%b1%e4%ba%ab/struct_test1.png width=auto alt></p><p>这样 a 和 b 变量就不会在同一个 Cache Line 中了，如下图：</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%e6%93%8d%e4%bd%9c%e7%b3%bb%e7%bb%9f/CPU%e4%bc%aa%e5%85%b1%e4%ba%ab/struct_ab1.png width=auto alt></p><p>所以，避免 Cache 伪共享实际上是用空间换时间的思想，浪费一部分 Cache 空间，从而换来性能的提升。</p><p>我们再来看一个应用层面的规避方案，有一个 Java 并发框架 Disruptor 使用「字节填充 + 继承」的方式，来避免伪共享的问题。</p><p>Disruptor 中有一个 RingBuffer 类会经常被多个线程使用，代码如下：</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%e6%93%8d%e4%bd%9c%e7%b3%bb%e7%bb%9f/CPU%e4%bc%aa%e5%85%b1%e4%ba%ab/Disruptor.png width=auto alt></p><p>你可能会觉得 RingBufferPad 类里 7 个 long 类型的名字很奇怪，但事实上，它们虽然看起来毫无作用，但却对性能的提升起到了至关重要的作用。</p><p>我们都知道，CPU Cache 从内存读取数据的单位是 CPU Cache Line，一般 64 位 CPU 的 CPU Cache Line 的大小是 64 个字节，一个 long 类型的数据是 8 个字节，所以 CPU 一下会加载 8 个 long 类型的数据。</p><p>根据 JVM 对象继承关系中父类成员和子类成员，内存地址是连续排列布局的，因此 RingBufferPad 中的 7 个 long 类型数据作为 Cache Line <strong>前置填充</strong>，而 RingBuffer 中的 7 个 long 类型数据则作为 Cache Line <strong>后置填充</strong>，这 14 个 long 变量没有任何实际用途，更不会对它们进行读写操作。</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%e6%93%8d%e4%bd%9c%e7%b3%bb%e7%bb%9f/CPU%e4%bc%aa%e5%85%b1%e4%ba%ab/%e5%a1%ab%e5%85%85%e5%ad%97%e8%8a%82.png width=auto alt></p><p>另外，RingBufferFelds 里面定义的这些变量都是 <code>final</code> 修饰的，意味着第一次加载之后不会再修改， 又<strong>由于「前后」各填充了 7 个不会被读写的 long 类型变量，所以无论怎么加载 Cache Line，这整个 Cache Line 里都没有会发生更新操作的数据，于是只要数据被频繁地读取访问，就自然没有数据被换出 Cache 的可能，也因此不会产生伪共享的问题</strong>。</p><hr><a href=#cpu-如何选择线程的><h2 id=cpu-如何选择线程的><span class=hanchor arialabel=Anchor># </span>CPU 如何选择线程的？</h2></a><p>了解完 CPU 读取数据的过程后，我们再来看看 CPU 是根据什么来选择当前要执行的线程。</p><p>在 Linux 内核中，进程和线程都是用 <code>task_struct</code> 结构体表示的，区别在于线程的 task_struct 结构体里部分资源是共享了进程已创建的资源，比如内存地址空间、代码段、文件描述符等，所以 Linux 中的线程也被称为轻量级进程，因为线程的 task_struct 相比进程的 task_struct 承载的 资源比较少，因此以「轻」得名。</p><p>一般来说，没有创建线程的进程，是只有单个执行流，它被称为是主线程。如果想让进程处理更多的事情，可以创建多个线程分别去处理，但不管怎么样，它们对应到内核里都是 <code>task_struct</code>。</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%e6%93%8d%e4%bd%9c%e7%b3%bb%e7%bb%9f/CPU%e4%bc%aa%e5%85%b1%e4%ba%ab/%e4%bb%bb%e5%8a%a1.png width=auto alt></p><p>所以，Linux 内核里的调度器，调度的对象就是 <code>task_struct</code>，接下来我们就把这个数据结构统称为<strong>任务</strong>。</p><p>在 Linux 系统中，根据任务的优先级以及响应要求，主要分为两种，其中优先级的数值越小，优先级越高：</p><ul><li>实时任务，对系统的响应时间要求很高，也就是要尽可能快的执行实时任务，优先级在 <code>0~99</code> 范围内的就算实时任务；</li><li>普通任务，响应时间没有很高的要求，优先级在 <code>100~139</code> 范围内都是普通任务级别；</li></ul><a href=#调度类><h3 id=调度类><span class=hanchor arialabel=Anchor># </span>调度类</h3></a><p>由于任务有优先级之分，Linux 系统为了保障高优先级的任务能够尽可能早的被执行，于是分为了这几种调度类，如下图：</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%e6%93%8d%e4%bd%9c%e7%b3%bb%e7%bb%9f/CPU%e4%bc%aa%e5%85%b1%e4%ba%ab/%e8%b0%83%e5%ba%a6%e7%b1%bb.png width=auto alt></p><p>Deadline 和 Realtime 这两个调度类，都是应用于实时任务的，这两个调度类的调度策略合起来共有这三种，它们的作用如下：</p><ul><li><em>SCHED_DEADLINE</em>：是按照 deadline 进行调度的，距离当前时间点最近的 deadline 的任务会被优先调度；</li><li><em>SCHED_FIFO</em>：对于相同优先级的任务，按先来先服务的原则，但是优先级更高的任务，可以抢占低优先级的任务，也就是优先级高的可以「插队」；</li><li><em>SCHED_RR</em>：对于相同优先级的任务，轮流着运行，每个任务都有一定的时间片，当用完时间片的任务会被放到队列尾部，以保证相同优先级任务的公平性，但是高优先级的任务依然可以抢占低优先级的任务；</li></ul><p>而 Fair 调度类是应用于普通任务，都是由 CFS 调度器管理的，分为两种调度策略：</p><ul><li><em>SCHED_NORMAL</em>：普通任务使用的调度策略；</li><li><em>SCHED_BATCH</em>：后台任务的调度策略，不和终端进行交互，因此在不影响其他需要交互的任务，可以适当降低它的优先级。</li></ul><a href=#完全公平调度><h3 id=完全公平调度><span class=hanchor arialabel=Anchor># </span>完全公平调度</h3></a><p>我们平日里遇到的基本都是普通任务，对于普通任务来说，公平性最重要，在 Linux 里面，实现了一个基于 CFS 的调度算法，也就是<strong>完全公平调度（<em>Completely Fair Scheduling</em>）</strong>。</p><p>这个算法的理念是想让分配给每个任务的 CPU 时间是一样，于是它为每个任务安排一个虚拟运行时间 vruntime，如果一个任务在运行，其运行的越久，该任务的 vruntime 自然就会越大，而没有被运行的任务，vruntime 是不会变化的。</p><p>那么，<strong>在 CFS 算法调度的时候，会优先选择 vruntime 少的任务</strong>，以保证每个任务的公平性。</p><p>这就好比，让你把一桶的奶茶平均分到 10 杯奶茶杯里，你看着哪杯奶茶少，就多倒一些；哪个多了，就先不倒，这样经过多轮操作，虽然不能保证每杯奶茶完全一样多，但至少是公平的。</p><p>当然，上面提到的例子没有考虑到优先级的问题，虽然是普通任务，但是普通任务之间还是有优先级区分的，所以在计算虚拟运行时间 vruntime 还要考虑普通任务的<strong>权重值</strong>，注意权重值并不是优先级的值，内核中会有一个 nice 级别与权重值的转换表，nice 级别越低的权重值就越大，至于 nice 值是什么，我们后面会提到。
于是就有了以下这个公式：</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%e6%93%8d%e4%bd%9c%e7%b3%bb%e7%bb%9f/CPU%e4%bc%aa%e5%85%b1%e4%ba%ab/vruntime.png width=auto alt></p><p>你可以不用管 NICE_0_LOAD 是什么，你就认为它是一个常量，那么在「同样的实际运行时间」里，高权重任务的 vruntime 比低权重任务的 vruntime <strong>少</strong>，你可能会奇怪为什么是少的？你还记得 CFS 调度吗，它是会优先选择 vruntime 少的任务进行调度，所以高权重的任务就会被优先调度了，于是高权重的获得的实际运行时间自然就多了。</p><a href=#cpu-运行队列><h3 id=cpu-运行队列><span class=hanchor arialabel=Anchor># </span>CPU 运行队列</h3></a><p>一个系统通常都会运行着很多任务，多任务的数量基本都是远超 CPU 核心数量，因此这时候就需要<strong>排队</strong>。</p><p>事实上，每个 CPU 都有自己的<strong>运行队列（<em>Run Queue, rq</em>）</strong>，用于描述在此 CPU 上所运行的所有进程，其队列包含三个运行队列，Deadline 运行队列 dl_rq、实时任务运行队列 rt_rq 和 CFS 运行队列 cfs_rq，其中 cfs_rq 是用红黑树来描述的，按 vruntime 大小来排序的，最左侧的叶子节点，就是下次会被调度的任务。</p><p>PS：下图中的 csf_rq 应该是 <code>cfs_rq</code>，由于找不到原图了，我偷个懒，我就不重新画了，嘻嘻。</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%e6%93%8d%e4%bd%9c%e7%b3%bb%e7%bb%9f/CPU%e4%bc%aa%e5%85%b1%e4%ba%ab/CPU%e9%98%9f%e5%88%97.png width=auto alt></p><p>这几种调度类是有优先级的，优先级如下：Deadline > Realtime > Fair，这意味着 Linux 选择下一个任务执行的时候，会按照此优先级顺序进行选择，也就是说先从 <code>dl_rq</code> 里选择任务，然后从 <code>rt_rq</code> 里选择任务，最后从 <code>cfs_rq</code> 里选择任务。因此，<strong>实时任务总是会比普通任务优先被执行</strong>。</p><a href=#调整优先级><h3 id=调整优先级><span class=hanchor arialabel=Anchor># </span>调整优先级</h3></a><p>如果我们启动任务的时候，没有特意去指定优先级的话，默认情况下都是普通任务，普通任务的调度类是 Fair，由 CFS 调度器来进行管理。CFS 调度器的目的是实现任务运行的公平性，也就是保障每个任务的运行的时间是差不多的。</p><p>如果你想让某个普通任务有更多的执行时间，可以调整任务的 <code>nice</code> 值，从而让优先级高一些的任务执行更多时间。nice 的值能设置的范围是 <code>-20～19</code>， 值越低，表明优先级越高，因此 -20 是最高优先级，19 则是最低优先级，默认优先级是 0。</p><p>是不是觉得 nice 值的范围很诡异？事实上，nice 值并不是表示优先级，而是表示优先级的修正数值，它与优先级（priority）的关系是这样的：priority(new) = priority(old) + nice。内核中，priority 的范围是 0~139，值越低，优先级越高，其中前面的 0~99 范围是提供给实时任务使用的，而 nice 值是映射到 100~139，这个范围是提供给普通任务用的，因此 nice 值调整的是普通任务的优先级。</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%e6%93%8d%e4%bd%9c%e7%b3%bb%e7%bb%9f/CPU%e4%bc%aa%e5%85%b1%e4%ba%ab/%e4%bc%98%e5%85%88%e7%ba%a7.png width=auto alt></p><p>在前面我们提到了，权重值与 nice 值是有关系的，nice 值越低，权重值就越大，计算出来的 vruntime 就会越少，由于 CFS 算法调度的时候，就会优先选择 vruntime 少的任务进行执行，所以 nice 值越低，任务的优先级就越高。</p><p>我们可以在启动任务的时候，可以指定 nice 的值，比如将 mysqld 以 -3 优先级：</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%e6%93%8d%e4%bd%9c%e7%b3%bb%e7%bb%9f/CPU%e4%bc%aa%e5%85%b1%e4%ba%ab/nice.png width=auto alt></p><p>如果想修改已经运行中的任务的优先级，则可以使用 <code>renice</code> 来调整 nice 值：</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%e6%93%8d%e4%bd%9c%e7%b3%bb%e7%bb%9f/CPU%e4%bc%aa%e5%85%b1%e4%ba%ab/renice.png width=auto alt></p><p>nice 调整的是普通任务的优先级，所以不管怎么缩小 nice 值，任务永远都是普通任务，如果某些任务要求实时性比较高，那么你可以考虑改变任务的优先级以及调度策略，使得它变成实时任务，比如：</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%e6%93%8d%e4%bd%9c%e7%b3%bb%e7%bb%9f/CPU%e4%bc%aa%e5%85%b1%e4%ba%ab/chrt.png width=auto alt></p><hr><a href=#总结><h2 id=总结><span class=hanchor arialabel=Anchor># </span>总结</h2></a><p>理解 CPU 是如何读写数据的前提，是要理解 CPU 的架构，CPU 内部的多个 Cache + 外部的内存和磁盘都就构成了金字塔的存储器结构，在这个金字塔中，越往下，存储器的容量就越大，但访问速度就会小。</p><p>CPU 读写数据的时候，并不是按一个一个字节为单位来进行读写，而是以 CPU Cache Line 大小为单位，CPU Cache Line 大小一般是 64 个字节，也就意味着 CPU 读写数据的时候，每一次都是以 64 字节大小为一块进行操作。</p><p>因此，如果我们操作的数据是数组，那么访问数组元素的时候，按内存分布的地址顺序进行访问，这样能充分利用到 Cache，程序的性能得到提升。但如果操作的数据不是数组，而是普通的变量，并在多核 CPU 的情况下，我们还需要避免 Cache Line 伪共享的问题。</p><p>所谓的 Cache Line 伪共享问题就是，多个线程同时读写同一个 Cache Line 的不同变量时，而导致 CPU Cache 失效的现象。那么对于多个线程共享的热点数据，即经常会修改的数据，应该避免这些数据刚好在同一个 Cache Line 中，避免的方式一般有 Cache Line 大小字节对齐，以及字节填充等方法。</p><p>系统中需要运行的多线程数一般都会大于 CPU 核心，这样就会导致线程排队等待 CPU，这可能会产生一定的延时，如果我们的任务对延时容忍度很低，则可以通过一些人为手段干预 Linux 的默认调度策略和优先级。</p><hr><a href=#关注作者><h2 id=关注作者><span class=hanchor arialabel=Anchor># </span>关注作者</h2></a><p><em><strong>哈喽，我是小林，就爱图解计算机基础，如果觉得文章对你有帮助，欢迎微信搜索「小林coding」，关注后，回复「网络」再送你图解网络 PDF</strong></em></p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%e5%85%b6%e4%bb%96/%e5%85%ac%e4%bc%97%e5%8f%b7%e4%bb%8b%e7%bb%8d.png width=auto alt></p></article><hr><div class=page-end id=footer><div class=backlinks-container><h3>Backlinks</h3><ul class=backlinks><li><a href=/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/README/ data-ctx="CPU 是如何执行任务的？" data-src=/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/README class=internal-link>README</a></li></ul></div><div><script src=https://cdn.jsdelivr.net/npm/d3@6.7.0/dist/d3.min.js integrity="sha256-+7jaYCp29O1JusNWHaYtgUn6EhuP0VaFuswhNV06MyI=" crossorigin=anonymous></script><h3>Interactive Graph</h3><div id=graph-container></div><style>:root{--g-node:var(--secondary);--g-node-active:var(--primary);--g-node-inactive:var(--visited);--g-link:var(--outlinegray);--g-link-active:#5a7282}</style><script src=https://googoo-s.github.io/js/graph.6579af7b10c818dbd2ca038702db0224.js></script></div></div><div id=contact_buttons><footer><p>Made by googoo-s using <a href=https://github.com/jackyzha0/quartz>Quartz</a>, © 2023</p><ul><li><a href=https://googoo-s.github.io/>Home</a></li><li><a href=https://github.com/googoo-s>GitHub</a></li></ul></footer></div></div></body></html>