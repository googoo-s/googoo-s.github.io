<!doctype html><html lang=en><head><meta charset=utf-8><meta name=description content="Kafka 是什么？主要应用场景有哪些？ Kafka 是一个分布式流式处理平台。这到底是什么意思呢？
流平台具有三个关键功能：
 消息队列：发布和订阅消息流，这个功能类似于消息队列，这也是 Kafka 也被归类为消息队列的原因。 容错的持久方式存储记录消息流：Kafka 会把消息持久化到磁盘，有效避免了消息丢失的风险。 流式处理平台： 在消息发布的时候进行处理，Kafka 提供了一个完整的流式处理类库。  Kafka 主要有两大应用场景：
 消息队列：建立实时流数据管道，以可靠地在系统或应用程序之间获取数据。 数据处理： 构建实时的流数据处理程序来转换或处理数据流。  # 和其他消息队列相比,Kafka 的优势在哪里？ 我们现在经常提到 Kafka 的时候就已经默认它是一个非常优秀的消息队列了，我们也会经常拿它跟 RocketMQ、RabbitMQ 对比。我觉得 Kafka 相比其他消息队列主要的优势如下："><meta property="og:title" content><meta property="og:description" content="Kafka 是什么？主要应用场景有哪些？ Kafka 是一个分布式流式处理平台。这到底是什么意思呢？
流平台具有三个关键功能：
 消息队列：发布和订阅消息流，这个功能类似于消息队列，这也是 Kafka 也被归类为消息队列的原因。 容错的持久方式存储记录消息流：Kafka 会把消息持久化到磁盘，有效避免了消息丢失的风险。 流式处理平台： 在消息发布的时候进行处理，Kafka 提供了一个完整的流式处理类库。  Kafka 主要有两大应用场景：
 消息队列：建立实时流数据管道，以可靠地在系统或应用程序之间获取数据。 数据处理： 构建实时的流数据处理程序来转换或处理数据流。  # 和其他消息队列相比,Kafka 的优势在哪里？ 我们现在经常提到 Kafka 的时候就已经默认它是一个非常优秀的消息队列了，我们也会经常拿它跟 RocketMQ、RabbitMQ 对比。我觉得 Kafka 相比其他消息队列主要的优势如下："><meta property="og:type" content="website"><meta property="og:image" content="https://googoo-s.github.io/icon.png"><meta property="og:url" content="https://googoo-s.github.io/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Kafka/Untitled/"><meta property="og:width" content="200"><meta property="og:height" content="200"><meta name=twitter:card content="summary"><meta name=twitter:title content><meta name=twitter:description content="Kafka 是什么？主要应用场景有哪些？ Kafka 是一个分布式流式处理平台。这到底是什么意思呢？
流平台具有三个关键功能：
 消息队列：发布和订阅消息流，这个功能类似于消息队列，这也是 Kafka 也被归类为消息队列的原因。 容错的持久方式存储记录消息流：Kafka 会把消息持久化到磁盘，有效避免了消息丢失的风险。 流式处理平台： 在消息发布的时候进行处理，Kafka 提供了一个完整的流式处理类库。  Kafka 主要有两大应用场景：
 消息队列：建立实时流数据管道，以可靠地在系统或应用程序之间获取数据。 数据处理： 构建实时的流数据处理程序来转换或处理数据流。  # 和其他消息队列相比,Kafka 的优势在哪里？ 我们现在经常提到 Kafka 的时候就已经默认它是一个非常优秀的消息队列了，我们也会经常拿它跟 RocketMQ、RabbitMQ 对比。我觉得 Kafka 相比其他消息队列主要的优势如下："><meta name=twitter:image content="https://googoo-s.github.io/icon.png"><title>googoo-s 😄😸😎</title><meta name=viewport content="width=device-width,initial-scale=1"><link rel="shortcut icon" type=image/png href=https://googoo-s.github.io//icon.png><link href=https://googoo-s.github.io/styles.19109a40042e9f0e72e952fda4442a34.min.css rel=stylesheet><link href=https://googoo-s.github.io/styles/_light_syntax.86a48a52faebeaaf42158b72922b1c90.min.css rel=stylesheet id=theme-link><script src=https://googoo-s.github.io/js/darkmode.953af745b0f9342644d632fc167f3727.min.js></script>
<script src=https://googoo-s.github.io/js/util.00639692264b21bc3ee219733d38a8be.min.js></script>
<link rel=preload href=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css as=style onload='this.onload=null,this.rel="stylesheet"' integrity=sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js integrity=sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/contrib/copy-tex.min.js integrity=sha384-ww/583aHhxWkz5DEVn6OKtNiIaLi2iBRNZXfJRiY1Ai7tnJ9UXpEsyvOITVpTl4A crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/@floating-ui/core@1.2.1></script>
<script src=https://cdn.jsdelivr.net/npm/@floating-ui/dom@1.2.1></script>
<script defer src=https://googoo-s.github.io/js/popover.aa9bc99c7c38d3ae9538f218f1416adb.min.js></script>
<script defer src=https://googoo-s.github.io/js/code-title.ce4a43f09239a9efb48fee342e8ef2df.min.js></script>
<script defer src=https://googoo-s.github.io/js/clipboard.2913da76d3cb21c5deaa4bae7da38c9f.min.js></script>
<script defer src=https://googoo-s.github.io/js/callouts.7723cac461d613d118ee8bb8216b9838.min.js></script>
<script>const SEARCH_ENABLED=!1,LATEX_ENABLED=!0,PRODUCTION=!0,BASE_URL="https://googoo-s.github.io/",fetchData=Promise.all([fetch("https://googoo-s.github.io/indices/linkIndex.42375ba996c43a74314996d90dacfb87.min.json").then(e=>e.json()).then(e=>({index:e.index,links:e.links})),fetch("https://googoo-s.github.io/indices/contentIndex.695fa792ad6814ee68ebc05dd3134b93.min.json").then(e=>e.json())]).then(([{index:e,links:t},n])=>({index:e,links:t,content:n})),render=()=>{const e=new URL(BASE_URL),t=e.pathname,n=window.location.pathname,s=t==n;addCopyButtons(),addTitleToCodeBlocks(),addCollapsibleCallouts(),initPopover("https://googoo-s.github.io",!0);const o=document.getElementById("footer");if(o){const e=document.getElementById("graph-container");if(!e)return requestAnimationFrame(render);e.textContent="";const t=s&&!0;drawGraph("https://googoo-s.github.io",t,[{"/moc":"#4388cc"}],t?{centerForce:1,depth:-1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.5,linkDistance:1,opacityScale:3,repelForce:1,scale:1.4}:{centerForce:1,depth:1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.6,linkDistance:1,opacityScale:3,repelForce:2,scale:1.2})}var i=document.getElementsByClassName("mermaid");i.length>0&&import("https://unpkg.com/mermaid@9/dist/mermaid.esm.min.mjs").then(e=>{e.default.init()});function a(n){const e=n.target,t=e.className.split(" "),s=t.includes("broken"),o=t.includes("internal-link");plausible("Link Click",{props:{href:e.href,broken:s,internal:o,graph:!1}})}const r=document.querySelectorAll("a");for(link of r)link.className.includes("root-title")&&link.addEventListener("click",a,{once:!0})},init=(e=document)=>{addCopyButtons(),addTitleToCodeBlocks(),renderMathInElement(e.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],macros:{'’':"'"},throwOnError:!1})}</script><script type=module>
    import { attachSPARouting } from "https:\/\/googoo-s.github.io\/js\/router.d6fe6bd821db9ea97f9aeefae814d8e7.min.js"
    attachSPARouting(init, render)
  </script><script defer data-domain=googoo-s.github.io src=https://plausible.io/js/script.js></script>
<script>window.plausible=window.plausible||function(){(window.plausible.q=window.plausible.q||[]).push(arguments)}</script></head><body><div id=search-container><div id=search-space><input autocomplete=off id=search-bar name=search type=text aria-label=Search placeholder="Search for something..."><div id=results-container></div></div></div><script src=https://cdn.jsdelivr.net/npm/flexsearch@0.7.21/dist/flexsearch.bundle.js integrity="sha256-i3A0NZGkhsKjVMzFxv3ksk0DZh3aXqu0l49Bbh0MdjE=" crossorigin=anonymous defer></script>
<script defer src=https://googoo-s.github.io/js/full-text-search.e6e2e0c213187ca0c703d6e2c7a77fcd.min.js></script><div class=singlePage><header><h1 id=page-title><a class=root-title href=https://googoo-s.github.io/>googoo-s 😄😸😎</a></h1><div class=spacer></div><div id=search-icon><p>Search</p><svg tabindex="0" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search Icon</title><desc id="desc">Icon to open search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"/><circle cx="8" cy="8" r="7"/></g></svg></div><div class=darkmode><input class=toggle id=darkmode-toggle type=checkbox tabindex=-1>
<label id=toggle-label-light for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="dayIcon" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35"><title>Light Mode</title><path d="M6 17.5C6 16.672 5.328 16 4.5 16h-3C.672 16 0 16.672.0 17.5S.672 19 1.5 19h3C5.328 19 6 18.328 6 17.5zM7.5 26c-.414.0-.789.168-1.061.439l-2 2C4.168 28.711 4 29.086 4 29.5 4 30.328 4.671 31 5.5 31c.414.0.789-.168 1.06-.44l2-2C8.832 28.289 9 27.914 9 27.5 9 26.672 8.329 26 7.5 26zm10-20C18.329 6 19 5.328 19 4.5v-3C19 .672 18.329.0 17.5.0S16 .672 16 1.5v3C16 5.328 16.671 6 17.5 6zm10 3c.414.0.789-.168 1.06-.439l2-2C30.832 6.289 31 5.914 31 5.5 31 4.672 30.329 4 29.5 4c-.414.0-.789.168-1.061.44l-2 2C26.168 6.711 26 7.086 26 7.5 26 8.328 26.671 9 27.5 9zM6.439 8.561C6.711 8.832 7.086 9 7.5 9 8.328 9 9 8.328 9 7.5c0-.414-.168-.789-.439-1.061l-2-2C6.289 4.168 5.914 4 5.5 4 4.672 4 4 4.672 4 5.5c0 .414.168.789.439 1.06l2 2.001zM33.5 16h-3c-.828.0-1.5.672-1.5 1.5s.672 1.5 1.5 1.5h3c.828.0 1.5-.672 1.5-1.5S34.328 16 33.5 16zM28.561 26.439C28.289 26.168 27.914 26 27.5 26c-.828.0-1.5.672-1.5 1.5.0.414.168.789.439 1.06l2 2C28.711 30.832 29.086 31 29.5 31c.828.0 1.5-.672 1.5-1.5.0-.414-.168-.789-.439-1.061l-2-2zM17.5 29c-.829.0-1.5.672-1.5 1.5v3c0 .828.671 1.5 1.5 1.5s1.5-.672 1.5-1.5v-3C19 29.672 18.329 29 17.5 29zm0-22C11.71 7 7 11.71 7 17.5S11.71 28 17.5 28 28 23.29 28 17.5 23.29 7 17.5 7zm0 18c-4.136.0-7.5-3.364-7.5-7.5s3.364-7.5 7.5-7.5 7.5 3.364 7.5 7.5S21.636 25 17.5 25z"/></svg></label><label id=toggle-label-dark for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="nightIcon" viewBox="0 0 100 100" style="enable-background='new 0 0 100 100'"><title>Dark Mode</title><path d="M96.76 66.458c-.853-.852-2.15-1.064-3.23-.534-6.063 2.991-12.858 4.571-19.655 4.571C62.022 70.495 50.88 65.88 42.5 57.5 29.043 44.043 25.658 23.536 34.076 6.47c.532-1.08.318-2.379-.534-3.23-.851-.852-2.15-1.064-3.23-.534-4.918 2.427-9.375 5.619-13.246 9.491-9.447 9.447-14.65 22.008-14.65 35.369.0 13.36 5.203 25.921 14.65 35.368s22.008 14.65 35.368 14.65c13.361.0 25.921-5.203 35.369-14.65 3.872-3.871 7.064-8.328 9.491-13.246C97.826 68.608 97.611 67.309 96.76 66.458z"/></svg></label></div></header><article><p class=meta>Last updated
Unknown</p><ul class=tags></ul><aside class=mainTOC><details><summary>Table of Contents</summary><nav id=TableOfContents><ol><li><ol><li><ol><li><a href=#kafka-是什么主要应用场景有哪些>Kafka 是什么？主要应用场景有哪些？</a></li><li><a href=#和其他消息队列相比-kafka-的优势在哪里-和其他消息队列相比kafka-的优势在哪里><a href=#%E5%92%8C%E5%85%B6%E4%BB%96%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E7%9B%B8%E6%AF%94-kafka-%E7%9A%84%E4%BC%98%E5%8A%BF%E5%9C%A8%E5%93%AA%E9%87%8C>#</a> 和其他消息队列相比,Kafka 的优势在哪里？</a></li><li><a href=#队列模型了解吗-kafka-的消息模型知道吗-队列模型了解吗kafka-的消息模型知道吗><a href=#%E9%98%9F%E5%88%97%E6%A8%A1%E5%9E%8B%E4%BA%86%E8%A7%A3%E5%90%97-kafka-%E7%9A%84%E6%B6%88%E6%81%AF%E6%A8%A1%E5%9E%8B%E7%9F%A5%E9%81%93%E5%90%97>#</a> 队列模型了解吗？Kafka 的消息模型知道吗？</a></li><li><a href=#什么是-producerconsumerbrokertopicpartition-什么是-producerconsumerbrokertopicpartition><a href=#%E4%BB%80%E4%B9%88%E6%98%AF-producer%E3%80%81consumer%E3%80%81broker%E3%80%81topic%E3%80%81partition>#</a> 什么是 Producer、Consumer、Broker、Topic、Partition？</a></li><li><a href=#kafka-的多副本机制了解吗-带来了什么好处-kafka-的多副本机制了解吗带来了什么好处><a href=#kafka-%E7%9A%84%E5%A4%9A%E5%89%AF%E6%9C%AC%E6%9C%BA%E5%88%B6%E4%BA%86%E8%A7%A3%E5%90%97-%E5%B8%A6%E6%9D%A5%E4%BA%86%E4%BB%80%E4%B9%88%E5%A5%BD%E5%A4%84>#</a> Kafka 的多副本机制了解吗？带来了什么好处？</a></li><li><a href=#zookeeper-在-kafka-中的作用知道吗-zookeeper-在-kafka-中的作用知道吗><a href=#zookeeper-%E5%9C%A8-kafka-%E4%B8%AD%E7%9A%84%E4%BD%9C%E7%94%A8%E7%9F%A5%E9%81%93%E5%90%97>#</a> Zookeeper 在 Kafka 中的作用知道吗？</a></li><li><a href=#kafka-如何保证消息的消费顺序-kafka-如何保证消息的消费顺序><a href=#kafka-%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E6%B6%88%E6%81%AF%E7%9A%84%E6%B6%88%E8%B4%B9%E9%A1%BA%E5%BA%8F>#</a> Kafka 如何保证消息的消费顺序？</a></li><li><a href=#kafka-如何保证消息不丢失-kafka-如何保证消息不丢失><a href=#kafka-%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E6%B6%88%E6%81%AF%E4%B8%8D%E4%B8%A2%E5%A4%B1>#</a> Kafka 如何保证消息不丢失</a></li><li><a href=#kafka-如何保证消息不重复消费-kafka-如何保证消息不重复消费><a href=#kafka-%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E6%B6%88%E6%81%AF%E4%B8%8D%E9%87%8D%E5%A4%8D%E6%B6%88%E8%B4%B9>#</a> Kafka 如何保证消息不重复消费</a></li><li><a href=#reference-reference><a href=#reference>#</a> Reference</a></li></ol></li></ol></li></ol></nav></details></aside><a href=#kafka-是什么主要应用场景有哪些><h3 id=kafka-是什么主要应用场景有哪些><span class=hanchor arialabel=Anchor># </span>Kafka 是什么？主要应用场景有哪些？</h3></a><p>Kafka 是一个分布式流式处理平台。这到底是什么意思呢？</p><p>流平台具有三个关键功能：</p><ol><li><strong>消息队列</strong>：发布和订阅消息流，这个功能类似于消息队列，这也是 Kafka 也被归类为消息队列的原因。</li><li><strong>容错的持久方式存储记录消息流</strong>：Kafka 会把消息持久化到磁盘，有效避免了消息丢失的风险。</li><li><strong>流式处理平台：</strong> 在消息发布的时候进行处理，Kafka 提供了一个完整的流式处理类库。</li></ol><p>Kafka 主要有两大应用场景：</p><ol><li><strong>消息队列</strong>：建立实时流数据管道，以可靠地在系统或应用程序之间获取数据。</li><li><strong>数据处理：</strong> 构建实时的流数据处理程序来转换或处理数据流。</li></ol><h3 id=和其他消息队列相比-kafka-的优势在哪里-和其他消息队列相比kafka-的优势在哪里><a rel=noopener class="internal-link broken" data-src=#%e5%92%8c%e5%85%b6%e4%bb%96%e6%b6%88%e6%81%af%e9%98%9f%e5%88%97%e7%9b%b8%e6%af%94-kafka-%e7%9a%84%e4%bc%98%e5%8a%bf%e5%9c%a8%e5%93%aa%e9%87%8c>#</a> 和其他消息队列相比,Kafka 的优势在哪里？</h3><p>我们现在经常提到 Kafka 的时候就已经默认它是一个非常优秀的消息队列了，我们也会经常拿它跟 RocketMQ、RabbitMQ 对比。我觉得 Kafka 相比其他消息队列主要的优势如下：</p><ol><li><strong>极致的性能</strong>：基于 Scala 和 Java 语言开发，设计中大量使用了批量处理和异步的思想，最高可以每秒处理千万级别的消息。</li><li><strong>生态系统兼容性无可匹敌</strong>：Kafka 与周边生态系统的兼容性是最好的没有之一，尤其在大数据和流计算领域。</li></ol><p>实际上在早期的时候 Kafka 并不是一个合格的消息队列，早期的 Kafka 在消息队列领域就像是一个衣衫褴褛的孩子一样，功能不完备并且有一些小问题比如丢失消息、不保证消息可靠性等等。当然，这也和 LinkedIn 最早开发 Kafka 用于处理海量的日志有很大关系，哈哈哈，人家本来最开始就不是为了作为消息队列滴，谁知道后面误打误撞在消息队列领域占据了一席之地。</p><p>随着后续的发展，这些短板都被 Kafka 逐步修复完善。所以，<strong>Kafka 作为消息队列不可靠这个说法已经过时！</strong></p><h3 id=队列模型了解吗-kafka-的消息模型知道吗-队列模型了解吗kafka-的消息模型知道吗><a rel=noopener class="internal-link broken" data-src=#%e9%98%9f%e5%88%97%e6%a8%a1%e5%9e%8b%e4%ba%86%e8%a7%a3%e5%90%97-kafka-%e7%9a%84%e6%b6%88%e6%81%af%e6%a8%a1%e5%9e%8b%e7%9f%a5%e9%81%93%e5%90%97>#</a> 队列模型了解吗？Kafka 的消息模型知道吗？</h3><blockquote><p>题外话：早期的 JMS 和 AMQP 属于消息服务领域权威组织所做的相关的标准，我在
<a href=https://github.com/Snailclimb/JavaGuide rel=noopener>JavaGuideopen in new window</a>的
<a href=https://github.com/Snailclimb/JavaGuide#%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1%E4%B8%AD%E9%97%B4%E4%BB%B6 rel=noopener>《消息队列其实很简单》open in new window</a>这篇文章中介绍过。但是，这些标准的进化跟不上消息队列的演进速度，这些标准实际上已经属于废弃状态。所以，可能存在的情况是：不同的消息队列都有自己的一套消息模型。</p></blockquote><h4 id=队列模型-早期的消息模型-队列模型早期的消息模型><a rel=noopener class="internal-link broken" data-src=#%e9%98%9f%e5%88%97%e6%a8%a1%e5%9e%8b-%e6%97%a9%e6%9c%9f%e7%9a%84%e6%b6%88%e6%81%af%e6%a8%a1%e5%9e%8b>#</a> 队列模型：早期的消息模型</h4><p><img src=https://googoo-s.github.io//statistic/%E9%98%9F%E5%88%97%E6%A8%A1%E5%9E%8B.png width=auto alt=队列模型></p><p>队列模型</p><p><strong>使用队列（Queue）作为消息通信载体，满足生产者与消费者模式，一条消息只能被一个消费者使用，未被消费的消息在队列中保留直到被消费或超时。</strong> 比如：我们生产者发送 100 条消息的话，两个消费者来消费一般情况下两个消费者会按照消息发送的顺序各自消费一半（也就是你一个我一个的消费。）</p><p><strong>队列模型存在的问题：</strong></p><p>假如我们存在这样一种情况：我们需要将生产者产生的消息分发给多个消费者，并且每个消费者都能接收到完整的消息内容。</p><p>这种情况，队列模型就不好解决了。很多比较杠精的人就说：我们可以为每个消费者创建一个单独的队列，让生产者发送多份。这是一种非常愚蠢的做法，浪费资源不说，还违背了使用消息队列的目的。</p><h4 id=发布-订阅模型-kafka-消息模型-发布-订阅模型kafka-消息模型><a rel=noopener class="internal-link broken" data-src=#%e5%8f%91%e5%b8%83-%e8%ae%a2%e9%98%85%e6%a8%a1%e5%9e%8b-kafka-%e6%b6%88%e6%81%af%e6%a8%a1%e5%9e%8b>#</a> 发布-订阅模型:Kafka 消息模型</h4><p>发布-订阅模型主要是为了解决队列模型存在的问题。</p><p><img src=https://googoo-s.github.io//statistic/%E5%8F%91%E5%B8%83%E8%AE%A2%E9%98%85%E6%A8%A1%E5%9E%8B.png width=auto alt=发布订阅模型></p><p>发布订阅模型</p><p>发布订阅模型（Pub-Sub） 使用<strong>主题（Topic）</strong> 作为消息通信载体，类似于<strong>广播模式</strong>；发布者发布一条消息，该消息通过主题传递给所有的订阅者，<strong>在一条消息广播之后才订阅的用户则是收不到该条消息的</strong>。</p><p><strong>在发布 - 订阅模型中，如果只有一个订阅者，那它和队列模型就基本是一样的了。所以说，发布 - 订阅模型在功能层面上是可以兼容队列模型的。</strong></p><p><strong>Kafka 采用的就是发布 - 订阅模型。</strong></p><blockquote><p><strong>RocketMQ 的消息模型和 Kafka 基本是完全一样的。唯一的区别是 Kafka 中没有队列这个概念，与之对应的是 Partition（分区）。</strong></p></blockquote><h3 id=什么是-producerconsumerbrokertopicpartition-什么是-producerconsumerbrokertopicpartition><a rel=noopener class="internal-link broken" data-src=#%e4%bb%80%e4%b9%88%e6%98%af-producer%e3%80%81consumer%e3%80%81broker%e3%80%81topic%e3%80%81partition>#</a> 什么是 Producer、Consumer、Broker、Topic、Partition？</h3><p>Kafka 将生产者发布的消息发送到 <strong>Topic（主题）</strong> 中，需要这些消息的消费者可以订阅这些 <strong>Topic（主题）</strong>，如下图所示：</p><p><img src=https://googoo-s.github.io//statistic/message-queue20210507200944439.png width=auto alt></p><p>上面这张图也为我们引出了，Kafka 比较重要的几个概念：</p><ol><li><strong>Producer（生产者）</strong> : 产生消息的一方。</li><li><strong>Consumer（消费者）</strong> : 消费消息的一方。</li><li><strong>Broker（代理）</strong> : 可以看作是一个独立的 Kafka 实例。多个 Kafka Broker 组成一个 Kafka Cluster。</li></ol><p>同时，你一定也注意到每个 Broker 中又包含了 Topic 以及 Partition 这两个重要的概念：</p><ul><li><strong>Topic（主题）</strong> : Producer 将消息发送到特定的主题，Consumer 通过订阅特定的 Topic(主题) 来消费消息。</li><li><strong>Partition（分区）</strong> : Partition 属于 Topic 的一部分。一个 Topic 可以有多个 Partition ，并且同一 Topic 下的 Partition 可以分布在不同的 Broker 上，这也就表明一个 Topic 可以横跨多个 Broker 。这正如我上面所画的图一样。</li></ul><blockquote><p>划重点：<strong>Kafka 中的 Partition（分区） 实际上可以对应成为消息队列中的队列。这样是不是更好理解一点？</strong></p></blockquote><h3 id=kafka-的多副本机制了解吗-带来了什么好处-kafka-的多副本机制了解吗带来了什么好处><a rel=noopener class="internal-link broken" data-src=#kafka-%e7%9a%84%e5%a4%9a%e5%89%af%e6%9c%ac%e6%9c%ba%e5%88%b6%e4%ba%86%e8%a7%a3%e5%90%97-%e5%b8%a6%e6%9d%a5%e4%ba%86%e4%bb%80%e4%b9%88%e5%a5%bd%e5%a4%84>#</a> Kafka 的多副本机制了解吗？带来了什么好处？</h3><p>还有一点我觉得比较重要的是 Kafka 为分区（Partition）引入了多副本（Replica）机制。分区（Partition）中的多个副本之间会有一个叫做 leader 的家伙，其他副本称为 follower。我们发送的消息会被发送到 leader 副本，然后 follower 副本才能从 leader 副本中拉取消息进行同步。</p><blockquote><p>生产者和消费者只与 leader 副本交互。你可以理解为其他副本只是 leader 副本的拷贝，它们的存在只是为了保证消息存储的安全性。当 leader 副本发生故障时会从 follower 中选举出一个 leader,但是 follower 中如果有和 leader 同步程度达不到要求的参加不了 leader 的竞选。</p></blockquote><p><strong>Kafka 的多分区（Partition）以及多副本（Replica）机制有什么好处呢？</strong></p><ol><li>Kafka 通过给特定 Topic 指定多个 Partition, 而各个 Partition 可以分布在不同的 Broker 上, 这样便能提供比较好的并发能力（负载均衡）。</li><li>Partition 可以指定对应的 Replica 数, 这也极大地提高了消息存储的安全性, 提高了容灾能力，不过也相应的增加了所需要的存储空间。</li></ol><h3 id=zookeeper-在-kafka-中的作用知道吗-zookeeper-在-kafka-中的作用知道吗><a rel=noopener class="internal-link broken" data-src=#zookeeper-%e5%9c%a8-kafka-%e4%b8%ad%e7%9a%84%e4%bd%9c%e7%94%a8%e7%9f%a5%e9%81%93%e5%90%97>#</a> Zookeeper 在 Kafka 中的作用知道吗？</h3><blockquote><p><strong>要想搞懂 zookeeper 在 Kafka 中的作用 一定要自己搭建一个 Kafka 环境然后自己进 zookeeper 去看一下有哪些文件夹和 Kafka 有关，每个节点又保存了什么信息。</strong> 一定不要光看不实践，这样学来的也终会忘记！这部分内容参考和借鉴了这篇文章：https://www.jianshu.com/p/a036405f989c 。</p></blockquote><p>下图就是我的本地 Zookeeper ，它成功和我本地的 Kafka 关联上（以下文件夹结构借助 idea 插件 Zookeeper tool 实现）。</p><p><img src=https://googoo-s.github.io//statistic/zookeeper-kafka.jpg width=auto alt></p><p>ZooKeeper 主要为 Kafka 提供元数据的管理的功能。</p><p>从图中我们可以看出，Zookeeper 主要为 Kafka 做了下面这些事情：</p><ol><li><strong>Broker 注册</strong>：在 Zookeeper 上会有一个专门<strong>用来进行 Broker 服务器列表记录</strong>的节点。每个 Broker 在启动时，都会到 Zookeeper 上进行注册，即到 <code>/brokers/ids</code> 下创建属于自己的节点。每个 Broker 就会将自己的 IP 地址和端口等信息记录到该节点中去</li><li><strong>Topic 注册</strong>：在 Kafka 中，同一个<strong>Topic 的消息会被分成多个分区</strong>并将其分布在多个 Broker 上，<strong>这些分区信息及与 Broker 的对应关系</strong>也都是由 Zookeeper 在维护。比如我创建了一个名字为 my-topic 的主题并且它有两个分区，对应到 zookeeper 中会创建这些文件夹：<code>/brokers/topics/my-topic/Partitions/0</code>、<code>/brokers/topics/my-topic/Partitions/1</code></li><li><strong>负载均衡</strong>：上面也说过了 Kafka 通过给特定 Topic 指定多个 Partition, 而各个 Partition 可以分布在不同的 Broker 上, 这样便能提供比较好的并发能力。 对于同一个 Topic 的不同 Partition，Kafka 会尽力将这些 Partition 分布到不同的 Broker 服务器上。当生产者产生消息后也会尽量投递到不同 Broker 的 Partition 里面。当 Consumer 消费的时候，Zookeeper 可以根据当前的 Partition 数量以及 Consumer 数量来实现动态负载均衡。</li><li>&mldr;&mldr;</li></ol><h3 id=kafka-如何保证消息的消费顺序-kafka-如何保证消息的消费顺序><a rel=noopener class="internal-link broken" data-src=#kafka-%e5%a6%82%e4%bd%95%e4%bf%9d%e8%af%81%e6%b6%88%e6%81%af%e7%9a%84%e6%b6%88%e8%b4%b9%e9%a1%ba%e5%ba%8f>#</a> Kafka 如何保证消息的消费顺序？</h3><p>我们在使用消息队列的过程中经常有业务场景需要严格保证消息的消费顺序，比如我们同时发了 2 个消息，这 2 个消息对应的操作分别对应的数据库操作是：</p><ol><li>更改用户会员等级。</li><li>根据会员等级计算订单价格。</li></ol><p>假如这两条消息的消费顺序不一样造成的最终结果就会截然不同。</p><p>我们知道 Kafka 中 Partition(分区)是真正保存消息的地方，我们发送的消息都被放在了这里。而我们的 Partition(分区) 又存在于 Topic(主题) 这个概念中，并且我们可以给特定 Topic 指定多个 Partition。</p><p><img src=https://googoo-s.github.io//statistic/KafkaTopicPartionsLayout.png width=auto alt></p><p>每次添加消息到 Partition(分区) 的时候都会采用尾加法，如上图所示。 <strong>Kafka 只能为我们保证 Partition(分区) 中的消息有序。</strong></p><blockquote><p>消息在被追加到 Partition(分区)的时候都会分配一个特定的偏移量（offset）。Kafka 通过偏移量（offset）来保证消息在分区内的顺序性。</p></blockquote><p>所以，我们就有一种很简单的保证消息消费顺序的方法：<strong>1 个 Topic 只对应一个 Partition</strong>。这样当然可以解决问题，但是破坏了 Kafka 的设计初衷。</p><p>Kafka 中发送 1 条消息的时候，可以指定 topic, partition, key,data（数据） 4 个参数。如果你发送消息的时候指定了 Partition 的话，所有消息都会被发送到指定的 Partition。并且，同一个 key 的消息可以保证只发送到同一个 partition，这个我们可以采用表/对象的 id 来作为 key 。</p><p>总结一下，对于如何保证 Kafka 中消息消费的顺序，有了下面两种方法：</p><ol><li>1 个 Topic 只对应一个 Partition。</li><li>（推荐）发送消息的时候指定 key/Partition。</li></ol><p>当然不仅仅只有上面两种方法，上面两种方法是我觉得比较好理解的，</p><h3 id=kafka-如何保证消息不丢失-kafka-如何保证消息不丢失><a rel=noopener class="internal-link broken" data-src=#kafka-%e5%a6%82%e4%bd%95%e4%bf%9d%e8%af%81%e6%b6%88%e6%81%af%e4%b8%8d%e4%b8%a2%e5%a4%b1>#</a> Kafka 如何保证消息不丢失</h3><h4 id=生产者丢失消息的情况-生产者丢失消息的情况><a rel=noopener class="internal-link broken" data-src=#%e7%94%9f%e4%ba%a7%e8%80%85%e4%b8%a2%e5%a4%b1%e6%b6%88%e6%81%af%e7%9a%84%e6%83%85%e5%86%b5>#</a> 生产者丢失消息的情况</h4><p>生产者(Producer) 调用<code>send</code>方法发送消息之后，消息可能因为网络问题并没有发送过去。</p><p>所以，我们不能默认在调用<code>send</code>方法发送消息之后消息发送成功了。为了确定消息是发送成功，我们要判断消息发送的结果。但是要注意的是 Kafka 生产者(Producer) 使用 <code>send</code> 方法发送消息实际上是异步的操作，我们可以通过 <code>get()</code>方法获取调用结果，但是这样也让它变为了同步操作，示例代码如下：</p><blockquote><p><strong>详细代码见我的这篇文章：
<a href="https://mp.weixin.qq.com/s?__biz=Mzg2OTA0Njk0OA==&mid=2247486269&idx=2&sn=ec00417ad641dd8c3d145d74cafa09ce&chksm=cea244f6f9d5cde0c8eb233fcc4cf82e11acd06446719a7af55230649863a3ddd95f78d111de&token=1633957262&lang=zh_CN#rd" rel=noopener>Kafka 系列第三篇！10 分钟学会如何在 Spring Boot 程序中使用 Kafka 作为消息队列?open in new window</a></strong></p></blockquote><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>SendResult&lt;String, Object&gt; sendResult = kafkaTemplate.send(topic, o).get();
</span></span><span class=line><span class=cl>if (sendResult.getRecordMetadata() != null) {
</span></span><span class=line><span class=cl>  logger.info(&#34;生产者成功发送消息到&#34; + sendResult.getProducerRecord().topic() + &#34;-&gt; &#34; + sendRe
</span></span><span class=line><span class=cl>              sult.getProducerRecord().value().toString());
</span></span><span class=line><span class=cl>}
</span></span></code></pre></td></tr></table></div></div><p>但是一般不推荐这么做！可以采用为其添加回调函数的形式，示例代码如下：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>        ListenableFuture&lt;SendResult&lt;String, Object&gt;&gt; future = kafkaTemplate.send(topic, o);
</span></span><span class=line><span class=cl>        future.addCallback(result -&gt; logger.info(&#34;生产者成功发送消息到topic:{} partition:{}的消息&#34;, result.getRecordMetadata().topic(), result.getRecordMetadata().partition()),
</span></span><span class=line><span class=cl>                ex -&gt; logger.error(&#34;生产者发送消失败，原因：{}&#34;, ex.getMessage()));
</span></span></code></pre></td></tr></table></div></div><p>如果消息发送失败的话，我们检查失败的原因之后重新发送即可！</p><p><strong>另外这里推荐为 Producer 的<code>retries</code> （重试次数）设置一个比较合理的值，一般是 3 ，但是为了保证消息不丢失的话一般会设置比较大一点。设置完成之后，当出现网络问题之后能够自动重试消息发送，避免消息丢失。另外，建议还要设置重试间隔，因为间隔太小的话重试的效果就不明显了，网络波动一次你 3 次一下子就重试完了</strong></p><h4 id=消费者丢失消息的情况-消费者丢失消息的情况><a rel=noopener class="internal-link broken" data-src=#%e6%b6%88%e8%b4%b9%e8%80%85%e4%b8%a2%e5%a4%b1%e6%b6%88%e6%81%af%e7%9a%84%e6%83%85%e5%86%b5>#</a> 消费者丢失消息的情况</h4><p>我们知道消息在被追加到 Partition(分区)的时候都会分配一个特定的偏移量（offset）。偏移量（offset)表示 Consumer 当前消费到的 Partition(分区)的所在的位置。Kafka 通过偏移量（offset）可以保证消息在分区内的顺序性。</p><p><img src=https://googoo-s.github.io//statistic/kafka_offset.jpg width=auto alt="kafka offset"></p><p>kafka offset</p><p>当消费者拉取到了分区的某个消息之后，消费者会自动提交了 offset。自动提交的话会有一个问题，试想一下，当消费者刚拿到这个消息准备进行真正消费的时候，突然挂掉了，消息实际上并没有被消费，但是 offset 却被自动提交了。</p><p><strong>解决办法也比较粗暴，我们手动关闭自动提交 offset，每次在真正消费完消息之后再自己手动提交 offset 。</strong> 但是，细心的朋友一定会发现，这样会带来消息被重新消费的问题。比如你刚刚消费完消息之后，还没提交 offset，结果自己挂掉了，那么这个消息理论上就会被消费两次。</p><h4 id=kafka-弄丢了消息-kafka-弄丢了消息><a rel=noopener class="internal-link broken" data-src=#kafka-%e5%bc%84%e4%b8%a2%e4%ba%86%e6%b6%88%e6%81%af>#</a> Kafka 弄丢了消息</h4><p>我们知道 Kafka 为分区（Partition）引入了多副本（Replica）机制。分区（Partition）中的多个副本之间会有一个叫做 leader 的家伙，其他副本称为 follower。我们发送的消息会被发送到 leader 副本，然后 follower 副本才能从 leader 副本中拉取消息进行同步。生产者和消费者只与 leader 副本交互。你可以理解为其他副本只是 leader 副本的拷贝，它们的存在只是为了保证消息存储的安全性。</p><p><strong>试想一种情况：假如 leader 副本所在的 broker 突然挂掉，那么就要从 follower 副本重新选出一个 leader ，但是 leader 的数据还有一些没有被 follower 副本的同步的话，就会造成消息丢失。</strong></p><p><strong>设置 acks = all</strong></p><p>解决办法就是我们设置 <strong>acks = all</strong>。acks 是 Kafka 生产者(Producer) 很重要的一个参数。</p><p>acks 的默认值即为 1，代表我们的消息被 leader 副本接收之后就算被成功发送。当我们配置 <strong>acks = all</strong> 表示只有所有 ISR 列表的副本全部收到消息时，生产者才会接收到来自服务器的响应. 这种模式是最高级别的，也是最安全的，可以确保不止一个 Broker 接收到了消息. 该模式的延迟会很高.</p><p><strong>设置 replication.factor >= 3</strong></p><p>为了保证 leader 副本能有 follower 副本能同步消息，我们一般会为 topic 设置 <strong>replication.factor >= 3</strong>。这样就可以保证每个 分区(partition) 至少有 3 个副本。虽然造成了数据冗余，但是带来了数据的安全性。</p><p><strong>设置 min.insync.replicas > 1</strong></p><p>一般情况下我们还需要设置 <strong>min.insync.replicas> 1</strong> ，这样配置代表消息至少要被写入到 2 个副本才算是被成功发送。<strong>min.insync.replicas</strong> 的默认值为 1 ，在实际生产中应尽量避免默认值 1。</p><p>但是，为了保证整个 Kafka 服务的高可用性，你需要确保 <strong>replication.factor > min.insync.replicas</strong> 。为什么呢？设想一下假如两者相等的话，只要是有一个副本挂掉，整个分区就无法正常工作了。这明显违反高可用性！一般推荐设置成 <strong>replication.factor = min.insync.replicas + 1</strong>。</p><p><strong>设置 unclean.leader.election.enable = false</strong></p><blockquote><p><strong>Kafka 0.11.0.0 版本开始 unclean.leader.election.enable 参数的默认值由原来的 true 改为 false</strong></p></blockquote><p>我们最开始也说了我们发送的消息会被发送到 leader 副本，然后 follower 副本才能从 leader 副本中拉取消息进行同步。多个 follower 副本之间的消息同步情况不一样，当我们配置了 <strong>unclean.leader.election.enable = false</strong> 的话，当 leader 副本发生故障时就不会从 follower 副本中和 leader 同步程度达不到要求的副本中选择出 leader ，这样降低了消息丢失的可能性。</p><h3 id=kafka-如何保证消息不重复消费-kafka-如何保证消息不重复消费><a rel=noopener class="internal-link broken" data-src=#kafka-%e5%a6%82%e4%bd%95%e4%bf%9d%e8%af%81%e6%b6%88%e6%81%af%e4%b8%8d%e9%87%8d%e5%a4%8d%e6%b6%88%e8%b4%b9>#</a> Kafka 如何保证消息不重复消费</h3><p><strong>kafka 出现消息重复消费的原因：</strong></p><ul><li>服务端侧已经消费的数据没有成功提交 offset（根本原因）。</li><li>Kafka 侧 由于服务端处理业务时间长或者网络链接等等原因让 Kafka 认为服务假死，触发了分区 rebalance。</li></ul><p><strong>解决方案：</strong></p><ul><li>消费消息服务做幂等校验，比如 Redis 的 set、MySQL 的主键等天然的幂等功能。这种方法最有效。</li><li>将 <strong><code>enable.auto.commit</code></strong> 参数设置为 false，关闭自动提交，开发者在代码中手动提交 offset。那么这里会有个问题：<strong>什么时候提交 offset 合适？</strong><ul><li>处理完消息再提交：依旧有消息重复消费的风险，和自动提交一样</li><li>拉取到消息即提交：会有消息丢失的风险。允许消息延时的场景，一般会采用这种方式。然后，通过定时任务在业务不繁忙（比如凌晨）的时候做数据兜底。</li></ul></li></ul><h3 id=reference-reference><a rel=noopener class="internal-link broken" data-src=#reference>#</a> Reference</h3><ul><li>Kafka 官方文档：https://kafka.apache.org/documentation/</li><li>极客时间—《Kafka 核心技术与实战》第 11 节：无消息丢失配置怎么实现？</li></ul><hr><p>著作权归Guide所有 原文链接：https://javaguide.cn/high-performance/message-queue/kafka-questions-01.html#kafka-%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E6%B6%88%E6%81%AF%E4%B8%8D%E4%B8%A2%E5%A4%B1</p></article><hr><div class=page-end id=footer><div class=backlinks-container><h3>Backlinks</h3><ul class=backlinks><li>No backlinks found</li></ul></div><div><script src=https://cdn.jsdelivr.net/npm/d3@6.7.0/dist/d3.min.js integrity="sha256-+7jaYCp29O1JusNWHaYtgUn6EhuP0VaFuswhNV06MyI=" crossorigin=anonymous></script><h3>Interactive Graph</h3><div id=graph-container></div><style>:root{--g-node:var(--secondary);--g-node-active:var(--primary);--g-node-inactive:var(--visited);--g-link:var(--outlinegray);--g-link-active:#5a7282}</style><script src=https://googoo-s.github.io/js/graph.6579af7b10c818dbd2ca038702db0224.js></script></div></div><div id=contact_buttons><footer><p>Made by googoo-s using <a href=https://github.com/jackyzha0/quartz>Quartz</a>, © 2023</p><ul><li><a href=https://googoo-s.github.io/>Home</a></li><li><a href=https://github.com/googoo-s>GitHub</a></li></ul></footer></div></div></body></html>