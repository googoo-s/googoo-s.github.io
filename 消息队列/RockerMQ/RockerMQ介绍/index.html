<!doctype html><html lang=en><head><meta charset=utf-8><meta name=description content="RocketMQ 的优缺点   RocketMQ优点：
  单机吞吐量：十万级
  可用性：非常高，分布式架构
  消息可靠性：经过参数优化配置，消息可以做到0丢失
  功能支持：MQ功能较为完善，还是分布式的，扩展性好
  支持10亿级别的消息堆积，不会因为堆积导致性能下降"><meta property="og:title" content><meta property="og:description" content="RocketMQ 的优缺点   RocketMQ优点：
  单机吞吐量：十万级
  可用性：非常高，分布式架构
  消息可靠性：经过参数优化配置，消息可以做到0丢失
  功能支持：MQ功能较为完善，还是分布式的，扩展性好
  支持10亿级别的消息堆积，不会因为堆积导致性能下降"><meta property="og:type" content="website"><meta property="og:image" content="https://googoo-s.github.io/icon.png"><meta property="og:url" content="https://googoo-s.github.io/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/RockerMQ/RockerMQ%E4%BB%8B%E7%BB%8D/"><meta property="og:width" content="200"><meta property="og:height" content="200"><meta name=twitter:card content="summary"><meta name=twitter:title content><meta name=twitter:description content="RocketMQ 的优缺点   RocketMQ优点：
  单机吞吐量：十万级
  可用性：非常高，分布式架构
  消息可靠性：经过参数优化配置，消息可以做到0丢失
  功能支持：MQ功能较为完善，还是分布式的，扩展性好
  支持10亿级别的消息堆积，不会因为堆积导致性能下降"><meta name=twitter:image content="https://googoo-s.github.io/icon.png"><title>googoo-s</title><meta name=viewport content="width=device-width,initial-scale=1"><link rel="shortcut icon" type=image/png href=https://googoo-s.github.io//icon.png><link href=https://googoo-s.github.io/styles.19109a40042e9f0e72e952fda4442a34.min.css rel=stylesheet><link href=https://googoo-s.github.io/styles/_light_syntax.86a48a52faebeaaf42158b72922b1c90.min.css rel=stylesheet id=theme-link><script src=https://googoo-s.github.io/js/darkmode.953af745b0f9342644d632fc167f3727.min.js></script>
<script src=https://googoo-s.github.io/js/util.00639692264b21bc3ee219733d38a8be.min.js></script>
<link rel=preload href=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css as=style onload='this.onload=null,this.rel="stylesheet"' integrity=sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js integrity=sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/contrib/copy-tex.min.js integrity=sha384-ww/583aHhxWkz5DEVn6OKtNiIaLi2iBRNZXfJRiY1Ai7tnJ9UXpEsyvOITVpTl4A crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/@floating-ui/core@1.2.1></script>
<script src=https://cdn.jsdelivr.net/npm/@floating-ui/dom@1.2.1></script>
<script defer src=https://googoo-s.github.io/js/popover.aa9bc99c7c38d3ae9538f218f1416adb.min.js></script>
<script defer src=https://googoo-s.github.io/js/code-title.ce4a43f09239a9efb48fee342e8ef2df.min.js></script>
<script defer src=https://googoo-s.github.io/js/clipboard.2913da76d3cb21c5deaa4bae7da38c9f.min.js></script>
<script defer src=https://googoo-s.github.io/js/callouts.7723cac461d613d118ee8bb8216b9838.min.js></script>
<script>const SEARCH_ENABLED=!1,LATEX_ENABLED=!0,PRODUCTION=!0,BASE_URL="https://googoo-s.github.io/",fetchData=Promise.all([fetch("https://googoo-s.github.io/indices/linkIndex.26897e4d1acf67c094aa607e8f2e6316.min.json").then(e=>e.json()).then(e=>({index:e.index,links:e.links})),fetch("https://googoo-s.github.io/indices/contentIndex.21bafd1d14d432c98660db2d3420e84e.min.json").then(e=>e.json())]).then(([{index:e,links:t},n])=>({index:e,links:t,content:n})),render=()=>{const e=new URL(BASE_URL),t=e.pathname,n=window.location.pathname,s=t==n;addCopyButtons(),addTitleToCodeBlocks(),addCollapsibleCallouts(),initPopover("https://googoo-s.github.io",!0);const o=document.getElementById("footer");if(o){const e=document.getElementById("graph-container");if(!e)return requestAnimationFrame(render);e.textContent="";const t=s&&!1;drawGraph("https://googoo-s.github.io",t,[{"/moc":"#4388cc"}],t?{centerForce:1,depth:-1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.5,linkDistance:1,opacityScale:3,repelForce:1,scale:1.4}:{centerForce:1,depth:1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.6,linkDistance:1,opacityScale:3,repelForce:2,scale:1.2})}var i=document.getElementsByClassName("mermaid");i.length>0&&import("https://unpkg.com/mermaid@9/dist/mermaid.esm.min.mjs").then(e=>{e.default.init()});function a(n){const e=n.target,t=e.className.split(" "),s=t.includes("broken"),o=t.includes("internal-link");plausible("Link Click",{props:{href:e.href,broken:s,internal:o,graph:!1}})}const r=document.querySelectorAll("a");for(link of r)link.className.includes("root-title")&&link.addEventListener("click",a,{once:!0})},init=(e=document)=>{addCopyButtons(),addTitleToCodeBlocks(),renderMathInElement(e.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],macros:{'’':"'"},throwOnError:!1})}</script><script type=module>
    import { attachSPARouting } from "https:\/\/googoo-s.github.io\/js\/router.d6fe6bd821db9ea97f9aeefae814d8e7.min.js"
    attachSPARouting(init, render)
  </script><script defer data-domain=googoo-s.github.io src=https://plausible.io/js/script.js></script>
<script>window.plausible=window.plausible||function(){(window.plausible.q=window.plausible.q||[]).push(arguments)}</script></head><body><div id=search-container><div id=search-space><input autocomplete=off id=search-bar name=search type=text aria-label=Search placeholder="Search for something..."><div id=results-container></div></div></div><script src=https://cdn.jsdelivr.net/npm/flexsearch@0.7.21/dist/flexsearch.bundle.js integrity="sha256-i3A0NZGkhsKjVMzFxv3ksk0DZh3aXqu0l49Bbh0MdjE=" crossorigin=anonymous defer></script>
<script defer src=https://googoo-s.github.io/js/full-text-search.e6e2e0c213187ca0c703d6e2c7a77fcd.min.js></script><div class=singlePage><header><h1 id=page-title><a class=root-title href=https://googoo-s.github.io/>googoo-s</a></h1><div class=spacer></div><div id=search-icon><p>Search</p><svg tabindex="0" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search Icon</title><desc id="desc">Icon to open search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"/><circle cx="8" cy="8" r="7"/></g></svg></div><div class=darkmode><input class=toggle id=darkmode-toggle type=checkbox tabindex=-1>
<label id=toggle-label-light for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="dayIcon" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35"><title>Light Mode</title><path d="M6 17.5C6 16.672 5.328 16 4.5 16h-3C.672 16 0 16.672.0 17.5S.672 19 1.5 19h3C5.328 19 6 18.328 6 17.5zM7.5 26c-.414.0-.789.168-1.061.439l-2 2C4.168 28.711 4 29.086 4 29.5 4 30.328 4.671 31 5.5 31c.414.0.789-.168 1.06-.44l2-2C8.832 28.289 9 27.914 9 27.5 9 26.672 8.329 26 7.5 26zm10-20C18.329 6 19 5.328 19 4.5v-3C19 .672 18.329.0 17.5.0S16 .672 16 1.5v3C16 5.328 16.671 6 17.5 6zm10 3c.414.0.789-.168 1.06-.439l2-2C30.832 6.289 31 5.914 31 5.5 31 4.672 30.329 4 29.5 4c-.414.0-.789.168-1.061.44l-2 2C26.168 6.711 26 7.086 26 7.5 26 8.328 26.671 9 27.5 9zM6.439 8.561C6.711 8.832 7.086 9 7.5 9 8.328 9 9 8.328 9 7.5c0-.414-.168-.789-.439-1.061l-2-2C6.289 4.168 5.914 4 5.5 4 4.672 4 4 4.672 4 5.5c0 .414.168.789.439 1.06l2 2.001zM33.5 16h-3c-.828.0-1.5.672-1.5 1.5s.672 1.5 1.5 1.5h3c.828.0 1.5-.672 1.5-1.5S34.328 16 33.5 16zM28.561 26.439C28.289 26.168 27.914 26 27.5 26c-.828.0-1.5.672-1.5 1.5.0.414.168.789.439 1.06l2 2C28.711 30.832 29.086 31 29.5 31c.828.0 1.5-.672 1.5-1.5.0-.414-.168-.789-.439-1.061l-2-2zM17.5 29c-.829.0-1.5.672-1.5 1.5v3c0 .828.671 1.5 1.5 1.5s1.5-.672 1.5-1.5v-3C19 29.672 18.329 29 17.5 29zm0-22C11.71 7 7 11.71 7 17.5S11.71 28 17.5 28 28 23.29 28 17.5 23.29 7 17.5 7zm0 18c-4.136.0-7.5-3.364-7.5-7.5s3.364-7.5 7.5-7.5 7.5 3.364 7.5 7.5S21.636 25 17.5 25z"/></svg></label><label id=toggle-label-dark for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="nightIcon" viewBox="0 0 100 100" style="enable-background='new 0 0 100 100'"><title>Dark Mode</title><path d="M96.76 66.458c-.853-.852-2.15-1.064-3.23-.534-6.063 2.991-12.858 4.571-19.655 4.571C62.022 70.495 50.88 65.88 42.5 57.5 29.043 44.043 25.658 23.536 34.076 6.47c.532-1.08.318-2.379-.534-3.23-.851-.852-2.15-1.064-3.23-.534-4.918 2.427-9.375 5.619-13.246 9.491-9.447 9.447-14.65 22.008-14.65 35.369.0 13.36 5.203 25.921 14.65 35.368s22.008 14.65 35.368 14.65c13.361.0 25.921-5.203 35.369-14.65 3.872-3.871 7.064-8.328 9.491-13.246C97.826 68.608 97.611 67.309 96.76 66.458z"/></svg></label></div></header><article><p class=meta>Last updated
Unknown
<a href=/%e6%b6%88%e6%81%af%e9%98%9f%e5%88%97/RockerMQ/RockerMQ%e4%bb%8b%e7%bb%8d.md rel=noopener>Edit Source</a></p><ul class=tags></ul><aside class=mainTOC><details open><summary>Table of Contents</summary><nav id=TableOfContents><ol><li><a href=#message>Message</a></li><li><a href=#topic>Topic</a></li><li><a href=#tag>Tag</a></li><li><a href=#group>Group</a></li><li><a href=#message-queue>Message Queue</a></li><li><a href=#offset>Offset</a></li></ol><ol><li><a href=#nameserver><strong>NameServer</strong></a></li><li><a href=#broker><strong>Broker</strong></a></li><li><a href=#producer>Producer</a></li><li><a href=#consumer><strong>Consumer</strong></a></li></ol><ol><li><a href=#生产阶段>生<strong>产阶段</strong></a></li><li><a href=#存储阶段><strong>存储阶段</strong></a></li><li><a href=#消费阶段><strong>消费阶段</strong></a></li></ol><ol><li><a href=#部分顺序消息>部分顺序消息</a></li><li><a href=#全局顺序消息>全局顺序消息</a></li></ol><ol><li><a href=#rocketmq怎么实现延时消息>RocketMQ怎么实现延时消息？</a></li></ol><ol><li><a href=#nameserver的高可用>NameServer的高可用</a></li><li><a href=#broker读的高可用>Broker读的高可用</a></li><li><a href=#broker写的高可用>Broker写的高可用</a></li></ol><ol><li><a href=#为啥rockermq-不使用zookeeper-作为注册中心>为啥RockerMQ 不使用zookeeper 作为注册中心</a></li></ol><ol><li><a href=#commitlog>CommitLog</a></li><li><a href=#consumequeue---可以看做是commitlog的索引文件><strong>ConsumeQueue - 可以看做是CommitLog的索引文件</strong></a></li><li><a href=#indexfile><strong>IndexFile</strong></a></li><li><a href=#总结>总结</a></li></ol><ol><li><a href=#pagecache顺序读取>PageCache、顺序读取</a></li><li><a href=#零拷贝>零拷贝</a><ol><li><a href=#啥是零拷贝>啥是零拷贝</a></li></ol></li></ol><ol><li><a href=#producer的负载均衡><strong>Producer</strong>的负载均衡</a></li><li><a href=#consumer的负载均衡><strong>Consumer</strong>的负载均衡</a></li><li><a href=#rocketmq消息长轮训>RocketMQ消息长轮训</a></li></ol></nav></details></aside><a href=#rocketmq-的优缺点><h1 id=rocketmq-的优缺点><span class=hanchor arialabel=Anchor># </span>RocketMQ 的优缺点</h1></a><ul><li><p>RocketMQ优点：</p><ul><li><p>单机吞吐量：十万级</p></li><li><p>可用性：非常高，分布式架构</p></li><li><p>消息可靠性：经过参数优化配置，<strong>消息可以做到0丢失</strong></p></li><li><p>功能支持：MQ功能较为完善，还是分布式的，扩展性好</p></li><li><p>支持10亿级别的消息堆积，不会因为堆积导致性能下降</p></li><li><p>源码是Java，方便结合公司自己的业务二次开发</p></li><li><p>天生为金融互联网领域而生，对于可靠性要求很高的场景，尤其是电商里面的订单扣款，以及业务削峰，在大量交易涌入时，后端可能无法及时处理的情况RoketMQ 在稳定性上可能更值得信赖，这些业务场景在阿里双11已经经历了次考验，如果你的业务有上述并发场景，建议可以选择 RocketMQ</p></li></ul></li><li><p>RocketMQ缺点：</p><ul><li><p>支持的客户端语言不多，目前是Java及c++，其中c++不成熟</p></li><li><p>没有在 MQ核心中去实现 JMS 等接口，有些系统要迁移需要修改大量代码</p></li></ul></li></ul><a href=#rocketmq-的消息模型><h1 id=rocketmq-的消息模型><span class=hanchor arialabel=Anchor># </span>RocketMQ 的消息模型</h1></a><p>RocketMQ使用的消息模型是标准的<strong>发布-订阅模型</strong></p><p><img src=https://googoo-s.github.io//statistic/asynccode-527.png width=auto alt></p><a href=#rocketmq-的名词介绍><h1 id=rocketmq-的名词介绍><span class=hanchor arialabel=Anchor># </span>RocketMQ 的名词介绍</h1></a><a href=#message><h2 id=message><span class=hanchor arialabel=Anchor># </span>Message</h2></a><p><strong>Message</strong>（消息）就是要传输的信息。</p><ul><li><p>一条消息必须有一个主题（Topic），主题可以看做是你的信件要邮寄的地址。</p></li><li><p>一条消息也可以拥有一个可选的标签（Tag）和额处的键值对，它们可以用于设置一个业务 Key 并在 Broker 上查找此消息以便在开发期间查找问题。</p></li></ul><a href=#topic><h2 id=topic><span class=hanchor arialabel=Anchor># </span>Topic</h2></a><p><strong>Topic</strong>（主题）可以看做消息的归类，它是消息的第一级类型。比如一个电商系统可</p><ul><li><p><strong>Topic</strong> 与生产者和消费者的关系非常松散，一个 Topic 可以有0个、1个、多个生产者向其发送消息，一个生产者也可以同时向不同的 Topic 发送消息。</p></li><li><p>一个 Topic 也可以被 0个、1个、多个消费者订阅。</p></li></ul><a href=#tag><h2 id=tag><span class=hanchor arialabel=Anchor># </span>Tag</h2></a><p><strong>Tag</strong>（标签）可以看作子主题，<strong>它是消息的第二级类型</strong>，用于为用户提供额外的灵活性。使<strong>用标签，同一业务模块不同目的的消息就可以用相同 Topic 而不同的 Tag 来标识</strong>。</p><ul><li><p>一条消息可以没有 <strong>Tag</strong> 。</p></li><li><p>标签有助于保持你的代码干净和连贯，并且还可以为 <strong>RocketMQ</strong> 提供的查询系统提 供帮助。</p></li></ul><a href=#group><h2 id=group><span class=hanchor arialabel=Anchor># </span>Group</h2></a><p>RocketMQ中，<strong>订阅者的概念是通过消费组（Consumer Group）来体现的</strong>。</p><ul><li><p><strong>每个消费组都消费主题中一份完整的消息，不同消费组之间消费进度彼此不受影响</strong>，也就是说，一条消息被Consumer Group1消费过，也会再给Consumer Group2消费。</p></li><li><p>消费组中包含多个消费者，<strong>同一个组内的消费者是竞争消费的关系，每个消费者负责消费组内的一部分消息</strong>。默认情况，如果一条消息被消费者Consumer1消费了，那同组的其他消费者就不会再收到这条消息。</p></li></ul><a href=#message-queue><h2 id=message-queue><span class=hanchor arialabel=Anchor># </span>Message Queue</h2></a><p><strong>Message Queue</strong>（消息队列），<strong>一个 Topic 下可以设置多个消息队列，Topic 包括多个 Message Queue ，如果一个 Consumer 需要获取 Topic下所有的消息</strong>，就要遍历所有的 Message Queue。</p><p>RocketMQ还有一些其它的Queue——例如ConsumerQueue。</p><a href=#offset><h2 id=offset><span class=hanchor arialabel=Anchor># </span>Offset</h2></a><p>在Topic的消费过程中，由于消息需要被不同的组进行多次消费，<strong>所以消费完的消息并不会立即被删除，这就需要RocketMQ为每个消费组在每个队列上维护一个消费位置（Consumer Offset）</strong>，这个位置之前的消息都被消费过，之后的消息都没有被消费过，每成功消费一条消息，消费位置就加一。</p><p><img src=https://googoo-s.github.io//statistic/asynccode-547.png width=auto alt></p><a href=#rocketmq-的基本架构><h1 id=rocketmq-的基本架构><span class=hanchor arialabel=Anchor># </span>RocketMQ 的基本架构</h1></a><p><img src=https://googoo-s.github.io//statistic/asynccode-533.png width=auto alt></p><p>RocketMQ 一共有是个部分</p><ul><li><p>NameServer&ndash;发现</p></li><li><p>Broker&ndash;存</p></li><li><p>Producer生产者-发</p></li><li><p>Consumer消费者-收</p></li></ul><p><img src=https://googoo-s.github.io//statistic/asynccode-528.png width=auto alt></p><a href=#nameserver><h2 id=nameserver><span class=hanchor arialabel=Anchor># </span><strong>NameServer</strong></h2></a><p>NameServer 是一<strong>个无状态的服务器，角色类似于 Kafka使用的 Zookeeper</strong>，但比Zookeeper 更轻量。</p><ul><li><p>特点：</p><ul><li><p><strong>每个 NameServer 结点之间是相互独立，彼此没有任何信息交互</strong>。</p></li><li><p>Nameserver 被设计成几乎是无状态的，通过部署多个结点来标识自己是一个伪集群，<strong>Producer 在发送消息前从 NameServer 中获取 Topic 的路由信息也就是发往哪个 Broker，Consumer 也会定时从 NameServer 获取 Topic 的路由信息</strong>，Broker在启动时会向 NameServer 注册，并定时进行心跳连接，且定时同步维护的 Topic到 NameServer。</p></li></ul></li><li><p>功能主要有两个：</p><ul><li><p>和Broker 结点保持长连接。</p></li><li><p>维护 Topic 的路由信息</p></li></ul></li></ul><a href=#broker><h2 id=broker><span class=hanchor arialabel=Anchor># </span><strong>Broker</strong></h2></a><p>消息存储和中转角色，<strong>负责存储和转发消息。</strong></p><ul><li><p>Broker 内部维护着一个个 Consumer Queue，用来存储消息的索引，真正存储消息的地方<strong>是 CommitLog（日志文件）</strong>。</p></li><li><p>单个 Broker <strong>与所有的 Nameserver 保持着长连接和心跳</strong>，并会定时将 Topic 信息同步到 NameServer，<strong>和 NameServer 的通信底层是通过 Netty 实现的。</strong></p></li></ul><p><img src=https://googoo-s.github.io//statistic/asynccode-543.png width=auto alt></p><a href=#producer><h2 id=producer><span class=hanchor arialabel=Anchor># </span>Producer</h2></a><p>消息生产者，业务端负责发送消息，由用户自行实现和分布式部署。</p><ul><li><p><strong>Producer</strong>由用户进行分布式部署，消息由<strong>Producer</strong>通过多种负载均衡模式发送到<strong>Broker</strong>集群，发送低延时，支持快速失败。</p></li><li><p><strong>RocketMQ</strong> 提供了三种方式发送消息：同步、异步和单向</p><ul><li><p>同步发送 ：<strong>同步发送指消息发送方发出数据后会在收到接收方发回响应之后才发下一个数据包</strong>。一般用于重要通知消息，例如重要通知邮件、营销短信。</p></li><li><p>异步发送 ：<strong>异步发送指发送方发出数据后，不等接收方发回响应，接着发送下个数据包</strong>，<strong>有回调</strong>。一般用于可能链路耗时较长而对响应时间敏感的业务场景，例如用户视频上传后通知启动转码服务。</p></li><li><p>单向发送 ：单向发送是指只负责发送消息<strong>而不等待服务器回应且没有回调函数触发</strong>，适用于某些耗时非常短但对可靠性要求并不高的场景，例如<strong>日志收集</strong>。</p></li></ul></li></ul><a href=#consumer><h2 id=consumer><span class=hanchor arialabel=Anchor># </span><strong>Consumer</strong></h2></a><p>消息消费者，<strong>负责消费消息，一般是后台系统负责异步消费。</strong></p><ul><li><p>Consumer 也由用户部署，<strong>支持PUSH和PULL两种消费模式，支持集群消费和广播消费</strong> ，<strong>提供实时的消息订阅机制 。</strong></p></li><li><p>Pull ：拉取型消费者（Pull Consumer）<strong>主动从消息服务器拉取信息</strong>，只要批量拉取到消息，用户应用就会启动消费过程，所以 Pull 称为主动消费型。</p></li><li><p>Push ：推<strong>送型消费者（Push Consumer）封装了消息的拉取、消费进度和其他的内部维护工作</strong>，将消息到达时执行的回调接口留给用户应用程序来实现。所以 Push 称为被动消费类型**，但其实从实现上看还是从消息服务器中拉取消息，不同于 Pull 的是 Push 首先要注册消费监听器**，当监听器处触发后才开始消费消息</p></li></ul><a href=#如何保证消息的可用性可靠性不丢失呢><h1 id=如何保证消息的可用性可靠性不丢失呢><span class=hanchor arialabel=Anchor># </span>如何保证消息的可用性**/<strong>可靠性</strong>/**不丢失呢</h1></a><p>消息可能在哪些阶段丢失呢？可能会在这三个阶段发生丢失：生<strong>产阶段、存储阶 段、消费阶段。</strong></p><p><img src=https://googoo-s.github.io//statistic/asynccode-529.png width=auto alt></p><a href=#生产阶段><h2 id=生产阶段><span class=hanchor arialabel=Anchor># </span>生<strong>产阶段</strong></h2></a><p>在生产阶段，主<strong>要通过请求确认机制，来保证消息的可靠传递。</strong></p><ol><li><p>同步发送的时候，<strong>要注意处理响应结果和异常</strong>。如果返回响应OK，表示消息成功发送到了Broker，如果响应失败，或者发生其它异常，都应该重试。</p></li><li><p>异步发送的时候，<strong>应该在回调方法里检查，如果发送失败或者异常，都应该进行重试</strong>。</p></li><li><p>如果发生超时的情况，<strong>也可以通过查询日志的API，来检查是否在Broker存储成功</strong>。</p></li></ol><a href=#存储阶段><h2 id=存储阶段><span class=hanchor arialabel=Anchor># </span><strong>存储阶段</strong></h2></a><p>可以通过<strong>配置可靠性优先的 Broker 参数来避免因为宕机丢消息</strong>，简单说就是可靠性优先的场景都应该使用同步</p><ol><li><p><strong>消息只要持久化到CommitLog（日志文件）中</strong>，即使Broker宕机，<strong>未消费的消息也能重新恢复再消费</strong>。</p></li><li><p><strong>Broker的刷盘机制：同步刷盘和异步刷盘，<strong>不管哪种刷盘都可以保证消息</strong>一定存储在pagecache中（内存中）</strong>，<strong>但是同步刷盘更可靠</strong>，它是Producer发送消息后等数据持久化到磁盘之后再返回响应给Producer。</p></li></ol><p><img src=https://googoo-s.github.io//statistic/asynccode-530.png width=auto alt></p><ol start=3><li>Broker通过主从模式来保证高可用，<strong>Broker支持Master和Slave同步复制、Master和Slave异步复制模式</strong>，生产者的消息都是发送给Master，但是消费既可以从Master消费，也可以从Slave消费。<strong>同步复制模式可以保证即使Master宕机，消息肯定在Slave中有备份，保证了消息不会丢失。</strong></li></ol><a href=#消费阶段><h2 id=消费阶段><span class=hanchor arialabel=Anchor># </span><strong>消费阶段</strong></h2></a><p>Consumer保证消息成功消费的<strong>关键在于确认的时机</strong>，<strong>不要在收到消息后就立即发送消费确认，而是应该在执行完所有消费业务逻辑之后，再发送消费确</strong>认。</p><p>因 为消息队列维护了消费的位置，逻辑执行失败了，没有确认，再去队列拉取消</p><p>息，就还是之前的一条</p><a href=#如何处理消息重复的问题呢><h1 id=如何处理消息重复的问题呢><span class=hanchor arialabel=Anchor># </span>如何处理消息重复的问题呢</h1></a><p>处理消息重复问题，<strong>主要有业务端自己保证，主要的方式有两种：业务幂等和消息去重</strong>。</p><ul><li><p>业务幂等：<strong>第一种是保证消费逻辑的幂等性，也就是多次调用和一次调用的效果是一样的</strong>。这样一来，不管消息消费多少次，对业务都没有影响</p></li><li><p>消息去重：第二种是业务端，<strong>对重复的消息就不再消费了。这种方法，需要保证每 条消息都有一个惟一的编号，通常是业务相关的，比如订单号，消费的记录需要落库，而且需要保证和消息确认这一步的原子性。</strong></p></li></ul><a href=#如何处理消息积压><h1 id=如何处理消息积压><span class=hanchor arialabel=Anchor># </span>如何处理消息积压</h1></a><p>发生了消息积压，这时候就得想办法赶紧把积压的消息消费完，就得考虑提高消费能力，一般有两种办法</p><p><img src=https://googoo-s.github.io//statistic/asynccode-536.png width=auto alt></p><ul><li><p>消费者扩容 **：如果当前Topic的Message Queue的数量大于消费者数量，就可以对 消费者进行扩容，增加消费者，**来提高消费能力，尽快把积压的消息消费玩。</p></li><li><p>消息迁移Queue扩容 ：如果当前Topic的Message Queue的数量小于或者等于消费者数量，这种情况，再扩容消费者就没什么用，<strong>就得考虑扩容Message Queue</strong>。可以新建一个临时的Topic，<strong>临时的Topic多设置一些Message Queue，然后先用一些消费者把消费的数据丢到临时的Topic</strong>，因为不用业务处理，<strong>只是转发一下消息，还是很快的。接下来用扩容的消费者去消费新的Topic里的数据，消费完了之后，恢复原状。</strong></p></li></ul><p><img src=https://googoo-s.github.io//statistic/asynccode-546.png width=auto alt></p><a href=#顺序消息如何实现><h1 id=顺序消息如何实现><span class=hanchor arialabel=Anchor># </span>顺序消息如何实现</h1></a><p>顺序消息分为<strong>全局顺序消息和部分顺序消息</strong>，</p><ul><li><p>全局顺序消息指某个 Topic 下的所有消息都要保证顺序</p></li><li><p>部分顺序消息只要保证每一组消息被顺序消费即可</p></li></ul><p><img src=https://googoo-s.github.io//statistic/asynccode-545.png width=auto alt></p><a href=#部分顺序消息><h2 id=部分顺序消息><span class=hanchor arialabel=Anchor># </span>部分顺序消息</h2></a><ul><li><p><strong>生产端需要做到把同 ID 的消息发送到同一个 Message Queue</strong></p></li><li><p>在消费过程中，要做到从同一个Message Queue读取的消息顺序处理——<strong>消费端不能并发处理顺序消息，这样才能达到部分有序。</strong></p></li></ul><p><img src=https://googoo-s.github.io//statistic/asynccode-535.png width=auto alt></p><p>发送端使用 MessageQueueSelector 类来控制 把消息发往哪个 Message Queue 。</p><p><img src=https://googoo-s.github.io//statistic/asynccode-543.png width=auto alt></p><p><img src=https://googoo-s.github.io//statistic/asynccode-550.png width=auto alt></p><p>消费端通过使用 <strong>MessageListenerOrderly</strong> 来解决单 Message Queue 的消息被并发处理的问题</p><p><img src=https://googoo-s.github.io//statistic/asynccode-542.png width=auto alt></p><a href=#全局顺序消息><h2 id=全局顺序消息><span class=hanchor arialabel=Anchor># </span>全局顺序消息</h2></a><p>RocketMQ 默认情况下不保证顺序，</p><ul><li><p>比如创建一个 Topic ，默认八个写队列，八个读 队列，<strong>这时候一条消息可能写入任意一个队列里</strong>；</p></li><li><p>在数据的读取过程中，可能有多个 Consumer ，<strong>每个 Consumer 也可能启动多个线程并行处理，所以消息被哪个 Consumer 消费，被消费的顺序和写人的顺序是否一致是不确定的</strong></p></li></ul><p>要保证全局顺序消息， 需要先把 Topic 的<strong>读写队列数设置为 一</strong>，<strong>然后Producer Consumer 的并发设置，也要是一</strong>。简单来说，为了保证整个 Topic全局消息有序， 只能消除所有的并发处理，各部分都设置成单线程处理 ，这时候就完全牺牲 RocketMQ的高并发、高吞吐的特性了。</p><a href=#如何实现消息过滤><h1 id=如何实现消息过滤><span class=hanchor arialabel=Anchor># </span>如何实现消息过滤</h1></a><ul><li><p><strong>一种是在 Broker 端按照 Consumer 的去重逻辑进行过滤</strong>，这样做的好处是避免了无用的消息传输到 Consumer 端，缺点是加重了 Broker 的负担，实现起来相对复杂。</p></li><li><p>另一种是在 Consumer 端过滤，比如按照消息设置的 tag 去重，这样的好处是实现起来简单，<strong>缺点是有大量无用的消息到达了 Consumer 端只能丢弃不处理</strong></p></li></ul><p><img src=https://googoo-s.github.io//statistic/asynccode-531.png width=auto alt></p><ul><li><p>根据Tag过滤：这是最常见的一种，用起来高效简单</p><p><img src=https://googoo-s.github.io//statistic/asynccode-535.png width=auto alt></p></li><li><p>SQL 表达式过滤：SQL表达式过滤更加灵活</p></li></ul><p><img src=https://googoo-s.github.io//statistic/asynccode-550.png width=auto alt></p><ul><li>Filter Server 方式：最灵活，也是最复杂的一种方式，允许用户自定义函数进行 过滤</li></ul><a href=#延时消息如何实现><h1 id=延时消息如何实现><span class=hanchor arialabel=Anchor># </span>延时消息如何实现</h1></a><p>用户提交了一个订单，就可以发送一个延时消息，1h后去检查这个订单的状态，如果还是未付款就</p><p>取消订单释放库存。</p><p>RocketMQ是支持延时消息的，<strong>只需要在生产消息的时候设置消息的延时级别</strong>：</p><p><img src=https://googoo-s.github.io//statistic/asynccode-546.png width=auto alt></p><p>RocketMQ支持的延时级别是有限的</p><p><img src=https://googoo-s.github.io//statistic/asynccode-532.png width=auto alt></p><a href=#rocketmq怎么实现延时消息><h2 id=rocketmq怎么实现延时消息><span class=hanchor arialabel=Anchor># </span>RocketMQ怎么实现延时消息？</h2></a><p>简单，八个字： 临时存储 + 定时任务</p><p>Broker收到延时消息了，<strong>会先发送到主题（SCHEDULE_TOPIC_XXXX）的相应时间</strong></p><p><strong>段的Message Queue中</strong>，然后通过一个定时任务轮询这些队列，到期后，把消息投递到目标Topic的队列中，然后消费者就可以正常消费这些消息</p><p><img src=https://googoo-s.github.io//statistic/asynccode-538.png width=auto alt></p><a href=#如何实现分布式消息事务半消息><h1 id=如何实现分布式消息事务半消息><span class=hanchor arialabel=Anchor># </span>如何实现分布式消息事务？半消息</h1></a><p>半消息：是指暂时还不能被 Consumer 消费的消息，<strong>Producer 成功发送到 Broker 端 的消息，但是此消息被标记为 “暂不可投递” 状态</strong>，只有等 Producer 端执行完<strong>本地事务后经过二次确认了之后，Consumer 才能消费此条消息</strong></p><p><img src=https://googoo-s.github.io//statistic/asynccode-538.png width=auto alt></p><ol><li><p>Producer 向 broker 发送半消息</p></li><li><p>Producer 端收到响应，消息发送成功，此时消息是半消息，标记为 “不可投递” 状态，Consumer 消费不了。</p></li><li><p>Producer 端执行本地事务。</p></li><li><p>正常情况本地事务执行完成，Producer 向 Broker 发送 Commit/Rollback，如果是 Commit，Broker 端将半消息标记为正常消息，Consumer 可以消费，如果是Rollback，Broker 丢弃此消息。</p></li><li><p>异常情况，Broker 端迟迟等不到二次确认。在一定时间后，会查询所有的半消息，然后到 Producer 端查询半消息的执行情况。</p></li><li><p>Producer 端查询本地事务的状态</p></li><li><p>根据事务的状态提交 commit/rollback 到 broker 端。（5，6，7 是消息回查）</p></li><li><p>消费者段消费到消息之后，执行本地事务，执行本地事务。</p></li></ol><a href=#死信队列知道吗><h1 id=死信队列知道吗><span class=hanchor arialabel=Anchor># </span>死信队列知道吗？</h1></a><p>死信队列用于处理无法被正常消费的消息，即死信消息。</p><p>当一条消息初次消费失败，消息队列 <strong>RocketMQ</strong> 会自动进行消息重试；达到最大重试次数后，若消费依然失败，则表明消费者在正常情况下无法正确地消费该消 息，此时，消息队列 RocketMQ 不会立刻将消息丢弃，<strong>而是将其发送到该消费者对应的特殊队列中，该特殊队列称为死信队列</strong>。</p><p>死信消息的特点：</p><ol><li><p><strong>不会再被消费者正常消费。</strong></p></li><li><p>有效期与正常消息相同，均为 3 天，3 天后会被自动删除。因此，需要在死信消息产生后的 3 天内及时处理。</p></li></ol><p>死信队列的特点：</p><ol><li><p><strong>一个死信队列对应一个 Group ID， 而不是对应单个消费者实例。</strong></p></li><li><p><strong>如果一个 Group ID 未产生死信消息，消息队列 RocketMQ 不会为其创建相应的死信队列。</strong></p></li><li><p>一个死信队列包含了对应 Group ID 产生的所有死信消息**，不论该消息属于哪个 Topic。**</p></li></ol><p>RocketMQ 控制台提供对死信消息的查询、导出和重发的功能。</p><a href=#如何保证rocketmq-的高可用><h1 id=如何保证rocketmq-的高可用><span class=hanchor arialabel=Anchor># </span>如何保证RocketMQ 的高可用</h1></a><a href=#nameserver的高可用><h2 id=nameserver的高可用><span class=hanchor arialabel=Anchor># </span>NameServer的高可用</h2></a><p><strong>NameServer因为是无状态，且不相互通信的</strong>，所以只要集群部署就可以保证高可用。</p><p>RocketMQ的高可用主要是在体现在Broker的读和写的高可用，<strong>Broker的高可用是通过 集群 和 主从 实现的</strong></p><p><img src=https://googoo-s.github.io//statistic/asynccode-546.png width=auto alt></p><p>Broker可以配置两种角色：**Master和Slave，Master角色的Broker支持读和写，Slave角色的Broker只支持读，Master会向Slave同步消息。**也就是说Producer只能向Master角色的Broker写入消息，Cosumer可以从Master和Slave 角色的Broker读取消息。</p><a href=#broker读的高可用><h2 id=broker读的高可用><span class=hanchor arialabel=Anchor># </span>Broker读的高可用</h2></a><p>Consumer 的配置文件中，<strong>并不需要设置是从 Master 读还是从 Slave读，当 Master 不可用或者繁忙的</strong>时候， <strong>Consumer 的读请求会被自动切换到从 Slave</strong>。有了自动切换Consumer 这种机制，当一个 Master 角色的机器出现故障后，<strong>Consumer 仍然可以从Slave 读取消息，不影响 Consumer 读取消息，这就实现了读的高可用</strong>。</p><a href=#broker写的高可用><h2 id=broker写的高可用><span class=hanchor arialabel=Anchor># </span>Broker写的高可用</h2></a><p>如何达到发送端写的高可用性呢？<strong>在创建 Topic 的时候，把 Topic 的多个Message Queue 创建在多个 Broker 组上（相同 Broker 名称，不同 brokerId机器组成 Broker 组），这样当 Broker 组的 Master 不可用后，其他组Master 仍然可用， Producer 仍然可以发送消息 RocketMQ 目前还不支持把Slave自动转成 Master</strong> ，如果机器资源不足，需要把 Slave 转成 Master ，则要手动停止 Slave 色的 Broker ，更改配置文件，用新的配置文件启动 Broker</p><a href=#说下-rocketmq-的整体流程><h1 id=说下-rocketmq-的整体流程><span class=hanchor arialabel=Anchor># </span>说下 RocketMQ 的整体流程</h1></a><p>简单来说，RocketMQ是一个分布式消息队列，也就是 消息队列 + 分布式系统 。</p><ul><li><p>作为消息队列，它是 <strong>发 - 存 - 收 的一个模型，对应的就是Producer、Broker、 Cosumer</strong>；</p></li><li><p>作为分布式系统，<strong>它要有服务端、客户端、注册中心，对应的就是 Broker、Producer/Consumer、NameServer</strong></p></li></ul><p>所以我们看一下它主要的工作流程：RocketMQ由NameServer注册中心集群、Producer生产者集群、Consumer消费者集群和若干Broker（RocketMQ进程）组成：</p><ol><li><p>Broker在启动的时候去向所有的NameServer注册，并保持长连接，每30s发送一次心跳</p></li><li><p>Producer在发送消息的时候从NameServer获取Broker服务器地址，根据负载均衡算法选择一台服务器来发送消息</p></li><li><p>Conusmer消费消息的时候同样从NameServer获取Broker地址，然后主动拉取消息 来消费</p></li></ol><p><img src=https://googoo-s.github.io//statistic/asynccode-538.png width=auto alt></p><a href=#为啥rockermq-不使用zookeeper-作为注册中心><h2 id=为啥rockermq-不使用zookeeper-作为注册中心><span class=hanchor arialabel=Anchor># </span>为啥RockerMQ 不使用zookeeper 作为注册中心</h2></a><p>Kafka我们都知道采用Zookeeper作为注册中心——当然也开始逐渐去Zookeeper， RocketMQ不使用Zookeeper其实主要可能从这几方面来考虑：</p><ol><li><p>基于可用性的考虑，根据CAP理论，<strong>同时最多只能满足两个点，而Zookeeper满 足的是CP，也就是说Zookeeper并不能保证服务的可用性，Zookeeper在进行选举 的时候，整个选举的时间太长</strong>，期**间整个集群都处于不可用的状态，而这对于一 个注册中心来说肯定是不能接受的，**作为服务发现来说就应该是为可用性而设 计。</p></li><li><p>**基于性能的考虑，NameServer本身的实现非常轻量，而且可以通过增加机器的方式水平扩展，增加集群的抗压能力，而Zookeeper的写是不可扩展的，Zookeeper 要解决这个问题只能通过划分领域，**划分多个Zookeeper集群来解决，首先操作 起来太复杂，其次这样还是又违反了CAP中的A的设计，导致服务之间是不连通 的。</p></li><li><p>持久化的机制来带的问题，**ZooKeeper 的 ZAB 协议对每一个写请求，会在每个 ZooKeeper 节点上保持写一个事务日志，同时再加上定期的将内存数据镜像 （Snapshot）到磁盘来保证数据的一致性和持久性，而对于一个简单的服务发现 的场景来说，这其实没有太大的必要，这个实现方案太重了。**而且本身存储的数 据应该是高度定制化的。</p></li><li><p><strong>消息发送应该弱依赖注册中心，而RocketMQ的设计理念也正是基于此，生产者 在第一次发送消息的时候从NameServer获取到Broker地址后缓存到本地</strong>，如果 NameServer整个集群不可用，短时间内对于生产者和消费者并不会产生太大影 响。</p></li></ol><a href=#broker-是如何保存数据的><h1 id=broker-是如何保存数据的><span class=hanchor arialabel=Anchor># </span>Broker 是如何保存数据的</h1></a><p>RocketMQ主要的存储文件包括CommitLog文件、ConsumeQueue文件、Indexfile文件。</p><p><img src=https://googoo-s.github.io//statistic/asynccode-537.png width=auto alt></p><p>消息的整体设计</p><p><img src=https://googoo-s.github.io//statistic/asynccode-550.png width=auto alt></p><a href=#commitlog><h2 id=commitlog><span class=hanchor arialabel=Anchor># </span>CommitLog</h2></a><p><strong>消息主体以及元数据的存储主体，存储Producer端写入的消息主体内容,消息内容不是定长的。单个文件大小默认1G, 文件名长度为20位，左边补零，剩余为起始偏移量</strong>，比如00000000000000000000代表了第一个文件，起始偏移量为0，文件大小为1G=1073741824；当第一个文件写满了，第二个文件为00000000001073741824，起始偏移量为1073741824，以此类推。<strong>消息主要是顺序写入日志文件，当文件满了，写入下一个文件</strong>。</p><p>CommitLog文件保存于${Rocket_Home}/store/commitlog目录中，从图中我们可以 明显看出来文件名的偏移量，每个文件默认1G，写满后自动生成一个新的文件</p><p><img src=https://googoo-s.github.io//statistic/asynccode-543.png width=auto alt></p><a href=#consumequeue---可以看做是commitlog的索引文件><h2 id=consumequeue---可以看做是commitlog的索引文件><span class=hanchor arialabel=Anchor># </span><strong>ConsumeQueue - 可以看做是CommitLog的索引文件</strong></h2></a><p>消息消费队列，引入的目的主要是提高消息消费的性能，<strong>由于RocketMQ是基于主题topic的订阅模式，消息消费是针对主题进行的，如果要遍历commitlog文件中根据topic检索消息是非常低效的</strong>。</p><p><strong>Consumer即可根据ConsumeQueue来查找待消费的消息</strong>。其中，C<strong>onsumeQueue（逻辑消费队列）作为消费消息的索引，保存了指定Topic下的队列消息在CommitLog中的起始物理偏移量offset，消息大小size和消息Tag的 HashCode值</strong>。</p><p>ConsumeQueue文件可以看成是基于Topic的CommitLog索引文件，故</p><p>ConsumeQueue文件夹的组织方式如下：<strong>topic/queue/file三层组织结构，具体存储 路径为：$HOME/store/consumequeue/{topic}/{queueId}/{fileName}</strong>。</p><p>同样 ConsumeQueue文件采取定长设计，每一个条目共20个字节，分别为8字节的</p><p>CommitLog物理偏移量、4字节的消息长度、8字节tag hashcode，单个文件由30W个条目组成，可以像数组一样随机访问每一个条目，每个ConsumeQueue文 件大小约5.72M；</p><p><img src=https://googoo-s.github.io//statistic/asynccode-535.png width=auto alt></p><a href=#indexfile><h2 id=indexfile><span class=hanchor arialabel=Anchor># </span><strong>IndexFile</strong></h2></a><p><strong>IndexFile（索引文件）提供了一种可以通过key或时间区间来查询消息的方法</strong>。Index文件的存储位置是：$HOME \store\index${fileName}，文件名 fileName是以创建时的时间戳命名的，固定的单个IndexFile文件大小约为400M， 一个IndexFile可以保存 2000W个索引**，IndexFile的底层存储设计为在文件系统中**</p><p><strong>实现HashMap结构，故RocketMQ的索引文件其底层实现为hash索引</strong></p><p><img src=https://googoo-s.github.io//statistic/asynccode-540.png width=auto alt></p><a href=#总结><h2 id=总结><span class=hanchor arialabel=Anchor># </span>总结</h2></a><ul><li><p>RocketMQ采用的是混合型的存储结构，即为<strong>Broker单个实例下所有的队列共用一个日志数据文件（即为CommitLog）来存储。</strong></p></li><li><p>RocketMQ的混合型存储结构(多个Topic的消息实体内容都存储于一个CommitLog中) <strong>针对Producer和Consumer分别采用了数据和索引部分相分离的存储结构</strong>，Producer发 送消息至Broker端，然后Broker端使用同步或者异步的方式对消息刷盘持久化，保存至CommitLog中。</p></li><li><p>只要消息被刷盘持久化至磁盘文件CommitLog中，那么Producer发送的消息就不会丢失。正因为如此，Consumer也就肯定有机会去消费这条消息。</p><ul><li><p>当无法拉取到消息后，可以等下一次消息拉取，同时服务端也支持长轮询模式，</p></li><li><p>如果一个消息拉取请未拉取到消息，Broker允许等待30s的时间，只要这段时间内有新消息到达，将直接返回给消费端。</p><ul><li>这里，RocketMQ的具体做法是，<strong>使用Broker端的后台服务线程— ReputMessageService不停地分发请求并异步构建ConsumeQueue（逻辑消费队列）和 IndexFile（索引文件）数据。</strong></li></ul></li></ul></li></ul><a href=#rocketmq-怎么对文件进行读写的><h1 id=rocketmq-怎么对文件进行读写的><span class=hanchor arialabel=Anchor># </span>RocketMQ 怎么对文件进行读写的</h1></a><p>RocketMQ对文件的读写巧妙地利用了操作系统的一些高效文件读写方式—— PageCache 、 顺序读写 、 零拷贝</p><a href=#pagecache顺序读取><h2 id=pagecache顺序读取><span class=hanchor arialabel=Anchor># </span>PageCache、顺序读取</h2></a><ul><li>ConsumeQueue逻辑消费队列存储的数据较少，并且是顺序读取，在page cache机制的预读取作用下，Consume Queue文件的读性能几乎接近读内存，即使在有消息堆积情况下也不会影响性能。</li></ul><p>而对于<strong>CommitLog消息存储的日志数据文件来说，读取消息内容时候会产生较多的随机访问读取</strong>，严重影响性能。</p><ul><li><p>如果选择<strong>合适的系统IO调度算法</strong>，比如设置调度算法为“Deadline”（此时块存储采用SSD的话），随机读的性能也会有所提升。</p></li><li><p><strong>页缓存（PageCache)是OS对文件的缓存</strong>，用于加速对文件的读写。一般来说，程序对文件进行顺序读写的速度几乎接近于内存的读写速度，主要原因就是由于OS使用<strong>PageCache机制对读写访问操作进行了性能优化</strong>，将一部分的内存用作PageCache**。**</p><ul><li><p><strong>对于数据的写入，OS会先写入至Cache内，随后通过异步的方式由pdflush内核线程将Cache内的数据刷盘至物理磁盘上</strong>。</p></li><li><p>对于数据的读取，如果一次读取文件时出现未命中PageCache的情况，OS从物理磁盘上访问读取文件的同时，<strong>会顺序对其他相邻块的数据文件进行预读取</strong>。</p></li></ul></li></ul><a href=#零拷贝><h2 id=零拷贝><span class=hanchor arialabel=Anchor># </span>零拷贝</h2></a><p>另外**，RocketMQ主要通过MappedByteBuffer对文件进行读写操作**。</p><ul><li>其中，利用了NIO中的FileChannel模型<strong>将磁盘上的物理文件直接映射到用户态的内存地址中</strong>（这种Mmap的方式减少了传统IO，将磁盘文件数据在操作系统内核地址空间的缓冲区，和用户应用程序地址空间的缓冲区之间来回进行拷贝的性能开销），<strong>将对文件的操作转化为直接对内存地址进行操作</strong>，从而极大地提高了文件的读写效率（<strong>正因为需要使用内存映射机制，故RocketMQ的文件存储都使用定长结构来存储，方便一次将整个文件映射至内存</strong>）。</li></ul><a href=#啥是零拷贝><h3 id=啥是零拷贝><span class=hanchor arialabel=Anchor># </span>啥是零拷贝</h3></a><p>在操作系统中，使用传统的方式，数据需要经历几次拷贝，还要经历用户态/内核态切换。</p><p><img src=https://googoo-s.github.io//statistic/asynccode-539.png width=auto alt></p><ol><li><p>从磁盘复制数据到内核态内存；</p></li><li><p>从内核态内存复制到用户态内存；</p></li><li><p>然后从用户态内存复制到网络驱动的内核态内存；</p></li><li><p>最后是从网络驱动的内核态内存复制到网卡中进行传输。</p></li></ol><p>可以通过零拷贝的方式，<strong>减少用户态与内核态的上下文切换和内存拷贝次数</strong>，用来提升I/O的性能。零拷贝比较常见的实现方式是<strong>mmap</strong>，这种机制在Java中是通过MappedByteBuffer实现的</p><p><img src=https://googoo-s.github.io//statistic/asynccode-538.png width=auto alt></p><a href=#消息刷盘怎么实现的呢><h1 id=消息刷盘怎么实现的呢><span class=hanchor arialabel=Anchor># </span>消息刷盘怎么实现的呢</h1></a><p>RocketMQ提供了两种刷盘策略：同步刷盘和异步刷盘</p><ul><li><p>同步刷盘：<strong>在消息达到Broker的内存之后，必须刷到commitLog日志文件中才算成功</strong>，然后返回Producer数据已经发送成功。</p></li><li><p>异步刷盘：<strong>异步刷盘是指消息达到Broker内存后就返回Producer数据已经发送成功，会唤醒一个线程去将数据持久化到CommitLog日志文件中。</strong></p></li></ul><p><strong>Broker</strong> 在消息的存取时直接操作的是内存（内存映射文件），这可以提供系统的吞吐量，但是无法避免机器掉电时数据丢失，所以需要持久化到磁盘中。</p><p>刷盘的最终实现都是使用<strong>NIO</strong>中的 MappedByteBuffer.force() 将映射区的数据写入到磁盘，</p><ul><li><p>如果是同步刷盘的话，在<strong>Broker把消息写到CommitLog映射区后</strong>，就会等待写入完成。</p></li><li><p>异步而言，只是唤醒对应的线程，不保证执行的时机，流程如图所示。</p></li></ul><p><img src=https://googoo-s.github.io//statistic/asynccode-534.png width=auto alt></p><a href=#rocketmq-的负载均衡是如何实现的><h1 id=rocketmq-的负载均衡是如何实现的><span class=hanchor arialabel=Anchor># </span><strong>RocketMQ</strong> 的负载均衡是如何实现的</h1></a><p>RocketMQ中的负载均衡都在Client端完成，具体来说的话，主要可以分为Producer端发送消息时候的负载均衡和Consumer端订阅消息的负载均衡。</p><a href=#producer的负载均衡><h2 id=producer的负载均衡><span class=hanchor arialabel=Anchor># </span><strong>Producer</strong>的负载均衡</h2></a><p>Producer端在发送消息的时候，会先根据Topic找到指定的TopicPublishInfo，<strong>在获取了</strong></p><p><strong>TopicPublishInfo路由信息后</strong>，RocketMQ的客户端在默认方式下 selectOneMessageQueue()方法会从TopicPublishInfo中的messageQueueList中选择一个队列（MessageQueue）进行发送消息。具这里有一个sendLatencyFaultEnable开关变量，如果开启，在随机递增取模的基础上，再过滤掉not available的Broker代理。</p><p><img src=https://googoo-s.github.io//statistic/asynccode-548.png width=auto alt></p><a href=#consumer的负载均衡><h2 id=consumer的负载均衡><span class=hanchor arialabel=Anchor># </span><strong>Consumer</strong>的负载均衡</h2></a><p>消息消费队列在同一消费组不同消费者之间的负载均衡，其核心设计理念是在一个 消息消费队列在同一时间只允许被同一消费组内的一个消费者消费，一个消息消费者能同时消费多个消息队列。</p><p>在RocketMQ中，C<strong>onsumer端的两种消费模式（Push/Pull）都是基于拉模式来获取消 息的</strong>，</p><ul><li><p>而在<strong>Push模式只是对pull模式的一种封装</strong>，其本质实现为消息拉取线程在从服务器拉取到一批消息后，然后提交到消息消费线程池后，</p><ul><li><p>又“马不停蹄”的继续向服务器再次尝试拉取消息。</p></li><li><p>如果未拉取到消息，则延迟一下又继续拉取。</p></li></ul></li><li><p>在两种基于拉模式的消费方式（Push/Pull）中，**均需要Consumer端知道从Broker端的哪一个消息队列中去获取消息。**因此，有必要在Consumer端来做负载均衡，即Broker端中多个MessageQueue分配给同一个ConsumerGroup中的哪些Consumer消费。</p></li></ul><ol><li>Consumer端的心跳包发送</li></ol><p>它就会通过定时任务不断地向RocketMQ集群中的所有Broker实例发送心跳包（其中包含了，消息消费分组名称、订阅关系集合、消息通信模式和客户端id的值等信息）。B<strong>roker端在收到Consumer的心跳消息后，会将它维护在 ConsumerManager的本地缓存变量—consumerTable</strong>，同时并将封装后的客户端网络通道信息保存在本地缓存变量—channelInfoTable中，为之后做Consumer端的负载均衡提供可以依据的元数据信息。</p><ol start=2><li>Consumer端实现负载均衡的核心类—RebalanceImpl</li></ol><p>在Consumer实例的启动流程中的启动MQClientInstance实例部分，<strong>会完成负载均衡服务线程—RebalanceService的启动</strong>（每隔20s执行一次）。</p><p>通过查看源码可以发现，<strong>RebalanceService线程的run()方法最终调用的是RebalanceImpl类的rebalanceByTopic()方法，这个方法是实现Consumer端负载均 衡的核心</strong>。</p><p>rebalanceByTopic()方法会根据消费者通信类型为“广播模式”还是“集群模式”做不同的逻辑处理。这里主要来看下集群模式下的主要处理流程：</p><p><img src=https://googoo-s.github.io//statistic/asynccode-544.png width=auto alt></p><ul><li><p>从rebalanceImpl实例的本地缓存变量—topicSubscribeInfoTable中**，获取该Topic主题下的消息消费队列集合（mqSet）**</p></li><li><p>根据topic和consumerGroup为参数调用mQClientFactory.findConsumerIdList()方法向Broker端发送通信请求，获取该消费组下消费者Id列表；</p></li><li><p>先对Topic下的消息消费队列、消费者Id排序，然后用消息队列分配策略算法（默认为：消息队列的平均分配算法），计算出待拉取的消息队列。</p><ul><li>这里的平均分配算法，类似于分页的算法，将所有MessageQueue排好序类似于记录，将所有消费端Consumer排好序类似页数，并求出每一页需要包含的平均size和每个页面记录的范围range，最后遍历整个range而计算出当前Consumer端应该分配到的的MessageQueue</li></ul></li></ul><p><img src=https://googoo-s.github.io//statistic/asynccode-544.png width=auto alt></p><ul><li>然后，调用updateProcessQueueTableInRebalance()方法，具体的做法是，<strong>先将分配到的消息队列集合（mqSet）与processQueueTable做一个过滤比对</strong></li></ul><p><img src=https://googoo-s.github.io//statistic/asynccode-541.png width=auto alt></p><ul><li><p>上图中processQueueTable标注的红色部分，表示与分配到的消息队列集合mqSet互不包含。将这些队列设置Dropped属性为true，然后查看这些队列是否可以移除出processQueueTable缓存变量，这里具体执行removeUnnecessaryMessageQueue()方法，即每隔1s 查看是否可以获取当前消费处理队列的锁，拿到的话返回true。 如果等待1s后，仍然拿不到当前消费处理队列的锁则返回false。如果返回true， 则从processQueueTable缓存变量中移除对应的Entry；</p></li><li><p>上图中processQueueTable的绿色部分，表示与分配到的消息队列集合mqSet的交 集。判断该ProcessQueue是否已经过期了，在Pull模式的不用管，如果是Push模式 的，设置Dropped属性为true，并且调用removeUnnecessaryMessageQueue()方法，像上面一样尝试移除Entry；</p></li><li><p>最后，为过滤后的消息队列集合（mqSet）中的每个MessageQueue创建一个 ProcessQueue对象并存入RebalanceImpl的processQueueTable队列中（其中调用RebalanceImpl实例的computePullFromWhere(MessageQueue mq)方法获取该MessageQueue对象的下一个进度消费值offset，随后填充至接下来要创建的pullRequest对象属性中），并创建拉取请求对象—pullRequest添加到拉取列表—pullRequestList中，最后执行dispatchPullRequest()方法，将Pull消息的请求对象PullRequest依次放入PullMessageService服务线程的阻塞队列pullRequestQueue中，待该服务线程取出后向Broker端发起Pull消息的请求。其中，可以重点对比下，RebalancePushImpl和RebalancePullImpl两个实现类的dispatchPullRequest()方法不同，RebalancePullImpl类里面的该方法为空。</p></li></ul><a href=#rocketmq消息长轮训><h2 id=rocketmq消息长轮训><span class=hanchor arialabel=Anchor># </span>RocketMQ消息长轮训</h2></a><p>所谓的长轮询，就是Consumer 拉取消息**，如果对应的 Queue 如果没有数据，Broker不会立即返回，而是把 PullReuqest hold起**来，等待 queue 有了消息后，或者长轮询阻塞时间到了，<strong>再重新处理该 queue 上的所有 PullRequest</strong>。</p><p><img src=https://googoo-s.github.io//statistic/asynccode-549.png width=auto alt></p><ul><li>PullMessageProcessor#processRequest</li></ul><p><img src=https://googoo-s.github.io//statistic/asynccode-544.png width=auto alt></p><p>挂起的请求，有一个服务线程会不停地检查，看queue中是否有数据，或者超时。</p><ul><li>PullRequestHoldService#run()</li></ul><p><img src=https://googoo-s.github.io//statistic/asynccode-549.png width=auto alt></p></article><hr><div class=page-end id=footer><div class=backlinks-container><h3>Backlinks</h3><ul class=backlinks><li>No backlinks found</li></ul></div><div><script src=https://cdn.jsdelivr.net/npm/d3@6.7.0/dist/d3.min.js integrity="sha256-+7jaYCp29O1JusNWHaYtgUn6EhuP0VaFuswhNV06MyI=" crossorigin=anonymous></script><h3>Interactive Graph</h3><div id=graph-container></div><style>:root{--g-node:var(--secondary);--g-node-active:var(--primary);--g-node-inactive:var(--visited);--g-link:var(--outlinegray);--g-link-active:#5a7282}</style><script src=https://googoo-s.github.io/js/graph.6579af7b10c818dbd2ca038702db0224.js></script></div></div><div id=contact_buttons><footer><p>Made by googoo-s using <a href=https://github.com/jackyzha0/quartz>Quartz</a>, © 2023</p><ul><li><a href=https://googoo-s.github.io/>Home</a></li><li><a href=https://github.com/googoo-s>GitHub</a></li></ul></footer></div></div></body></html>