<!doctype html><html lang=en><head><meta charset=utf-8><meta name=description content="4.4 TCP 半连接队列和全连接队列 网上许多博客针对增大 TCP 半连接队列和全连接队列的方式如下：
 增大 TCP 半连接队列的方式是增大 /proc/sys/net/ipv4/tcp_max_syn_backlog； 增大 TCP 全连接队列的方式是增大 listen() 函数中的 backlog；  这里先跟大家说下，上面的方式都是不准确的。
 “你怎么知道不准确？”"><meta property="og:title" content><meta property="og:description" content="4.4 TCP 半连接队列和全连接队列 网上许多博客针对增大 TCP 半连接队列和全连接队列的方式如下：
 增大 TCP 半连接队列的方式是增大 /proc/sys/net/ipv4/tcp_max_syn_backlog； 增大 TCP 全连接队列的方式是增大 listen() 函数中的 backlog；  这里先跟大家说下，上面的方式都是不准确的。
 “你怎么知道不准确？”"><meta property="og:type" content="website"><meta property="og:image" content="https://googoo-s.github.io/icon.png"><meta property="og:url" content="https://googoo-s.github.io/%E7%BD%91%E7%BB%9C/3_tcp/tcp_queue/"><meta property="og:width" content="200"><meta property="og:height" content="200"><meta name=twitter:card content="summary"><meta name=twitter:title content><meta name=twitter:description content="4.4 TCP 半连接队列和全连接队列 网上许多博客针对增大 TCP 半连接队列和全连接队列的方式如下：
 增大 TCP 半连接队列的方式是增大 /proc/sys/net/ipv4/tcp_max_syn_backlog； 增大 TCP 全连接队列的方式是增大 listen() 函数中的 backlog；  这里先跟大家说下，上面的方式都是不准确的。
 “你怎么知道不准确？”"><meta name=twitter:image content="https://googoo-s.github.io/icon.png"><title>googoo-s 😄😸😎</title><meta name=viewport content="width=device-width,initial-scale=1"><link rel="shortcut icon" type=image/png href=https://googoo-s.github.io//icon.png><link href=https://googoo-s.github.io/styles.19109a40042e9f0e72e952fda4442a34.min.css rel=stylesheet><link href=https://googoo-s.github.io/styles/_light_syntax.86a48a52faebeaaf42158b72922b1c90.min.css rel=stylesheet id=theme-link><script src=https://googoo-s.github.io/js/darkmode.953af745b0f9342644d632fc167f3727.min.js></script>
<script src=https://googoo-s.github.io/js/util.00639692264b21bc3ee219733d38a8be.min.js></script>
<link rel=preload href=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css as=style onload='this.onload=null,this.rel="stylesheet"' integrity=sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js integrity=sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/contrib/copy-tex.min.js integrity=sha384-ww/583aHhxWkz5DEVn6OKtNiIaLi2iBRNZXfJRiY1Ai7tnJ9UXpEsyvOITVpTl4A crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/@floating-ui/core@1.2.1></script>
<script src=https://cdn.jsdelivr.net/npm/@floating-ui/dom@1.2.1></script>
<script defer src=https://googoo-s.github.io/js/popover.aa9bc99c7c38d3ae9538f218f1416adb.min.js></script>
<script defer src=https://googoo-s.github.io/js/code-title.ce4a43f09239a9efb48fee342e8ef2df.min.js></script>
<script defer src=https://googoo-s.github.io/js/clipboard.2913da76d3cb21c5deaa4bae7da38c9f.min.js></script>
<script defer src=https://googoo-s.github.io/js/callouts.7723cac461d613d118ee8bb8216b9838.min.js></script>
<script>const SEARCH_ENABLED=!1,LATEX_ENABLED=!0,PRODUCTION=!0,BASE_URL="https://googoo-s.github.io/",fetchData=Promise.all([fetch("https://googoo-s.github.io/indices/linkIndex.0be9ea5cc5a709de699463fae2ac30a8.min.json").then(e=>e.json()).then(e=>({index:e.index,links:e.links})),fetch("https://googoo-s.github.io/indices/contentIndex.0d1fcd0ce55147328e47ced9d4063f41.min.json").then(e=>e.json())]).then(([{index:e,links:t},n])=>({index:e,links:t,content:n})),render=()=>{const e=new URL(BASE_URL),t=e.pathname,n=window.location.pathname,s=t==n;addCopyButtons(),addTitleToCodeBlocks(),addCollapsibleCallouts(),initPopover("https://googoo-s.github.io",!0);const o=document.getElementById("footer");if(o){const e=document.getElementById("graph-container");if(!e)return requestAnimationFrame(render);e.textContent="";const t=s&&!0;drawGraph("https://googoo-s.github.io",t,[{"/moc":"#4388cc"}],t?{centerForce:1,depth:-1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.5,linkDistance:1,opacityScale:3,repelForce:1,scale:1.4}:{centerForce:1,depth:1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.6,linkDistance:1,opacityScale:3,repelForce:2,scale:1.2})}var i=document.getElementsByClassName("mermaid");i.length>0&&import("https://unpkg.com/mermaid@9/dist/mermaid.esm.min.mjs").then(e=>{e.default.init()});function a(n){const e=n.target,t=e.className.split(" "),s=t.includes("broken"),o=t.includes("internal-link");plausible("Link Click",{props:{href:e.href,broken:s,internal:o,graph:!1}})}const r=document.querySelectorAll("a");for(link of r)link.className.includes("root-title")&&link.addEventListener("click",a,{once:!0})},init=(e=document)=>{addCopyButtons(),addTitleToCodeBlocks(),renderMathInElement(e.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],macros:{'’':"'"},throwOnError:!1})}</script><script type=module>
    import { attachSPARouting } from "https:\/\/googoo-s.github.io\/js\/router.d6fe6bd821db9ea97f9aeefae814d8e7.min.js"
    attachSPARouting(init, render)
  </script><script defer data-domain=googoo-s.github.io src=https://plausible.io/js/script.js></script>
<script>window.plausible=window.plausible||function(){(window.plausible.q=window.plausible.q||[]).push(arguments)}</script></head><body><div id=search-container><div id=search-space><input autocomplete=off id=search-bar name=search type=text aria-label=Search placeholder="Search for something..."><div id=results-container></div></div></div><script src=https://cdn.jsdelivr.net/npm/flexsearch@0.7.21/dist/flexsearch.bundle.js integrity="sha256-i3A0NZGkhsKjVMzFxv3ksk0DZh3aXqu0l49Bbh0MdjE=" crossorigin=anonymous defer></script>
<script defer src=https://googoo-s.github.io/js/full-text-search.e6e2e0c213187ca0c703d6e2c7a77fcd.min.js></script><div class=singlePage><header><h1 id=page-title><a class=root-title href=https://googoo-s.github.io/>googoo-s 😄😸😎</a></h1><div class=spacer></div><div id=search-icon><p>Search</p><svg tabindex="0" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search Icon</title><desc id="desc">Icon to open search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"/><circle cx="8" cy="8" r="7"/></g></svg></div><div class=darkmode><input class=toggle id=darkmode-toggle type=checkbox tabindex=-1>
<label id=toggle-label-light for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="dayIcon" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35"><title>Light Mode</title><path d="M6 17.5C6 16.672 5.328 16 4.5 16h-3C.672 16 0 16.672.0 17.5S.672 19 1.5 19h3C5.328 19 6 18.328 6 17.5zM7.5 26c-.414.0-.789.168-1.061.439l-2 2C4.168 28.711 4 29.086 4 29.5 4 30.328 4.671 31 5.5 31c.414.0.789-.168 1.06-.44l2-2C8.832 28.289 9 27.914 9 27.5 9 26.672 8.329 26 7.5 26zm10-20C18.329 6 19 5.328 19 4.5v-3C19 .672 18.329.0 17.5.0S16 .672 16 1.5v3C16 5.328 16.671 6 17.5 6zm10 3c.414.0.789-.168 1.06-.439l2-2C30.832 6.289 31 5.914 31 5.5 31 4.672 30.329 4 29.5 4c-.414.0-.789.168-1.061.44l-2 2C26.168 6.711 26 7.086 26 7.5 26 8.328 26.671 9 27.5 9zM6.439 8.561C6.711 8.832 7.086 9 7.5 9 8.328 9 9 8.328 9 7.5c0-.414-.168-.789-.439-1.061l-2-2C6.289 4.168 5.914 4 5.5 4 4.672 4 4 4.672 4 5.5c0 .414.168.789.439 1.06l2 2.001zM33.5 16h-3c-.828.0-1.5.672-1.5 1.5s.672 1.5 1.5 1.5h3c.828.0 1.5-.672 1.5-1.5S34.328 16 33.5 16zM28.561 26.439C28.289 26.168 27.914 26 27.5 26c-.828.0-1.5.672-1.5 1.5.0.414.168.789.439 1.06l2 2C28.711 30.832 29.086 31 29.5 31c.828.0 1.5-.672 1.5-1.5.0-.414-.168-.789-.439-1.061l-2-2zM17.5 29c-.829.0-1.5.672-1.5 1.5v3c0 .828.671 1.5 1.5 1.5s1.5-.672 1.5-1.5v-3C19 29.672 18.329 29 17.5 29zm0-22C11.71 7 7 11.71 7 17.5S11.71 28 17.5 28 28 23.29 28 17.5 23.29 7 17.5 7zm0 18c-4.136.0-7.5-3.364-7.5-7.5s3.364-7.5 7.5-7.5 7.5 3.364 7.5 7.5S21.636 25 17.5 25z"/></svg></label><label id=toggle-label-dark for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="nightIcon" viewBox="0 0 100 100" style="enable-background='new 0 0 100 100'"><title>Dark Mode</title><path d="M96.76 66.458c-.853-.852-2.15-1.064-3.23-.534-6.063 2.991-12.858 4.571-19.655 4.571C62.022 70.495 50.88 65.88 42.5 57.5 29.043 44.043 25.658 23.536 34.076 6.47c.532-1.08.318-2.379-.534-3.23-.851-.852-2.15-1.064-3.23-.534-4.918 2.427-9.375 5.619-13.246 9.491-9.447 9.447-14.65 22.008-14.65 35.369.0 13.36 5.203 25.921 14.65 35.368s22.008 14.65 35.368 14.65c13.361.0 25.921-5.203 35.369-14.65 3.872-3.871 7.064-8.328 9.491-13.246C97.826 68.608 97.611 67.309 96.76 66.458z"/></svg></label></div></header><article><p class=meta>Last updated
Unknown</p><ul class=tags></ul><aside class=mainTOC><details><summary>Table of Contents</summary><nav id=TableOfContents><ol><li><a href=#44-tcp-半连接队列和全连接队列>4.4 TCP 半连接队列和全连接队列</a><ol><li><a href=#什么是-tcp-半连接队列和全连接队列>什么是 TCP 半连接队列和全连接队列？</a></li><li><a href=#实战---tcp-全连接队列溢出>实战 - TCP 全连接队列溢出</a></li><li><a href=#实战---tcp-半连接队列溢出>实战 - TCP 半连接队列溢出</a></li><li><a href=#读者问答>读者问答</a></li><li><a href=#最后>最后</a></li></ol></li></ol></nav></details></aside><a href=#44-tcp-半连接队列和全连接队列><h1 id=44-tcp-半连接队列和全连接队列><span class=hanchor arialabel=Anchor># </span>4.4 TCP 半连接队列和全连接队列</h1></a><p>网上许多博客针对增大 TCP 半连接队列和全连接队列的方式如下：</p><ul><li>增大 TCP 半连接队列的方式是增大 /proc/sys/net/ipv4/tcp_max_syn_backlog；</li><li>增大 TCP 全连接队列的方式是增大 listen() 函数中的 backlog；</li></ul><p>这里先跟大家说下，<strong>上面的方式都是不准确的。</strong></p><blockquote><p>“你怎么知道不准确？”</p></blockquote><p>很简单呀，因为我做了实验和看了 TCP 协议栈的内核源码，发现要增大这两个队列长度，不是简简单单增大某一个参数就可以的。</p><p>接下来，就会以<strong>实战 + 源码分析，带大家解密 TCP 半连接队列和全连接队列。</strong></p><blockquote><p>“源码分析，那不是劝退吗？我们搞 Java 的看不懂呀”</p></blockquote><p>放心，本文的源码分析不会涉及很深的知识，因为都被我删减了，你只需要会条件判断语句 if、左移右移操作符、加减法等基本语法，就可以看懂。</p><p>另外，不仅有源码分析，还会介绍 Linux 排查半连接队列和全连接队列的命令。</p><blockquote><p>“哦？似乎很有看头，那我姑且看一下吧！”</p></blockquote><p>行，没有被劝退的小伙伴，值得鼓励，下面这图是本文的提纲：</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/2.jpg width=auto alt=本文提纲></p><hr><a href=#什么是-tcp-半连接队列和全连接队列><h2 id=什么是-tcp-半连接队列和全连接队列><span class=hanchor arialabel=Anchor># </span>什么是 TCP 半连接队列和全连接队列？</h2></a><p>在 TCP 三次握手的时候，Linux 内核会维护两个队列，分别是：</p><ul><li>半连接队列，也称 SYN 队列；</li><li>全连接队列，也称 accept 队列；</li></ul><p>服务端收到客户端发起的 SYN 请求后，<strong>内核会把该连接存储到半连接队列</strong>，并向客户端响应 SYN+ACK，接着客户端会返回 ACK，服务端收到第三次握手的 ACK 后，<strong>内核会把连接从半连接队列移除，然后创建新的完全的连接，并将其添加到 accept 队列，等待进程调用 accept 函数时把连接取出来。</strong></p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/3.jpg width=auto alt=半连接队列与全连接队列></p><p>不管是半连接队列还是全连接队列，都有最大长度限制，超过限制时，内核会直接丢弃，或返回 RST 包。</p><hr><a href=#实战---tcp-全连接队列溢出><h2 id=实战---tcp-全连接队列溢出><span class=hanchor arialabel=Anchor># </span>实战 - TCP 全连接队列溢出</h2></a><blockquote><p>如何知道应用程序的 TCP 全连接队列大小？</p></blockquote><p>在服务端可以使用 <code>ss</code> 命令，来查看 TCP 全连接队列的情况：</p><p>但需要注意的是 <code>ss</code> 命令获取的 <code>Recv-Q/Send-Q</code> 在「LISTEN 状态」和「非 LISTEN 状态」所表达的含义是不同的。从下面的内核代码可以看出区别：</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/4.jpg width=auto alt></p><p>在「LISTEN 状态」时，<code>Recv-Q/Send-Q</code> 表示的含义如下：</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/5.jpg width=auto alt></p><ul><li>Recv-Q：当前全连接队列的大小，也就是当前已完成三次握手并等待服务端 <code>accept()</code> 的 TCP 连接；</li><li>Send-Q：当前全连接最大队列长度，上面的输出结果说明监听 8088 端口的 TCP 服务，最大全连接长度为 128；</li></ul><p>在「非 LISTEN 状态」时，<code>Recv-Q/Send-Q</code> 表示的含义如下：</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/6.jpg width=auto alt></p><ul><li>Recv-Q：已收到但未被应用进程读取的字节数；</li><li>Send-Q：已发送但未收到确认的字节数；</li></ul><blockquote><p>如何模拟 TCP 全连接队列溢出的场景？</p></blockquote><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/7.jpg width=auto alt=测试环境></p><p>实验环境：</p><ul><li>客户端和服务端都是 CentOs 6.5 ，Linux 内核版本 2.6.32</li><li>服务端 IP 192.168.3.200，客户端 IP 192.168.3.100</li><li>服务端是 Nginx 服务，端口为 8088</li></ul><p>这里先介绍下 <code>wrk</code> 工具，它是一款简单的 HTTP 压测工具，它能够在单机多核 CPU 的条件下，使用系统自带的高性能 I/O 机制，通过多线程和事件模式，对目标机器产生大量的负载。</p><p>本次模拟实验就使用 <code>wrk</code> 工具来压力测试服务端，发起大量的请求，一起看看服务端 TCP 全连接队列满了会发生什么？有什么观察指标？</p><p>客户端执行 <code>wrk</code> 命令对服务端发起压力测试，并发 3 万个连接：</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/8.jpg width=auto alt></p><p>在服务端可以使用 <code>ss</code> 命令，来查看当前 TCP 全连接队列的情况：</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/9.jpg width=auto alt></p><p>其间共执行了两次 ss 命令，从上面的输出结果，可以发现当前 TCP 全连接队列上升到了 129 大小，超过了最大 TCP 全连接队列。</p><p><strong>当超过了 TCP 最大全连接队列，服务端则会丢掉后续进来的 TCP 连接</strong>，丢掉的 TCP 连接的个数会被统计起来，我们可以使用 netstat -s 命令来查看：</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/10.jpg width=auto alt></p><p>上面看到的 41150 times ，表示全连接队列溢出的次数，注意这个是累计值。可以隔几秒钟执行下，如果这个数字一直在增加的话肯定全连接队列偶尔满了。</p><p>从上面的模拟结果，可以得知，<strong>当服务端并发处理大量请求时，如果 TCP 全连接队列过小，就容易溢出。发生 TCP 全连接队溢出的时候，后续的请求就会被丢弃，这样就会出现服务端请求数量上不去的现象。</strong></p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/11.jpg width=auto alt=全连接队列溢出></p><blockquote><p>Linux 有个参数可以指定当 TCP 全连接队列满了会使用什么策略来回应客户端。</p></blockquote><p>实际上，丢弃连接只是 Linux 的默认行为，我们还可以选择向客户端发送 RST 复位报文，告诉客户端连接已经建立失败。</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/12.jpg width=auto alt></p><p>tcp_abort_on_overflow 共有两个值分别是 0 和 1，其分别表示：</p><ul><li>0 ：如果全连接队列满了，那么 server 扔掉 client 发过来的 ack ；</li><li>1 ：如果全连接队列满了，server 发送一个 <code>reset</code> 包给 client，表示废掉这个握手过程和这个连接；</li></ul><p>如果要想知道客户端连接不上服务端，是不是服务端 TCP 全连接队列满的原因，那么可以把 tcp_abort_on_overflow 设置为 1，这时如果在客户端异常中可以看到很多 <code>connection reset by peer</code> 的错误，那么就可以证明是由于服务端 TCP 全连接队列溢出的问题。</p><p>通常情况下，应当把 tcp_abort_on_overflow 设置为 0，因为这样更有利于应对突发流量。</p><p>举个例子，当 TCP 全连接队列满导致服务器丢掉了 ACK，与此同时，客户端的连接状态却是 ESTABLISHED，进程就在建立好的连接上发送请求。只要服务器没有为请求回复 ACK，请求就会被多次<strong>重发</strong>。如果服务器上的进程只是<strong>短暂的繁忙造成 accept 队列满，那么当 TCP 全连接队列有空位时，再次接收到的请求报文由于含有 ACK，仍然会触发服务器端成功建立连接。</strong></p><p>所以，tcp_abort_on_overflow 设为 0 可以提高连接建立的成功率，只有你非常肯定 TCP 全连接队列会长期溢出时，才能设置为 1 以尽快通知客户端。</p><blockquote><p>如何增大 TCP 全连接队列呢？</p></blockquote><p>是的，当发现 TCP 全连接队列发生溢出的时候，我们就需要增大该队列的大小，以便可以应对客户端大量的请求。</p><p><strong>TCP 全连接队列的最大值取决于 somaxconn 和 backlog 之间的最小值，也就是 min(somaxconn, backlog)</strong>。从下面的 Linux 内核代码可以得知：</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/13.jpg width=auto alt></p><ul><li><code>somaxconn</code> 是 Linux 内核的参数，默认值是 128，可以通过 <code>/proc/sys/net/core/somaxconn</code> 来设置其值；</li><li><code>backlog</code> 是 <code>listen(int sockfd, int backlog)</code> 函数中的 backlog 大小，Nginx 默认值是 511，可以通过修改配置文件设置其长度；</li></ul><p>前面模拟测试中，我的测试环境：</p><ul><li>somaxconn 是默认值 128；</li><li>Nginx 的 backlog 是默认值 511</li></ul><p>所以测试环境的 TCP 全连接队列最大值为 min(128, 511)，也就是 <code>128</code>，可以执行 <code>ss</code> 命令查看：</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/14.jpg width=auto alt></p><p>现在我们重新压测，把 TCP 全连接队列<strong>搞大</strong>，把 <code>somaxconn</code> 设置成 5000：</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/15.jpg width=auto alt></p><p>接着把 Nginx 的 backlog 也同样设置成 5000：</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/16.jpg width=auto alt></p><p>最后要重启 Nginx 服务，因为只有重新调用 <code>listen()</code> 函数 TCP 全连接队列才会重新初始化。</p><p>重启完后 Nginx 服务后，服务端执行 ss 命令，查看 TCP 全连接队列大小：</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/17.jpg width=auto alt></p><p>从执行结果，可以发现 TCP 全连接最大值为 5000。</p><blockquote><p>增大 TCP 全连接队列后，继续压测</p></blockquote><p>客户端同样以 3 万个连接并发发送请求给服务端：</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/18.jpg width=auto alt></p><p>服务端执行 <code>ss</code> 命令，查看 TCP 全连接队列使用情况：</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/19.jpg width=auto alt></p><p>从上面的执行结果，可以发现全连接队列使用增长的很快，但是一直都没有超过最大值，所以就不会溢出，那么 <code>netstat -s</code> 就不会有 TCP 全连接队列溢出个数的显示：</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/20.jpg width=auto alt></p><p>说明 TCP 全连接队列最大值从 128 增大到 5000 后，服务端抗住了 3 万连接并发请求，也没有发生全连接队列溢出的现象了。</p><p><strong>如果持续不断地有连接因为 TCP 全连接队列溢出被丢弃，就应该调大 backlog 以及 somaxconn 参数。</strong></p><hr><a href=#实战---tcp-半连接队列溢出><h2 id=实战---tcp-半连接队列溢出><span class=hanchor arialabel=Anchor># </span>实战 - TCP 半连接队列溢出</h2></a><blockquote><p>如何查看 TCP 半连接队列长度？</p></blockquote><p>很遗憾，TCP 半连接队列长度的长度，没有像全连接队列那样可以用 ss 命令查看。</p><p>但是我们可以抓住 TCP 半连接的特点，就是服务端处于 <code>SYN_RECV</code> 状态的 TCP 连接，就是 TCP 半连接队列。</p><p>于是，我们可以使用如下命令计算当前 TCP 半连接队列长度：</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/21.jpg width=auto alt></p><blockquote><p>如何模拟 TCP 半连接队列溢出场景？</p></blockquote><p>模拟 TCP 半连接溢出场景不难，实际上就是对服务端一直发送 TCP SYN 包，但是不回第三次握手 ACK，这样就会使得服务端有大量的处于 <code>SYN_RECV</code> 状态的 TCP 连接。</p><p>这其实也就是所谓的 SYN 洪泛、SYN 攻击、DDos 攻击。</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/22.jpg width=auto alt=测试环境></p><p>实验环境：</p><ul><li>客户端和服务端都是 CentOs 6.5 ，Linux 内核版本 2.6.32</li><li>服务端 IP 192.168.3.200，客户端 IP 192.168.3.100</li><li>服务端是 Nginx 服务，端口为 8088</li></ul><p>注意：本次模拟实验是没有开启 tcp_syncookies，关于 tcp_syncookies 的作用，后续会说明。</p><p>本次实验使用 <code>hping3</code> 工具模拟 SYN 攻击：</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/23.jpg width=auto alt></p><p>当服务端受到 SYN 攻击后，连接服务端 ssh 就会断开了，无法再连上。只能在服务端主机上执行查看当前 TCP 半连接队列大小：</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/24.jpg width=auto alt></p><p>同时，还可以通过 netstat -s 观察半连接队列溢出的情况：</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/25.jpg width=auto alt></p><p>上面输出的数值是<strong>累计值</strong>，表示共有多少个 TCP 连接因为半连接队列溢出而被丢弃。<strong>隔几秒执行几次，如果有上升的趋势，说明当前存在半连接队列溢出的现象</strong>。</p><blockquote><p>大部分人都说 tcp_max_syn_backlog 是指定半连接队列的大小，是真的吗？</p></blockquote><p>很遗憾，半连接队列的大小并不单单只跟 <code>tcp_max_syn_backlog</code> 有关系。</p><p>上面模拟 SYN 攻击场景时，服务端的 tcp_max_syn_backlog 的默认值如下：</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/26.jpg width=auto alt></p><p>但是在测试的时候发现，服务端最多只有 256 个半连接队列，而不是 512，所以<strong>半连接队列的最大长度不一定由 tcp_max_syn_backlog 值决定的</strong>。</p><blockquote><p>接下来，走进 Linux 内核的源码，来分析 TCP 半连接队列的最大值是如何决定的。</p></blockquote><p>TCP 第一次握手（收到 SYN 包）的 Linux 内核代码如下，其中缩减了大量的代码，只需要重点关注 TCP 半连接队列溢出的处理逻辑：</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/27.jpg width=auto alt></p><p>从源码中，我可以得出共有三个条件因队列长度的关系而被丢弃的：</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/28.jpg width=auto alt></p><ol><li><strong>如果半连接队列满了，并且没有开启 tcp_syncookies，则会丢弃；</strong></li><li><strong>若全连接队列满了，且没有重传 SYN+ACK 包的连接请求多于 1 个，则会丢弃；</strong></li><li><strong>如果没有开启 tcp_syncookies，并且 max_syn_backlog 减去 当前半连接队列长度小于 (max_syn_backlog &#187; 2)，则会丢弃；</strong></li></ol><p>关于 tcp_syncookies 的设置，后面在详细说明，可以先给大家说一下，开启 tcp_syncookies 是缓解 SYN 攻击其中一个手段。</p><p>接下来，我们继续跟一下检测半连接队列是否满的函数 inet_csk_reqsk_queue_is_full 和 检测全连接队列是否满的函数 sk_acceptq_is_full ：</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/29.jpg width=auto alt></p><p>从上面源码，可以得知：</p><ul><li><strong>全</strong>连接队列的最大值是 <code>sk_max_ack_backlog</code> 变量，sk_max_ack_backlog 实际上是在 listen() 源码里指定的，也就是 <strong>min(somaxconn, backlog)</strong>；</li><li><strong>半</strong>连接队列的最大值是 <code>max_qlen_log</code> 变量，max_qlen_log 是在哪指定的呢？现在暂时还不知道，我们继续跟进；</li></ul><p>我们继续跟进代码，看一下是哪里初始化了半连接队列的最大值 max_qlen_log：</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/30.jpg width=auto alt></p><p>从上面的代码中，我们可以算出 max_qlen_log 是 8，于是代入到 检测半连接队列是否满的函数 reqsk_queue_is_full ：</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/31.jpg width=auto alt></p><p>也就是 <code>qlen >> 8</code> 什么时候为 1 就代表半连接队列满了。这计算这不难，很明显是当 qlen 为 256 时，<code>256 >> 8 = 1</code>。</p><p>至此，总算知道为什么上面模拟测试 SYN 攻击的时候，服务端处于 <code>SYN_RECV</code> 连接最大只有 256 个。</p><p>可见，<strong>半连接队列最大值不是单单由 max_syn_backlog 决定，还跟 somaxconn 和 backlog 有关系。</strong></p><p>在 Linux 2.6.32 内核版本，它们之间的关系，总体可以概况为：</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/32.jpg width=auto alt></p><ul><li>当 max_syn_backlog > min(somaxconn, backlog) 时， 半连接队列最大值 max_qlen_log = min(somaxconn, backlog) * 2;</li><li>当 max_syn_backlog &lt; min(somaxconn, backlog) 时， 半连接队列最大值 max_qlen_log = max_syn_backlog * 2;</li></ul><blockquote><p>半连接队列最大值 max_qlen_log 就表示服务端处于 SYN_RECV 状态的最大个数吗？</p></blockquote><p>依然很遗憾，并不是。</p><p>max_qlen_log 是<strong>理论</strong>半连接队列最大值，并不一定代表服务端处于 SYN_RECV 状态的最大个数。</p><p>在前面我们在分析 TCP 第一次握手（收到 SYN 包）时会被丢弃的三种条件：</p><ol><li>如果半连接队列满了，并且没有开启 tcp_syncookies，则会丢弃；</li><li>若全连接队列满了，且没有重传 SYN+ACK 包的连接请求多于 1 个，则会丢弃；</li><li><strong>如果没有开启 tcp_syncookies，并且 max_syn_backlog 减去 当前半连接队列长度小于 (max_syn_backlog &#187; 2)，则会丢弃；</strong></li></ol><p>假设条件 1 当前半连接队列的长度 「没有超过」理论的半连接队列最大值 max_qlen_log，那么如果条件 3 成立，则依然会丢弃 SYN 包，也就会使得服务端处于 SYN_RECV 状态的最大个数不会是理论值 max_qlen_log。</p><p>似乎很难理解，我们继续接着做实验，实验见真知。</p><p>服务端环境如下：</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/33.jpg width=auto alt></p><p>配置完后，服务端要重启 Nginx，因为全连接队列最大值和半连接队列最大值是在 listen() 函数初始化。</p><p>根据前面的源码分析，我们可以计算出半连接队列 max_qlen_log 的最大值为 256：</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/34.jpg width=auto alt></p><p>客户端执行 hping3 发起 SYN 攻击：</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/35.jpg width=auto alt></p><p>服务端执行如下命令，查看处于 SYN_RECV 状态的最大个数：</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/36.jpg width=auto alt></p><p>可以发现，服务端处于 SYN_RECV 状态的最大个数并不是 max_qlen_log 变量的值。</p><p>这就是前面所说的原因：<strong>如果当前半连接队列的长度 「没有超过」理论半连接队列最大值 max_qlen_log，那么如果条件 3 成立，则依然会丢弃 SYN 包，也就会使得服务端处于 SYN_RECV 状态的最大个数不会是理论值 max_qlen_log。</strong></p><p>我们来分析一波条件 3 :</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/37.jpg width=auto alt></p><p>从上面的分析，可以得知如果触发「当前半连接队列长度 > 192」条件，TCP 第一次握手的 SYN 包是会被丢弃的。</p><p>在前面我们测试的结果，服务端处于 SYN_RECV 状态的最大个数是 193，正好是触发了条件 3，所以处于 SYN_RECV 状态的个数还没到「理论半连接队列最大值 256」，就已经把 SYN 包丢弃了。</p><p>所以，服务端处于 SYN_RECV 状态的最大个数分为如下两种情况：</p><ul><li>如果「当前半连接队列」<strong>没超过</strong>「理论半连接队列最大值」，但是<strong>超过</strong> max_syn_backlog - (max_syn_backlog &#187; 2)，那么处于 SYN_RECV 状态的最大个数就是 max_syn_backlog - (max_syn_backlog &#187; 2)；</li><li>如果「当前半连接队列」<strong>超过</strong>「理论半连接队列最大值」，那么处于 SYN_RECV 状态的最大个数就是「理论半连接队列最大值」；</li></ul><blockquote><p>每个 Linux 内核版本「理论」半连接最大值计算方式会不同。</p></blockquote><p>在上面我们是针对 Linux 2.6.32 版本分析的「理论」半连接最大值的算法，可能每个版本有些不同。</p><p>比如在 Linux 5.0.0 的时候，「理论」半连接最大值就是全连接队列最大值，但依然还是有队列溢出的三个条件：</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/38.jpg width=auto alt></p><blockquote><p>如果 SYN 半连接队列已满，只能丢弃连接吗？</p></blockquote><p>并不是这样，<strong>开启 syncookies 功能就可以在不使用 SYN 半连接队列的情况下成功建立连接</strong>，在前面我们源码分析也可以看到这点，当开启了 syncookies 功能就不会丢弃连接。</p><p>syncookies 是这么做的：服务器根据当前状态计算出一个值，放在己方发出的 SYN+ACK 报文中发出，当客户端返回 ACK 报文时，取出该值验证，如果合法，就认为连接建立成功，如下图所示。</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/39.jpg width=auto alt="开启 syncookies 功能"></p><p>syncookies 参数主要有以下三个值：</p><ul><li>0 值，表示关闭该功能；</li><li>1 值，表示仅当 SYN 半连接队列放不下时，再启用它；</li><li>2 值，表示无条件开启功能；</li></ul><p>那么在应对 SYN 攻击时，只需要设置为 1 即可：</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/40.jpg width=auto alt></p><blockquote><p>如何防御 SYN 攻击？</p></blockquote><p>这里给出几种防御 SYN 攻击的方法：</p><ul><li>增大半连接队列；</li><li>开启 tcp_syncookies 功能</li><li>减少 SYN+ACK 重传次数</li></ul><p><em>方式一：增大半连接队列</em></p><p>在前面源码和实验中，得知<strong>要想增大半连接队列，我们得知不能只单纯增大 tcp_max_syn_backlog 的值，还需一同增大 somaxconn 和 backlog，也就是增大全连接队列</strong>。否则，只单纯增大 tcp_max_syn_backlog 是无效的。</p><p>增大 tcp_max_syn_backlog 和 somaxconn 的方法是修改 Linux 内核参数：</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/41.jpg width=auto alt></p><p>增大 backlog 的方式，每个 Web 服务都不同，比如 Nginx 增大 backlog 的方法如下：</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/42.jpg width=auto alt></p><p>最后，改变了如上这些参数后，要重启 Nginx 服务，因为半连接队列和全连接队列都是在 listen() 初始化的。</p><p><em>方式二：开启 tcp_syncookies 功能</em></p><p>开启 tcp_syncookies 功能的方式也很简单，修改 Linux 内核参数：</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/43.jpg width=auto alt></p><p><em>方式三：减少 SYN+ACK 重传次数</em></p><p>当服务端受到 SYN 攻击时，就会有大量处于 SYN_RECV 状态的 TCP 连接，处于这个状态的 TCP 会重传 SYN+ACK ，当重传超过次数达到上限后，就会断开连接。</p><p>那么针对 SYN 攻击的场景，我们可以减少 SYN+ACK 的重传次数，以加快处于 SYN_RECV 状态的 TCP 连接断开。</p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/44.jpg width=auto alt></p><hr><p>参考资料：</p><p>[1] 系统性能调优必知必会.陶辉.极客时间.</p><p>[2]
<a href=https://www.cnblogs.com/zengkefu/p/5606696.html rel=noopener>https://www.cnblogs.com/zengkefu/p/5606696.html</a></p><p>[3]
<a href=https://blog.cloudflare.com/syn-packet-handling-in-the-wild/ rel=noopener>https://blog.cloudflare.com/syn-packet-handling-in-the-wild/</a></p><hr><a href=#读者问答><h2 id=读者问答><span class=hanchor arialabel=Anchor># </span>读者问答</h2></a><blockquote><p>读者问：“咦 我比较好奇博主都是从哪里学到这些知识的呀？书籍？视频？还是多种参考资料”</p></blockquote><p>你可以看我的参考文献呀，知识点我主要是在极客专栏学的，实战模拟实验和源码解析是自己瞎折腾出来的。</p><blockquote><p>读者问：“syncookies 启用后就不需要半链接了？那请求的数据会存在哪里？”</p></blockquote><p>syncookies = 1 时，半连接队列满后，后续的请求就不会存放到半连接队列了，而是在第二次握手的时候，服务端会计算一个 cookie 值，放入到 SYN +ACK 包中的序列号发给客户端，客户端收到后并回 ack ，服务端就会校验连接是否合法，合法就直接把连接放入到全连接队列。</p><hr><a href=#最后><h2 id=最后><span class=hanchor arialabel=Anchor># </span>最后</h2></a><p>本文是以 Linux 2.6.32 版本的内核用实验 + 源码的方式，给大家说明了 TCP 半连接队列和全连接队列，我们可以看到 TCP 半连接队列「并不是」如网上说的那样 tcp_max_syn_backlog 表示半连接队列。</p><p>TCP 半连接队列的大小对于不同的 Linux 内核版本会有不同的计算方式，所以并不要求大家要死记住本文计算 TCP 半连接队列的大小。</p><p>重要的是要学会自我源码分析，这样不管碰到什么版本的 Linux 内核，都不再怕了。</p><p>网上搜索出来的信息，并不一定针对你的系统，通过自我分析一波，你会更了解你当前使用的 Linux 内核版本！</p><p><strong>小林是专为大家图解的工具人，Goodbye，我们下次见！</strong></p><p><img src=https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E5%85%B6%E4%BB%96/%E5%85%AC%E4%BC%97%E5%8F%B7%E4%BB%8B%E7%BB%8D.png width=auto alt></p></article><hr><div class=page-end id=footer><div class=backlinks-container><h3>Backlinks</h3><ul class=backlinks><li><a href=/%E7%BD%91%E7%BB%9C/README/ data-ctx="TCP 半连接队列和全连接队列" data-src=/%E7%BD%91%E7%BB%9C/README class=internal-link>README</a></li></ul></div><div><script src=https://cdn.jsdelivr.net/npm/d3@6.7.0/dist/d3.min.js integrity="sha256-+7jaYCp29O1JusNWHaYtgUn6EhuP0VaFuswhNV06MyI=" crossorigin=anonymous></script><h3>Interactive Graph</h3><div id=graph-container></div><style>:root{--g-node:var(--secondary);--g-node-active:var(--primary);--g-node-inactive:var(--visited);--g-link:var(--outlinegray);--g-link-active:#5a7282}</style><script src=https://googoo-s.github.io/js/graph.6579af7b10c818dbd2ca038702db0224.js></script></div></div><div id=contact_buttons><footer><p>Made by googoo-s using <a href=https://github.com/jackyzha0/quartz>Quartz</a>, © 2023</p><ul><li><a href=https://googoo-s.github.io/>Home</a></li><li><a href=https://github.com/googoo-s>GitHub</a></li></ul></footer></div></div></body></html>