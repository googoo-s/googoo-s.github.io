{"ElasticSearch/KQL":{"title":"KQL","links":[],"tags":[],"content":"Kibana  Query Language\njuejin.cn/post/7003201901382598686\nwww.elastic.co/guide/en/kibana/7.14/kuery-query.html#kuery-query"},"GO/GO":{"title":"GO","links":["GO/八股文/Golang基础","GO/八股文/Slice","GO/八股文/Map-和Sync.map","GO/并发编程/Channel/channel","GO/并发编程/基础并发原语/Context","GO/八股文/Goroutine","GO/八股文/并发","GO/八股文/Mutex和RWMutex","GO/八股文/内存管理和GC","GO/八股文/调度器和GMP","GO/并发编程/基础并发原语/Mutex","GO/并发编程/基础并发原语/RWMutex","GO/并发编程/基础并发原语/WaitGroup","GO/并发编程/基础并发原语/Cond","GO/并发编程/基础并发原语/Once","GO/并发编程/基础并发原语/map","GO/并发编程/基础并发原语/Pool","GO/并发编程/原子操作/atomic","GO/并发编程/扩展并发原语/Semaphore-信号量","GO/并发编程/扩展并发原语/SingleFlight-和-CyclicBarrier-请求合并和循环栅栏","GO/并发编程/分布式并发原语/Leader选举互斥锁和读写锁","GO/并发编程/分布式并发原语/队列、栅栏和STM"],"tags":["GO"],"content":"八股文\n\nGolang基础\nSlice\nMap 和Sync.map\nchannel\nContext\nGoroutine\n并发\nMutex和RWMutex\n内存管理和GC\n调度器和GMP\n\n并发编程\n\n基础并发原语\n\nMutex\nRWMutex\nWaitGroup\nCond\nOnce\nmap\nPool\nContext\n\n\n原子操作\n\natomic\n\n\nChannel\n\nchannel\n\n\n扩展并发原语\n\nSemaphore-信号量\nSingleFlight 和 CyclicBarrier-请求合并和循环栅栏\n\n\n分布式并发原语\n\nLeader选举互斥锁和读写锁\n队列、栅栏和STM\n\n\n"},"GO/八股文/Context":{"title":"Context","links":["tags/"],"tags":[""],"content":"参考\nGolang context 实现原理\ngo 之 Context 基本使用\n前言\ncontext 是 golang 中的经典工具\n\n主要在异步场景中用于实现并发协调以及对 goroutine 的生命周期控制.\n除此之外，context 还兼有一定的数据存储能力.\n本着知其然知其所以然的精神，本文和大家一起深入 context 源码一探究竟，较为细节地对其实现原理进行梳理.\n\n为啥使用 Context\n比如以下这个例子，一旦主协程关闭done channel，那么子协程就可以退出了，这样就实现了主协程通知子协程的需求\n  \nfunc main() {\n    // 数据通道\n    messages := make(chan int, 10)\n    // 信号通道\n    done := make(chan bool)\n\n    defer close(messages)\n    // consumer\n    go func() {\n        // 每隔一秒执行一次，定时器\n        ticker := time.NewTicker(1 * time.Second)\n        for _ = range ticker.C {\n            select {\n            // 若关闭了通道则 执行下面的代码\n            case &lt;-done:\n                fmt.Println(&quot;child process interrupt...&quot;)\n                return\n            default:\n                fmt.Printf(&quot;send message: %d\\n&quot;, &lt;-messages)\n            }\n        }\n    }()\n\n    // producer\n    for i := 0; i &lt; 10; i++ {\n        messages &lt;- i\n    }\n    time.Sleep(5 * time.Second)\n    // 关闭通道, 退出上面的匿名函数\n    close(done)\n    time.Sleep(1 * time.Second)\n    fmt.Println(&quot;main process exit!&quot;)\n}\n\n假如主协程中有多个任务1, 2, …m，主协程对这些任务有超时控制。如果还是使用done channel的用法 ，那么使用done channel的方式将会变得非常繁琐且混乱\n我们需要一种优雅的方案来实现这样一种机制：\n\n上层任务取消后，所有的下层任务都会被取消；\n中间某一层的任务取消后，只会将当前任务的下层任务取消，而不会影响上层的任务以及同级任务。\n\n这个时候context就派上用场了\nContext 的使用\n注意: 这两种方式是创建根context，不具备任何功能，需要用到with系列函数来实现具体功能`\n根 Context\n\ncontext.Backgroud()\n\n是上下文的默认值，所有其他的上下文都应该从它衍生（Derived）出来, ,一般情况下我们用这个\n\n\ncontext.TODO()\n\n 应该只在不确定应该使用哪种上下文时使用；\n\n\n\nWith 系列函数\n context.withCancel() 取消控制\n就可以使用withCancel来衍生一个context传递到不同的goroutine中，当我想让这些goroutine停止运行，就可以调用cancel来进行取消\n// 案例一\n\n/*  \n\t代码逻辑:\n    我们使用withCancel创建一个基于Background的ctx，然后启动一个讲话程序，\n    每隔1s说一话，main函数在10s后执行cancel，那么speak检测到取消信号就会退出。\n*/\n\npackage main\n\nimport (\n\t&quot;context&quot;\n\t&quot;fmt&quot;\n\t&quot;time&quot;\n)\n\n// context.Background()函数创建根上下文，返回父context和cancel函数\nfunc NewWithCancel() (context.Context, context.CancelFunc) {\n\treturn context.WithCancel(context.Background())\n\n}\n\n//  业务逻辑\nfunc Speak(ctx context.Context) {\n\tfor range time.Tick(time.Second) {\n\t\tselect {\n\t\tcase &lt;-ctx.Done():\n\t\t\tfmt.Println(&quot;关闭线程...&quot;)\n\t\t\tfmt.Println(ctx.Err())\n\t\tdefault:\n\t\t\tfmt.Println(&quot;hahahhaa&quot;)\n\t\t}\n\t}\n}\n\nfunc main() {\n        // 创建父context和cancel函数\n\tctx, cancel := NewWithCancel()\n\n        // 使用协程来启动业务逻辑\n\tgo Speak(ctx)\n\n\ttime.Sleep(10 * time.Second)\n\n        // 取消的信号，结束Speak函数的运行\n\tcancel()\n\n\ttime.Sleep(1 * time.Second)\n\n}\n\n  \n// 案例二\n\n/*\n代码逻辑: \n1. 利用根Context创建一个父Context，使用父Context创建一个协程，\n2. 利用上面的父Context再创建一个子Context，使用该子Context创建一个协程\n3. 一段时间后，调用父Context的cancel函数，会发现父Context的协程和子Context的协程都收到了信号，被结束了\n\n*/\npackage main\n \nimport (\n\t&quot;context&quot;\n\t&quot;fmt&quot;\n\t&quot;time&quot;\n)\n \nfunc main() {\n\t// 父context(利用根context得到)\n\tctx, cancel := context.WithCancel(context.Background())\n \n\t// 父context的子协程\n\tgo watch1(ctx)\n \n\t// 子context，注意：这里虽然也返回了cancel的函数对象，但是未使用\n\tvalueCtx, _ := context.WithCancel(ctx)\n\t// 子context的子协程\n\tgo watch2(valueCtx)\n \n\tfmt.Println(&quot;现在开始等待3秒,time=&quot;, time.Now().Unix())\n\ttime.Sleep(3 * time.Second)\n \n\t// 调用cancel()\n\tfmt.Println(&quot;等待3秒结束,调用cancel()函数&quot;)\n\tcancel()\n \n\t// 再等待5秒看输出，可以发现父context的子协程和子context的子协程都会被结束掉\n\ttime.Sleep(5 * time.Second)\n\tfmt.Println(&quot;最终结束,time=&quot;, time.Now().Unix())\n}\n \n// 父context的协程\nfunc watch1(ctx context.Context) {\n\tfor {\n\t\tselect {\n\t\tcase &lt;-ctx.Done(): //取出值即说明是结束信号\n\t\t\tfmt.Println(&quot;收到信号，父context的协程退出,time=&quot;, time.Now().Unix())\n\t\t\treturn\n\t\tdefault:\n\t\t\tfmt.Println(&quot;父context的协程监控中,time=&quot;, time.Now().Unix())\n\t\t\ttime.Sleep(1 * time.Second)\n\t\t}\n\t}\n}\n \n// 子context的协程\nfunc watch2(ctx context.Context) {\n\tfor {\n\t\tselect {\n\t\tcase &lt;-ctx.Done(): //取出值即说明是结束信号\n\t\t\tfmt.Println(&quot;收到信号，子context的协程退出,time=&quot;, time.Now().Unix())\n\t\t\treturn\n\t\tdefault:\n\t\t\tfmt.Println(&quot;子context的协程监控中,time=&quot;, time.Now().Unix())\n\t\t\ttime.Sleep(1 * time.Second)\n\t\t}\n\t}\n}\n\ncontext.WithTimeout 超时控制\nwithTimeout或者withDeadline来做超时控制，当一次请求到达我们设置的超时时间，就会及时取消，不在往下执行。withTimeout和withDeadline作用是一样的，就是传递的时间参数不同而已，他们都会通过传入的时间来自动取消Context，这里要注意的是他们都会返回一个cancelFunc方法，通过调用这个方法可以达到提前进行取消\n  \n// 案例一\n\npackage main\n\nimport (\n\t&quot;context&quot;\n\t&quot;fmt&quot;\n\t&quot;time&quot;\n)\n\n// 创建一个带超时context， 三秒后退出执行\nfunc NewContextWithTimeout() (context.Context, context.CancelFunc) {\n\treturn context.WithTimeout(context.Background(), 3*time.Second)\n}\n\n// 处理程序\nfunc HttpHandler() {\n\tctx, cancel := NewContextWithTimeout()\n\tdefer cancel()\n\tdeal(ctx)\n\n}\n\n// 业务逻辑代码\nfunc deal(ctx context.Context) {\n\tfor i := 0; i &lt; 10; i++ {\n\t\ttime.Sleep(1 * time.Second)\n\t\tselect {\n\t\tcase &lt;-ctx.Done():\n\t\t\tfmt.Println(ctx.Err())\n\t\t\treturn\n\t\tdefault:\n\t\t\tfmt.Printf(&quot;deal time is %d\\n&quot;, i)\n\t\t}\n\t}\n}\nfunc main() {\n\tHttpHandler()\n}\n\n// 案例二\n\npackage main\n \nimport (\n\t&quot;context&quot;\n\t&quot;fmt&quot;\n\t&quot;time&quot;\n)\n \nfunc main() {\n\t// 创建一个子节点的context,3秒后自动超时\n\tctx, cancel := context.WithTimeout(context.Background(), time.Second*3)\n \n\tgo watch(ctx, &quot;监控1&quot;)\n\tgo watch(ctx, &quot;监控2&quot;)\n \n\tfmt.Println(&quot;现在开始等待8秒,time=&quot;, time.Now().Unix())\n\ttime.Sleep(8 * time.Second)\n \n\tfmt.Println(&quot;等待8秒结束,准备调用cancel()函数，发现两个子协程已经结束了，time=&quot;, time.Now().Unix())\n\tcancel()\n}\n \n// 单独的监控协程\nfunc watch(ctx context.Context, name string) {\n\tfor {\n\t\tselect {\n\t\tcase &lt;-ctx.Done():\n\t\t\tfmt.Println(name, &quot;收到信号，监控退出,time=&quot;, time.Now().Unix())\n\t\t\treturn\n\t\tdefault:\n\t\t\tfmt.Println(name, &quot;goroutine监控中,time=&quot;, time.Now().Unix())\n\t\t\ttime.Sleep(1 * time.Second)\n\t\t}\n\t}\n}\n\n context.WithValue() 携带数据 [谨慎使用]\n日常在业务开发中都希望能有一个trace_id能串联所有的日志，这就需要我们打印日志时能够获取到这个trace_id，在python中我们可以用gevent.local来传递，在java中我们可以用ThreadLocal来传递，在Go语言中我们就可以使用Context来传递，通过使用WithValue来创建一个携带trace_id的context，然后不断透传下去，打印日志时输出即可\n/*\n我们基于context.Background创建一个携带trace_id的ctx，然后通过context树一起传递，\n从中派生的任何context都会获取此值，我们最后打印日志的时候就可以从ctx中取值输出到日志中。\n目前一些RPC框架都是支持了Context，所以trace_id的向下传递就更方便了\n*/\npackage main\n\nimport (\n\t&quot;context&quot;\n\t&quot;fmt&quot;\n\t&quot;strings&quot;\n\t&quot;time&quot;\n\n\t&quot;github.com/google/uuid&quot;\n)\n\ntype MyKEY string\n\nconst (\n\tKEY MyKEY = &quot;trace_id&quot;\n)\n\n// 返回一个UUID\nfunc NewRequestID1() MyKEY {\n\treturn MyKEY(strings.Replace(uuid.New().String(), &quot;-&quot;, &quot;&quot;, -1))\n\n}\n\n// 创建一个携带trace_id 的ctx\nfunc NewContextWithTraceID() context.Context {\n\tctx := context.WithValue(context.Background(), KEY, NewRequestID1())\n\treturn ctx\n}\n\n// 打印值\nfunc PrintLog(ctx context.Context, message string) {\n\tfmt.Printf(&quot;%s|info|trace_id=%s|%s&quot;, time.Now().Format(&quot;2006-01-02 15:04:05&quot;), GetContextValue1(ctx, KEY), message)\n}\n\n// 获取设置的key对应的值,并断言\nfunc GetContextValue1(ctx context.Context, k MyKEY) MyKEY {\n\tv, ok := ctx.Value(k).(MyKEY)\n\tfmt.Println(&quot;打印k:&quot; + k)\n\tfmt.Printf(&quot;打印v: %v\\n&quot;, v)\n\tif !ok {\n\t\treturn &quot;&quot;\n\t}\n\treturn v\n}\n\nfunc ProcessEnter(ctx context.Context) {\n\tPrintLog(ctx, &quot;Golang&quot;)\n}\n\nfunc main() {\n\tProcessEnter(NewContextWithTraceID())\n}\n\n\n不建议使用 context 值传递关键参数，关键参数应该显示的声明出来\n因为携带value也是key value，避免context多个包使用带来的冲突,建议使用内置类型\ncontext 传递的数据 key value 都是 interface，所以类型断言时别忘了保证程序的健壮性\n\n应用场景\n\n\nRPC调用\n\n\nPipeLine\n\n\n超时请求\n\n\n`HTTP服务器的request互相传递数据\n\n\n注意：\n\n不要将 Context 塞到结构体里。直接将 Context 类型作为函数的第一参数，而且一般都命名为 ctx。\n不要向函数传入一个 nil 的 context，如果你实在不知道传什么，标准库给你准备好了一个 context：todo。\n不要把本应该作为函数参数的类型塞到 context 中，context 存储的应该是一些共同的数据。例如：登陆的 session、cookie 等。\n同一个 context 可能会被传递到多个 goroutine，别担心，context 是并发安全的\n\n核心数据结构\ncontext.Context\n\ncontext数据结构\ntype Context interface {\n    Deadline() (deadline time.Time, ok bool)\n    Done() &lt;-chan struct{}\n    Err() error\n    Value(key any) any\n}\n\nContext 为 interface，定义了四个核心 api：\n\n\nDeadline：返回 context 的过期时间；也就是完成工作的截止日期；如果没有设定期限，将返回ok == false\n\n\nDone：返回 context 中的 channel；当绑定当前context的任务被取消时，将返回一个关闭的channel；如果当前context不会被取消，将返回nil\n\n\nErr：返回错误；\n\n如果 Done 返回的 channel 没有关闭，将返回 nil;如果 Done 返回的 channel 已经关闭，将返回非空的值表示任务结束的原因\n如果是 context 被取消，Err 将返回 Canceled；如果是 context 超时，Err 将返回 DeadlineExceeded\nErr() error\n\n\n\nValue：返回 context 中的对应 key 的值.\n\n\n标准 error\nvar Canceled = errors.New(&quot;context canceled&quot;)\n\nvar DeadlineExceeded error = deadlineExceededError{}\n\ntype deadlineExceededError struct{}\n\nfunc (deadlineExceededError) Error() string   { return &quot;context deadline exceeded&quot; }\nfunc (deadlineExceededError) Timeout() bool   { return true }\nfunc (deadlineExceededError) Temporary() bool { return true\n\n\n\n• Canceled：context 被 cancel 时会报此错误；\n\n\n• DeadlineExceeded：context 超时时会报此错误.\n\n\nemptyCtx\n类的实现\ntype emptyCtx int\n\nfunc (*emptyCtx) Deadline() (deadline time.Time, ok bool) {\n    return\n}\n\nfunc (*emptyCtx) Done() &lt;-chan struct{} {\n    return nil\n}\n\nfunc (*emptyCtx) Err() error {\n    return nil\n}\n\nfunc (*emptyCtx) Value(key any) any {\n    return \n}\n\n\n\nemptyCtx 是一个空的 context，本质上类型为一个整型；\n\n\nDeadline 方法会返回一个公元元年时间以及 false 的 flag，标识当前 context 不存在过期时间；\n\n\nDone 方法返回一个 nil 值，用户无论往 nil 中写入或者读取数据，均会陷入阻塞；\n\n\nErr 方法返回的错误永远为 nil；\n\n\n Value 方法返回的 value 同样永远为 nil.\n\n\ncontext.Background() &amp; context.TODO()\nvar (\n    background = new(emptyCtx)\n    todo       = new(emptyCtx)\n)\n\nfunc Background() Context {\n    return background\n}\n\nfunc TODO() Context {\n    return todo\n}\n\n我们所常用的 context.Background() 和 context.TODO() 方法返回的均是 emptyCtx 类型的一个实例.\ncancelCtx\ncancelCtx 数据结构\n\ncancelCtx数据结构\ntype cancelCtx struct {\n    Context\n   \n    mu       sync.Mutex            // protects following fields\n    done     atomic.Value          // of chan struct{}, created lazily, closed by first cancel call\n    children map[canceler]struct{} // set to nil by the first cancel call\n    err      error                 // set to non-nil by the first cancel call\n}\n\ntype canceler interface {\n    cancel(removeFromParent bool, err error)\n    Done() &lt;-chan struct{}\n}\n\n\n\nembed 了一个 context 作为其父 context. 可见，cancelCtx 必然为某个 context 的子 context；\n\n\nMu 内置了一把锁，用以协调并发场景下的资源获取；\n\n\ndone：实际类型为 chan struct{}，即用以反映 cancelCtx 生命周期的通道；c.done 是“懒汉式”创建，只有调用了 Done() 方法的时候才会被创建。再次说明，函数返回的是一个只读的 channel，而且没有地方向这个 channel 里面写数据。所以，直接调用读这个 channel，协程会被 block 住。一般通过搭配 select 来使用。一旦关闭，就会立即读出零值。\n\n\nchildren：一个 set，指向 cancelCtx 的所有子 context；\n\n\nerr：记录了当前 cancelCtx 的错误. 必然为某个 context 的子 context；\n\n\nDeadline 方法\ncancelCtx 未实现该方法，仅是 embed 了一个带有 Deadline 方法的 Context interface，因此倘若直接调用会报错.\nDone 方法\n\ncancelCtx.Done\n.done 是“懒汉式”创建**，只有调用了 Done () 方法的时候才会被创建。再次说明，函数返回的是一个只读的 channel，而且没有地方向这个 channel 里面写数据。所以，直接调用读这个 channel，协程会被 block 住。一般通过搭配 select 来使用。\nfunc (c *cancelCtx) Done() &lt;-chan struct{} {\n    d := c.done.Load()\n    if d != nil {\n        return d.(chan struct{})\n    }\n    c.mu.Lock()\n    defer c.mu.Unlock()\n    d = c.done.Load()\n    if d == nil {\n        d = make(chan struct{})\n        c.done.Store(d)\n    }\n    return d.(chan struct{})\n}\n\n\n\n基于 atomic 包，读取 cancelCtx 中的 chan；倘若已存在，则直接返回；\n\n\n加锁后，在此检查 chan 是否存在，若存在则返回；（double check）\n\n\n初始化 chan 存储到 aotmic.Value 当中，并返回.（懒加载机制）\n\n\nErr 方法\nfunc (c *cancelCtx) Err() error {\n    c.mu.Lock()\n    err := c.err\n    c.mu.Unlock()\n    return err\n}\n\n\n\n• 加锁；\n\n\n• 读取 cancelCtx.err；\n\n\n• 解锁；\n\n\n• 返回结果.\n\n\nValue 方法\nfunc (c *cancelCtx) Value(key any) any {\n    if key == &amp;cancelCtxKey {\n        return c\n    }\n    return value(c.Context, key)\n}\n\n\n\n• 倘若 key 特定值 &amp;cancelCtxKey，则返回 cancelCtx 自身的指针；\n\n\n• 否则遵循 valueCtx 的思路取值返回\n\n\ncontext.WithCancel()\ncontext.WithCancel()\nfunc WithCancel(parent Context) (ctx Context, cancel CancelFunc) {\n    if parent == nil {\n        panic(&quot;cannot create context from nil parent&quot;)\n    }\n    c := newCancelCtx(parent)\n    propagateCancel(parent, &amp;c)\n    return &amp;c, func() { c.cancel(true, Canceled) }\n}\n\nfunc newCancelCtx(parent Context) cancelCtx {\n    return cancelCtx{Context: parent}\n}\n\n\n\n• 校验父 context 非空；\n\n\n• 注入父 context 构造好一个新的 cancelCtx；\n\n\n• 在 propagateCancel 方法内启动一个守护协程，以保证父 context 终止时，该 cancelCtx 也会被终止；\n\n\n• 将 cancelCtx 返回，连带返回一个用以终止该 cancelCtx 的闭包函数.\n\n\n这是一个暴露给用户的方法，传入一个父 Context（这通常是一个 background，作为根节点），返回新建的 context，新 context 的 done channel 是新建的（前文讲过）。\n当 WithCancel 函数返回的 CancelFunc 被调用或者是父节点的 done channel 被关闭（父节点的 CancelFunc 被调用），此 context（子节点） 的 done channel 也会被关闭。\n注意传给 WithCancel 方法的参数，前者是 true，也就是说取消的时候，需要将自己从父节点里删除。第二个参数则是一个固定的取消错误类型：\npropagateCancel\n\n这个方法的作用就是向上寻找可以“挂靠”的“可取消”的 context，并且“挂靠”上去。这样，调用上层 cancel 方法的时候，由上层的协程来管理对子 context 的取消。如果没有父 context ，就自己新建一个携程\npropagate流程\nfunc propagateCancel(parent Context, child canceler) {\n\t// 父节点是个空节点\n\tif parent.Done() == nil {\n\t\treturn // parent is never canceled\n\t}\n\t// 找到可以取消的父 context\n\tif p, ok := parentCancelCtx(parent); ok {\n\t\tp.mu.Lock()\n\t\tif p.err != nil {\n\t\t\t// 父节点已经被取消了，本节点（子节点）也要取消\n\t\t\tchild.cancel(false, p.err)\n\t\t} else {\n\t\t\t// 父节点未取消\n\t\t\tif p.children == nil {\n\t\t\t\tp.children = make(map[canceler]struct{})\n\t\t\t}\n\t\t\t// &quot;挂到&quot;父节点上\n\t\t\tp.children[child] = struct{}{}\n\t\t}\n\t\tp.mu.Unlock()\n\t} else {\n\t\t// 如果没有找到可取消的父 context。新启动一个协程监控父节点或子节点取消信号\n\t\tgo func() {\n\t\t\tselect {\n\t\t\tcase &lt;-parent.Done():\n\t\t\t\tchild.cancel(false, parent.Err())\n\t\t\tcase &lt;-child.Done():\n\t\t\t}\n\t\t}()\n\t}\n}\n\npropagateCancel 方法顾名思义，用以传递父子 context 之间的 cancel 事件：\n\n\n倘若 parent 是不会被 cancel 的类型（如 emptyCtx），则直接返回；\n\n\n 倘若 parent 已经被 cancel，则直接终止子 context，并以 parent 的 err 作为子 context 的 err；\n\n\n 假如 parent 是 cancelCtx 的类型，则加锁，并将子 context 添加到 parent 的 children map 当中；\n\n\n 假如 parent 不是 cancelCtx 类型，但又存在 cancel 的能力（比如用户自定义实现的 context），则启动一个协程，通过多路复用的方式监控 parent 状态，倘若其终止，则同时终止子 context，并透传 parent 的 err.\n\n\n• 倘若 parent 的 channel 已关闭或者是不会被 cancel 的类型，则返回 false；\n\n\n• 倘若以特定的 cancelCtxKey 从 parent 中取值，取得的 value 是 parent 本身，则返回 true. （基于 cancelCtxKey 为 key 取值时返回 cancelCtx 自身，是 cancelCtx 特有的协议）.\n\n\ncancelCtx.cancel\n\ncancel() 方法的功能就是关闭 channel：c.done；递归地取消它的所有子节点；从父节点从删除自己。达到的效果是通过关闭 channel，将取消信号传递给了它的所有子节点。Goroutine 接收到取消信号的方式就是 select 语句中的 读 c.done 被选中\nfunc (c *cancelCtx) cancel(removeFromParent bool, err error) {\n    // 必须要传 err\n\tif err == nil {\n\t\tpanic(&quot;context: internal error: missing cancel error&quot;)\n\t}\n\tc.mu.Lock()\n\tif c.err != nil {\n\t\tc.mu.Unlock()\n\t\treturn // 已经被其他协程取消\n\t}\n\t// 给 err 字段赋值\n\tc.err = err\n\t// 关闭 channel，通知其他协程\n\tif c.done == nil {\n\t\tc.done = closedchan\n\t} else {\n\t\tclose(c.done)\n\t}\n\t\n\t// 遍历它的所有子节点\n\tfor child := range c.children {\n\t    // 递归地取消所有子节点\n\t\tchild.cancel(false, err)\n\t}\n\t// 将子节点置空\n\tc.children = nil\n\tc.mu.Unlock()\n\n\tif removeFromParent {\n\t    // 从父节点中移除自己 \n\t\tremoveChild(c.Context, c)\n\t}\n}\n\n\n\n• cancelCtx.cancel 方法有两个入参，第一个 removeFromParent 是一个 bool 值，表示当前 context 是否需要从父 context 的 children set 中删除；第二个 err 则是 cancel 后需要展示的错误；\n\n\n• 进入方法主体，首先校验传入的 err 是否为空，若为空则 panic；\n\n\n• 加锁；\n\n\n• 校验 cancelCtx 自带的 err 是否已经非空，若非空说明已被 cancel，则解锁返回；\n\n\n• 将传入的 err 赋给 cancelCtx.err；\n\n\n• 处理 cancelCtx 的 channel，若 channel 此前未初始化，则直接注入一个 closedChan，否则关闭该 channel；\n\n\n• 遍历当前 cancelCtx 的 children set，依次将 children context 都进行 cancel；\n\n\n• 解锁.\n\n\n• 根据传入的 removeFromParent flag 判断是否需要手动把 cancelCtx 从 parent 的 children set 中移除.\n\n\n走进 removeChild 方法中，观察如何将 cancelCtx 从 parent 的 children set 中移除：\nfunc removeChild(parent Context, child canceler) {\n    p, ok := parentCancelCtx(parent)\n    if !ok {\n        return\n    }\n    p.mu.Lock()\n    if p.children != nil {\n        delete(p.children, child)\n    }\n    p.mu.Unlock()\n}\n\n\n\n• 如果 parent 不是 cancelCtx，直接返回（因为只有 cancelCtx 才有 children set） \n\n\n• 加锁；\n\n\n• 从 parent 的 children set 中删除对应 child\n\n\n• 解锁返回.\n\n\ntimerCtx\n类\n\ntimerCtx数据结构\ntype timerCtx struct {\n    cancelCtx\n    timer *time.Timer // Under cancelCtx.mu.\n\n    deadline time.Time\n}\n\ntimerCtx 在 cancelCtx 基础上又做了一层封装，除了继承 cancelCtx 的能力之外，新增了一个 time.Timer 用于定时终止 context；另外新增了一个 deadline 字段用于字段 timerCtx 的过期时间.\ntimerCtx.Deadline()\nfunc (c *timerCtx) Deadline() (deadline time.Time, ok bool) {\n    return c.deadline, true\n}\n\ncontext.Context interface 下的 Deadline api 仅在 timerCtx 中有效，由于展示其过期时间.\ntimerCtx.cancel\nfunc (c *timerCtx) cancel(removeFromParent bool, err error) {\n    c.cancelCtx.cancel(false, err)\n    if removeFromParent {\n        removeChild(c.cancelCtx.Context, c)\n    }\n    c.mu.Lock()\n    if c.timer != nil {\n        c.timer.Stop()\n        c.timer = nil\n    }\n    c.mu.Unlock()\n}\n\n\n\n• 复用继承的 cancelCtx 的 cancel 能力，进行 cancel 处理；\n\n\n• 判断是否需要手动从 parent 的 children set 中移除，若是则进行处理\n\n\n• 加锁；\n\n\n• 停止 time.Timer\n\n\n• 解锁返回.\n\n\ncontext.WithTimeout &amp; context.WithDeadline\nfunc WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc) {\n    return WithDeadline(parent, time.Now().Add(timeout))\n}\n\ncontext.WithTimeout 方法用于构造一个 timerCtx，本质上会调用 context.WithDeadline 方法：\nfunc WithDeadline(parent Context, d time.Time) (Context, CancelFunc) {\n    if parent == nil {\n        panic(&quot;cannot create context from nil parent&quot;)\n    }\n    if cur, ok := parent.Deadline(); ok &amp;&amp; cur.Before(d) {\n        // The current deadline is already sooner than the new one.\n        return WithCancel(parent)\n    }\n    c := &amp;timerCtx{\n        cancelCtx: newCancelCtx(parent),\n        deadline:  d,\n    }\n    propagateCancel(parent, c)\n    dur := time.Until(d)\n    if dur &lt;= 0 {\n        c.cancel(true, DeadlineExceeded) // deadline has already passed\n        return c, func() { c.cancel(false, Canceled) }\n    }\n    c.mu.Lock()\n    defer c.mu.Unlock()\n    if c.err == nil {\n        c.timer = time.AfterFunc(dur, func() {\n            c.cancel(true, DeadlineExceeded)\n        })\n    }\n    return c, func() { c.cancel(true, Canceled) }\n}\n\n\n\n• 校验 parent context 非空；\n\n\n• 校验 parent 的过期时间是否早于自己，若是，则构造一个 cancelCtx 返回即可；\n\n\n• 构造出一个新的 timerCtx；\n\n\n• 启动守护方法，同步 parent 的 cancel 事件到子 context；\n\n\n• 判断过期时间是否已到，若是，直接 cancel timerCtx，并返回 DeadlineExceeded 的错误；\n\n\n• 加锁；\n\n\n• 启动 time.Timer，设定一个延时时间，即达到过期时间后会终止该 timerCtx，并返回 DeadlineExceeded 的错误；\n\n\n• 解锁；\n\n\n• 返回 timerCtx，已经一个封装了 cancel 逻辑的闭包 cancel 函数.\n\n\nvalueCtx\n类\n\nvalueCtx数据结构\ntype valueCtx struct {\n    Context\n    key, val any\n}\n\n\n\n• valueCtx 同样继承了一个 parent context；\n\n\n• 一个 valueCtx 中仅有一组 kv 对.\n\n\nvalueCtx.Value()\n\nvalueCtx.Value\nfunc (c *valueCtx) Value(key any) any {\n    if c.key == key {\n        return c.val\n    }\n    return value(c.Context, key)\n}\n\n\n\n• 假如当前 valueCtx 的 key 等于用户传入的 key，则直接返回其 value；\n\n\n• 假如不等，则从 parent context 中依次向上寻找.\n\n\nfunc value(c Context, key any) any {\n    for {\n        switch ctx := c.(type) {\n        case *valueCtx:\n            if key == ctx.key {\n                return ctx.val\n            }\n            c = ctx.Context\n        case *cancelCtx:\n            if key == &amp;cancelCtxKey {\n                return c\n            }\n            c = ctx.Context\n        case *timerCtx:\n            if key == &amp;cancelCtxKey {\n                return &amp;ctx.cancelCtx\n            }\n            c = ctx.Context\n        case *emptyCtx:\n            return nil\n        default:\n            return c.Value(key)\n        }\n    }\n}\n\n\n\n• 启动一个 for 循环，由下而上，由子及父，依次对 key 进行匹配；\n\n\n• 其中 cancelCtx、timerCtx、emptyCtx 类型会有特殊的处理方式；\n\n\n• 找到匹配的 key，则将该组 value 进行返回.\n\n\nvalueCtx 用法小结\n阅读源码可以看出，valueCtx 不适合视为存储介质，存放大量的 kv 数据，原因有三：\n\n\n• 一个 valueCtx 实例只能存一个 kv 对，因此 n 个 kv 对会嵌套 n 个 valueCtx，造成空间浪费；\n\n\n• 基于 k 寻找 v 的过程是线性的，时间复杂度 O(N)；\n\n\n• 不支持基于 k 的去重，相同 k 可能重复存在，并基于起点的不同，返回不同的 v. 由此得知，valueContext 的定位类似于请求头，只适合存放少量作用域较大的全局 meta 数据.\n\n\ncontext.WithValue()\nfunc WithValue(parent Context, key, val any) Context {\n    if parent == nil {\n        panic(&quot;cannot create context from nil parent&quot;)\n    }\n    if key == nil {\n        panic(&quot;nil key&quot;)\n    }\n    if !reflectlite.TypeOf(key).Comparable() {\n        panic(&quot;key is not comparable&quot;)\n    }\n    return &amp;valueCtx{parent, key, val}\n}\n\n\n\n• 倘若 parent context 为空，panic；\n\n\n• 倘若 key 为空 panic；\n\n\n• 倘若 key 的类型不可比较，panic；\n\n\n• 包括 parent context 以及 kv 对，返回一个新的 valueCtx.\n\n\n通过层层传递 Context ，最终形成这样一棵树：\n\n和链表有点像，只是它的方向相反：Context 指向它的父节点，链表则指向下一个节点。通过 WithValue 函数，可以创建层层的 valueCtx，存储 goroutine 间可以共享的变量。\n取值的过程，实际上是一个递归查找的过程：\nfunc (c *valueCtx) Value(key interface{}) interface{} {\n\tif c.key == key {\n\t\treturn c.val\n\t}\n\treturn c.Context.Value(key)\n}\n它会顺着链路一直往上找，比较当前节点的 key 是否是要找的 key，如果是，则直接返回 value。否则，一直顺着 context 往前，最终找到根节点（一般是 emptyCtx），直接返回一个 nil。所以用 Value 方法的时候要判断结果是否为 nil。"},"GO/八股文/Golang基础":{"title":"Golang基础","links":[],"tags":["GO/八股文"],"content":"init 和 main 函数相关特点\ninit 函数 （没有输入参数、返回值）的主要作用\n\n初始化不能采用初始化表达式初始化的变量。\n程序运行前的注册。\n实现sync.Once功能。\n其他\n\ninit 顺序\n\n在同一个 package 中，可以多个文件中定义 init 方法\n在同一个 go 文件中，可以重复定义 init 方法\n在同一个 package 中，不同文件中的 init 方法的执行按照文件名先后执行各个文件中的 init 方法\n在同一个文件中的多个 init 方法，按照在代码中编写的顺序依次执行不同的 init 方法\n对于不同的 package，如果不相互依赖的话，按照 main 包中 import 的顺序调用其包中的 init() 函数\n如果 package 存在依赖，调用顺序为最后被依赖的最先被初始化，例如：导入顺序 main –&gt; A –&gt; B –&gt; C，则初始化顺序为 C –&gt; B –&gt; A –&gt; main，一次执行对应的 init 方法。\n\n所有 init 函数都在同⼀个 goroutine 内执行。\n所有 init 函数结束后才会执行 main.main 函数\n\nGo 的数据结构的零值是什么?\n\n\n所有整型类型：0\n\n\n浮点类型：0.0\n\n\n布尔类型：false\n\n\n字符串类型：””\n\n\n指针、interface、切片（slice）、channel、map、function ：nil\n\n\nGo的零值初始是递归的，即数组、结构体等类型的零值初始化就是对其组成元素逐一进行零值初始化。\nbyte和rune有什么区别\nrune和byte在go语言中都是字符类型，且都是别名类型\n\n\nbyte 型本质上是 uint8类型的别名，代表了 ASCII 码的一个字符\n\n\nrune 型本质上是 int32型的别名，代表一个 UTF-8 字符\n\n\nGo struct 能不能比较\n需要具体情况具体分析，如果struct中含有不能被比较的字段类型，就不能被比较。\n如果struct中所有的字段类型都支持比较，那么就可以被比较。\n\n不可被比较的类型：\n\nslice，因为slice是引用类型，除非是和nil比较\nmap，和slice同理，如果要比较两个map只能通过循环遍历实现\n函数类型\n\n\n\n其他的类型都可以比较。\n还有两点值得注意：\n\n结构体之间只能比较它们是否相等，而不能比较它们的大小\n只有所有属性都相等而且属性顺序都一致的结构体才能进行比较\n\nGo 语言如何初始化变量\nvar a int=10  \nvar a=10  \na:=10\n\nGo import 的三种方式\n一、加下划线：\nimport 下划线（如：_ “github.com/go-sql-driver/mysql”）\n作用：使用[import _ 包路径]只是引用该包，仅仅是为了调用init()函数，所以无法通过包名来调用包中的其他函数。\n二、加点(.)：\nimport和引用的包名之间加点（.）操作的含义就是这个包导入之后在调用这个包的函数时，可以省略前缀的包名。\n三、别名：\n别名操作顾名思义可以把包命名成另一个用起来容易记忆的名字。\n与其他语言相比，使用 Go 有什么好处？\n\n与其他作为学术实验开始的语⾔不同，Go 代码的设计是务实的。每个功能和语法决策都旨在让程序员的⽣活更轻松。\nGolang 针对并发进行了优化，并且在规模上运行良好。\n由于单⼀的标准代码格式，Golang 通常被认为比其他语⾔更具可读性。\n⾃动垃圾收集明显比Java 或 Python 更有效，因为它与程序同时执行。\n\n听说 go 有什么什么的缺陷，你怎么看\n\n缺少框架；\ngo 语言通过函数和预期的调用代码简单地返回错误，容易丢失错误发生的范围；\ngo语言的软件包管理没有办法制定特定版本的依赖库。\n\nGolang的常量取地址\nGo 语⾔中，常量⽆法寻址, 是不能进⾏取指针操作的\nconst i = 100  \n  \nvar j = 123  \n  \nfunc main() {  \n\tfmt.Println(&amp;j, j)   \n\tfmt.Println(&amp;i, i)  //panic  \n} //Go语⾔中，常量⽆法寻址, 是不能进⾏取指针操作的\n\nGolang 的字符串拼接\nA. str := &#039;abc&#039; + &#039;123&#039;  \nB. str := &quot;abc&quot; + &quot;123&quot;  \nC. str ：= &#039;123&#039; + &quot;abc&quot;  \nD. fmt.Sprintf(&quot;abc%d&quot;, 123)\n\n答案：B、D\n\nstring 和 []byte 如何取舍\nstring 擅长的场景：\n\n需要字符串比较的场景；\n不需要nil字符串的场景；\n\n[]byte擅长的场景：\n\n修改字符串的场景，尤其是修改粒度为1个字节；\n函数返回值，需要用nil表示含义的场景；\n需要切片操作的场景；\n\n使用过哪些 Golang 的 String 类库\nstrings. Builder\nGo 语言提供了一个专门操作字符串的库 strings，可以用于字符串查找、替换、比较等。\n使用 strings.Builder 可以进行字符串拼接，提供了 writeString 方法拼接字符串，使用方式如下：\nvar builder strings.Builder\nbuilder.WriteString(&quot;asong&quot;)\nbuilder.String()\n\nstrings.builder 的实现原理很简单，结构如下：\ntype Builder struct {\n    addr *Builder // of receiver, to detect copies by value\n    buf  []byte // 1\n}\n\naddr 字段主要是做 copycheck，buf 字段是一个 byte 类型的切片，这个就是用来存放字符串内容的，提供的 writeString() 方法就是向切片 buf 中追加数据：\nfunc (b *Builder) WriteString(s string) (int, error) {\n b.copyCheck()\n b.buf = append(b.buf, s...)\n return len(s), nil\n}\n\n提供的 String 方法就是将 []byte 转换为 string 类型，这里为了避免内存拷贝的问题，使用了强制转换来避免内存拷贝：\nfunc (b *Builder) String() string {\n return *(*string)(unsafe.Pointer(&amp;b.buf))\n}\n\nbytes. Buffer\n因为 string 类型底层就是一个 byte 数组，所以我们就可以 Go 语言的 bytes.Buffer 进行字符串拼接。bytes.Buffer 是一个一个缓冲 byte 类型的缓冲器，这个缓冲器里存放着都是 byte。使用方式如下：\nbuf := new(bytes.Buffer)\nbuf.WriteString(&quot;asong&quot;)\nbuf.String()\n\nbytes.buffer 底层也是一个 []byte 切片，结构体如下：\ntype Buffer struct {\n buf      []byte // contents are the bytes buf[off : len(buf)]\n off      int    // read at &amp;buf[off], write at &amp;buf[len(buf)]\n lastRead readOp // last read operation, so that Unread* can work correctly.\n}\n\n因为 bytes.Buffer 可以持续向 Buffer 尾部写入数据，从 Buffer 头部读取数据，所以 off 字段用来记录读取位置，再利用切片的 cap 特性来知道写入位置，这个不是本次的重点，重点看一下 WriteString 方法是如何拼接字符串的：\nfunc (b *Buffer) WriteString(s string) (n int, err error) {\n b.lastRead = opInvalid\n m, ok := b.tryGrowByReslice(len(s))\n if !ok {\n  m = b.grow(len(s))\n }\n return copy(b.buf[m:], s), nil\n}\n\n切片在创建时并不会申请内存块，只有在往里写数据时才会申请，首次申请的大小即为写入数据的大小。如果写入的数据小于 64 字节，则按 64 字节申请。采用 动态扩展slice 的机制，字符串追加采用 copy 的方式将追加的部分拷贝到尾部，copy 是内置的拷贝函数，可以减少内存分配。\n但是在将 []byte 转换为 string 类型依旧使用了标准类型，所以会发生内存分配：\nfunc (b *Buffer) String() string {\n if b == nil {\n  // Special case, useful in debugging.\n  return &quot;&lt;nil&gt;&quot;\n }\n return string(b.buf[b.off:])\n}\n\n字符串转成 byte 数组，会发生内存拷贝吗\n字符串转成切片，会产生拷贝。严格来说，只要是发生类型强转都会发生内存拷贝\nmp.weixin.qq.com/s#wechat_redirect\n翻转含有中文、数字、英文字母的字符串\n\n\nrune 关键字，从 golang 源码中看出，它是 int32的别名（-2^31 ~ 2^31-1），比起 byte（-128～127），可表示更多的字符。\n\n\n由于rune可表示的范围更大，所以能处理一切字符，当然也包括中文字符。在平时计算中文字符，可用rune。\n\n\n因此将字符串转为rune的切片，再进行翻转，完美解决\n\n\nmp.weixin.qq.com/s#wechat_redirect\njson 包变量不加 tag 会怎么样？\n\n\n如果变量 首字母小写，则为 private。无论如何 不能转，因为取不到 反射信息。\n\n\n如果变量首字母大写，则为public。\n\n\n不加tag，可以正常转为json里的字段，json内字段名跟结构体内字段原名一致。\n\n\n加了tag，从struct转json的时候，json的字段名就是tag里的字段名，原字段名已经没用。\n\n\n\n\nmp.weixin.qq.com/s#wechat_redirect\nreflect（反射包）如何获取字段 tag？为什么 json 包不能导出私有变量的 tag？\nmp.weixin.qq.com/s#wechat_redirect\n昨天那个在 for 循环里 append 元素的同事，今天还在么？\nmp.weixin.qq.com/s#wechat_redirect\nGolang 语言的自增，自减操作\nGolang 语言没++i、–i，只有 i++、i–-。\nPrintf()、Sprintf()、Fprintf()函数的区别用法是什么\n都是把格式好的字符串输出，只是输出的目标不一样。\n\nPrintf()，是把格式字符串输出到标准输出（一般是屏幕，可以重定向）。Printf() 是和标准输出文件 (stdout) 关联的，Fprintf 则没有这个限制。\nSprintf()，是把格式字符串输出到指定字符串中，所以参数比 printf 多一个 char*。那就是目标字符串地址。\nFprintf()，是把格式字符串输出到指定文件设备中，所以参数比 printf 多一个文件指针 FILE*。主要用于文件操作。Fprintf() 是格式化输出到一个 stream，通常是到文件。\n\nGo 语言中 cap 函数可以作用于哪些内容？\n\n\narray 返回数组的元素个数；\n\n\nslice 返回 slice 的最⼤容量；\n\n\nchannel 返回 channel 的容量；\n\n\nGolang 语言的引用类型有什么?\nGo语言中的引用类型有\n\n\nfunc（函数类型）\n\n\ninterface（接口类型）\n\n\nslice（切片类型）\n\n\nmap（字典类型）\n\n\nchannel（管道类型）\n\n\n指针类型\n\n\n通过指针变量  p 访问其成员变量 name，有哪几种方式？\nA. p.name\nB. (&amp;p).name\nC. (*p).name\nD. p→name\n答案：A、C\nfor select 时，如果通道已经关闭会怎么样？如果只有⼀个 case 呢？\n\n\nfor 循环 select 时，如果其中一个 case 通道已经关闭，则每次都会执行到这个 case。\n\n\n如果select里边只有一个case，而这个case被关闭了，则会出现死循环。\n\n\nmp.weixin.qq.com/s#wechat_redirect\nGolang 的 bool 类型的赋值\nA. b = true  \nB. b = 1  \nC. b = bool(1)  \nD. b = (1 == 2)  \n  \n赋值正确的是A,D。   \n首先B选项，int类型不能由bool类型来表示。  \n其次C选项，bool()不能转化int类型。int和float可以相互转化\n\n空结构体占不占内存空间？ 为什么使用空结构体？\n空结构体是没有内存大小的结构体。\n通过 unsafe.Sizeof() 可以查看空结构体的宽度，代码如下：\nvar s struct{}\nfmt.Println(unsafe.Sizeof(s)) // prints 0\n\n准确的来说，空结构体有一个特殊起点： zerobase 变量。zerobase是一个占用 8 个字节的uintptr全局变量。每次定义 struct {} 类型的变量，编译器只是把zerobase变量的地址给出去。也就是说空结构体的变量的内存地址都是一样的。\n空结构体的使用场景主要有三种：\n\n实现方法接收者：在业务场景下，我们需要将方法组合起来，代表其是一个 ”分组“ 的，便于后续拓展和维护。\n实现集合类型：在** Go 语言的标准库中并没有提供集合（Set）的相关实现，因此一般在代码中我们图方便，会直接用 map 来替代：type Set map[string]struct{}**。\n实现空通道：在 Go channel 的使用场景中，常常会遇到通知型 channel，其不需要发送任何数据，只是用于协调 Goroutine 的运行，用于流转各类状态或是控制并发情况。\n\n空结构体的使用场景\n空结构体（empty struct）是在 Go 语言中一个特殊的概念，它没有任何字段。在 Go 中，它通常被称为匿名结构体或零宽度结构体。尽管它没有字段，但它在某些情况下仍然有其用途，以下是一些常见的空结构体的使用场景：\n\n占位符：空结构体可以用作占位符，用于表示某个数据结构或数据集合的存在而不实际存储任何数据。这在某些数据结构的实现中非常有用，特别是在要实现某种数据结构的集合或映射时，但并不需要存储实际的值。\n\ngoCopy code// 表示集合中是否包含某个元素的映射\nset := make(map[string]struct{})\nset[&quot;apple&quot;] = struct{}{}\n\n\n信号量：空结构体可以用作信号量，用于控制并发操作。通过向通道发送或接收空结构体，可以实现信号的传递和同步。\n\ngoCopy code// 用通道作为信号量\nsemaphore := make(chan struct{}, 5) // 控制并发数为5\ngo func() {\n    semaphore &lt;- struct{}{} // 获取信号量\n    defer func() { &lt;-semaphore }() // 释放信号量\n    // 执行并发操作\n}()\n\n\n强调结构：有时，空结构体可用于强调某个结构的重要性或存在。它可以用作结构体的标签，表示关注该结构的存在而不是其内容。\n\ngoCopy code// 表示一篇文章的元信息，不包含实际内容\ntype Article struct {\n    Title       string\n    Author      string\n    PublishedAt time.Time\n    Metadata    struct{} // 空结构体强调元信息的存在\n}\n\n\nJSON 序列化：在处理 JSON 数据时，有时需要表示一个空对象。可以使用空结构体来表示 JSON 中的空对象（{}）。\n\ngoCopy code// 表示一个空的JSON对象\nemptyJSON := struct{}{}\njsonBytes, _ := json.Marshal(emptyJSON)\nfmt.Println(string(jsonBytes)) // 输出: {}\n\n尽管空结构体没有字段，但它在上述情况下提供了一种轻量级的方式来实现特定的需求，而无需分配额外的内存或定义具体的数据结构。这使得它成为 Go 中的一种有用工具，可以在编写清晰、高效和易于理解的代码时派上用场。\nstruct 的特点\n\n用来自定义复杂数据结构\nStruct 里面可以包含多个字段（属性）\nStruct 类型可以定义方法，注意和函数的区分\nStruct 类型是值类型\nStruct 类型可以嵌套\nGO 语言没有 class 类型，只有 struct 类型\n\n特殊之处\n\n结构体是用户单独定义的类型，不能和其他类型进行强制转换\nGolang 中的 struct 没有构造函数，一般可以使用工厂模式来解决这个问题\n我们可以为 struct 中的每个字段，写上一个 tag。这个 tag 可以通过反射的机制获取到，最常用的场景就是 json 序列化和反序列化。\n结构体中字段可以没有名字，即匿名字段\n\nGo 的面向对象特性\n接口\n接口使用 interface 关键字声明，任何实现接口定义方法的类都可以实例化该接口，接口和实现类之间没有任何依赖\n你可以实现一个新的类当做 Sayer 来使用，而不需要依赖 Sayer 接口，也可以为已有的类创建一个新的接口，而不需要修改任何已有的代码，和其他静态语言相比，这可以算是 golang 的特色了吧\ntype Sayer interface {\n Say(message string)\n SayHi()\n}\n\n继承\n继承使用组合的方式实现\ntype Animal struct {\n Name string\n}\n\nfunc (a *Animal) Say(message string) {\n    fmt.Printf(&quot;Animal[%v] say: %v\n&quot;, a.Name, message)\n}\n\ntype Dog struct {\n Animal\n}\n\nDog 将继承 Animal 的 Say 方法，以及其成员 Name\n覆盖\n子类可以重新实现父类的方法\n// override Animal.Say\nfunc (d *Dog) Say(message string) {\n    fmt.Printf(&quot;Dog[%v] say: %v\n&quot;, d.Name, message)\n}\n\nDog.Say 将覆盖 Animal.Say\n多态\n接口可以用任何实现该接口的指针来实例化\nvar sayer Sayer\n\nsayer = &amp;Dog{Animal{Name: &quot;Yoda&quot;}}\nsayer.Say(&quot;hello world&quot;)\n\n但是不支持父类指针指向子类，下面这种写法是不允许的\nvar animal *Animal\nanimal = &amp;Dog{Animal{Name: &quot;Yoda&quot;}}\n\n同样子类继承的父类的方法引用的父类的其他方法也没有多态特性\nfunc (a *Animal) Say(message string) {\n    fmt.Printf(&quot;Animal[%v] say: %v\n&quot;, a.Name, message)\n}\n\nfunc (a *Animal) SayHi() {\n    a.Say(&quot;Hi&quot;)\n}\n\nfunc (d *Dog) Say(message string) {\n    fmt.Printf(&quot;Dog[%v] say: %v\n&quot;, d.Name, message)\n}\n\nfunc main() {\n var sayer Sayer\n\n    sayer = &amp;Dog{Animal{Name: &quot;Yoda&quot;}}\n    sayer.Say(&quot;hello world&quot;) // Dog[Yoda] say: hello world\n    sayer.SayHi() // Animal[Yoda] say: Hi\n    }\n\n上面这段代码中，子类 Dog 没有实现 SayHi 方法，调用的是从父类 Animal.SayHi，而 Animal.SayHi 调用的是 Animal.Say 而不是Dog.Say，这一点和其他面向对象语言有所区别，需要特别注意，但是可以用下面的方式来实现类似的功能，以提高代码的复用性\nfunc SayHi(s Sayer) {\n    s.Say(&quot;Hi&quot;)\n}\n\ntype Cat struct {\n Animal\n}\n\nfunc (c *Cat) Say(message string) {\n    fmt.Printf(&quot;Cat[%v] say: %v\n&quot;, c.Name, message)\n}\n\nfunc (c *Cat) SayHi() {\n SayHi(c)\n}\n\nfunc main() {\n var sayer Sayer\n\n    sayer = &amp;Cat{Animal{Name: &quot;Jerry&quot;}}\n    sayer.Say(&quot;hello world&quot;) // Cat[Jerry] say: hello world\n    sayer.SayHi() // Cat[Jerry] say: Hi\n}\n\nGo 语言中 ,下面哪个关于指针的说法是错误的?\n\n指针不能进行算术运算\n指针可以比较\n指针可以是nil\n指针可以指向任何类型\n\n指针在 Go 语言中只能指向相同类型的结构体或者基本类型。例如，一个 int 类型的变量，只能指向 int 类型的指针。如果尝试将一个不同类型的指针赋给一个变量，将会导致编译错误。\nGo 语言的接口类型是如何实现的？\n在Go语言中，接口类型是通过类型嵌入（embedding的方式实现的。每个实现了接口的类型的结构体中都有一个隐含的成员，该成员是指向接口类型的指针。通过这种方式，接口实现了对类型的约束和定义。\n具体来说，当一个类型实现了某个接口的所有方法后，该类型就被认为是实现了该接口。在结构体中，可以通过嵌入接口类型的方式来实现接口方法。在实现接口方法时，方法的签名需要与接口定义中的方法签名保持一致。\nGo 结构体内嵌后的命名冲突\npackage main\n\nimport (\n\t&quot;fmt&quot;\n)\n\ntype A struct {\n\ta int\n}\n\ntype B struct {\n\ta int\n}\n\ntype C struct {\n\tA\n\tB\n}\n\nfunc main() {\n\tc := &amp;C{}\n\tc.A.a = 1\n\tfmt.Println(c)\n}\n// 输出 &amp;{{1} {0}}\n\n第 7 行和第 11 行分别定义了两个拥有 a int 字段的结构体。\n第 15 行的结构体嵌入了 A 和 B 的结构体。\n第 21 行实例化 C 结构体。\n第 22 行按常规的方法，访问嵌入结构体 A 中的 a 字段，并赋值1。\n第 23 行可以正常输出实例化 C 结构体。\n接着，将第 22 行修改为如下代码：\nfunc main(){\n\tc:=&amp;C{}\n    c.a=1\n    fmt.Println(c)\n}\n\n\n此时再编译运行，编译器报错：\n.main. Go:22:3:ambiguousselectorc. A\n编译器告知 C 的选择器 a 引起歧义，也就是说，编译器无法决定将 1 赋给 C 中的 A 还是 B 里的字段 a。使用c.a 引发二义性的问题一般应该由程序员逐级完整写出避免错误。\n在使用内嵌结构体时，Go 语言的编译器会非常智能地提醒我们可能发生的歧义和错误。\n**解决：可以通过：c.A.a 或者c.B.a 都可以正确得到对应的值\n关于 switch 语句，下⾯说法正确的有?\nA. 条件表达式必须为常量或者整数；\nB. 单个case中，可以出现多个结果选项；\nC. 需要⽤break来明确退出⼀个case；\nD. 只有在case中明确添加fallthrough关键字，才会继续执⾏紧跟的下⼀个case；\n答案B、D\nGo 编程语言中 switch 语句的语法\nswitch var1 {\n    case val1:\n        ...\n    case val2:\n        ...\n    default:\n        .\n}\n\nswitch{\n    case 1,2,3,4:\n    default:\n} //case可以有多个数据\n\n\n变量 var1 可以是任何类型，而 val1 和 val2 则可以是同类型的任意值。类型不被局限于常量或整数，但必须是相同的类型；或者最终结果为相同类型的表达式。\nGo 关键字 fallthrough 有什么作用\nFallthrough 关键字只能用在 switch 中。且只能在每个 case 分支中最后一行出现，作用是如果这个 case 分支被执行，将会继续执行下一个 case 分支，而且不会去判断下一个分支的 case 条件是否成立。\npackage main  \n  \nimport &quot;fmt&quot;  \n  \nfunc main() {  \n\tswitch &quot;a&quot; {  \n\tcase &quot;a&quot;:  \n\t\tfmt.Println(&quot;匹配a&quot;)  \n\t\tfallthrough  \n\tcase &quot;b&quot;:  \n\t\tfmt.Println(&quot;a成功了，也执行b分支&quot;)  \n\tcase &quot;c&quot;:  \n\t\tfmt.Println(&quot;a成功了，c分支会执行吗？&quot;)  \n\tdefault:  \n\t\tfmt.Println(&quot;默认执行&quot;)  \n\t}  \n}  \n/*  \n\t匹配a  \n    a成功了，也执行b分支  \n*/\n\ncopy 是操作符还是内置函数\nGolang中copy是内置函数。\nGo 两个接口之间可以存在什么关系？\n如果两个接口有相同的方法列表，那么他们就是等价的，可以相互赋值。如果接口 A的方法列表是接口B的方法列表的自己，那么接口B可以赋值给接口A。接口查询是否成功，要在运行期才能够确定。\nGolang 的返回值命名\n\nGolang 的 iota 如何使用？\n\n\niota在const关键字出现时被重置为0\nconst声明块中每新增一行iota值自增1\n第一个常量必须指定一个表达式，后续的常量如果没有表达式，则继承上面的表达式\n\n数组之间如何进行比较？\n\nfor range 的注意点和坑\n第一个说法\n1.迭代变量。Python中for in 可以直接的到value，但Go的for range 迭代变量有两个，第一个是元素在迭代集合中的序号值key（从0开始），第二个值才是元素值value。\n2.针对字符串。在Go中对字符串运用for range操作，每次返回的是一个码点，而不是一个字节。Go编译器不会为[]byte进行额外的内存分配，而是直接使用string的底层数据。\n3.对map类型内元素的迭代顺序是随机的。要想有序迭代map内的元素，我们需要额外的数据结构支持，比如使用一个切片来有序保存map内元素的key值。\n4.针对切片类型复制之后，如果原切片扩容增加新元素。迭代复制后的切片并不会输出扩容新增元素。这是因为range表达式中的切片实际上是原切片的副本。\n5.迭代变量是重用的。类似PHP语言中的i=0；如果其他循环中使用相同的迭代变量，需要重新初始化i。\n6.for range使用时，k,v值已经赋值好了，不会因为for循环的改变而改变\npackage main\n\nimport (\n\t&quot;fmt&quot;\n)\n\nfunc main() {\n\tx := []string{&quot;a&quot;, &quot;b&quot;, &quot;c&quot;}\n\tfor v := range x {\n\t\tfmt.Println(v)\n\t}\n}\n//输出 0 1 2\n\n第二个说法\n应该是一个for循环中作用域的问题\nsrc := []int{1, 2, 3, 4, 5}\nvar dst2 []*inv\nfor _, v := range src {\n    dst2 = append(dst2, &amp;v)\n    // fmt.println(&amp;v)\n}\n\nfor _, p := range dst2 {\n    fmt.Print(*p)\n}\n// 输出\n// 5555\n\n为什么呢, 因为 for-range 中 循环变量的作用域的规则限制\n假如取消append()后一行的注释，可以发现循环中v的变量内存地址是一样的，也可以解释为for range相当于\nvar i int\nfor j := 0; j &lt; len(src); j++ {\n    i = src[j]\n    dst2 = append(dst2, &amp;i)\n}\n\n而不是我们想象中的\nfor j := 0; j &lt; len(src); j++ {\n    dst2 = append(dst2, &amp;src[j])\n}\n\n如果要在for range中实现，我们可以改写为\nsrc := []int{1, 2, 3, 4, 5}\nvar dst2 []*int\nfor _, v := range src {\n    new_v := v\n    dst2 = append(dst2, &amp;new_v)\n    // fmt.println(&amp;new_v)\n}\n\nfor _, p := range dst2 {\n    fmt.Print(*p)\n}\n\nGolang 的断言\nGo中的所有程序都实现了interface{}的接口，这意味着，所有的类型如string,int,int64甚至是自定义的struct类型都就此拥有了interface{}的接口.那么在一个数据通过func funcName(interface{})的方式传进来的时候，也就意味着这个参数被自动的转为interface{}的类型。\n如以下的代码：\nfunc funcName(a interface{}) string {\n\treturn string(a)\n}\n\n编译器将会返回：cannot convert a (type interface{}) to type string: need type assertion\n此时，意味着整个转化的过程需要类型断言。类型断言有以下几种形式：\n直接断言使用\nvar a interface{}\nfmt.Println(&quot;Where are you,Jonny?&quot;, a.(string))\n\n但是如果断言失败一般会导致panic的发生。所以为了防止panic的发生，我们需要在断言前进行一定的判断\nvalue, ok := a.(string)\n\n如果断言失败，那么ok的值将会是false,但是如果断言成功ok的值将会是true,同时value将会得到所期待的正确的值。示例：\nvalue, ok := a.(string)\nif !ok {\n    fmt.Println(&quot;It&#039;s not ok for type string&quot;)\n    return\n}\nfmt.Println(&quot;The value is &quot;, value)\n\n另外也可以配合switch语句进行判断：\nvar t interface{}\nt = functionOfSomeType()\nswitch t := t.(type) {\ndefault:\n    fmt.Printf(&quot;unexpected type %T&quot;, t)       // %T prints whatever type t has    break\ncase bool:\n    fmt.Printf(&quot;boolean %t\\n&quot;, t)             // t has type bool    break\ncase int:\n    fmt.Printf(&quot;integer %d\\n&quot;, t)             // t has type int    break\ncase *bool:\n    fmt.Printf(&quot;pointer to boolean %t\\n&quot;, *t) // t has type *bool    break\ncase *int:\n    fmt.Printf(&quot;pointer to integer %d\\n&quot;, *t) // t has type *int    break\n}\n\n如何在运行时检查变量类型？\n类型开关是在运行时检查变量类型的最佳方式。类型开关按类型而不是值来评估变量。每个 Switch ⾄少包含⼀个 case，⽤作条件语句，和⼀个 default，如果没有⼀个 case 为真，则执行。\nfunc classifier(items ...interface{}) {\n    for i, x := range items {\n        switch x.(type) {\n        case bool:\n            fmt.Printf(&quot;Param #%d is a bool\\n&quot;, i)\n        case float64:\n            fmt.Printf(&quot;Param #%d is a float64\\n&quot;, i)\n        case int, int64:\n            fmt.Printf(&quot;Param #%d is a int\\n&quot;, i)\n        case nil:\n            fmt.Printf(&quot;Param #%d is a nil\\n&quot;, i)\n        case string:\n            fmt.Printf(&quot;Param #%d is a string\\n&quot;, i)\n        default:\n            fmt.Printf(&quot;Param #%d is unknown\\n&quot;, i)\n        }\n    }\n}\n\n精通 Golang 项目依赖 Go modules\nwww.topgoer.cn/docs/golangxiuyang/golangxiuyang-1cmee13oek1e8\nGo string 的底层实现\n源码包src/runTime/string.go.stringStruct定义了string的数据结构\nType stringStruct struct{\n\tstr unsafe.Pointer // 字符串的首地址\n \tlen int // 字符串的长度\n}\n\n声明：\n如下代码所示，可以声明一个string变量赋予初值\nvar str string\nstr = &quot;Hello world&quot;\n\n字符串构建过程是根据字符串构建stringStruct，再转化成string。转换的源码如下：\nfunc gostringnocopy(str *byte) string{       //根据字符串地址构建string\n       ss := stringStruct{str:unsafe.Pointer(str),len:findnull(str)}  // 先构造 stringStruct\n       s := *(*string)(unsafe.Pointer(&amp;ss))   //再将stringStruct 转换成string\n       return s\n}\n\nGo 语言的 panic 如何恢复\nrecover 可以中止 panic 造成的程序崩溃，或者说平息运行时恐慌，recover 函数不需要任何参数，并且会返回一个空接口类型的值。需要注意的是 recover 只能在 defer 中发挥作用，在其他作用域中调用不会发挥作用。编译器会将 recover 转换成 runtime.gorecover，该函数的实现逻辑是如果当前 goroutine 没有调用 panic，那么该函数会直接返回 nil，当前 goroutine 调用 panic 后，会先调用 runtime.gopaic 函数 runtime.gopaic 会从 runtime.  _defer 结构体中取出程序计数器 pc 和栈指针 sp，再调用 runtime.recovery 函数来恢复程序，runtime.recovery 会根据传入的 pc 和 sp 跳转回 runtime.deferproc，编译器自动生成的代码会发现 runtime.deferproc 的返回值不为 0，这时会调回 runtime.deferreturn 并恢复到正常的执行流程。总的来说恢复流程就是通过程序计数器来回跳转。\nGo 如何避免 panic\n首先明确panic定义：go把真正的异常叫做 panic，是指出现重大错误，比如数组越界之类的编程BUG或者是那些需要人工介入才能修复的问题，比如程序启动时加载资源出错等等。\n几个容易出现panic的点:\n\n函数返回值或参数为指针类型，nil, 未初始化结构体，此时调用容易出现panic，可加 != nil 进行判断\n数组切片越界\n如果我们关闭未初始化的通道，重复关闭通道，向已经关闭的通道中发送数据，这三种情况也会引发 panic，导致程序崩溃\n如果我们直接操作未初始化的映射（map），也会引发 panic，导致程序崩溃\n另外，操作映射可能会遇到的更为严重的一个问题是，同时对同一个映射并发读写，它会触发 runtime.throw，不像 panic 可以使用 recover 捕获。所以，我们在对同一个映射并发读写时，一定要使用锁。\n如果类型断言使用不当，比如我们不接收布尔值的话，类型断言失败也会引发 panic，导致程序崩溃。\n如果很多时候不可避免地出现了panic, 记得使用 defer/recover\n\ndefer 的几个坑\nfunc main() {\n    fmt.Println(test())\n}\n\nfunc test() error {\n    var err error\n    defer func() {\n       if r := recover(); r != nil {\n          err = errors.New(fmt.Sprintf(&quot;%s&quot;, r))\n       }\n    }()\n    raisePanic()\n    return err\n}\n\nfunc raisePanic() {\n    panic(&quot;发生了错误&quot;)\n}\n\n为什么输出****?\npackage main\n\nimport (\n    &quot;fmt&quot;\n)\n\nfunc main()  {\n\n    defer func() {\n       if err := recover(); err != nil{\n           fmt.Println(err)\n       }else {\n           fmt.Println(&quot;fatal&quot;)\n       }\n    }()\n\n    defer func() {\n        panic(&quot;defer panic&quot;)\n    }()\n\n    panic(&quot;panic&quot;)\n}\n\n结果\ndefer panic\n\n分析\npanic仅有最后一个可以被revover捕获。\n触发panic(&quot;panic&quot;)后defer顺序出栈执行，第一个被执行的defer中 会有panic(&quot;defer panic&quot;)异常语句，这个异常将会覆盖掉main中的异常panic(&quot;panic&quot;)，最后这个异常被第二个执行的defer捕获到。\npackage main\n\nimport &quot;fmt&quot;\n\nfunc function(index int, value int) int {\n\n    fmt.Println(index)\n\n    return index\n}\n\nfunc main() {\n    defer function(1, function(3, 0))\n    defer function(2, function(4, 0))\n}\n\n这里，有4个函数，他们的index序号分别为1，2，3，4。\n那么这4个函数的先后执行顺序是什么呢？这里面有两个defer， 所以defer一共会压栈两次，先进栈1，后进栈2。 那么在压栈function1的时候，需要连同函数地址、函数形参一同进栈，那么为了得到function1的第二个参数的结果，所以就需要先执行function3将第二个参数算出，那么function3就被第一个执行。同理压栈function2，就需要执行function4算出function2第二个参数的值。然后函数结束，先出栈fuction2、再出栈function1.\n所以顺序如下：\n\ndefer压栈function1，压栈函数地址、形参1、形参2(调用function3) –&gt; 打印3\ndefer压栈function2，压栈函数地址、形参1、形参2(调用function4) –&gt; 打印4\ndefer出栈function2, 调用function2 –&gt; 打印2\ndefer 出栈 function1, 调用 function1–&gt; 打印1\n\n3\n4\n2\n1\n\n**\nGo程序中的包是什么？\n包(pkg)是 Go 工作区中包含 Go 源⽂件或其他包的目录。源文件中的每个函数、变量和类型都存储在链接包中。每个 Go 源文件都属于⼀个包，该包在文件顶部使⽤以下命令声明：\npackage &lt;packagename&gt;\n\n您可以使⽤以下⽅法导⼊和导出包以重⽤导出的函数或类型：\nimport &lt;packagename&gt;\n\nGolang 的标准包是 fmt，其中包含格式化和打印功能，如 Println().\nGo 实现不重启热部署\n根据系统的 SIGHUP 信号量，以此信号量触发进程重启，达到热更新的效果。\n热部署我们需要考虑几个能力：\n\n新进程启动成功，老进程不会有资源残留\n新进程初始化的过程中，服务不会中断\n新进程初始化失败，老进程仍然继续工作\n同一时间，只能有一个更新动作执行\n\n监听信号量的方法的环境是在 类 UNIX 系统中，在现在的 UNIX 内核中，允许多个进程同时监听一个端口。在收到 SIGHUP 信号量时，先 fork 出一个新的进程监听端口，同时等待旧进程处理完已经进来的连接，最后杀掉旧进程。\n我基于这个思路，实现了一段示例代码，仓库地址：github.com/guowei-gong/tablefilp-example，  如果你希望动手来加深印象可以打开看看。\nGo 中的指针强转\n在 Golang 中无法使用指针类型对指针进行强制转换\n\n但可以借助 unsafe 包中的 unsafe.Pointer 转换\n\n在 src/unsafe.go 中可以看到指针类型说明\n// ArbitraryType 与 IntegerType 在此只用于文档描述，实际并不 unsafe 包中的一部分\n// 表示任意 go 的表达式\ntype ArbitraryType int\n\n// 表示任意 integer 类型\ntype IntegerType int\n\ntype Pointer *ArbitraryType\n\n对于指针类型 Pointer 强调以下四种操作\n\n指向任意类型的指针都可以被转化成 Pointer\nPointer 可以转化成指向任意类型的指针\nuintptr 可以转化成 Pointer\nPointer 可以转化成 uintptr\n\n\nuintptr 在 src/builtin/builtin.go 中定义\n\n其后描述了六种指针转换的情形\n其一：*Conversion of a T1 to Pointer to *T2\n转换条件：\n\nT2 的数据类型不大于 T1\nT1、T2 的内存模型相同\n\n因此对于 *int 不能强制转换 *float64 可以变化为 *int → unsafe.Pointer → *float64 的过程\nGo 支持什么形式的类型转换？将整数转换为浮点数。\nGo 支持显式类型转换以满足其严格的类型要求。\ni := 55 //int\nj := 67.8 //float64\nsum := i + int(j)//j is converted to int\n\nGolang 语言中== 的使用\npackage main\n\nfunc main() {\n\tvar x interface{}\n\tvar y interface{} = []int{3, 5}\n\t_ = x == x //输出true\n\t_ = x == y //interface{}比较的是动态类型和动态值，输出false\n\t_ = y == y //panic,切片不可比较\n}\n\nGo 语言实现小根堆\npackage main\n\nimport (\n\t&quot;container/heap&quot;\n\t&quot;fmt&quot;\n)\n\ntype MinHeap []int\n\nfunc (h MinHeap) Len() int           { return len(h) }\nfunc (h MinHeap) Less(i, j int) bool { return h[i] &lt; h[j] }\nfunc (h MinHeap) Swap(i, j int)      { h[i], h[j] = h[j], h[i] }\n\nfunc (h *MinHeap) Push(x interface{}) {\n\t*h = append(*h, x.(int))\n}\n\nfunc (h *MinHeap) Pop() interface{} {\n\told := *h\n\tn := len(old)\n\tx := old[n-1]\n\t*h = old[:n-1]\n\treturn x\n}\n\nfunc main() {\n\th := &amp;MinHeap{2, 1, 5, 3, 4}\n\theap.Init(h)\n\tfmt.Println(&quot;堆中最小的元素是：&quot;, (*h)[0])\n\theap.Push(h, 0)\n\tfmt.Println(&quot;插入后最小的元素是：&quot;, (*h)[0])\n\tmin := heap.Pop(h).(int)\n\tfmt.Println(&quot;弹出最小的元素是：&quot;, min)\n}\n\nGo 怎么实现 func 的自定义参数\n在 golang中，type 可以定义任何自定义的类型\nfunc 也是可以作为类型自定义的，type myFunc func(int) int，意思是自定义了一个叫 myFunc 的函数类型，这个函数的签名必须符合输入为 int，输出为 int。\ngolang通过type定义函数类型\n通过 type 可以定义函数类型，格式如下\ntype typeName func(arguments) retType\n\n函数类型也是一种类型，故可以将其定义为函数入参，在 go 语言中函数名可以看做是函数类型的常量，所以我们可以直接将函数名作为参数传入的函数中。\npackage main\n\nimport &quot;fmt&quot;\n\nfunc add(a, b int) int {\n\treturn a + b\n}\n\n//sub作为函数名可以看成是 op 类型的常量\nfunc sub(a, b int) int {\n\treturn a - b\n}\n\n//定义函数类型 op\ntype op func(a, b int) int\n\n//形参指定传入参数为函数类型op\nfunc Oper(fu op, a, b int) int {\n\treturn fu(a, b)\n}\n\nfunc main() {\n\t//在go语言中函数名可以看做是函数类型的常量，所以我们可以直接将函数名作为参数传入的函数中。\n\taa := Oper(add, 1, 2)\n\tfmt.Println(aa)\n\tbb := Oper(sub, 1, 2)\n\tfmt.Println(bb)\n}\n\n为什么 go 的变量申请类型是为了什么？\n在 Go 编程语言中，数据类型用于声明函数和变量。\n数据类型的出现是为了把数据分成所需内存大小不同的数据，编程的时候需要用大数据的时候才需要申请大内存，就可以充分利用内存。\nGo 的闭包语法\ngo语言的闭包可以理解为一个引用外部变量的匿名函数，Go语言中闭包是引用了自由变量的函数，被引用的自由变量和函数一同存在，即使已经离开了自由变量的环境也不会被释放或者删除，在闭包中可以继续使用这个自由变量，因此，简单的说：\n函数 + 引用环境 = 闭包\n同一个函数与不同引用环境组合，可以形成不同的实例，如下图：\n\n一个函数类型就像结构体一样，可以被实例化，函数本身不存储任何信息，只有与引用环境结合后形成的闭包才具有“记忆性”，函数是编译期静态的概念，而闭包是运行期动态的概念。\nGo 语言中 int 占几个字节\nGo语言中的int的大小是和操作系统位数相关的，如果是32位操作系统，int类型的大小就是4字节; 如果是64位操作系统，int类型的大小就是8个字节\nGolang 程序启动过程\nGo程序启动过程 \nGolang 程序启动过程 \nGolang 开发新手常犯的50个错误\nblog.csdn.net/gezhonglei2007/article/details/52237582 \ngo基础语法50问\njuejin.cn/post/7160639446612705316\nGo 程序的基本结构？\n\nGo 有哪些关键字？\n\nGo 有哪些数据类型？\n\nGo 方法与函数的区别？\n\nGo 方法值接收者和指针接收者的区别?\n\n\n如果方法的接收者是指针类型，无论调用者是对象还是对象指针，修改的都是对象本身，会影响调用者；\n\n\n如果方法的接收者是值类型，无论调用者是对象还是对象指针，修改的都是对象的副本，不影响调用者；\n\n\npackage main\n\nimport &quot;fmt&quot;\n\ntype Person struct {\n\tage int\n}\n\n// 如果实现了接收者是指针类型的方法，会隐含地也实现了接收者是值类型的IncrAge1方法。\n// 会修改age的值\nfunc (p *Person) IncrAge1() {\n\tp.age += 1\n}\n\n// 如果实现了接收者是值类型的方法，会隐含地也实现了接收者是指针类型的IncrAge2方法。\n// 不会修改age的值\nfunc (p Person) IncrAge2() {\n\tp.age += 1\n}\n\n// 如果实现了接收者是值类型的方法，会隐含地也实现了接收者是指针类型的GetAge方法。\nfunc (p Person) GetAge() int {\n\treturn p.age\n}\n\nfunc main() {\n\t// p1 是值类型\n\tp := Person{age: 10}\n\n\t// 值类型 调用接收者是指针类型的方法\n\tp.IncrAge1()\n\tfmt.Println(p.GetAge())\n\t// 值类型 调用接收者是值类型的方法\n\tp.IncrAge2()\n\tfmt.Println(p.GetAge())\n\n\t// ----------------------\n\n\t// p2 是指针类型\n\tp2 := &amp;Person{age: 20}\n\n\t// 指针类型 调用接收者是指针类型的方法\n\tp2.IncrAge1()\n\tfmt.Println(p2.GetAge())\n\t// 指针类型 调用接收者是值类型的方法\n\tp2.IncrAge2()\n\tfmt.Println(p2.GetAge())\n}\n/*\n11\n11\n21\n21\n*/\n\n上述代码中：\n实现了接收者是指针类型的 IncrAge 1 函数，不管调用者是值类型还是指针类型，都可以调用 IncrAge 1 方法，并且它的 age 值都改变了。\n实现了接收者是指针类型的 IncrAge 2 函数，不管调用者是值类型还是指针类型，都可以调用 IncrAge 2 方法，并且它的 age 值都没有被改变。\n通常我们使用指针类型作为方法的接收者的理由：\n\n使用指针类型能够修改调用者的值。\n使用指针类型可以避免在每次调用方法时复制该值，在值的类型为大型结构体时，这样做会更加高效。\n\nGo 函数返回局部变量的指针是否安全?\n一般来说，局部变量会在函数返回后被销毁，因此被返回的引用就成为了”无所指”的引用，程序会进入未知状态。\n但这在 Go 中是安全的，Go 编译器将会对每个局部变量进行逃逸分析。如果发现局部变量的作用域超出该函数，则不会将内存分配在栈上，而是分配在堆上，因为他们不在栈区，即使释放函数，其内容也不会受影响。\npackage main\n\nimport &quot;fmt&quot;\n\nfunc add(x, y int) *int {\n\tres := 0\n\tres = x + y\n\treturn &amp;res\n}\n\nfunc main() {\n\tfmt.Println(add(1, 2))\n}\n\n这个例子中，函数 add 局部变量 res 发生了逃逸。Res 作为返回值，在 main 函数中继续使用，因此 res 指向的内存不能够分配在栈上，随着函数结束而回收，只能分配在堆上。\n编译时可以借助选项 -gcflags=-m，查看变量逃逸的情况\n./main.go:6:2: res escapes to heap:\n./main.go:6:2:   flow: ~r2 = &amp;res:\n./main.go:6:2:     from &amp;res (address-of) at ./main.go:8:9\n./main.go:6:2:     from return &amp;res (return) at ./main.go:8:2\n./main.go:6:2: moved to heap: res\n./main.go:12:13: ... argument does not escape\n0xc0000ae008\n\nres escapes to heap 即表示 res 逃逸到堆上了。\nGo 函数参数传递到底是值传递还是引用传递？\n先说下结论：\nGo 语言中所有的传参都是值传递（传值），都是一个副本，一个拷贝。\n参数如果是非引用类型（int、string、struct 等这些），这样就在函数中就无法修改原内容数据；如果是引用类型（指针、map、slice、chan 等这些），这样就可以修改原内容数据。\n是否可以修改原内容数据，和传值、传引用没有必然的关系。在 C++中，传引用肯定是可以修改原内容数据的，在 Go 语言里，虽然只有传值，但是我们也可以修改原内容数据，因为参数是引用类型\n引用类型和引用传递是 2 个概念，切记！！！\n什么是值传递？\n将实参的值传递给形参，形参是实参的一份拷贝，实参和形参的内存地址不同。函数内对形参值内容的修改，是否会影响实参的值内容，取决于参数是否是引用类型\n什么是引用传递？\n将实参的地址传递给形参，函数内对形参值内容的修改，将会影响实参的值内容。Go 语言是没有引用传递的，在 C++中，函数参数的传递方式有引用传递。\n例子：\npackage main\n\nimport &quot;fmt&quot;\n\nfunc main() {\n    m := make(map[string]int)\n    m[&quot;age&quot;] = 8\n\n    fmt.Printf(&quot;原始map的内存地址是：%p\\n&quot;, &amp;m)\n    modifyMap(m)\n    fmt.Printf(&quot;改动后的值是: %v\\n&quot;, m)\n}\n\nfunc modifyMap(m map[string]int) {\n    fmt.Printf(&quot;函数里接收到map的内存地址是：%p\\n&quot;, &amp;m)\n    m[&quot;age&quot;] = 9\n}\n/*\n原始map的内存地址是：0xc00000e028\n函数里接收到map的内存地址是：0xc00000e038\n改动后的值是: map[age:9]\n通过make函数创建的map变量本质是一个hmap类型的指针*hmap，所以函数内对形参的修改，会修改原内容数据(channel也如此)\n*/\n\nGo defer 关键字的实现原理？\n定义：\nDefer 能够让我们推迟执行某些函数调用，推迟到当前函数返回前才实际执行。Defer 与 panic 和 recover 结合，形成了 Go 语言风格的异常与捕获机制。\n使用场景：\nDefer 语句经常被用于处理成对的操作，如文件句柄关闭、连接关闭、释放锁\n优点：\n方便开发者使用\n缺点：\n有性能损耗\n实现原理：\nGo 1.14 中编译器会将 defer 函数直接插入到函数的尾部，无需链表和栈上参数拷贝，性能大幅提升。把 defer 函数在当前函数内展开并直接调用，这种方式被称为 open coded defer\n源代码：\nfunc A(i int) {\n    defer A1(i, 2*i)\n    if(i &gt; 1) {\n        defer A2(&quot;Hello&quot;, &quot;eggo&quot;)\n    }\n    // code to do something\n    return\n}\nfunc A1(a,b int) {\n    //......\n}\nfunc A2(m,n string) {\n    //......\n}\n\n编译后（伪代码）：\nfunc A(i int) {\n        // code to do something\n    if(i &gt; 1){\n       A2(&quot;Hello&quot;, &quot;eggo&quot;)\n    }\n    A1(i, 2*i)\n    return\n}\n\n代码示例：\n1、函数退出前，按照先进后出的顺序，执行 defer 函数\npackage main\n\nimport &quot;fmt&quot;\n\n// defer：延迟函数执行，先进后出\nfunc main() {\n    defer fmt.Println(&quot;defer1&quot;)\n    defer fmt.Println(&quot;defer2&quot;)\n    defer fmt.Println(&quot;defer3&quot;)\n    defer fmt.Println(&quot;defer4&quot;)\n    fmt.Println(&quot;11111&quot;)\n}\n\n// 11111\n// defer4\n// defer3\n// defer2\n// defer1\n\n2、panic 后的 defer 函数不会被执行（遇到 panic，如果没有捕获错误，函数会立刻终止）\npackage main\n\nimport &quot;fmt&quot;\n\n// panic后的defer函数不会被执行\nfunc main() {\n    defer fmt.Println(&quot;panic before&quot;)\n    panic(&quot;发生panic&quot;)\n    defer func() {\n        fmt.Println(&quot;panic after&quot;)\n    }()\n}\n\n// panic before\n// panic: 发生panic\n\n3、panic 没有被 recover 时，抛出的 panic 到当前 goroutine 最上层函数时，最上层程序直接异常终止\npackage main\n\nimport &quot;fmt&quot;\n\nfunc F() {\n    defer func() {\n        fmt.Println(&quot;b&quot;)\n    }()\n    panic(&quot;a&quot;)\n}\n\n// 子函数抛出的panic没有recover时，上层函数时，程序直接异常终止\nfunc main() {\n    defer func() {\n        fmt.Println(&quot;c&quot;)\n    }()\n    F()\n    fmt.Println(&quot;继续执行&quot;)\n}\n\n// b\n// c\n// panic: a\n\n4、panic 有被 recover 时，当前 goroutine 最上层函数正常执行\npackage main\n\nimport &quot;fmt&quot;\n\nfunc F() {\n    defer func() {\n        if err := recover(); err != nil {\n            fmt.Println(&quot;捕获异常:&quot;, err)\n        }\n        fmt.Println(&quot;b&quot;)\n    }()\n    panic(&quot;a&quot;)\n}\n\nfunc main() {\n    defer func() {\n        fmt.Println(&quot;c&quot;)\n    }()\n    F()\n    fmt.Println(&quot;继续执行&quot;)\n}\n\n// 捕获异常: a\n// b\n// 继续执行\n// c\n\npackage main\n\nimport &quot;fmt&quot;\n\nfunc main() {\n\n\tdefer func() {\n\t\tif v := recover();v == 11 {\n\t\t\tfmt.Println(&quot;v:&quot;,v)\n\t\t}\n\t\tfmt.Printf(&quot;defer1...&quot;)\n\t\t}()\n\n\tdefer func() {\n\t\tfmt.Printf(&quot;defer2...&quot;)\n\t}()\n\n\tarray := [2]int{1,2}\n\tfmt.Println(&quot;array: &quot;,array[1])\n\tpanic(11)\n}\n//array:  2\n//defer2...\n//v:  11   \n//defer1...\n\n\n执行过程是: 保存返回值 (若有)–&gt;执行 defer（若有）–&gt;执行 ret 跳转\n\nfunc foo() (ret int) {\n    defer func() {\n        ret++\n    }()\n\n    return 0\n}\n\n\n延迟函数的参数在 defer 语句出现时就已经确定下来了\n\nfunc a() {\n    i := 0\n    defer fmt.Println(i)\n    i++\n    return\n}\n\n注意：\n执行顺序应该为 panic、defer、recover\n\n发生 panic 的函数并不会立刻返回，而是先层层函数执行 defer，再返回。如果有办法将 panic 捕获到 panic，就正常处理（若是外部函数捕获到，则外部函数只执行 defer），如果没有没有捕获，程序直接异常终止。\nGo 语言提供了 recover 内置函数。前面提到，一旦 panic 逻辑就会走到 defer（defer 必须在 panic 的前面！)。调用 recover 函数将会捕获到当前的 panic，被捕获到的 panic 就不会向上传递了\n在 panic 发生时，在前面的 defer 中通过 recover 捕获这个 panic，转化为错误通过返回值告诉方法调用者。\n\nGo 内置函数 make 和 new 的区别？\n首先纠正下 make 和 new 是内置函数，不是关键字\n变量初始化，一般包括 2 步，变量声明 + 变量内存分配，var 关键字就是用来声明变量的，new 和 make 函数主要是用来分配内存的\nVar 声明值类型的变量时，系统会默认为他分配内存空间，并赋该类型的零值\n比如布尔、数字、字符串、结构体\n如果指针类型或者引用类型的变量，系统不会为它分配内存，默认就是 nil。此时如果你想 直接使用，那么系统会抛异常，必须进行内存分配后，才能使用。\nNew 和 make 两个内置函数，主要用来分配内存空间，有了内存，变量就能使用了，主要有以下 2 点区别：\n使用场景区别：\nMake 只能用来分配及初始化类型为 slice、map、chan 的数据。\nNew 可以分配任意类型的数据，并且置零。\n返回值区别：\nMake 函数原型如下，返回的是 slice、map、chan 类型本身\n这 3 种类型是引用类型，就没有必要返回他们的指针\nfunc make(t Type, size ...IntegerType) Type\n\nNew 函数原型如下，返回一个指向该类型内存地址的指针\ntype slice struct {\n    array unsafe.Pointer\n    len   int\n    cap   int\n}\n\nMake 函数底层实现\nfunc makeslice(et *_type, len, cap int) unsafe.Pointer {\n\tmem, overflow := math.MulUintptr(et.size, uintptr(cap))\n\tif overflow || mem &gt; maxAlloc || len &lt; 0 || len &gt; cap {\n\t\t// NOTE: Produce a &#039;len out of range&#039; error instead of a\n\t\t// &#039;cap out of range&#039; error when someone does make([]T, bignumber).\n\t\t// &#039;cap out of range&#039; is true too, but since the cap is only being\n\t\t// supplied implicitly, saying len is clearer.\n\t\t// See golang.org/issue/4085.\n\t\tmem, overflow := math.MulUintptr(et.size, uintptr(len))\n\t\tif overflow || mem &gt; maxAlloc || len &lt; 0 {\n\t\t\tpanicmakeslicelen()\n\t\t}\n\t\tpanicmakeslicecap()\n\t}\n\n\treturn mallocgc(mem, et, true)\n}\n\n函数功能：\n\n检查切片占用的内存空间是否溢出。\n调用 mallocgc 在堆上申请一片连续的内存。\n\n检查内存空间这里是根据切片容量进行计算的，根据当前切片元素的大小与切片容量的乘积得出当前内存空间的大小，检查溢出的条件：\n\n内存空间大小溢出了\n申请的内存空间大于最大可分配的内存\n传入的 len 小于 0，cap 的大小只小于 `len\n"},"GO/八股文/Map-和Sync.map":{"title":"Map","links":["tags/"],"tags":["GO/八股文",""],"content":"参考\nGolang map 实现原理\nGolang sync.Map 实现原理\nMap 概述\nmap 又称字典，是一种常用的数据结构，核心特征包含下述三点：\n（1）存储基于 key-value 对映射的模式；\n（2）基于 key 维度实现存储数据的去重；\n（3）读、写、删操作控制，时间复杂度 O(1).\nMap 初始化\nGolang 中，对 map 的初始化分为以下几种方式：\n\n\nmyMap1 := make(map[int]int,2)\n//通过 make 关键字进行初始化，同时指定 map 预分配的容量.\n\nmyMap2 := make(map[int]int)\n//通过 make 关键字进行初始化，不显式声明容量，因此默认容量 为 0.\n\nmyMap3 :=map[int]int{\n  1:2,\n  3:4,\n}\n\nMap 的 key 可以是哪些类型？可以嵌套 map 吗？\n\n\nMap key 必须是可比较的类型，\n\n语言规范中定义了可比较的类型：boolean, numeric, string, pointer, channel, interface,以及仅包含这些类型的 struct 和 array 。\n不能作为 map key 的类型有：slice，map, function。\n\n\n\n可以嵌套 map。\n\n\nMap 读\n\n第一种方式是直接读，倘若 key 存在，则获取到对应的 val，倘若 key 不存在或者 map 未初始化，会返回 val 类型的零值作为兜底\n\nv1 := myMap[10]\n\n\n第二种方式是读的同时添加一个 bool 类型的 flag 标识是否读取成功. 倘若 ok == false，说明读取失败， key 不存在，或者 map 未初始化.\n\nv2,ok := myMap[10]\n\n\n如果 map 没有初始化,取值得到零值\n\npackage main\n\nimport &quot;fmt&quot;\n\nfunc main() {\n    var myMap map[string]int // 未初始化的 map\n    value := myMap[&quot;some_key&quot;] // 尝试获取一个键的值\n\n    fmt.Println(value)\n}\n//panic: assignment to entry in nil map\n\nMap 的查询复杂度\n空间复杂度:\n由于溢出桶数量超过 hash 桶数量时会触发缩容，所以最坏的情况是数据被集中在一条链上，hash 表基本是空的，这时空间浪费 O (n)。\n最好的情况下，数据均匀散列在 hash 表上，没有元素溢出，这时最好的空间复杂度就是扩散因子决定了，当前 go 的扩散因子由全局变量决定，即 loadFactorNum/loadFactorDen = 6.5。即平均每个 hash 桶被分配到 6.5 个元素以上时，开始扩容。所以最小的空间浪费是 (8-6.5)/8 = 0.1875，即 O (0.1875n)\n结论：go map 的空间复杂度（指除去正常存储元素所需空间之外的空间浪费）是 O (0.1875 n) ~ O (n)之间。\n​ 具体细节：blog.csdn.net/dongjijiaoxiangqu/article/details/109643025 \n时间复杂度：\nGo 采用的 hash 算法应是很成熟的算法，极端情况暂不考虑。所以综合情况下 go map 的时间复杂度应为 O(1)\nMap 写\nmyMap[5] = 6\n\n倘若 map 未初始化，直接执行写操作会导致 panic：\nconst plainError string\npanic(plainError(&quot;assignment to entry in nil map&quot;))\n\nMap 删除\ndelete(myMap,5)\n\n\n执行 delete 方法时，倘若 key 存在，则会从 map 中将对应的 key-value 对删除；倘若 key 不存在或 map 未初始化，则方法直接结束，不会产生显式提示.\nMap 遍历\n遍历分为下面两种方式：\nfor k,v := range myMap{\n// ...\n}\n\n基于 k,v 依次承接 map 中的 key-value 对；\nfor k := range myMap{  \n// ...\n}\n\n基于 k 依次承接 map 中的 key，不关注 val 的取值.\n需要注意的是，在执行 map 遍历操作时，获取的 key-value 对并没有一个固定的顺序，因此前后两次遍历顺序可能存在差异.\nmap 的底层实现原理？\nmap 又称为 hash map，在算法上基于 hash 实现 key 的映射和寻址；在数据结构上基于桶数组实现 key-value 对的存储.\n以一组 key-value 对写入 map 的流程为例进行简述：\n（1）通过哈希方法取得 key 的 hash 值；\n（2）hash 值对桶数组长度取模，确定其所属的桶；\n（3）在桶中插入 key-value 对.\nHash\nhash 译作散列，是一种将任意长度的输入压缩到某一固定长度的输出摘要的过程\n\n（1）hash 的可重入性：相同的 key，必然产生相同的 hash 值；\n（2）hash 的离散性：只要两个 key 不相同，不论其相似度的高低，产生的 hash 值会在整个输出域内均匀地离散化；\n（3）hash 的单向性：企图通过 hash 值反向映射回 key 是无迹可寻的.\n（4）hash 冲突：由于输入域（key）无穷大，输出域（hash 值）有限，因此必然存在不同 key 映射到相同 hash 值的情况，称之为 hash 冲突.\n\n桶数组\nmap 中，会通过长度为 2 的整数次幂的桶数组进行 key-value 对的存储：\n（1）每个桶固定可以存放 8 个 key-value 对；\n（2）倘若超过 8 个 key-value 对打到桶数组的同一个索引当中，此时会通过创建桶链表的方式来化解这一问题.\n\nmap 冲突的解决方式？\n比较常用的 Hash 冲突解决方案有链地址法和开放寻址法：\n链地址法\n当哈希冲突发生时，创建新单元，并将新单元添加到冲突单元所在链表的尾部. 在 Go 中将命中同一个桶的元素通过链表的形式进行链接，因此很便于动态扩展\n\n开放寻址法\n当哈希冲突发生时，从发生冲突的那个单元起，按照一定的次序，从哈希表中寻找一个空闲的单元，然后把发生冲突的元素存入到该单元。开放寻址法需要的表长度要大于等于所需要存放的元素数量\n开放寻址法有多种方式：线性探测法、平方探测法、随机探测法和双重哈希法。这里以线性探测法来帮助读者理解开放寻址法思想\n两种解决方案比较\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n方法优点拉链法简单常用；无需预先为元素分配内存.开放寻址法无需额外的指针用于链接元素；内存地址完全连续，可以基于局部性原理，充分利用 CPU 高速缓存.\n总结\nGO 中 实际上结合了拉链法和开放寻址法两种思路. 以 map 的插入写流程为例，进行思路阐述：\n\n\n（1）桶数组中的每个桶，严格意义上是一个单向桶链表，以桶为节点进行串联；\n\n\n（2）每个桶固定可以存放 8 个 key-value 对；\n\n\n（3）当 key 命中一个桶时，首先根据开放寻址法，在桶的 8 个位置中寻找空位进行插入；\n\n\n（4）倘若桶的 8 个位置都已被占满，则基于桶的溢出桶指针，找到下一个桶，重复第（3）步；\n\n\n（5）倘若遍历到链表尾部，仍未找到空位，则基于拉链法，在桶链表尾部续接新桶，并插入 key-value 对.\n\n\n\n扩容\nmap 扩容机制的核心点包括：\n\n\n\n（1）扩容分为增量扩容和等量扩容；\n\n双倍扩容：新建一个 buckets 数组，新的 buckets 大小是原来的 2 倍，然后旧 buckets 数据搬迁到新的 buckets。该方法我们称之为双倍扩容\n等量扩容：并不扩大容量，buckets 数量维持不变，重新做一遍类似双倍扩容的搬迁动作，把松散的键值对重新排列一次，使得同一个 bucket 中的 key 排列地更紧密，节省空间，提高 bucket 利用率，进而保证更快的存取。该方法我们称之为等量扩容。\n\n\n\n（2）当桶内 key-value 总数/桶数组长度 &gt; 6.5 时发生增量扩容，桶数组长度增长为原值的两倍；\n\n\n（3）当桶内溢出桶数量大于等于 2^B 时( B 为桶数组长度的指数，B 最大取 15)，发生等量扩容，桶的长度保持为原值；\n\n\n（4）采用渐进扩容的方式，当桶被实际操作到时，由使用者负责完成数据迁移，避免因为一次性的全量数据迁移引发性能抖动.\n\n\n\nhmap 结构体\nGo 中的 map 是一个应用，占用 8 个字节，指向 hmap 结构体\n源码包中 src/runtime/map.go 定义了 hmap 的数据结构：\nHmap 包含若干个结构为 bmap 的数组，每个 bmap 底层都采用链表结构，bmap 通常叫其 bucket\n\n\n// A header for a Go map.\ntype hmap struct {\n    count     int \n    // 代表哈希表中的元素个数，调用len(map)时，返回的就是该字段值。\n    flags     uint8 \n    // 状态标志（是否处于正在写入的状态等）\n    B         uint8  \n    // buckets（桶）的对数\n    // 如果B=5，则buckets数组的长度 = 2^B=32，意味着有32个桶\n    noverflow uint16 \n    // 溢出桶的数量\n    hash0     uint32 \n    // 生成hash的随机数种子\n    buckets    unsafe.Pointer \n    // 指向buckets数组的指针，数组大小为2^B，如果元素个数为0，它为nil。\n    oldbuckets unsafe.Pointer \n    // 如果发生扩容，oldbuckets是指向老的buckets数组的指针，老的buckets数组大小是新的buckets的1/2;非扩容状态下，它为nil。\n    nevacuate  uintptr        \n    // 表示扩容进度，小于此地址的buckets代表已搬迁完成。\n    extra *mapextra \n    // 存储溢出桶，这个字段是为了优化GC扫描而设计的，下面详细介绍\n }\n\n\n\n（1）count：map 中的 key-value 总数；\n\n\n（2）flags：map 状态标识，可以标识出 map 是否被 goroutine 并发读写；\n\n\n（3）B：桶数组长度的指数，桶数组长度为 2^B；\n\n\n（4）noverflow：map 中溢出桶的数量；\n\n\n（5）hash0：hash 随机因子，生成 key 的 hash 值时会使用到；\n\n\n（6）buckets：桶数组；\n\n\n（7）oldbuckets：扩容过程中老的桶数组；\n\n\n（8）nevacuate：扩容时的进度标识，index 小于 nevacuate 的桶都已经由老桶转移到新桶中；\n\n\n（9）extra：预申请的溢出桶.\n\n\nbmap 结构体\n\nbmap 就是我们常说的“桶”，一个桶里面会最多装 8 个 key，\n\n这些 key 之所以会落入同一个桶，是因为它们经过哈希计算后，哈希结果的低 B 位是相同的，\n在桶内，又会根据 key 计算出来的 hash 值的高 8 位来决定 key 到底落入桶内的哪个位置（一个桶内最多有 8 个位置)。\n\n// A bucket for a Go map.\ntype bmap struct {\n    tophash [bucketCnt]uint8        \n    // len为8的数组\n    // 用来快速定位key是否在这个bmap中\n    // 一个桶最多8个槽位，如果key所在的tophash值在tophash中，则代表该key在这个桶中\n}\n\n上面 bmap 结构是静态结构，在编译过程中 runtime.bmap 会拓展成以下结构体：\ntype bmap struct{\n    tophash [8]uint8\n    keys [8]keytype \n    // keytype 由编译器编译时候确定\n    values [8]elemtype \n    // elemtype 由编译器编译时候确定\n    overflow uintptr \n    // overflow指向下一个bmap，overflow是uintptr而不是*bmap类型，保证bmap完全不含指针，是为了减少gc，溢出桶存储到extra字段中\n}\n\n\n\nTophash 就是用于实现快速定位 key 的位置，在实现过程中会使用 key 的 hash 值的高 8 位作为 tophash 值，存放在 bmap 的 tophash 字段中\n\n\nTophash 字段不仅存储 key 哈希值的高 8 位，还会存储一些状态值，用来表明当前桶单元状态，这些状态值都是小于 minTopHash 的\n\n\n为了避免 key 哈希值的高 8 位值和这些状态值相等，产生混淆情况，所以当 key 哈希值高 8 位若小于 minTopHash 时候，自动将其值加上 minTopHash 作为该 key 的 tophash。桶单元的状态值如下：\n\n\nemptyRest      = 0 // 表明此桶单元为空，且更高索引的单元也是空\nemptyOne       = 1 // 表明此桶单元为空\nevacuatedX     = 2 // 用于表示扩容迁移到新桶前半段区间\nevacuatedY     = 3 // 用于表示扩容迁移到新桶后半段区间\nevacuatedEmpty = 4 // 用于表示此单元已迁移\nminTopHash     = 5 // key的tophash值与桶状态值分割线值，小于此值的一定代表着桶单元的状态，大于此值的一定是key对应的tophash值\n\nfunc tophash(hash uintptr) uint8 {\n    top := uint8(hash &gt;&gt; (goarch.PtrSize*8 - 8))\n    if top &lt; minTopHash {\n        top += minTopHash\n    }\n    return top\n}\n\n总结\nBmap（bucket）内存数据结构可视化如下:\n\nmapextra 结构体\n当 map 的 key 和 value 都不是指针类型时候，bmap 将完全不包含指针，那么 gc 时候就不用扫描 bmap。Bmap 指向溢出桶的字段 overflow 是 uintptr 类型，为了防止这些 overflow 桶被 gc 掉，所以需要 mapextra. Overflow 将它保存起来。如果 bmap 的 overflow 是 bmap 类型，那么 gc 扫描的是一个个拉链表，效率明显不如直接扫描一段内存 (hmap. Mapextra. Overflow)\ntype mapextra struct {\n    overflow    *[]*bmap\n    // overflow 包含的是 hmap.buckets 的 overflow 的 buckets\n    oldoverflow *[]*bma\n   // oldoverflow 包含扩容时 hmap.oldbuckets 的 overflow 的 bucket\n    nextOverflow *bmap \n     // 指向空闲的 overflow bucket 的指针\n}\n\n在 map 初始化时，倘若容量过大，会提前申请好一批溢出桶，以供后续使用，这部分溢出桶存放在 hmap.mapextra 当中：\n（1）mapextra.overflow：供桶数组 buckets 使用的溢出桶；\n（2）mapextra.oldoverFlow: 扩容流程中，供老桶数组 oldBuckets 使用的溢出桶；\n（3）mapextra.nextOverflow：下一个可用的溢出桶.\nMap 的负载因子为什么是 6.5？\n什么是负载因子?\n负载因子（load factor），用于衡量当前哈希表中空间占用率的核心指标，也就是每个 bucket 桶存储的平均元素个数。\n\n\n\n\n\n\n负载因子 = 哈希表存储的元素个数/桶个\n另外负载因子与扩容、迁移等重新散列（rehash）行为有直接关系：\n\n在程序运行时，会不断地进行插入、删除等，会导致 bucket 不均，内存利用率低，需要迁移。\n在程序运行时，出现负载因子过大，需要做扩容，解决 bucket 过大的问题。\n\n负载因子是哈希表中的一个重要指标，在各种版本的哈希表实现中都有类似的东西，主要目的是为了平衡 buckets 的存储空间大小和查找元素时的性能高低。\n在接触各种哈希表时都可以关注一下，做不同的对比，看看各家的考量。\n为什么是 6.5?\n为什么 Go 语言中哈希表的负载因子是 6.5，为什么不是 8 ，也不是 1。这里面有可靠的数据支撑吗？\n测试报告\n实际上这是 Go 官方的经过认真的测试得出的数字，一起来看看官方的这份测试报告。\n报告中共包含 4 个关键指标，如下：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nloadFactor%overflowbytes/entryhitprobemissprobe4.002.1320.773.004.004.504.0517.303.254.505.006.8514.773.505.005.5010.5512.943.755.506.0015.2711.674.006.006.5020.9010.794.256.507.0027.1410.154.507.007.5034.039.734.757.508.0041.109.405.008.00\n\nLoadFactor：负载因子，也有叫装载因子。\n%overflow：溢出率，有溢出 bukcet 的百分比。\nBytes/entry：平均每对 key/value 的开销字节数.\nHitprobe：查找一个存在的 key 时，要查找的平均个数。\nMissprobe：查找一个不存在的 key 时，要查找的平均个数。\n\n选择数值\nGo 官方发现：装载因子越大，填入的元素越多，空间利用率就越高，但发生哈希冲突的几率就变大。反之，装载因子越小，填入的元素越少，冲突发生的几率减小，但空间浪费也会变得更多，而且还会提高扩容操作的次数\n根据这份测试结果和讨论，Go 官方取了一个相对适中的值，把 Go 中的 map 的负载因子硬编码为 6.5，这就是 6.5 的选择缘由。\n这意味着在 Go 语言中，当 map 存储的元素个数大于或等于 6.5 * 桶个数时，就会触发扩容行为。\n构造流程\n\n创建 map 时，实际上会调用 runtime/map.go 文件中的 makemap 方法，下面对源码展开分析：\nfunc makemap(t *maptype, hint int, h *hmap) *hmap {\n    mem, overflow := math.MulUintptr(uintptr(hint), t.bucket.size)\n    if overflow || mem &gt; maxAlloc {\n        hint = 0\n    }\n\n\n    if h == nil {\n        h = new(hmap)\n    }\n    h.hash0 = fastrand()\n\n\n    B := uint8(0)\n    for overLoadFactor(hint, B) {\n        B++\n    }\n    h.B = B\n\n\n    if h.B != 0 {\n        var nextOverflow *bmap\n        h.buckets, nextOverflow = makeBucketArray(t, h.B, nil)\n        if nextOverflow != nil {\n            h.extra = new(mapextra)\n            h.extra.nextOverflow = nextOverflow\n        }\n    }\n\n\n    return \n\n\n\n（1）hint 为 map 拟分配的容量；在分配前，会提前对拟分配的内存大小进行判断，倘若超限，会将 hint 置为零；\n\n\n（2）通过 new 方法初始化 hmap；\n\n\n（3）调用 fastrand，构造 hash 因子：hmap.hash0；\n\n\n（4）大致上基于 log2(B) &gt;= hint 的思路，计算桶数组的容量 B；\n\noverLoadFactor   中实现\n倘若 map 预分配容量小于等于 8，B 取 0，桶的个数为 1；\n保证 map 预分配容量小于等于桶数组长度 * 6.5.\n\n\n\n（5）调用 makeBucketArray 方法，初始化桶数组 hmap.buckets\n\nmakeBucketArray 方法会进行桶数组的初始化，并根据桶的数量决定是否需要提前作溢出桶的初始化.\n\n\n\n（6）倘若 map 容量较大，会提前申请一批溢出桶 hmap.extra.\n\n\n读流程\n\nmap 读流程主要分为以下几步：\n（1）根据 key 取 hash 值；\n（2）根据 hash 值对桶数组取模，确定所在的桶；\n（3）沿着桶链表依次遍历各个桶内的 key-value 对；\n（4）命中相同的 key，则返回 value；倘若 key 不存在，则返回零值.\nmap 读操作最终会走进 runtime/map.go 的 mapaccess 方法中，下面开始阅读源码\nfunc mapaccess1(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer {\n    if h == nil || h.count == 0 {\n        return unsafe.Pointer(&amp;zeroVal[0])\n    }\n    if h.flags&amp;hashWriting != 0 {\n        fatal(&quot;concurrent map read and map write&quot;)\n    }\n    hash := t.hasher(key, uintptr(h.hash0))\n    m := bucketMask(h.B)\n    b := (*bmap)(add(h.buckets, (hash&amp;m)*uintptr(t.bucketsize)))\n    if c := h.oldbuckets; c != nil {\n        if !h.sameSizeGrow() {\n            m &gt;&gt;= 1\n        }\n        oldb := (*bmap)(add(c, (hash&amp;m)*uintptr(t.bucketsize)))\n        if !evacuated(oldb) {\n            b = oldb\n        }\n    }\n    top := tophash(hash)\nbucketloop:\n    for ; b != nil; b = b.overflow(t) {\n        for i := uintptr(0); i &lt; bucketCnt; i++ {\n            if b.tophash[i] != top {\n                if b.tophash[i] == emptyRest {\n                    break bucketloop\n                }\n                continue\n            }\n            k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize))\n            if t.indirectkey() {\n                k = *((*unsafe.Pointer)(k))\n            }\n            if t.key.equal(key, k) {\n                e := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize))\n                if t.indirectelem() {\n                    e = *((*unsafe.Pointer)(e))\n                }\n                return e\n            }\n        }\n    }\n    return unsafe.Pointer(&amp;zeroVal[0])\n}\n\n\nfunc (h *hmap) sameSizeGrow() bool {\n    return h.flags&amp;sameSizeGrow != 0\n}\n\n\nfunc evacuated(b *bmap) bool {\n    h := b.tophash[0]\n    return h &gt; emptyOne &amp;&amp; h &lt; minTopHash\n}\n\n（1）倘若 map 未初始化，或此时存在 key-value 对数量为 0，直接返回零值；\n（2）倘若发现存在其他 goroutine 在写 map，直接抛出并发读写的 fatal error；其中，并发写标记，位于 hmap.flags 的第 3 个 bit 位；\n（3）通过 maptype.hasher() 方法计算得到 key 的 hash 值，并对桶数组长度取模，取得对应的桶. 关于 hash 方法的内部实现，golang 并未暴露.\n\n其中，bucketMast 方法会根据 B 求得桶数组长度 - 1 的值，用于后续的 &amp; 运算，实现取模的效果：\n\n（4）在取桶时，会关注当前 map 是否处于扩容的流程，倘若是的话，需要在老的桶数组 oldBuckets 中取桶，通过 evacuated 方法判断桶数据是已迁到新桶还是仍存留在老桶，倘若仍在老桶，需要取老桶进行遍历.\n\n在取老桶前，会先判断 map 的扩容流程是否是增量扩容，倘若是的话，说明老桶数组的长度是新桶数组的一半，需要将桶长度值 m 除以 2.\n\n（5）取 key hash 值的高 8 位值 top. 倘若该值 &lt; 5，会累加 5，以避开 0 ~ 4 的取值. 因为这几个值会用于枚举，具有一些特殊的含义.\n（6）开启两层 for 循环进行遍历流程，外层基于桶链表，依次遍历首个桶和后续的每个溢出桶，内层依次遍历一个桶内的 key-value 对.\n\n\n内存遍历时，首先查询高 8 位的 tophash 值，看是否和 key 的 top 值匹配.\n\n\n倘若不匹配且当前位置 tophash 值为 0，说明桶的后续位置都未放入过元素，当前 key 在 map 中不存在，可以直接打破循环，返回零值.\n\n\n倘若找到了相等的 key，则通过地址偏移的方式取到 value 并返回.\n\n\n其中 dataOffset 为一个桶中 tophash 数组所占用的空间大小.\n写流程\n\nmap 写流程主要分为以下几步：\n（1）根据 key 取 hash 值；\n（2）根据 hash 值对桶数组取模，确定所在的桶；\n（3）倘若 map 处于扩容，则迁移命中的桶，帮助推进渐进式扩容；\n（4）沿着桶链表依次遍历各个桶内的 key-value 对；\n（5）倘若命中相同的 key，则对 value 中进行更新；\n（6）倘若 key 不存在，则插入 key-value 对；\n（7）倘若发现 map 达成扩容条件，则会开启扩容模式，并重新返回第（2）步.\nfunc mapassign(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer {\n    if h == nil {\n        panic(plainError(&quot;assignment to entry in nil map&quot;))\n    }\n    if h.flags&amp;hashWriting != 0 {\n        fatal(&quot;concurrent map writes&quot;)\n    }\n    hash := t.hasher(key, uintptr(h.hash0))\n\n\n    h.flags ^= hashWriting\n\n\n    if h.buckets == nil {\n        h.buckets = newobject(t.bucket) \n    }\n\n\nagain:\n    bucket := hash &amp; bucketMask(h.B)\n    if h.growing() {\n        growWork(t, h, bucket)\n    }\n    b := (*bmap)(add(h.buckets, bucket*uintptr(t.bucketsize)))\n    top := tophash(hash)\n\n\n    var inserti *uint8\n    var insertk unsafe.Pointer\n    var elem unsafe.Pointer\nbucketloop:\n    for {\n        for i := uintptr(0); i &lt; bucketCnt; i++ {\n            if b.tophash[i] != top {\n                if isEmpty(b.tophash[i]) &amp;&amp; inserti == nil {\n                    inserti = &amp;b.tophash[i]\n                    insertk = add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize))\n                    elem = add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize))\n                }\n                if b.tophash[i] == emptyRest {\n                    break bucketloop\n                }\n                continue\n            }\n            k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize))\n            if t.indirectkey() {\n                k = *((*unsafe.Pointer)(k))\n            }\n            if !t.key.equal(key, k) {\n                continue\n            }\n            if t.needkeyupdate() {\n                typedmemmove(t.key, k, key)\n            }\n            elem = add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize))\n            goto done\n        }\n        ovf := b.overflow(t)\n        if ovf == nil {\n            break\n        }\n        b = ovf\n    }\n\n\n    if !h.growing() &amp;&amp; (overLoadFactor(h.count+1, h.B) || tooManyOverflowBuckets(h.noverflow, h.B)) {\n        hashGrow(t, h)\n        goto again \n    }\n\n\n    if inserti == nil {\n        newb := h.newoverflow(t, b)\n        inserti = &amp;newb.tophash[0]\n        insertk = add(unsafe.Pointer(newb), dataOffset)\n        elem = add(insertk, bucketCnt*uintptr(t.keysize))\n    }\n\n\n    if t.indirectkey() {\n        kmem := newobject(t.key)\n        *(*unsafe.Pointer)(insertk) = kmem\n        insertk = kmem\n    }\n    if t.indirectelem() {\n        vmem := newobject(t.elem)\n        *(*unsafe.Pointer)(elem) = vmem\n    }\n    typedmemmove(t.key, insertk, key)\n    *inserti = top\n    h.count++\n\n\n\n\ndone:\n    if h.flags&amp;hashWriting == 0 {\n        fatal(&quot;concurrent map writes&quot;)\n    }\n    h.flags &amp;^= hashWriting\n    if t.indirectelem() {\n        elem = *((*unsafe.Pointer)(elem))\n    }\n    return \n}\n\n（1）写操作时，倘若 map 未初始化，直接 panic；\n（2）倘若其他 goroutine 在进行写或删操作，抛出并发写 fatal error；\n（3）通过 maptype.hasher() 方法求得 key 对应的 hash 值；\n（4）通过异或位运算，将 map.flags 的第 3 个 bit 位置为 1，添加写标记；\n（5）倘若 map 的桶数组 buckets 未空，则对其进行初始化；\n（6）找到当前 key 对应的桶索引 bucket；\n（7）倘若发现当前 map 正处于扩容过程，则帮助其渐进扩容，具体内容在第 9 节中再作展开；\n（8）从 map 的桶数组 buckets 出发，结合桶索引和桶容量大小，进行地址偏移，获得对应桶 b；\n（9）取得 key 的高 8 位 tophash：\n（10）提前声明好的三个指针，用于指向存放 key-value 的空槽:\ninserti：tophash 拟插入位置；\n\ninsertk：key 拟插入位置 ；\n\nelem：val 拟插入位置；\n\n（11）开启两层 for 循环，外层沿着桶链表依次遍历，内层依次遍历桶内的 key-value 对：\n(12）倘若 key 的 tophash 和当前位置 tophash 不同，则会尝试将 inserti、insertk elem 调整指向首个空位，用于后续的插入操作.\n\n\n倘若发现当前位置 tophash 标识为 emtpyRest（0），则说明当前桶链表后续位置都未空，无需继续遍历，直接 break 遍历流程即可.\n\n\n倘若桶中某个位置的 tophash 标识为 emptyOne（1），说明当前位置未放入元素，倘若为 emptyRest（0），说明包括当前位置在内，此后的位置都为空.\n\n\n（13）倘若找到了相等的 key，则执行更新操作，并且直接跳转到方法的 done 标志位处，进行收尾处理\n（14）倘若没找到相等的 key，会在执行插入操作前，判断 map 是否需要开启扩容模式. 这部分内容在第 9 节中作展开.\n倘若需要扩容，会在开启扩容模式后，跳转回 again 标志位，重新开始桶的定位以及遍历流程.\n（15）倘若遍历完桶链表，都没有为当前待插入的 key-value 对找到空位，则会创建一个新的溢出桶，挂载在桶链表的尾部，并将 inserti、insertk、elem 指向溢出桶的首个空位：\n创建溢出桶时：\n\n\n\nI 倘若 hmap.extra 中还有剩余可用的溢出桶，则直接获取 hmap.extra.nextOverflow，并将 nextOverflow 调整指向下一个空闲可用的溢出桶；\n\n\nII 倘若 hmap 已经没有空闲溢出桶了，则创建一个新的溢出桶.\n\n\nIII hmap 的溢出桶数量 hmap.noverflow 累加 1；\n\n\nIV 将新获得的溢出桶添加到原桶链表的尾部；\n\n\nV 返回溢出桶.\n\n\n（16）将 tophash、key、value 插入到取得空位中，并且将 map 的 key-value 对计数器 count 值加 1；\n（17）收尾环节，再次校验是否有其他协程并发写，倘若有，则抛 fatal error. 将 hmap.flags 中的写标记抹去，然后退出方法.\n删除流程\n\nmap 删楚 kv 对流程主要分为以下几步：\n（1）根据 key 取 hash 值；\n（2）根据 hash 值对桶数组取模，确定所在的桶；\n（3）倘若 map 处于扩容，则迁移命中的桶，帮助推进渐进式扩容；\n（4）沿着桶链表依次遍历各个桶内的 key-value 对；\n（5）倘若命中相同的 key，删除对应的 key-value 对；并将当前位置的 tophash 置为 emptyOne，表示为空；\n（6）倘若当前位置为末位，或者下一个位置的 tophash 为 emptyRest，则沿当前位置向前遍历，将毗邻的 emptyOne 统一更新为 emptyRest.\nmap 删操作最终会走进 runtime/map.go 的 mapdelete 方法中，下面开始阅读源码：\nfunc mapdelete(t *maptype, h *hmap, key unsafe.Pointer) {\n    if h == nil || h.count == 0 {\n        return\n    }\n    if h.flags&amp;hashWriting != 0 {\n        fatal(&quot;concurrent map writes&quot;)\n    }\n\n\n    hash := t.hasher(key, uintptr(h.hash0))\n\n\n    h.flags ^= hashWriting\n\n\n    bucket := hash &amp; bucketMask(h.B)\n    if h.growing() {\n        growWork(t, h, bucket)\n    }\n    b := (*bmap)(add(h.buckets, bucket*uintptr(t.bucketsize)))\n    bOrig := b\n    top := tophash(hash)\nsearch:\n    for ; b != nil; b = b.overflow(t) {\n        for i := uintptr(0); i &lt; bucketCnt; i++ {\n            if b.tophash[i] != top {\n                if b.tophash[i] == emptyRest {\n                    break search\n                }\n                continue\n            }\n            k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize))\n            k2 := k\n            if t.indirectkey() {\n                k2 = *((*unsafe.Pointer)(k2))\n            }\n            if !t.key.equal(key, k2) {\n                continue\n            }\n            // Only clear key if there are pointers in it.\n            if t.indirectkey() {\n                *(*unsafe.Pointer)(k) = nil\n            } else if t.key.ptrdata != 0 {\n                memclrHasPointers(k, t.key.size)\n            }\n            e := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize))\n            if t.indirectelem() {\n                *(*unsafe.Pointer)(e) = nil\n            } else if t.elem.ptrdata != 0 {\n                memclrHasPointers(e, t.elem.size)\n            } else {\n                memclrNoHeapPointers(e, t.elem.size)\n            }\n            b.tophash[i] = emptyOne\n            if i == bucketCnt-1 {\n                if b.overflow(t) != nil &amp;&amp; b.overflow(t).tophash[0] != emptyRest {\n                    goto notLast\n                }\n            } else {\n                if b.tophash[i+1] != emptyRest {\n                    goto notLast\n                }\n            }\n            for {\n                b.tophash[i] = emptyRest\n                if i == 0 {\n                    if b == bOrig {\n                        break\n                    }\n                    c := b\n                    for b = bOrig; b.overflow(t) != c; b = b.overflow(t) {\n                    }\n                    i = bucketCnt - 1\n                } else {\n                    i--\n                }\n                if b.tophash[i] != emptyOne {\n                    break\n                }\n            }\n        notLast:\n            h.count--\n            if h.count == 0 {\n                h.hash0 = fastrand()\n            }\n            break search\n        }\n    }\n\n\n    if h.flags&amp;hashWriting == 0 {\n        fatal(&quot;concurrent map writes&quot;)\n    }\n    h.flags &amp;^= hashWritin\n\n（1）倘若 map 未初始化或者内部 key-value 对数量为 0，删除时不会报错，直接返回；\n（2）倘若存在其他 goroutine 在进行写或删操作，抛出并发写的 fatal error；\n（3）通过 maptype.hasher() 方法求得 key 对应的 hash 值；\n（4）通过异或位运算，将 map.flags 的第 3 个 bit 位置为 1，添加写标记；\n（5）找到当前 key 对应的桶索引 bucket；\n（6）倘若发现当前 map 正处于扩容过程，则帮助其渐进扩容\n（7）从 map 的桶数组 buckets 出发，结合桶索引和桶容量大小，进行地址偏移，获得对应桶 b，并赋值给 bOrg\n（8）取得 key 的高 8 位 tophash：\n（9）开启两层 for 循环，外层沿着桶链表依次遍历，内层依次遍历桶内的 key-value 对\n（10）遍历时，倘若发现当前位置 tophash 值为 emptyRest，则直接结束遍历流程：\n（11）倘若 key 不相等，则继续遍历：\n（12）倘若 key 相等，则删除对应的 key-value 对，并且将当前位置的 tophash 置为 emptyOne：\n（13）倘若当前位置不位于最后一个桶的最后一个位置，或者当前位置的后置位 tophash 不为 emptyRest，则无需向前遍历更新 tophash 标识，直接跳转到 notLast 位置即可；\n（14）向前遍历，将沿途的空位（ tophash 为 emptyOne ）的 tophash 都更新为 emptySet.\n（15）倘若成功从 map 中删除了一组 key-value 对，则将 hmap 的计数器 count 值减 1. 倘若 map 中的元素全都被删除完了，会为 map 更换一个新的随机因子 hash0.\n（16）收尾环节，再次校验是否有其他协程并发写，倘若有，则抛 fatal error. 将 hmap.flags 中的写标记抹去，然后退出方法.\n遍历流程\n\nMap 的遍历流程首先会走进 runtime/map.go 的 mapiterinit() 方法当中，初始化用于遍历的迭代器 hiter；接着会调用 runtime/map.go 的 mapiternext() 方法开启遍历流程.\n迭代器数据结构\ntype hiter struct {\n    key         unsafe.Pointer \n    elem        unsafe.Pointer \n    t           *maptype\n    h           *hmap\n    buckets     unsafe.Pointer \n    bptr        *bmap         \n    overflow    *[]*bmap      \n    oldoverflow *[]*bmap      \n    startBucket uintptr       \n    offset      uint8         \n    wrapped     bool         \n    B           uint8\n    i           uint8\n    bucket      uintptr\n    checkBucket uintptr\n}\n\nhiter 是遍历 map 时用于存放临时数据的迭代器：\n（1）key：指向遍历得到 key 的指针；\n（2）value：指向遍历得到 value 的指针；\n（3）t：map 类型，包含了 key、value 类型大小等信息；\n（4）h：map 的指针；\n（5）buckets：map 的桶数组；\n（6）bptr：当前遍历到的桶；\n（7）overflow：新老桶数组对应的溢出桶；\n（8）startBucket：遍历起始位置的桶索引；\n（9）offset：遍历起始位置的 key-value 对索引；\n（10）wrapped：遍历是否穿越桶数组尾端回到头部了；\n（11）B：桶数组的长度指数；\n（12）i：当前遍历到的 key-value 对在桶中的索引；\n（13）bucket：当前遍历到的桶；\n（14）checkBucket：因为扩容流程的存在，需要额外检查的桶.\nmap 遍历流程开始时，首先会走进 runtime/map.go 的 mapiterinit() 方法当中，此时会对创建 map 迭代器 hiter，并且通过取随机数的方式，决定遍历的起始桶号，以及起始 key-value 对索引号.\n\n1）遍历时发现其他 goroutine 在并发写，直接抛出 fatal error：\n（2）开启最外圈的循环，依次遍历桶数组中的每个桶链表，通过 next 和 goto next 关键字实现循环代码块；\n（3）倘若已经遍历完所有的桶，重新回到起始桶为止，则直接结束方法；\n（4）倘若 map 处于扩容流程，取桶时兼容新老桶数组的逻辑. 倘若桶处于旧桶数组且未完成迁移，需要将 checkBucket 置为当前的桶号；\n5）遍历的桶号加 1，倘若来到桶数组末尾，则将桶号置为 0. 将 key-value 对的遍历索引 i 置为 0.\n（6）依次遍历各个桶中每个 key-value 对：\n（7）倘若遍历到的桶属于旧桶数组未迁移完成的桶，需要按照其在新桶中的顺序完成遍历. 比如，增量扩容流程中，旧桶中的 key-value 对最终应该被分散迁移到新桶数组的 x、y 两个区域，则此时遍历时，哪怕 key-value 对仍存留在旧桶中未完成迁移，遍历时也应该严格按照其在新桶数组中的顺序来执行.\n（8）执行 mapaccessK 方法，基于读流程方法获取 key-value 对，通过迭代 hiter 的 key、value 指针进行接收，用于对用户的遍历操作进行响应：\n扩容流程\n\n扩容类型\n（1）增量扩容\n表现：扩容后，桶数组的长度增长为原长度的 2 倍；\n目的：降低每个桶中 key-value 对的数量，优化 map 操作的时间复杂度.\n（2）等量扩容\n表现：扩容后，桶数组的长度和之前保持一致；但是溢出桶的数量会下降.\n目的：提高桶主体结构的数据填充率，减少溢出桶数量，避免发生内存泄漏\n何时扩容\n（1）只有 map 的写流程可能开启扩容模式；\n（2）写 map 新插入 key-value 对之前，会发起是否需要扩容的逻辑判断：\n（3）根据 hmap 的 oldbuckets 是否空，可以判断 map 此前是否已开启扩容模式：\n（4）倘若此前未进入扩容模式，且 map 中 key-value 对的数量超过 8 个，且大于桶数组长度的 6.5 倍，则进入增量扩容：\n（5）倘若溢出桶的数量大于 2^B 个（即桶数组的长度；B 大于 15 时取15），则进入等量扩容：\n如何开启扩容模式\n开启扩容模式的方法位于 runtime/map.go 的 hashGrow 方法中：\nfunc hashGrow(t *maptype, h *hmap) {\n    bigger := uint8(1)\n    if !overLoadFactor(h.count+1, h.B) {\n        bigger = 0\n        h.flags |= sameSizeGrow\n    }\n    oldbuckets := h.buckets\n    newbuckets, nextOverflow := makeBucketArray(t, h.B+bigger, nil)\n\n\n\n\n    flags := h.flags &amp;^ (iterator | oldIterator)\n    if h.flags&amp;iterator != 0 {\n        flags |= oldIterator\n    }\n    // commit the grow (atomic wrt gc)\n    h.B += bigger\n    h.flags = flags\n    h.oldbuckets = oldbuckets\n    h.buckets = newbuckets\n    h.nevacuate = 0\n    h.noverflow = 0\n\n\n    if h.extra != nil &amp;&amp; h.extra.overflow != nil {\n        // Promote current overflow buckets to the old generation.\n        if h.extra.oldoverflow != nil {\n            throw(&quot;oldoverflow is not nil&quot;)\n        }\n        h.extra.oldoverflow = h.extra.overflow\n        h.extra.overflow = nil\n    }\n    if nextOverflow != nil {\n        if h.extra == nil {\n            h.extra = new(mapextra)\n        }\n        h.extra.nextOverflow = nextOverflow\n    }\n\n（1）倘若是增量扩容，bigger 值取 1；倘若是等量扩容，bigger 值取 0，并将 hmap.flags 的第 4 个 bit 位置为 1，标识当前处于等量扩容流程\n（2）将原桶数组赋值给 oldBuckets，并创建新的桶数组和一批新的溢出桶.\n此处会通过变量 bigger，实现不同扩容模式下，新桶数组长度的区别处理.\n（3）更新 hmap 的桶数组长度指数 B，flag 标识，并将新、老桶数组赋值给 hmap.oldBuckets 和 hmap.buckets；扩容迁移进度 hmap.nevacuate 标记为 0；新桶数组的溢出桶数量 hmap.noverflow 置为 0.\n（4）将原本存量可用的溢出桶赋给 hmap.extra.oldoverflow；倘若存在下一个可用的溢出桶，赋给 hmap.extra.nextOverflow.\n扩容迁移规则\n\n（1）在等量扩容中，新桶数组长度与原桶数组相同；\n（2）key-value 对在新桶数组和老桶数组的中的索引号保持一致；\n（3）在增量扩容中，新桶数组长度为原桶数组的两倍；\n（4）把新桶数组中桶号对应于老桶数组的区域称为 x 区域，新扩展的区域称为 y 区域.\n（5）实际上，一个 key 属于哪个桶，取决于其 hash 值对桶数组长度取模得到的结果，因此依赖于其低位的 hash 值结果.；\n（6）在增量扩容流程中，新桶数组的长度会扩展一位，假定 key 原本从属的桶号为 i，则在新桶数组中从属的桶号只可能是 i （x 区域）或者 i + 老桶数组长度（y 区域）；\n（7）当 key 低位 hash 值向左扩展一位的 bit 位为 0，则应该迁往 x 区域的 i 位置；倘若该 bit 位为 1，应该迁往 y 区域对应的 i + 老桶数组长度的位置.\n渐进式扩容\nmap 采用的是渐进扩容的方式，避免因为一次性的全量数据迁移引发性能抖动.\n当每次触发写、删操作时，会为处于扩容流程中的 map 完成两组桶的数据迁移：\n（1）一组桶是当前写、删操作所命中的桶；\n（2）另一组桶是，当前未迁移的桶中，索引最小的那个桶.\n\n数据迁移的逻辑位于 runtime/map.go 的 evacuate 方法当中：\nfunc evacuate(t *maptype, h *hmap, oldbucket uintptr) {\n    // 入参中，oldbucket 为当前要迁移的桶在旧桶数组中的索引\n    // 获取到待迁移桶的内存地址 b\n    b := (*bmap)(add(h.oldbuckets, oldbucket*uintptr(t.bucketsize)))\n    // 获取到旧桶数组的容量 newbit\n    newbit := h.noldbuckets()\n    // evacuated 方法判断出桶 b 是否已经迁移过了，未迁移过，才进入此 if 分支进行迁移处理\n    if !evacuated(b) {\n        // 通过一个二元数组 xy 指向当前桶可能迁移到的目的桶\n        // x = xy[0]，代表新桶数组中索引和旧桶数组一致的桶\n        // y = xy[1]，代表新桶数组中，索引为原索引加上旧桶容量的桶，只在增量扩容中会使用到\n        var xy [2]evacDst\n        x := &amp;xy[0]\n        x.b = (*bmap)(add(h.buckets, oldbucket*uintptr(t.bucketsize)))\n        x.k = add(unsafe.Pointer(x.b), dataOffset)\n        x.e = add(x.k, bucketCnt*uintptr(t.keysize))\n\n\n        // 只有进入增量扩容的分支，才需要对 y 进行初始化\n        if !h.sameSizeGrow() {\n            // Only calculate y pointers if we&#039;re growing bigger.\n            // Otherwise GC can see bad pointers.\n            y := &amp;xy[1]\n            y.b = (*bmap)(add(h.buckets, (oldbucket+newbit)*uintptr(t.bucketsize)))\n            y.k = add(unsafe.Pointer(y.b), dataOffset)\n            y.e = add(y.k, bucketCnt*uintptr(t.keysize))\n        }\n\n\n        // 外层 for 循环，遍历桶 b 和对应的溢出桶\n        for ; b != nil; b = b.overflow(t) {\n            // k,e 分别记录遍历桶时，当前的 key 和 value 的指针\n            k := add(unsafe.Pointer(b), dataOffset)\n            e := add(k, bucketCnt*uintptr(t.keysize))\n            // 遍历桶内的 key-value 对\n            for i := 0; i &lt; bucketCnt; i, k, e = i+1, add(k, uintptr(t.keysize)), add(e, uintptr(t.elemsize)) {\n                top := b.tophash[i]\n                if isEmpty(top) {\n                    b.tophash[i] = evacuatedEmpty\n                    continue\n                }\n                if top &lt; minTopHash {\n                    throw(&quot;bad map state&quot;)\n                }\n                k2 := k\n                if t.indirectkey() {\n                    k2 = *((*unsafe.Pointer)(k2))\n                }\n                var useY uint8\n                if !h.sameSizeGrow() {\n                    // Compute hash to make our evacuation decision (whether we need\n                    // to send this key/elem to bucket x or bucket y).\n                    hash := t.hasher(k2, uintptr(h.hash0))\n                    if hash&amp;newbit != 0 {\n                       useY = 1\n                    }\n                }\n                b.tophash[i] = evacuatedX + useY // evacuatedX + 1 == evacuatedY\n                dst := &amp;xy[useY]                 // evacuation destination\n                if dst.i == bucketCnt {\n                    dst.b = h.newoverflow(t, dst.b)\n                    dst.i = 0\n                    dst.k = add(unsafe.Pointer(dst.b), dataOffset)\n                    dst.e = add(dst.k, bucketCnt*uintptr(t.keysize))\n                }\n                dst.b.tophash[dst.i&amp;(bucketCnt-1)] = top // mask dst.i as an optimization, to avoid a bounds check\n                if t.indirectkey() {\n                    *(*unsafe.Pointer)(dst.k) = k2 // copy pointer\n                } else {\n                    typedmemmove(t.key, dst.k, k) // copy elem\n                }\n                if t.indirectelem() {\n                    *(*unsafe.Pointer)(dst.e) = *(*unsafe.Pointer)(e)\n                } else {\n                    typedmemmove(t.elem, dst.e, e)\n                }\n                dst.i++\n                dst.k = add(dst.k, uintptr(t.keysize))\n                dst.e = add(dst.e, uintptr(t.elemsize))\n            }\n        }\n        // Unlink the overflow buckets &amp; clear key/elem to help GC.\n        if h.flags&amp;oldIterator == 0 &amp;&amp; t.bucket.ptrdata != 0 {\n            b := add(h.oldbuckets, oldbucket*uintptr(t.bucketsize))\n            // Preserve b.tophash because the evacuation\n            // state is maintained there.\n            ptr := add(b, dataOffset)\n            n := uintptr(t.bucketsize) - dataOffset\n            memclrHasPointers(ptr, n)\n        }\n    }\n\n\n    if oldbucket == h.nevacuate {\n        advanceEvacuationMark(h, t, newbit)\n    }\n}\n\n\nfunc (h *hmap) noldbuckets() uintptr {\n    oldB := h.B\n    if !h.sameSizeGrow() {\n        oldB--\n    }\n    return bucketShift(oldB)\n\n（1）从老桶数组中获取到待迁移的桶 b；\n（2）获取到老桶数组的长度 newbit；\n（3）倘若当前桶已经完成了迁移，则无需处理；\n（4）创建一个二元数组 xy，分别承载 x 区域和 y 区域（含义定义见 9.4 小节）中的新桶位置，用于接受来自老桶数组的迁移数组；只有在增量扩容的流程中，才存在 y 区域，因此才需要对 xy 中的 y 进行定义；\n（5）开启两层 for 循环，外层遍历桶链表，内层遍历每个桶中的 key-value 对：\n（6）取每个位置的 tophash 值进行判断，倘若当前是个空位，则将当前位置 tophash 值置为 evacuatedEmpty，开始遍历下一个位置：\n（7）基于 9.4 的规则，寻找到迁移的目的桶；\n其中目的桶的类型定义如下：\ntype evacDst struct {\n    b *bmap          // current destination bucket\n    i int            // key/elem index into b\n    k unsafe.Pointer // pointer to current key storage\n    e unsafe.Pointer // pointer to current elem storage\n}\n\nI evacDst.b：目的地的所在桶；\nII evacDst.i：即将入桶的 key-value 对在桶中的索引；\nIII evacDst.k：入桶 key 的存储指针；\nIV evacDst.e：入桶 value 的存储指针.\n（8）将 key-value 对迁移到目的桶中，并且更新目的桶结构内几个指针的指向：\n（9）倘若当前迁移的桶是旧桶数组未迁移的桶中索引最小的一个，则 hmap.nevacuate 累加 1.\n倘若已经迁移完所有的旧桶，则会确保 hmap.flags 中，等量扩容的标识位被置为 0.\nmap 遍历为什么是无序的？\n使用 range 多次遍历 map 时输出的 key 和 value 的顺序可能不同。这是 Go 语言的设计者们有意为之，旨在提示开发者们，Go 底层实现并不保证 map 遍历顺序稳定，请大家不要依赖 range 遍历结果顺序\n主要原因有 2 点：\n\nMap 在遍历时，并不是从固定的 0 号 bucket 开始遍历的，每次遍历，都会从一个随机值序号的 bucket，再从其中随机的 cell开始遍历\nMap 遍历时，是按序遍历 bucket，同时按需遍历 bucket 中和其 overflow bucket 中的 cell。但是 map 在扩容后，会发生 key 的搬迁，这造成原来落在一个 bucket 中的 key，搬迁后，有可能会落到其他 bucket 中了，从这个角度看，遍历 map 的结果就不可能是按照原来的顺序了\n\nMap 本身是无序的，且遍历时顺序还会被随机化，如果想顺序遍历 map，需要对 map key 先排序，再按照 key 的顺序遍历 map。\nfunc TestMapRange(t *testing.T) {\n    m := map[int]string{1: &quot;a&quot;, 2: &quot;b&quot;, 3: &quot;c&quot;}\n    t.Log(&quot;first range:&quot;)\n    for i, v := range m {\n        t.Logf(&quot;m[%v]=%v &quot;, i, v)\n    }\n    t.Log(&quot;\\nsecond range:&quot;)\n    for i, v := range m {\n        t.Logf(&quot;m[%v]=%v &quot;, i, v)\n    }\n\n    // 实现有序遍历\n    var sl []int\n    // 把 key 单独取出放到切片\n    for k := range m {\n        sl = append(sl, k)\n    }\n    // 排序切片\n    sort.Ints(sl)\n    // 以切片中的 key 顺序遍历 map 就是有序的了\n    for _, k := range sl {\n        t.Log(k, m[k])\n    }\n}\n\nmap 为什么是非线程安全的？\nMap 默认是并发不安全的，同时对 map 进行并发读写时，程序会 panic，原因如下：\nGo 官方在经过了长时间的讨论后，认为 Go map 更应适配典型使用场景（不需要从多个 goroutine 中进行安全访问），而不是为了小部分情况（并发访问），导致大部分程序付出加锁代价（性能），决定了不支持。\n场景: 2 个协程同时读和写，以下程序会出现致命错误：fatal error: concurrent map writes\npackage main\n\nimport (\n    &quot;fmt&quot;\n    &quot;time&quot;\n)\n\nfunc main() {\n    s := make(map[int]int)\n    for i := 0; i &lt; 100; i++ {\n        go func(i int) {\n            s[i] = i\n        }(i)\n    }\n    for i := 0; i &lt; 100; i++ {\n        go func(i int) {\n            fmt.Printf(&quot;map第%d个元素值是%d\\n&quot;, i, s[i])\n        }(i)\n    }\n    time.Sleep(1 * time.Second)\n}\n\n如果想实现 map 线程安全，有两种方式：\n方式一：使用读写锁 map + sync.RWMutex\npackage main\n\nimport (\n    &quot;fmt&quot;\n    &quot;sync&quot;\n    &quot;time&quot;\n)\n\nfunc main() {\n    var lock sync.RWMutex\n    s := make(map[int]int)\n    for i := 0; i &lt; 100; i++ {\n        go func(i int) {\n            lock.Lock()\n            s[i] = i\n            lock.Unlock()\n        }(i)\n    }\n    for i := 0; i &lt; 100; i++ {\n        go func(i int) {\n            lock.RLock()\n            fmt.Printf(&quot;map第%d个元素值是%d\\n&quot;, i, s[i])\n            lock.RUnlock()\n        }(i)\n    }\n    time.Sleep(1 * time.Second)\n}\n\n\n方式二：使用 Go 提供的 sync.Map\npackage main\n\nimport (\n    &quot;fmt&quot;\n    &quot;sync&quot;\n    &quot;time&quot;\n)\n\nfunc main() {\n    var m sync.Map\n    for i := 0; i &lt; 100; i++ {\n        go func(i int) {\n            m.Store(i, i)\n        }(i)\n    }\n    for i := 0; i &lt; 100; i++ {\n        go func(i int) {\n            v, ok := m.Load(i)\n            fmt.Printf(&quot;Load: %v, %v\\n&quot;, v, ok)\n        }(i)\n    }\n    time.Sleep(1 * time.Second)\n}\n\nMap 怎么知道自己处于竞争状态？是 Go 编码实现的还是底层硬件实现的？\n\n\n代码实现的，在查找、赋值、遍历、删除的过程中**都会检测写标志 flags，一旦发现写标志置位 (等于 1)，抛出 fatal error，无法使用 recover 进行恢复。\n\n\n赋值和删除函数载检测完标志是复位状态 (等于 0)之后，先将写标志位置位，才会进行之后的操作。\n\n\nMap 的 panic 能被 recover 掉吗？了解 panic 和 recover 的机制？\n抛出 fatal error，无法使用 recover 进行恢复\nfunc main() {\n    defer errorHandler()\n    m := map[string]int{}\n\n    go func() {\n        for {\n            m[&quot;x&quot;] = 1\n        }\n    }()\n    for {\n        _ = m[&quot;x&quot;]\n    }\n}\n\nfunc errorHandler() {\n    if r := recover(); r != nil {\n        fmt.Println(r)\n    }\n}//不能\n\nMap 由于不是线程安全的，所以在遇到并发读写的时候会抛出 concurrent map read and map write 异常，从而使程序直接退出。\nfunc mapaccess1_faststr(t *maptype, h *hmap, ky string) unsafe.Pointer {\n    ...\n    if h.flags&amp;hashWriting != 0 {\n        throw(&quot;concurrent map read and map write&quot;)\n    }\n    ...\n｝\n\n这里的 throw 和上面一样，最终会调用到 exit 执行退出。\nGo 中两个 map 对象如何比较\n使用 reflect. DeepEqual 这个函数进行比较。使用 reflect. DeepEqual 有一点注意：由于使用了反射，所以有性能的损失。如果你多做一些测试，那么你会发现 reflect. DeepEqual 会比 == 慢 100 倍以上。\nMap 的优缺点以及改进?\n优点：\n\n\nMap 类似其他语言中的哈希表或字典，以 key-value 形式存储数据\n\n\nKey 必须是支持==或!=比较运算的类型，不可以是函数、map 或 slice\n\n\nMap 通过 key 查找 value 比线性搜索快很多。\n\n\nMap 使用 make ()创建，支持:=这种简写方式\n\n\n超出容量时会自动扩容，\n\n\n当键值对不存在时自动添加，使用 delete ()删除某键值对\n\n\n缺点：\n并发中的 map 不是安全的\nSync. Map 怎么使用\npackage main\n\nimport (\n    &quot;fmt&quot;\n    &quot;sync&quot;\n)\n\nfunc main() {\n    var scene sync.Map\n    // 将键值对保存到sync.Map\n    scene.Store(&quot;1&quot;, 1)\n    scene.Store(&quot;2&quot;, 2)\n    scene.Store(&quot;3&quot;, 3)\n    // 从sync.Map中根据键取值\n    fmt.Println(scene.Load(&quot;1&quot;))\n    // 根据键删除对应的键值对\n    scene.Delete(&quot;1&quot;)\n    // 遍历所有sync.Map中的键值对\n    scene.Range(func(k, v interface{}) bool {\n        fmt.Println(&quot;iterate:&quot;, k, v)\n        return true\n    })\n}\n\nSync. Map 底层实现原理\nSync. Map\n\ntype Map struct {\n    mu Mutex\n    read atomic.Value \n    dirty map[any]*entry\n    misses int\n}\n\nsync.Map 主类中包含以下核心字段：\n\n\nread：无锁化的只读 map，实际类型为 readOnly，2.3 小节会进一步介绍；\n\n\ndirty：加锁处理的读写 map；\n\n\nmisses：记录访问 read 的失效次数，累计达到阈值时，会进行 read map/dirty map 的更新轮换；\n\n\nmu：一把互斥锁，实现 dirty 和 misses 的并发管理.\n\n\n可见，sync.Map 的特点是冗余了两份 map：read map 和 dirty map，后续的所介绍的交互流程也和这两个 map 息息相关，基本可以归结为两条主线\n\n\n主线一：首先基于无锁操作访问 read map；倘若 read map 不存在该 key，则加锁并使用 dirty map 兜底；\n\n\n主线二：read map 和 dirty map 之间会交替轮换更新\n\n\nEntry\ntype entry struct {\n    p unsafe.Pointer \n}\n\nkv 对中的 value，统一采用 unsafe.Pointer 的形式进行存储，通过 entry.p 的指针进行链接.\nentry.p 的指向分为三种情况：\n\n\nI 存活态：正常指向元素；\n\n\nII 软删除态：指向 nil；\n\n\nIII 硬删除态：指向固定的全局变量 expunged.\n\n\nvar expunged = unsafe.Pointer(new(any))\n\n\n\n\n存活态很好理解，即 key-entry 对仍未删除；\n\n\nnil 态表示软删除，read map 和 dirty map 底层的 map 结构仍存在 key-entry 对，但在逻辑上该 key-entry 对已经被删除，因此无法被用户查询到；\n    * expunged 态表示硬删除，dirty map 中已不存在该 key-entry 对.\n\n\n\nreadOnly (无锁化的只读 map)\ntype readOnly struct {\n    m       map[any]*entry\n    amended bool // true if the dirty map contains some key not in m.\n}\n\nsync.Map 中的只读 map：read 内部包含两个成员属性：\n\n\nm：真正意义上的 read map，实现从 key 到 entry 的映射；\n\n\namended：标识 read map 中的 key-entry 对是否存在缺失，需要通过 dirty map 兜底.\n\n\n读流程\n\nsync.Map.Load()\nfunc (m *Map) Load(key any) (value any, ok bool) {\n    read, _ := m.read.Load().(readOnly)\n    e, ok := read.m[key]\n    if !ok &amp;&amp; read.amended {\n        m.mu.Lock()\n        read, _ = m.read.Load().(readOnly)\n        e, ok = read.m[key]\n        if !ok &amp;&amp; read.amended {\n            e, ok = m.dirty[key]\n            m.missLocked()\n        }\n        m.mu.Unlock()\n    }\n    if !ok {\n        return nil, false\n    }\n    return e.load()\n}\n\n\n\n查看 read map 中是否存在 key-entry 对，若存在，则直接读取 entry 返回；\n\n\n倘若第一轮 read map 查询 miss，且 read map 不全，则需要加锁 double check；\n\n\n第二轮 read map 查询仍 miss（加锁后），且 read map 不全，则查询 dirty map 兜底；\n\n\n 查询操作涉及到与 dirty map 的交互，misses 加一；\n\n\n 解锁，返回查得的结果.\n\n\nentry.load()\nfunc (e *entry) load() (value any, ok bool) {\n    p := atomic.LoadPointer(&amp;e.p)\n    if p == nil || p == expunged {\n        return nil, false\n    }\n    return *(*any)(p), true\n}\n\n\n\nsync.Map 中，kv 对的 value 是基于 entry 指针封装的形式；\n\n\n 从 map 取得 entry 后，最终需要调用 entry.load 方法读取指针指向的内容；\n\n\n倘若 entry 的指针状态为 nil 或者 expunged，说明 key-entry 对已被删除，则返回 nil；\n\n\n 倘若 entry 未被删除，则读取指针内容，并且转为 any 的形式进行返回.\n\n\n sync.Map.missLocked()\nfunc (m *Map) missLocked() {\n    m.misses++\n    if m.misses &lt; len(m.dirty) {\n        return\n    }\n    m.read.Store(readOnly{m: m.dirty})\n    m.dirty = nil\n    m.misses = 0\n}\n\n\n\n 在读流程中，倘若未命中 read map，且由于 read map 内容存在缺失需要和 dirty map 交互时，会走进 missLocked 流程；\n\n\n 在 missLocked 流程中，首先 misses 计数器累加 1；\n\n\n 倘若 miss 次数小于 dirty map 中存在的 key-entry 对数量，直接返回即可；\n\n\n 倘若 miss 次数大于等于 dirty map 中存在的 key-entry 对数量，则使用 dirty map 覆盖 read map，并将 read map 的 amended flag 置为 false；\n\n\n 新的 dirty map 置为 nil，misses 计数器清零.\n\n\n 写流程\n\nsync.Map 写流程\nsync.Map.Store()\nfunc (m *Map) Store(key, value any) {\n    read, _ := m.read.Load().(readOnly)\n    if e, ok := read.m[key]; ok &amp;&amp; e.tryStore(&amp;value) {\n        return\n    }\n\n\n    m.mu.Lock()\n    read, _ = m.read.Load().(readOnly)\n    if e, ok := read.m[key]; ok {\n        if e.unexpungeLocked() {\n            m.dirty[key] = e\n        }\n        e.storeLocked(&amp;value)\n    } else if e, ok := m.dirty[key]; ok {\n        e.storeLocked(&amp;value)\n    } else {\n        if !read.amended {\n            m.dirtyLocked()\n            m.read.Store(readOnly{m: read.m, amended: true})\n        }\n        m.dirty[key] = newEntry(value)\n    }\n    m.mu.Unlock()\n}\n\n\nfunc (e *entry) storeLocked(i *any) {\n    atomic.StorePointer(&amp;e.p, unsafe.Pointe\n}\n\n（1）倘若 read map 存在拟写入的 key，且 entry 不为 expunged 状态，说明这次操作属于更新而非插入，直接基于 CAS 操作进行 entry 值的更新，并直接返回（存活态或者软删除，直接覆盖更新）；\n（2）倘若未命中（1）的分支，则需要加锁 double check；\n（3）倘若第二轮检查中发现 read map 或者 dirty map 中存在 key-entry 对，则直接将 entry 更新为新值即可（存活态或者软删除，直接覆盖更新）；\n（4）在第（3）步中，如果发现 read map 中该 key-entry 为 expunged 态，需要在 dirty map 先补齐 key-entry 对，再更新 entry 值（从硬删除中恢复，然后覆盖更新）；\n（5）倘若 read map 和 dirty map 均不存在，则在 dirty map 中插入新 key-entry 对，并且保证 read map 的 amended flag 为 true.（插入）\n（6）第（5）步的分支中，倘若发现 dirty map 未初始化，需要前置执行 dirtyLocked 流程；\n（7）解锁返回.  \n下面补充介绍 Store() 方法中涉及到的几个子方法.\nentry.tryStore()\nfunc (m *Map) Store(key, value any) {\n    read, _ := m.read.Load().(readOnly)\n    if e, ok := read.m[key]; ok &amp;&amp; e.tryStore(&amp;value) {\n        return\n    }\n\n\n    m.mu.Lock()\n   // ...\n}\n\n\nfunc (e *entry) tryStore(i *any) bool {\n    for {\n        p := atomic.LoadPointer(&amp;e.p)\n        if p == expunged {\n            return false\n        }\n        if atomic.CompareAndSwapPointer(&amp;e.p, p, unsafe.Pointer(i)) {\n            return true\n        }\n    }\n}\n\n\n\n• 在写流程中，倘若发现 read map 中已存在对应的 key-entry 对，则会对调用 tryStore 方法尝试进行更新；\n\n\n• 倘若 entry 为 expunged 态，说明已被硬删除，dirty 中缺失该项数据，因此 tryStore 执行失败，回归主干流程；\n\n\n• 倘若 entry 非 expunged 态，则直接执行 CAS 操作完成值的更新即可.\n\n\nentry.unexpungeLocked()\nfunc (m *Map) Store(key, value any) {\n    // ...\n    m.mu.Lock()\n    read, _ = m.read.Load().(readOnly)\n    if e, ok := read.m[key]; ok {\n        if e.unexpungeLocked() {\n            m.dirty[key] = e\n        }\n        e.storeLocked(&amp;value)\n    } \n    // ...\n}\n\n\nfunc (e *entry) unexpungeLocked() (wasExpunged bool) {\n    return atomic.CompareAndSwapPointer(&amp;e.p, expunged, nil)\n}\n\n\n\n• 在写流程加锁 double check 的过程中，倘若发现 read map 中存在对应的 key-entry 对，会执行该方法；\n\n\n• 倘若 key-entry 为硬删除 expunged 态，该方法会基于 CAS 操作将其更新为软删除 nil 态，然后进一步在 dirty map 中补齐该 key-entry 对，实现从硬删除到软删除的恢复.\n\n\nentry.storeLocked()\nfunc (m *Map) Store(key, value any) {\n    // ...\n    m.mu.Lock()\n    read, _ = m.read.Load().(readOnly)\n    if e, ok := read.m[key]; ok {\n       // ...\n        e.storeLocked(&amp;value)\n    } else if e, ok := m.dirty[key]; ok {\n        e.storeLocked(&amp;value)\n    } \n    // ...\n}\n\n\nfunc (e *entry) storeLocked(i *any) {\n    atomic.StorePointer(&amp;e.p, unsafe.Pointer)\n}\n\n写流程中，倘若 read map 或者 dirty map 存在对应 key-entry，最终会通过原子操作，将新值的指针存储到 entry.p 当中.\nsync.Map.dirtyLocked()\n\ndirtyLock 方法\nfunc (m *Map) dirtyLocked() {\n    if m.dirty != nil {\n        return\n    }\n\n\n    read, _ := m.read.Load().(readOnly)\n    m.dirty = make(map[any]*entry, len(read.m))\n    for k, e := range read.m {\n        if !e.tryExpungeLocked() {\n            m.dirty[k] = e\n        }\n    }\n}\n\n\nfunc (e *entry) tryExpungeLocked() (isExpunged bool) {\n    p := atomic.LoadPointer(&amp;e.p)\n    for p == nil {\n        if atomic.CompareAndSwapPointer(&amp;e.p, nil, expunged) {\n            return true\n        }\n        p = atomic.LoadPointer(&amp;e.p)\n    }\n    return p == expunged\n}\n\n\n\n• 在写流程中，倘若需要将 key-entry 插入到兜底的 dirty map 中，并且此时 dirty map 为空（从未写入过数据或者刚发生过 missLocked），会进入 dirtyLocked 流程；\n\n\n• 此时会遍历一轮 read map ，将未删除的 key-entry 对拷贝到 dirty map 当中；\n\n\n• 在遍历时，还会将 read map 中软删除 nil 态的 entry 更新为硬删除 expunged 态，因为在此流程中，不会将其拷贝到 dirty map.\n\n\n删流程\n\nDelete流程\nsync.Map.Delete()\nfunc (m *Map) Delete(key any) {\n    m.LoadAndDelete(key)\n}\n\n\nfunc (m *Map) LoadAndDelete(key any) (value any, loaded bool) {\n    read, _ := m.read.Load().(readOnly)\n    e, ok := read.m[key]\n    if !ok &amp;&amp; read.amended {\n        m.mu.Lock()\n        read, _ = m.read.Load().(readOnly)\n        e, ok = read.m[key]\n        if !ok &amp;&amp; read.amended {\n            e, ok = m.dirty[key]\n            delete(m.dirty, key)\n            m.missLocked()\n        }\n        m.mu.Unlock()\n    }\n    if ok {\n        return e.delete()\n    }\n    return nil, false\n}\n\n（1）倘若 read map 中存在 key，则直接基于 cas 操作将其删除；\n（2）倘若read map 不存在 key，且 read map 有缺失（amended flag 为 true），则加锁 dou check；\n（3）倘若加锁 double check 时，read map 仍不存在 key 且 read map 有缺失，则从 dirty map 中取元素，并且将 key-entry 对从 dirty map 中物理删除；\n（4）走入步骤（3），删操作需要和 dirty map 交互，需要走进 3.3 小节介绍的 missLocked 流程；\n（5）解锁；\n（6）倘若从 read map 或 dirty map 中获取到了 key 对应的 entry，则走入 entry.delete() 方法逻辑删除 entry；\n（7）倘若 read map 和 dirty map 中均不存在 key，返回 false 标识删除失败.  \nentry.delete()\nfunc (e *entry) delete() (value any, ok bool) {\n    for {\n        p := atomic.LoadPointer(&amp;e.p)\n        if p == nil || p == expunged {\n            return nil, false\n        }\n        if atomic.CompareAndSwapPointer(&amp;e.p, p, nil) {\n            return *(*any)(p), true\n        }\n    }\n}\n\n\n\n• 该方法是 entry 的逻辑删除方法；\n\n\n• 倘若 entry 此前已被删除，则直接返回 false 标识删除失败；\n\n\n• 倘若 entry 当前仍存在，则通过 CAS 将 entry.p 指向 nil，标识其已进入软删除状态.\n\n\n遍历流程\n\n遍历流程\nfunc (m *Map) Range(f func(key, value any) bool) {\n    read, _ := m.read.Load().(readOnly)\n    if read.amended {\n        m.mu.Lock()\n        read, _ = m.read.Load().(readOnly)\n        if read.amended {\n            read = readOnly{m: m.dirty}\n            m.read.Store(read)\n            m.dirty = nil\n            m.misses = 0\n        }\n        m.mu.Unlock()\n    }\n\n\n    for k, e := range read.m {\n        v, ok := e.load()\n        if !ok {\n            continue\n        }\n        if !f(k, v) {\n            break\n        }\n    }\n}\n\n\n\n（1）在遍历过程中，倘若发现 read map 数据不全（amended flag 为 true），会额外加一次锁，并使用 dirty map 覆盖 read map；\n\n\n（2）遍历 read map（通过步骤（1）保证 read map 有全量数据），执行用户传入的回调函数，倘若某次回调时返回值为 false，则会终止全流程.\n\n\n总结\nentry 的 expunged 态\n思考问题：\n为什么需要使用 expunged 态来区分软硬删除呢？仅用 nil 一种状态来标识删除不可以吗？\n回答：\n首先需要明确，无论是软删除(nil)还是硬删除(expunged),都表示在逻辑意义上 key-entry 对已经从 sync.Map 中删除，nil 和 expunged 的区别在于：\n• 软删除态（nil）：read map 和 dirty map 在物理上仍保有该 key-entry 对，因此倘若此时需要对该 entry 执行写操作，可以直接 CAS 操作；\n• 硬删除态（expunged）：dirty map 中已经没有该 key-entry 对，倘若执行写操作，必须加锁（dirty map 必须含有全量 key-entry 对数据）.\n\n复用 nil 态软删除的数据\n设计 expunged 和 nil 两种状态的原因，就是为了优化在 dirtyLocked 前，针对同一个 key 先删后写的场景. 通过 expunged 态额外标识出 dirty map 中是否仍具有指向该 entry 的能力，这样能够实现对一部分 nil 态 key-entry 对的解放，能够基于 CAS 完成这部分内容写入操作而无需加锁.\nread map 和 dirty map 的数据流转\nsync.Map 由两个 map 构成：\n\n\n• read map：访问时全程无锁；\n\n\n• dirty map：是兜底的读写 map，访问时需要加锁.\n\n\n之所以这样处理，是希望能根据对读、删、更新、写操作频次的探测，来实时动态地调整操作方式，希望在读、更新、删频次较高时，更多地采用 CAS 的方式无锁化地完成操作；在写操作频次较高时，则直接了当地采用加锁操作完成.\n因此， sync.Map 本质上采取了一种以空间换时间 + 动态调整策略的设计思路，下面对两个 map 间的数据流转过程进行详细介绍：\n两个 map\n\nread map&amp; dirty map\n\n\n• 总体思想，希望能多用 read map，少用 dirty map，因为操作前者无锁，后者需要加锁；\n\n\n• 除了 expunged 态的 entry 之外，read map 的内容为 dirty map 的子集；\n\n\ndirty map → read map\n\ndirty map 覆写 read map\n\n• 记录读/删流程中，通过 misses 记录访问 read map miss 由 dirty 兜底处理的次数，当 miss 次数达到阈值，则进入 missLocked 流程，进行新老 read/dirty 替换流程；此时将老 dirty 作为新 read，新 dirty map 则暂时为空，直到 dirtyLocked 流程完成对 dirty 的初始化；\n\nread map → dirty map\n\n遍历 read map 填充 dirty map\n\n\n• 发生 dirtyLocked 的前置条件：I dirty 暂时为空（此前没有写操作或者近期进行过 missLocked 流程）；II 接下来一次写操作访问 read 时 miss，需要由 dirty 兜底；\n\n\n• 在 dirtyLocked 流程中，需要对 read 内的元素进行状态更新，因此需要遍历，是一个线性时间复杂度的过程，可能存在性能抖动；\n\n\n• dirtyLocked 遍历中，会将 read 中未被删除的元素（非 nil 非 expunged）拷贝到 dirty 中；会将 read 中所有此前被删的元素统一置为 expunged 态.\n\n\nGo map 和 sync. Map 谁的性能好，为什么？\nGo 语言的 sync. Map 支持并发读写，采取了 “空间换时间” 的机制，冗余了两个数据结构，分别是：read 和 dirty\ntype Map struct {\n   mu Mutex\n   read atomic.Value // readOnly\n   dirty map[interface{}]*entry\n   misses int\n}\n\n对比原始 map：\n和原始 map+RWLock 的实现并发的方式相比，减少了加锁对性能的影响。它做了一些优化：可以无锁访问 read map，而且会优先操作 read map，倘若只操作 read map 就可以满足要求，那就不用去操作 write map (dirty)，所以在某些特定场景中它发生锁竞争的频率会远远小于 map+RWLock 的实现方式\n优点：\n适合读多写少的场景\n缺点：\n写多的场景，会导致 read map 缓存失效，需要加锁，冲突变多，性能急剧下降"},"GO/八股文/Slice":{"title":"Slice","links":[],"tags":["GO/八股文"],"content":"参考\n你真的了解go语言中的切片吗\n基本介绍\ngo 语言中的切片对标于其他编程语言中通俗意义上的“数组”. 切片中的元素存放在一块内存地址连续的区域，使用索引可以快速检索到指定位置的元素；切片长度和容量是可变的，在使用过程中可以根据需要进行扩容.\nGo slice 的底层实现原理?\n切片是基于数组实现的，它的底层是数组，可以理解为对底层数组的抽象。\n源码包中 src/runtime/slice. Go 定义了 slice 的数据结构：\n\ntype slice struct {\n\t// 指向起点的地址\n    array unsafe.Pointer\n    // 切片长度\n    len   int\n    // 切片容量\n    cap   int\n}\n\nSlice 占用 24 个字节\n\n\nArray: 指向底层数组的指针，占用 8 个字节\n\n\nLen: 切片的长度，占用 8 个字节\n\n\nCap: 切片的容量，cap 总是大于等于 len 的，占用 8 个字节\n\n\nSlice 有 4 种初始化方式\n// 初始化方式1：直接声明\nvar slice1 []int\n\n// 初始化方式2：使用字面量\nslice2 := []int{1, 2, 3, 4}\n\n// 初始化方式3：使用make创建slice\nslice3 := make([]int, 3, 5)         \n\n// 初始化方式4: 从切片或数组“截取”\nslcie4 := arr[1:3]\n\n通过一个简单程序，看下 slice 初始化调用的底层函数\npackage main\n\nimport &quot;fmt&quot;\n\nfunc main() {\n    slice := make([]int, 0)\n    slice = append(slice, 1)\n    fmt.Println(slice, len(slice), cap(slice))\n}\n\n通过 go tool compile -S test.go | grep CALL 得到汇编代码\n0x0042 00066 (test.go:6)        CALL    runtime.makeslice(SB)\n0x006d 00109 (test.go:7)        CALL    runtime.growslice(SB)\n0x00a4 00164 (test.go:8)        CALL    runtime.convTslice(SB)\n0x00c0 00192 (test.go:8)        CALL    runtime.convT64(SB)\n0x00d8 00216 (test.go:8)        CALL    runtime.convT64(SB)\n0x0166 00358 ($GOROOT/src/fmt/print.go:274)     CALL    fmt.Fprintln(SB)\n0x0180 00384 (test.go:5)        CALL    runtime.morestack_noctxt(SB)\n0x0079 00121 (&lt;autogenerated&gt;:1)        CALL    runtime.efaceeq(SB)\n0x00a0 00160 (&lt;autogenerated&gt;:1)        CALL    runtime.morestack_noctxt(SB)\n\n初始化 slice 调用的是 runtime. Makeslice，makeslice 函数的工作主要就是计算 slice 所需内存大小，然后调用 mallocgc 进行内存的分配\n所需内存大小 = 切片中元素大小 * 切片的容量\nfunc makeslice(et *_type, len, cap int) unsafe.Pointer {\n    // 根据 cap 结合每个元素的大小，计算出消耗的总容量\n    mem, overflow := math.MulUintptr(et.size, uintptr(cap))\n    if overflow || mem &gt; maxAlloc || len &lt; 0 || len &gt; cap {\n        // 倘若容量超限，len 取负值或者 len 超过 cap，直接 panic\n        mem, overflow := math.MulUintptr(et.size, uintptr(len))\n        if overflow || mem &gt; maxAlloc || len &lt; 0 {\n            panicmakeslicelen()\n        }\n        panicmakeslicecap()\n    }\n    // 走 mallocgc 进行内存分配以及切片初始化\n    return mallocgc(mem, et, true)\n}\n\nSlice 切片的截取\n x := make([]int, 2, 10)\n _ = x[6:10]\n _ = x[6:]\n _ = x[2:]\n\n//_ = x[6:] 这⼀⾏会发⽣panic, 截取符号 [i:j]，\n//如果 j 省略，默认是原切⽚或者数组的⻓度，x 的⻓度是 2，⼩于起始下标 6 ，所以 panic\n\n可以修改 slice 下标的方式，进行 slice 内容的截取，形如 s[a: b] 的格式，其中 a b 代表切片的索引 index，左闭右开，比如 s[a: b] 对应的范围是 [a,b)，代表的是取切片 slice index = a ~ index = b-1 范围的内容.\n此外，这里我聊到的 a 和 b 是可以缺省的：\n\n\n如果 a 缺省不填则默认取 0 ，则代表从切片起始位置开始截取. 比如 s[:b] 等价于 s[0:b]\n\n\n 如果 b 缺省不填，则默认取 len(s)，则代表末尾截取到切片长度 len 的终点，比如 s[a:] 等价于 s[a:len(s)]\n\n\n•a 和 b 均缺省也是可以的，则代表截取整个切片长度的范围，比如 s[:] 等价于 s[0:len(s)\n\n\n对切片 slice 执行截取操作时，本质上是一次引用传递操作，因为不论如何截取，底层复用的都是同一块内存空间中的数据，只不过，截取动作会创建出一个新的 slice header 实例\n\nSlice 元素追加\n通过 append 操作，可以在 slice 末尾，额外新增一个元素. 需要注意，这里的末尾指的是针对 slice 的长度 len 而言. 这个过程中倘若发现 slice 的剩余容量已经不足了，则会对 slice 进行扩容.\nSlice 扩容\n版本 1.18 之前\n扩容会发生在 slice append 的时候，当 slice 的 cap 不足以容纳新元素，就会进行扩容，扩容规则如下\n\n如果原有 slice 长度小于 1024，那么每次就扩容为原来的 2 倍\n如果原 slice 长度大于等于 1024，那么每次扩容就扩为原来的 1.25 倍\n\n1.18 +\n切片的扩容流程源码位于 runtime/slice.go 文件的 growslice 方法当中，其中核心步骤如下：\n\n\n\n倘若扩容后预期的新容量小于原切片的容量，则 panic\n\n\n倘若切片元素大小为 0（元素类型为 struct{}），则直接复用一个全局的 zerobase 实例，直接返回\n\n\n倘若预期的新容量超过老容量的两倍，则直接采用预期的新容量\n\n\n倘若老容量小于 256，则直接采用老容量的2倍作为新容量\n\n\n倘若老容量已经大于等于 256，则在老容量的基础上扩容 1/4 的比例并且累加上 192 的数值，持续这样处理，直到得到的新容量已经大于等于预期的新容量为止\n\n\n 结合 mallocgc 流程中，对内存分配单元 mspan 的等级制度，推算得到实际需要申请的内存空间大小\n\n\n调用 mallocgc，对新切片进行内存初始化\n\n\n调用 memmove 方法，将老切片中的内容拷贝到新切片中\n\n\n 返回扩容后的新切片\n\n\nfunc growslice(et *_type, old slice, cap int) slice {\n    //... \n    if cap &lt; old.cap {\n        panic(errorString(&quot;growslice: cap out of range&quot;))\n    }\n\n\n    if et.size == 0 {\n        // 倘若元素大小为 0，则无需分配空间直接返回\n        return slice{unsafe.Pointer(&amp;zerobase), old.len, cap}\n    }\n\n\n    // 计算扩容后数组的容量\n    newcap := old.cap\n    // 取原容量两倍的容量数值\n    doublecap := newcap + newcap\n    // 倘若新的容量大于原容量的两倍，直接取新容量作为数组扩容后的容量\n    if cap &gt; doublecap {\n        newcap = cap\n    } else {\n        const threshold = 256\n        // 倘若原容量小于 256，则扩容后新容量为原容量的两倍\n        if old.cap &lt; threshold {\n            newcap = doublecap\n        } else {\n            // 在原容量的基础上，对原容量 * 5/4 并且加上 192\n            // 循环执行上述操作，直到扩容后的容量已经大于等于预期的新容量为止\n            for 0 &lt; newcap &amp;&amp; newcap &lt; cap {             \n                newcap += (newcap + 3*threshold) / 4\n            }\n            // 倘若数值越界了，则取预期的新容量 cap 封顶\n            if newcap &lt;= 0 {\n                newcap = cap\n            }\n        }\n    }\n\n\n    var overflow bool\n    var lenmem, newlenmem, capmem uintptr\n    // 基于容量，确定新数组容器所需要的内存空间大小 capmem\n    switch {\n    // 倘若数组元素的大小为 1，则新容量大小为 1 * newcap.\n    // 同时会针对 span class 进行取整\n    case et.size == 1:\n        lenmem = uintptr(old.len)\n        newlenmem = uintptr(cap)\n        capmem = roundupsize(uintptr(newcap))\n        overflow = uintptr(newcap) &gt; maxAlloc\n        newcap = int(capmem)\n    // 倘若数组元素为指针类型，则根据指针占用空间结合元素个数计算空间大小\n    // 并会针对 span class 进行取整\n    case et.size == goarch.PtrSize:\n        lenmem = uintptr(old.len) * goarch.PtrSize\n        newlenmem = uintptr(cap) * goarch.PtrSize\n        capmem = roundupsize(uintptr(newcap) * goarch.PtrSize)\n        overflow = uintptr(newcap) &gt; maxAlloc/goarch.PtrSize\n        newcap = int(capmem / goarch.PtrSize)\n    // 倘若元素大小为 2 的指数，则直接通过位运算进行空间大小的计算   \n    case isPowerOfTwo(et.size):\n        var shift uintptr\n        if goarch.PtrSize == 8 {\n            // Mask shift for better code generation.\n            shift = uintptr(sys.Ctz64(uint64(et.size))) &amp; 63\n        } else {\n            shift = uintptr(sys.Ctz32(uint32(et.size))) &amp; 31\n        }\n        lenmem = uintptr(old.len) &lt;&lt; shift\n        newlenmem = uintptr(cap) &lt;&lt; shift\n        capmem = roundupsize(uintptr(newcap) &lt;&lt; shift)\n        overflow = uintptr(newcap) &gt; (maxAlloc &gt;&gt; shift)\n        newcap = int(capmem &gt;&gt; shift)\n    // 兜底分支：根据元素大小乘以元素个数\n    // 再针对 span class 进行取整     \n    default:\n        lenmem = uintptr(old.len) * et.size\n        newlenmem = uintptr(cap) * et.size\n        capmem, overflow = math.MulUintptr(et.size, uintptr(newcap))\n        capmem = roundupsize(capmem)\n        newcap = int(capmem / et.size)\n    }\n\n\n\n\n    // 进行实际的切片初始化操作\n    var p unsafe.Pointer\n    // 非指针类型\n    if et.ptrdata == 0 {\n        p = mallocgc(capmem, nil, false)\n        // ...\n    } else {\n        // 指针类型\n        p = mallocgc(capmem, et, true)\n        // ...\n    }\n    // 将切片的内容拷贝到扩容后的位置 p \n    memmove(p, old.array, lenmem)\n    return slice{p, old.len, newcap}\n}\n\nSlice 元素删除\n从切片中删除元素的实现思路，本质上和切片内容截取的思路是一致的.\n需要删除 slice 中间的某个元素，操作思路则是采用内容截取加上元素追加的复合操作，可以先截取待删除元素的左侧部分内容，然后在此基础上追加上待删除元素后侧部分的内容：\n    s := []int{0,1,2,3,4}\n    // 删除 index = 2 的元素\n    s = append(s[:2],s[3:]...)\n    // s: [0,1,3,4], len: 4, cap: 5\n    t.Logf(&quot;s: %v, len: %d, cap: %d&quot;, s, len(s), cap(s))\n}\nGo 语言删除切片元素的方法：\n1、指定删除位置，如【index := 1】;\n2、查看删除位置之前的元素和之后的元素;\n3、将删除点前后的元素连接起来即可。\nGo 语言并没有对删除切片元素提供专用的语法或者接口，需要使用切片本身的特性来删除元素。\n示例代码如下：\nstr := []string{&quot;a&quot;,&quot;b&quot;,&quot;c&quot;}\n// step 1\nindex := 1\n// step 2\nfmt.Println(str[:index], str[index+1])\n// step 3\nstr = append(str[:index], str[index+1]...)\n// res\nfmt.Println(str)\n\nSlice 切片拷贝\nslice 的拷贝可以分为简单拷贝和完整拷贝两种类型.\n\n简单拷贝，只需要对切片的字面量进行赋值传递即可，这样相当于创建出了一个新的 slice header 实例，但是其中的指针 array、容量 cap 和长度 len 仍和老的 slice header 实例相同.\n\nfunc Test_slice(t *testing.T) {\n    s := []int{0, 1, 2, 3, 4}\n    s1 := s\n    t.Logf(&quot;address of s: %p, address of s1: %p&quot;, s, s1)\n}\n\n\nslice 的完整复制，指的是会创建出一个和 slice 容量大小相等的独立的内存区域，并将原 slice 中的元素一一拷贝到新空间中.\n\nfunc Test_slice(t *testing.T) {\n    s := []int{0, 1, 2, 3, 4}\n    s1 := make([]int, len(s))\n    copy(s1, s)\n    t.Logf(&quot;s: %v, s1: %v&quot;, s, s1)\n    t.Logf(&quot;address of s: %p, address of s1: %p&quot;, s, s1)\n}\n\nGo array 和 slice 的区别？\n1）数组长度不同\n数组初始化必须指定长度，并且长度就是固定的\n切片的长度是不固定的，可以追加元素，在追加时可能使切片的容量增大\n2）函数传参不同\n数组是值类型，将一个数组赋值给另一个数组时，传递的是一份深拷贝，函数传参操作都会复制整个数组数据，会占用额外的内存，函数内对数组元素值的修改，不会修改原数组内容。\n切片是引用类型，将一个切片赋值给另一个切片时，传递的是一份浅拷贝，函数传参操作不会拷贝整个切片，只会复制 len 和 cap，底层共用同一个数组，不会占用额外的内存，函数内对数组元素值的修改，会修改原数组内容。\n3）计算数组长度方式不同\n数组需要遍历计算数组长度，时间复杂度为 O (n)\n切片底层包含 len 字段，可以通过 len ()计算切片长度，时间复杂度为 O (1)\nGo slice 深拷贝和浅拷贝\n深拷贝：拷贝的是数据本身，创造一个新对象，新创建的对象与原对象不共享内存，新创建的对象在内存中开辟一个新的内存地址，新对象值修改时不会影响原对象值\n实现深拷贝的方式：\n\nCopy (slice 2, slice 1)\n遍历 append 赋值\n\nfunc main() {\n    slice1 := []int{1, 2, 3, 4, 5}\n    slice2 := make([]int, 5, 5)\n    fmt.Printf(&quot;slice1: %v, %p\\n&quot;, slice1, slice1)\n    copy(slice2, slice1)\n    fmt.Printf(&quot;slice2: %v, %p\\n&quot;, slice2, slice2)\n    slice3 := make([]int, 0, 5)\n    for _, v := range slice1 {\n        slice3 = append(slice3, v)\n    }\n    fmt.Printf(&quot;slice3: %v, %p\\n&quot;, slice3, slice3)\n}\n\nslice1: [1 2 3 4 5], 0xc0000b0030\nslice2: [1 2 3 4 5], 0xc0000b0060\nslice3: [1 2 3 4 5], 0xc0000b0090\n\n浅拷贝：拷贝的是数据地址，只复制指向的对象的指针，此时新对象和老对象指向的内存地址是一样的，新对象值修改时老对象也会变化\n实现浅拷贝的方式：\n引用类型的变量，默认赋值操作就是浅拷贝\nfunc main() {\n    slice1 := []int{1, 2, 3, 4, 5}\n    fmt.Printf(&quot;slice1: %v, %p\\n&quot;, slice1, slice1)\n    slice2 := slice1\n    fmt.Printf(&quot;slice2: %v, %p\\n&quot;, slice2, slice2)\n}\n\nslice1: [1 2 3 4 5], 0xc00001a120\nslice2: [1 2 3 4 5], 0xc00001a120\n\nGo slice 为什么不是线程安全的？\n先看下线程安全的定义：\n多个线程访问同一个对象时，调用这个对象的行为都可以获得正确的结果，那么这个对象就是线程安全的。\n若有多个线程同时执行写操作，一般都需要考虑线程同步，否则的话就可能影响线程安全。\n再看 Go 语言实现线程安全常用的几种方式：\n\n互斥锁\n读写锁\n原子操作\nSync. Once\nSync. Atomic\nChannel\n\nSlice 底层结构并没有使用加锁等方式，不支持并发读写，所以并不是线程安全的，使用多个 goroutine 对类型为 slice 的变量进行操作，每次输出的值大概率都不会一样，与预期值不一致; slice 在并发执行中不会报错，但是数据会丢失\n/**\n* 切片非并发安全\n* 多次执行，每次得到的结果都不一样\n* 可以考虑使用 channel 本身的特性 (阻塞) 来实现安全的并发读写\n */\nfunc TestSliceConcurrencySafe(t *testing.T) {\n a := make([]int, 0)\n var wg sync.WaitGroup\n for i := 0; i &lt; 10000; i++ {\n  wg.Add(1)\n  go func(i int) {\n   a = append(a, i)\n   wg.Done()\n  }(i)\n }\n wg.Wait()\n t.Log(len(a)) \n // not equal 10000\n}\n\nnil 切片和空切片指向的地址一样？\nfunc main() {\n    var s1 []int\n    s2 := make([]int, 0)\n    s3 := make([]int, 0)\n    data1 := (*reflect.SliceHeader)(unsafe.Pointer(&amp;s1)).Data\n    data2 := (*reflect.SliceHeader)(unsafe.Pointer(&amp;s2)).Data\n    data3 := (*reflect.SliceHeader)(unsafe.Pointer(&amp;s3)).Data\n\n    fmt.Printf(&quot;s1 data:%+v\\n&quot;, data1)\n    fmt.Printf(&quot;s2 data:%+v\\n&quot;, data2)\n    fmt.Printf(&quot;s3 data:%+v\\n&quot;, data3)\n\n    fmt.Printf(&quot;s1:s2=&gt;%t\\n&quot;, data1 == data2)\n    fmt.Printf(&quot;s2:s3=&gt;%t\\n&quot;, data2 == data3)\n}\n\n//输出\ns1 data:0\ns2 data:824634859200\ns3 data:824634859200\ns1:s2=&gt;false\ns2:s3=&gt;true\n\nNil 切片和空切片指向的地址不一样。\nNil 切片引用数组指针地址为 0（无指向任何实际地址）\n空切片的引用数组指针地址是有的，且固定为一个值。\n//切片的数据结构\ntype SliceHeader struct {\n    Data uintptr //引用数组指针地址\n    Len  int\n    Cap  int\n}\n\nNil 切片和空切片最大的区别在于指向的数组引用地址是不一样的\n拷贝大切片一定比小切片代价大吗？\n并不是，所有切片的大小相同；三个字段（一个 uintptr，两个 int）。切片中的第一个字段是指向切片底层数组的指针，这是切片的存储空间，第二个字段是切片的长度，第三个字段是容量。将一个 slice 变量分配给另一个变量只会复制三个机器字。所以拷贝大切片跟小切片的代价应该是一样的。\nSliceHeader 是切片在 go 的底层结构。\ntype SliceHeader struct {\n    Data uintptr\n    Len  int\n    Cap  int\n}\n\n大切片跟小切片的区别无非就是 Len 和 Cap 的值比小切片的这两个值大一些，如果发生拷贝，本质上就是拷贝上面的三个字段。\njson 库对 nil slice 和空 slice 的处理是一致的吗？\nJson 库对 nil slice 和空 slice 的处理是不一致的，\n因为 nil slice 只是声明了 slice，却没有给实例化的对象。\n\tvar f1 []string\n    f2 := make([]string, 0)\n    json1, _ := json.Marshal(Person{f1})\n    json2, _ := json.Marshal(Person{f2})\n    fmt.Printf(&quot;%s\\n&quot;, string(json1))\n    fmt.Printf(&quot;%s\\n&quot;, string(json2))\n\n//输出\n{&quot;Friends&quot;:null}\n{&quot;Friends&quot;:[]}\n\nJson 库对 nil slice 编码为 null, json 库对空 slice 编码为[]。\n扩容前后的 Slice 是否相同?\n情况一：原数组还有容量可以扩容（实际容量没有填充完），这种情况下，扩容以后的数组还是指向原来的数组，对一个切片的操作可能影响多个指针指向相同地址的 slice。\n情况二：原来数组的容量已经达到了最大值，再想扩容，go 默认会先开一片内存区域，把原来的值拷贝过来，然后再执行 append ()操作。这种情况丝毫不影响原数组。要复制一个 slice，最好使用 copy 函数。\n\n输出：\n函数内s=[1,2]\n主函数内s=[1]\n\n使用值为 nil 的 slice、map 会发生啥\n允许对值为 nil 的 slice 添加元素，但对值为 nil 的 map 添加元素，则会造成运行时 panic。\n// map 错误示例  \nfunc main () {  \n    var m map[string]int  \n    m[&quot;one&quot;] = 1  // error: panic: assignment to entry in nil map  \n    // m := make (map[string]int)// map 的正确声明，分配了实际的内存  \n}      \n  \n// slice 正确示例  \nfunc main () {  \n var s []int  \n s = append (s, 1)  \n}\n\n如果先使用 make(),那么可以使用 m[&quot;one&quot;]=1,因为分配了内存。\nslice 分配在堆上还是栈上\n有可能分配到栈上，也有可能分配到栈上。当开辟切片空间较大时，会逃逸到堆上。\n通过命令 go build -gcflags &quot;-m -l&quot; xxx.go 观察 golang 是如何进行逃逸分析的\n// map 错误示例\nfunc main() {\n    var m map[string]int\n    m[&quot;one&quot;] = 1  // error: panic: assignment to entry in nil map\n    // m := make(map[string]int)// map 的正确声明，分配了实际的内存\n}    \n\n// slice 正确示例\nfunc main() {\n var s []int\n s = append(s, 1)\n}\n\nGo 中如果 new 一个切片会怎么样\nnew ([]int) 之后的 list 是⼀个未设置⻓度的  * []int 类型的指针不能对未设置⻓度的指针执⾏ append 操作。\n\npackage main\n\nimport &quot;fmt&quot;\n\nfunc main() {\n\tlist := new([]int)\n\t// 编译错误\n\t// new([]int) 之后的 list 是⼀个未设置⻓度的 *[]int 类型的指针\n\t// 不能对未设置⻓度的指针执⾏ append 操作。\n\t*list = append(*list, 1)\n\tfmt.Println(*list)\n\ts1 := []int{1, 2, 3}\n\ts2 := []int{4, 5}\n\t// 编译错误，s2需要展开\n\ts1 = append(s1, s2...)\n\tfmt.Println(s1)\n}//正确写法\n\n整型切片如何初始化？\n//数组初始化\narr1 := [3]int{1, 2, 3}\narr2 := [...]int{1, 2, 3}\narr3 := [3]int{0:3,1:4}\n\n数组怎么转集合 ?\n可以使用数组的索引作为 map 的 key，数组的值作为 map 的值。\n//数组初始化\narr1 := [3]int{1, 2, 3}\narr2 := [...]int{1, 2, 3}\narr3 := [3]int{0:3,1:4}\n\n数组是如何实现根据下标随机访问数组元素的吗？\n例如： a := [10]int{0}\n\n计算机给数组 a，分配了一组连续的内存空间。\n比如内存块的首地址为 base_address=1000。\n当计算给每个内存单元分配一个地址，计算机通过地址来访问数据。当计算机需要访问数组的某个元素的时候，会通过一个寻址公式来计算存储的内存地址。\n\n一个函数传参一个 slice，先 append 再赋值和另一个函数先赋值再 append，哪个会发生变化？\npackage main\n\nimport &quot;fmt&quot;\n\nfunc BeforeAppend(s []int) []int {\n\ts = append(s, 1)\n\ts = []int{1, 2, 3}\n\treturn s\n}\n\nfunc AfterAppend(s []int) []int {\n\ts = []int{1, 2, 3}\n\ts = append(s, 1)\n\treturn s\n}\n\nfunc main() {\n\ts := make([]int, 0)\n\tfmt.Println(BeforeAppend(s))\n\tfmt.Println(AfterAppend(s))\n}\n"},"GO/八股文/内存管理和GC":{"title":"内存管理","links":[],"tags":["GO/八股文"],"content":"内存管理\nGolang 的内存模型，为什么小对象多了会造成 gc 压力。\n通常小对象过多会导致 GC 三色法消耗过多的 GPU。优化思路是，减少对象分配。\nGo 语言什么时候垃圾回收，写代码的时候如何减少对象分配\n当 goroutine 申请新的内存管理单元时触发垃圾回收。\n写代码的时候如何减少对象分配，这是一个关于性能的问题，\n\n\n例如如果需要把数字转换成字符串，使用 strconv.Itoa () 比 fmt.Sprintf () 要快一倍左右。\n\n\n如果需要把数字转换成字符串，使用 strconv.Itoa () 比 fmt.Sprintf () 要快一倍左右。这里就不一一展开了。\n\n\n给大家丢脸了，用了三年 Golang，我还是没答对这道内存泄漏题\nmp.weixin.qq.com/s#wechat_redirect\nGo 内存泄漏？不是那么简单\ncolobu.com/2019/08/28/go-memory-leak-i-dont-think-so/ \nGo 内存分配，和 tcmalloc 的区别?\nGO 内存分配\nGo 内存分配核心思想就是把内存分为多级管理，从而降低锁的粒度。\n它将可用的堆内存采用二级分配的方式进行管理：每个线程都会自行维护一个独立的内存池，进行内存分配时优先从该内存池中分配，当内存池不足时才会向全局内存池申请，以避免不同线程对全局内存池的频繁竞争。\n\nGo 在程序启动时，会向操作系统申请一大块内存，之后自行管理。\nGo 内存管理的基本单元是 mspan，它由若干个页组成，每种 mspan 可以分配特定大小的 object。\nMcache, mcentral, mheap 是 Go 内存管理的三大组件，层层递进。\n\nMcache 管理线程在本地缓存的 mspan；\nmcentral 管理全局的 mspan 供所有线程使用；\nmheap 管理 Go 的所有动态分配内存。\n\n\n分配对象\n\n极小的对象 (⇐16B)会分配在一个 object 中，以节省资源，使用 tiny 分配器分配内存；\n一般对象(16B-32KB)通过 mspan 分配内存；\n大对象(&gt;32 KB)则直接由 mheap 分配内存。\n\n\n\ntcmalloc\nTcmalloc 是 google 开发的内存分配算法库，最开始它是作为 google 的一个性能工具库 perftools 的一部分。TCMalloc 是用来替代传统的 malloc 内存分配函数。它有减少内存碎片，适用于多核，更好的并行性支持等特性。\nTC 就是 Thread Cache 两英文的简写。它提供了很多优化，如：\n\nTCMalloc 用固定大小的 page (页)来执行内存获取、分配等操作。这个特性跟 Linux 物理内存页的划分是不是有同样的道理。\n\nTCMalloc 用固定大小的对象，比如 8 KB，16 KB 等用于特定大小对象的内存分配，这对于内存获取或释放等操作都带来了简化的作用。\n\n\nTCMalloc 还利用缓存常用对象来提高获取内存的速度。\nTCMalloc 还可以基于每个线程或者每个 CPU 来设置缓存大小，这是默认设置。\n\nTCMalloc 基于每个线程独立设置缓存分配策略，减少了多线程之间锁的竞争。\n\n\n\nGo 中的内存分类并不像 TCMalloc 那样分成小、中、大对象，但是它的小对象里又细分了一个 Tiny 对象，Tiny 对象指大小在 1 Byte 到 16 Byte 之间并且不包含指针的对象。小对象和大对象只用大小划定，无其他区分。\nGo 内存管理与 tcmalloc 最大的不同在于，它提供了逃逸分析和垃圾回收机制。\nGo 语言中的堆和栈\n\n\n栈主要用来存储值类型的数据，如整数、浮点数、布尔值等。因为值类型的数据大小是固定的，所以可以直接分配在栈上，访问速度非常快。\n\n\n堆主要用来存储引用类型的数据，如字符串、切片、字典等。因为引用类型的数据大小是不固定的，所以需要动态分配内存，通常在堆上进行。同时，由于引用类型的数据通常需要共享和修改，因此使用指针来进行引用和操作，从而避免了复制大量的数据。\n\n\n可以看出，栈的性能会更好——不需要额外的垃圾回收机制（离开该作用域，它们的内存就会被自动回收），CPU 可以连续缓存（内存空间是连续的）。堆是通过GC 回收内存的。\nGo 内存分配机制？\nGo 语言内置运行时（就是 runtime），抛弃了传统的内存分配方式，改为自主管理。这样可以自主地实现更好的内存使用模式，比如内存池、预分配等等。这样，不会每次内存分配都需要进行系统调用。\n操作系统的内存管理\n 操作系统存储模型\n\n观察上图，我们可以从中捕捉到的关键词是：\n\n\n多级模型\n\n\n动态切换\n\n\n虚拟内存与物理内存\n\n操作系统内存管理中，另一个重要概念是虚拟内存，其作用如下：\n\n\n在用户与硬件间添加中间代理层（没有什么是加一个中间层解决不了的）\n\n\n 优化用户体验（进程感知到获得的内存空间是“连续”的）\n\n\n “放大”可用内存（虚拟内存可以由物理内存+磁盘补足，并根据冷热动态置换，用户无感知）\n\n\n 分页管理\n操作系统中通常会将虚拟内存和物理内存切割成固定的尺寸，于虚拟内存而言叫作“页”，于物理内存而言叫作“帧”，原因及要点如下：\n\n\n提高内存空间利用（以页为粒度后，消灭了不稳定的外部碎片，取而代之的是相对可控的内部碎片）\n\n\n 提高内外存交换效率（更细的粒度带来了更高的灵活度）\n\n\n 与虚拟内存机制呼应，便于建立虚拟地址→物理地址的映射关系（聚合映射关系的数据结构，称为页表）\n\n\n linux 页/帧的大小固定，为 4KB（这实际是由实践推动的经验值，太粗会增加碎片率，太细会增加分配频率影响效率）\n\n\nGO 内存模型设计思想\n\n内存分配算法采用 Google 的 TCMalloc算法，每个线程都会自行维护一个独立的内存池，进行内存分配时优先从该内存池中分配，当内存池不足时才会向加锁向全局内存池申请，减少系统调用并且避免不同线程对全局内存池的锁竞争\n把内存切分的非常的细小，分为多级管理，以降低锁的粒度\n回收对象内存时，并没有将其真正释放掉，只是放回预先分配的大块内存中，以便复用。只有内存闲置过多的时候，才会尝试归还部分内存给操作系统，降低整体开销\n\n具体来说\n\n以空间换时间，一次缓存，多次复用\n\n由于每次向操作系统申请内存的操作很重，那么不妨一次多申请一些，以备后用.\nGolang 中的堆 mheap 正是基于该思想，产生的数据结构. 我们可以从两个视角来解决 Golang 运行时的堆：\n\n\nI 对操作系统而言，这是用户进程中缓存的内存\n\n\nII 对于 Go 进程内部，堆是所有对象的内存起源\n\n\n\n 多级缓存，实现无/细锁化\n\n\n堆是 Go 运行时中最大的临界共享资源，这意味着每次存取都要加锁，在性能层面是一件很可怕的事情.\n在解决这个问题，Golang 在堆 mheap 之上，依次细化粒度，建立了 mcentral、mcache 的模型，下面对三者作个梳理：\n\n\nmheap：全局的内存起源，访问要加全局锁\n\n\nmcentral：每种对象大小规格（全局共划分为 68 种）对应的缓存，锁的粒度也仅限于同一种规格以内\n\n\n mcache：每个 P（正是 GMP 中的 P）持有一份的内存缓存，访问时无锁\n\n\n这些概念，我们在第 2 节中都会再作详细展开，此处可以先不深究，注重于宏观架构即可.\n\n 多级规格，提高利用率\n\n\n首先理下 page 和 mspan 两个概念：\n（1）page：最小的存储单元.\nGolang 借鉴操作系统分页管理的思想，每个最小的存储单元也称之为页 page，但大小为 8 KB\n（2）mspan：最小的管理单元.\nmspan 大小为 page 的整数倍，且从 8B 到 80 KB 被划分为 67 种不同的规格，分配对象时，会根据大小映射到不同规格的 mspan，从中获取空间.\n于是，我们回头小节多规格 mspan 下产生的特点：\n\n\nI 根据规格大小，产生了等级的制度\n\n\nII 消除了外部碎片，但不可避免会有内部碎片\n\n\nIII 宏观上能提高整体空间利用率\n\n\nIV 正是因为有了规格等级的概念，才支持 mcentral 实现细锁化\n\n\n\n• 全局总览，留个印象\n\n\n上图是 Thread-Caching Malloc 的整体架构图，Golang 正是借鉴了该内存模型. 我们先看眼架构，有个整体概念，后续小节中，我们会不断对细节进行补充.\n分配组件\nGo 的内存管理组件主要有：mspan、mcache、mcentral 和 mheap\n\n内存管理单元：mspan\n\n\n\n mspan 是 Golang 内存管理的最小单元，该结构体中包含 next 和 prev 两个字段，它们分别指向了前一个和后一个 mspan\n\n\nmspan 大小是 page 的整数倍（Go 中的 page 大小为 8KB），且内部的页是连续的（至少在虚拟内存的视角中是这样），这里的页不是操作系统中的内存页，它们是操作系统内存页的整数倍。\n\n\n 每个 mspan 根据空间大小以及面向分配对象的大小，会被划分为不同的等级（2.2小节展开）\n\n\n 同等级的 mspan 会从属同一个 mcentral，最终会被组织成链表，因此带有前后指针（prev、next）\n\n\n 由于同等级的 mspan 内聚于同一个 mcentral，所以会基于同一把互斥锁管理\n\n\n mspan 会基于 bitMap 辅助快速找到空闲内存块（块大小为对应等级下的 object 大小），此时需要使用到 Ctz64 算法.\n\n\npage 是内存存储的基本单元，“对象”放到 page 中\ntype mspan struct {\n    // 标识前后节点的指针 \n    next *mspan     \n    prev *mspan    \n    // ...\n    // 起始地址\n    startAddr uintptr \n    // 包含几页，页是连续的\n    npages    uintptr \n\n\n    // 标识此前的位置都已被占用 \n    freeindex uintptr\n    // 最多可以存放多少个 object\n    nelems uintptr // number of object in the span.\n\n\n    // bitmap 每个 bit 对应一个 object 块，标识该块是否已被占用\n    allocCache uint64\n    // ...\n    // 标识 mspan 等级，包含 class 和 noscan 两部分信息\n    spanclass             spanClass    \n    // ...\n}\n\n内存单元等级 spanClass\nGo 有 68 种不同大小的 spanClass，用于小对象的分配\nconst _NumSizeClasses = 68\nvar class_to_size = [_NumSizeClasses]uint16{0, 8, 16, 32, 48, 64, 80, 96, 112, 128, 144, 160, 176, 192, 208, 224, 240, 256, 288, 320, 352, 384, 416, 448, 480, 512, 576, 640, 704, 768, 896, 1024, 1152, 1280, 1408, 1536,1792, 2048, 2304, 2688, 3072, 3200, 3456, 4096, 4864, 5376, 6144, 6528, 6784, 6912, 8192, 9472, 9728, 10240, 10880, 12288, 13568, 14336, 16384, 18432, 19072, 20480, 21760, 24576, 27264, 28672, 32768}\n\n如果按照序号为 1 的 spanClass（对象规格为 8 B）分配，每个 span 占用堆的字节数：8 k，mspan 可以保存 1024个对象\n如果按照序号为 2 的 spanClass（对象规格为 16 B）分配，每个 span 占用堆的字节数：8 k，mspan 可以保存 512个对象\n…\n如果按照序号为 67 的 spanClass（对象规格为 32 K）分配，每个 span 占用堆的字节数：32 k，mspan 可以保存1个对象\n\n字段含义：\n\nClass： class ID，每个 span 结构中都有一个 class ID, 表示该 span 可处理的对象类型\nBytes/obj：该 class 代表对象的字节数\nBytes/span：每个 span 占用堆的字节数，也即页数*页大小\nObjects: 每个 span 可分配的对象个数，也即（bytes/spans）/（bytes/obj）\nWaste bytes: 每个 span 产生的内存碎片，也即（bytes/spans）%（bytes/obj）\n\n大于 32 k 的对象出现时，会直接从 heap 分配一个特殊的 span，这个特殊的 span 的类型 (class)是 0, 只包含了一个大对象\n代码位于 runtime/mheap.go\ntype spanClass uint8\n\n\n// uint8 左 7 位为 mspan 等级，最右一位标识是否为 noscan\nfunc makeSpanClass(sizeclass uint8, noscan bool) spanClass {\n    return spanClass(sizeclass&lt;&lt;1) | spanClass(bool2int(noscan))\n}\n\n\nfunc (sc spanClass) sizeclass() int8 {\n    return int8(sc &gt;&gt; 1)\n}\n\n\nfunc (sc spanClass) noscan() bool {\n    return sc&amp;1 != 0\n}\n\n线程缓存：mcache\n\nmcache 管理线程在本地缓存的 mspan，每个 goroutine 绑定的 P 都有一个 mcache 字段\ntype mcache struct {\n\t // 微对象分配器相关\n    tiny       uintptr\n    tinyoffset uintptr\n    tinyAllocs uintptr\n\n\t // mcache 中缓存的 mspan，每种 spanClass 各一个\n    alloc [numSpanClasses]*mspan\n    \n}\n\n_NumSizeClasses = 68\nnumSpanClasses = _NumSizeClasses &lt;&lt; 1\n\n\n\nmcache 是每个 P 独有的缓存，因此交互无锁\n\n\nmcache 用 Span Classes 作为索引管理多个用于分配的 mspan，它包含所有规格的 mspan。它是 _NumSizeClasses 的 2 倍，也就是 68*2=136，\n\n其中* 2 是将 spanClass 分成了有指针和没有指针两种, 方便与垃圾回收。\n对于每种规格，有 2 个 mspan，一个 mspan 不包含指针，另一个 mspan 则包含指针。对于无指针对象的 mspan 在进行垃圾回收的时候无需进一步扫描它是否引用了其他活跃的对象。\n\n\n\nmcache 在初始化的时候是没有任何 mspan 资源的，在使用过程中会动态地从 mcentral 申请，之后会缓存下来。当对象小于等于 32 KB 大小时，使用 mcache 的相应规格的 mspan 进行分配。\n\n\nmcache 中还有一个为对象分配器 tiny allocator，用于处理小于 16B 对象的内存分配，在 3.3 小节中详细展开.\n\n\n中心缓存：mcentral\n\nMcentral 管理全局的 mspan 供所有线程使用，全局 mheap 变量包含 central 字段，每个 mcentral 结构都维护在mheap结构内\ntype mcentral struct {\n    spanclass spanClass // 指当前规格大小\n\n    partial [2]spanSet // 有空闲object的mspan列表\n    full    [2]spanSet // 没有空闲object的mspan列表\n}\n\n\n每个 mcentral 管理一种 spanClass 的 mspan，\n每个 mcentral 下聚合了该 spanClass 下的 mspan\n并将有空闲空间和没有空闲空间的 mspan 分开管理。Partial 和 full 的数据类型为 spanSet，表示 mspans 集，可以通过 pop、push 来获得 mspans\n每个 mcentral 一把锁\n\ntype spanSet struct {\n    spineLock mutex\n    spine     unsafe.Pointer // 指向[]span的指针\n    spineLen  uintptr        // Spine array length, accessed atomically\n    spineCap  uintptr        // Spine array cap, accessed under lock\n\n    index headTailIndex  // 前32位是头指针，后32位是尾指针\n}\n\n简单说下 mcache 从 mcentral 获取和归还 mspan 的流程：\n\n获取；加锁，从 partial 链表找到一个可用的 mspan；并将其从 partial 链表删除；将取出的 mspan 加入到 full 链表；将 mspan 返回给工作线程，解锁。\n归还；加锁，将 mspan 从 full 链表删除；将 mspan 加入到 partial 链表，解锁。\n\n页堆：mheap\nMheap 管理 Go 的所有动态分配内存，可以认为是 Go 程序持有的整个堆空间，全局唯一\nvar mheap_ mheap\n\ntype mheap struct {\n    // 堆的全局锁\n    lock mutex\n\n\n    // 空闲页分配器，底层是多棵基数树组成的索引，每棵树对应 16 GB 内存空间\n    pages pageAlloc \n\n\n    // 记录了所有的 mspan. 需要知道，所有 mspan 都是经由 mheap，使用连续空闲页组装生成的\n    allspans []*mspan\n\n\n    // heapAreana 数组，64 位系统下，二维数组容量为 [1][2^22]\n    // 每个 heapArena 大小 64M，因此理论上，Golang 堆上限为 2^22*64M = 256T\n    arenas [1 &lt;&lt; arenaL1Bits]*[1 &lt;&lt; arenaL2Bits]*heapArena\n\n\n    // ...\n    // 多个 mcentral，总个数为 spanClass 的个数\n    central [numSpanClasses]struct {\n        mcentral mcentral\n        // 用于内存地址对齐\n        pad      [cpu.CacheLinePadSize - unsafe.Sizeof(mcentral{})%cpu.CacheLinePadSize]byte\n    }\n\n\n    // ...\n}\n\n\n\n对于 Golang 上层应用而言，堆是操作系统虚拟内存的抽象\n\n\n所有 mcentral 的集合则是存放于 mheap 中的。mheap 里的 arena 区域是堆内存的抽象，运行时会将 8KB 看做一页，这些内存页中存储了所有在堆上初始化的对象\n\n\n以页（8KB）为单位，作为最小内存存储单元\n\n\n负责将连续页组装成 mspan\n\n\n全局内存基于 bitMap 标识其使用情况，每个 bit 对应一页，为 0 则自由，为 1 则已被 mspan 组装\n\n\n通过 heapArena 聚合页，记录了页到 mspan 的映射信息（2.7小节展开）\n\n\n建立空闲页基数树索引 radix tree index，辅助快速寻找空闲页（2.6小节展开）\n\n\n是 mcentral 的持有者，持有所有 spanClass 下的 mcentral，作为自身的缓存\n\n\n内存不够时，向操作系统申请，申请单位为 heapArena（64M） 运行时使用二维的 runtime. HeapArena 数组管理所有的内存，每个 runtime. HeapArena 都会管理 64 MB 的内存。\n\n\n\n当申请内存时，依次经过 mcache 和 mcentral 都没有可用合适规格的大小内存，这时候会向 mheap 申请一块内存。然后按指定规格划分为一些列表，并将其添加到相同规格大小的 mcentral 的 非空闲列表 后面\n\n 空闲页索引 pageAlloc\n代码位于 runtime/mpagealloc.go\nconst summaryLevels = 5\n\n\ntype pageAlloc struct {\n    // 共有五层基数树，第一层有 2^14 个节点，因此共用 2^14棵基数树\n    // 总空间大小为 2^14*16GB = 256T\n    // 接下来每层的节点数为上层的 8 倍\n    summary [summaryLevels][]pallocSum\n    \n    // ...\n    // 类似于 tiny offset，小于此值的地址无锁检索，必然没有空间可用\n    searchAddr offAddr\n\n\n    // ...\n}\n\n（1）数据结构背后的含义：\n\n\nmheap 会基于 bitMap 标识内存中各页的使用情况，bit 位为 0 代表该页是空闲的，为 1 代表该页已被 mspan 占用.\n\n\n每棵基数树聚合了 16 GB 内存空间中各页使用情况的索引信息，用于帮助 mheap 快速找到指定长度的连续空闲页的所在位置\n\n\nmheap 持有 2^14 棵基数树，因此索引全面覆盖到 2^14 * 16 GB = 256 T 的内存空间.\n\n\n（2）基数树节点设定\n\n基数树中，每个节点称之为 PallocSum，是一个 uint64 类型，体现了索引的聚合信息，包含以下四部分：\n\n\n start：最右侧 21 个 bit，标识了当前节点映射的 bitMap 范围中首端有多少个连续的 0 bit（空闲页），\n\n\n•max：中间 21 个 bit，标识了当前节点映射的 bitMap 范围中最多有多少个连续的 0 bit（空闲页），称之为 max；\n\n\n• end：左侧 21 个 bit，标识了当前节点映射的 bitMap 范围中最末端有多少个连续的 0 bit（空闲页），称之为 end.\n\n\n• 最左侧一个 bit，弃置不用\n\n\n（2）基数树节点设定\n\n\n\n每个父 pallocSum 有 8 个子 pallocSum\n\n\n根 pallocSum 总览全局，映射的 bitMap 范围为全局的 16 GB 空间（其 max 最大值为 2^21，因此总空间大小为 2^21*8KB=16GB）；\n\n\n从首层向下是一个依次八等分的过程，每一个 pallocSum 映射其父节点 bitMap 范围的八分之一，因此第二层 pallocSum 的 bitMap 范围为 16GB/8 = 2GB，以此类推，第五层节点的范围为 16GB / (8^4) = 4 MB，已经很小\n\n\n\n\n\n•聚合信息时，自底向上. 每个父 pallocSum 聚合 8 个子 pallocSum 的 start、max、end 信息，形成自己的信息，直到根 pallocSum，坐拥全局 16 GB 的 start、max、end 信息\n\n\n mheap 寻页时，自顶向下. 对于遍历到的每个 pallocSum，\n\n先看起 start 是否符合，是则寻页成功；\n再看 max 是否符合，是则进入其下层孩子 pallocSum 中进一步寻访；\n最后看 end 和下一个同辈 pallocSum 的 start 聚合后是否满足，是则寻页成功.\n\n基数树节点\n\n\nconst(\n    logMaxPackedValue = 21\n    maxPackedValue    = 1 &lt;&lt; logMaxPackedValue\n)\n\n\ntype pallocSum uint64\n\n\n// 基于 start、max、end 组装成一个基数树节点 pallocSum\nfunc packPallocSum(start, max, end uint) pallocSum {\n    // ...\n    return pallocSum((uint64(start) &amp; (maxPackedValue - 1)) |\n        ((uint64(max) &amp; (maxPackedValue - 1)) &lt;&lt; logMaxPackedValue) |\n        ((uint64(end) &amp; (maxPackedValue - 1)) &lt;&lt; (2 * logMaxPackedValue)))\n}\n\n\n// 当前节点对应区域内，首部连续空闲页的长度\n// 通过 uint64 最右侧 21 个 bit 标识\nfunc (p pallocSum) start() uint {\n    // ...\n    return uint(uint64(p) &amp; (maxPackedValue - 1))\n}\n\n\n// 当前节点对应区域内，连续空闲页的最大长度\n// 通过 uint64 左数 23~43 个 bit 标识\nfunc (p pallocSum) max() uint {\n    // ...\n    return uint((uint64(p) &gt;&gt; logMaxPackedValue) &amp; (maxPackedValue - 1))\n}\n\n\n// 当前节点对应区域内，尾部连续空闲页的长度\n// 通过 uint64 左数 2~22 个 bit 标识\nfunc (p pallocSum) end() uint {\n    return uint((uint64(p) &gt;&gt; (2 * logMaxPackedValue)) &amp; (maxPackedValue - 1))\n}\n\n记录页到 mspan 的映射：heapArena\n\n\n每个 heapArena 包含 8192 个页，大小为 8192 * 8KB = 64 MB\n\n\n heapArena 记录了页到 mspan 的映射. 因为 GC 时，通过地址偏移找到页很方便，但找到其所属的 mspan 不容易. 因此需要通过这个映射信息进行辅助.\n\n\n heapArena 是 mheap 向操作系统申请内存的单位（64MB）\n\n\nconst pagesPerArena = 8192\n\n\ntype heapArena struct {\n    // ...\n    // 实现 page 到 mspan 的映射\n    spans [pagesPerArena]*mspan\n\n\n    // ...\n}\n\n分配流程\n下面来串联 Golang 中分配对象的流程，不论是以下哪种方式，最终都会殊途同归步入 mallocgc 方法中，并且根据 3.1 小节中的策略执行分配流程：\n\n\nnew(T)\n\n\n &amp;T{}\n\n\n make(xxxx)\n\n\n分配对象\n\n微对象 (0, 16 B)：先使用线程缓存上的微型分配器 (tiny allocator)，再依次尝试线程缓存、中心缓存、堆分配内存；\n小对象 [16 B, 32 KB]：依次尝试线程缓存、中心缓存、堆分配内存；\n大对象 (32 KB, +∞)：直接尝试堆分配内存；\n\n分配策略\n不同类型的对象，会有着不同的分配策略，这些内容在 mallocgc 方法中都有体现.\n核心流程类似于读多级缓存的过程，由上而下，每一步只要成功则直接返回. 若失败，则由下层方法兜底.\n对于微对象的分配流程：\n（1）从 P 专属 mcache 的 tiny 分配器取内存（无锁）\n（2）根据所属的 spanClass，从 P 专属 mcache 缓存的 mspan 中取内存（无锁）\n（3）根据所属的 spanClass 从对应的 mcentral 中取 mspan 填充到 mcache，然后从 mspan 中取内存（spanClass 粒度锁）\n（4）根据所属的 spanClass，从 mheap 的页分配器 pageAlloc 取得足够数量空闲页组装成 mspan 填充到 mcache，然后从 mspan 中取内存（全局锁）\n（5）mheap 向操作系统申请内存，更新页分配器的索引信息，然后重复（4）.\n对于小对象的分配流程是跳过（1）步，执行上述流程的（2）-（5）步；\n对于大对象的分配流程是跳过（1）-（3）步，执行上述流程的（4）-（5）步.\n\nGo 内存逃逸机制？\n概念\n在一段程序中，每一个函数都会有自己的内存区域存放自己的局部变量、返回地址等，这些内存会由编译器在栈中进行分配，每一个函数都会分配一个栈桢，在函数运行结束后进行销毁，但是有些变量我们想在函数运行结束后仍然使用它，那么就需要把这个变量在堆上分配，这种从”栈”上逃逸到”堆”上的现象就成为内存逃逸。\n在栈上分配的地址，一般由系统申请和释放，不会有额外性能的开销，比如函数的入参、局部变量、返回值等。在堆上分配的内存，如果要回收掉，需要进行 GC，那么 GC 一定会带来额外的性能开销。编程语言不断优化 GC 算法，主要目的都是为了减少 GC 带来的额外性能开销，变量一旦逃逸会导致性能开销变大。\n逃逸机制\n编译器会根据变量是否被外部引用来决定是否逃逸：\n\n如果函数外部没有引用，则优先放到栈中；\n如果函数外部存在引用，则必定放到堆中;\n如果栈上放不下，则必定放到堆上;\n\n逃逸分析也就是由编译器决定哪些变量放在栈，哪些放在堆中，通过编译参数 -gcflag=-m 可以查看编译过程中的逃逸分析，发生逃逸的几种场景如下：\n指针逃逸\npackage main\n\nfunc escape1() *int {\n    var a int = 1\n    return &amp;a\n}\n\nfunc main() {\n    escape1()\n}\n\n通过 go build -gcflags=-m main.go 查看逃逸情况：\n./main.go:4:6: moved to heap: a\n\n函数返回值为局部变量的指针，函数虽然退出了，但是因为指针的存在，指向的内存不能随着函数结束而回收，因此只能分配在堆上。\n栈空间不足\npackage main\n\nfunc escape2() {\n    s := make([]int, 0, 10000)\n    for index, _ := range s {\n        s[index] = index\n    }\n}\n\nfunc main() {\n    escape2()\n}\n\n通过 go build -gcflags=-m main.go 查看逃逸情况：\n./main.go:4:11: make([]int, 10000, 10000) escapes to heap\n\n当栈空间足够时，不会发生逃逸，但是当变量过大时，已经完全超过栈空间的大小时，将会发生逃逸到堆上分配内存。局部变量 s 占用内存过大，编译器会将其分配到堆上\n变量大小不确定\npackage main\n\nfunc escape3() {\n    number := 10\n    s := make([]int, number) // 编译期间无法确定slice的长度\n    for i := 0; i &lt; len(s); i++ {\n        s[i] = i\n    }\n}\n\nfunc main() {\n    escape3()\n}\n\n编译期间无法确定 slice 的长度，这种情况为了保证内存的安全，编译器也会触发逃逸，在堆上进行分配内存。直接 s := make([]int, 10) 不会发生逃逸\n动态类型\n动态类型就是编译期间不确定参数的类型、参数的长度也不确定的情况下就会发生逃逸\n空接口 interface{} 可以表示任意的类型，如果函数参数为 interface{}，编译期间很难确定其参数的具体类型，也会发生逃逸。\npackage main\n\nimport &quot;fmt&quot;\n\nfunc escape4() {\n    fmt.Println(1111)\n}\n\nfunc main() {\n    escape4()\n}\n\n通过 go build -gcflags=-m main.go 查看逃逸情况：\n./main.go:4:6: moved to heap: i\n\nFmt.Println (a …interface{})函数参数为 interface，编译器不确定参数的类型，会将变量分配到堆上\n闭包引用对象\npackage main\n\nfunc escape5() func() int {\n    var i int = 1\n    return func() int {\n        i++\n        return i\n    }\n}\n\nfunc main() {\n    escape5()\n}\n\n通过 go build -gcflags=-m main.go 查看逃逸情况：\n./main.go:4:6: moved to heap: i\n\n闭包函数中局部变量 i 在后续函数是继续使用的，编译器将其分配到堆上\n总结\n\n栈上分配内存比在堆中分配内存效率更高\n栈上分配的内存不需要 GC 处理，而堆需要\n逃逸分析目的是决定内分配地址是栈还是堆\n逃逸分析在编译阶段完成\n\n因为无论变量的大小，只要是指针变量都会在堆上分配，所以对于小变量我们还是使用传值效率（而不是传指针）更高一点。\n怎么避免内存逃逸？\n\n不要盲目使用变量指针作为参数，虽然减少了复制，但变量逃逸的开销更大。\n预先设定好 slice 长度，避免频繁超出容量，重新分配。\n一个经验是，指针指向的数据大部分在堆上分配的，请注意。\n\n出现内存逃逸的情况有：\n\n\n发送指针或带有指针的值到 channel，因为编译时候无法知道那个 goroutine 会在 channel 接受数据，编译器无法知道什么时候释放。\n\n\n在一个切片上存储指针或带指针的值。比如[]*string，导致切片内容逃逸，其引用值一直在堆上。\n\n\n切片的 append 导致超出容量，切片重新分配地址，切片背后的存储基于运行时的数据进行扩充，就会在堆上分配。\n\n\n调用接口类型时，接口类型的方法调用是动态调度，实际使用的具体实现只能在运行时确定，如一个接口类型为 io. Reader 的变量 r，对r.Read (b)的调用将导致 r 的值和字节片 b 的后续转义并因此分配到堆上。\n\n\n在方法内把局部变量指针返回，被外部引用，其生命周期大于栈，导致内存溢出。\n\n\nGo 内存对齐机制？\n什么是内存对齐\n为了能让 CPU 可以更快的存取到各个字段，Go 编译器会帮你把 struct 结构体做数据的对齐。所谓的数据对齐，是指内存地址是所存储数据大小（按字节为单位）的整数倍，以便 CPU 可以一次将该数据从内存中读取出来。 编译器通过在结构体的各个字段之间填充一些空白已达到对齐的目的。\n对齐系数\n\n\n不同硬件平台占用的大小和对齐值都可能是不一样的 32 位系统对齐系数是 4，64 位系统对齐系数是 8\n\n\n不同类型的对齐系数也可能不一样，使用 Go 语言中的 unsafe.Alignof 函数可以返回相应类型的对齐系数，对齐系数都符合 2^n 这个规律，最大也不会超过8\n\n\npackage main\n\nimport (\n    &quot;fmt&quot;\n    &quot;unsafe&quot;\n)\n\nfunc main() {\n    fmt.Printf(&quot;bool alignof is %d\\n&quot;, unsafe.Alignof(bool(true)))\n    fmt.Printf(&quot;string alignof is %d\\n&quot;, unsafe.Alignof(string(&quot;a&quot;)))\n    fmt.Printf(&quot;int alignof is %d\\n&quot;, unsafe.Alignof(int(0)))\n    fmt.Printf(&quot;float alignof is %d\\n&quot;, unsafe.Alignof(float64(0)))\n    fmt.Printf(&quot;int32 alignof is %d\\n&quot;, unsafe.Alignof(int32(0)))\n    fmt.Printf(&quot;float32 alignof is %d\\n&quot;, unsafe.Alignof(float32(0)))\n}\n\n\n可以查看到各种类型在 Mac 64 位上的对齐系数如下：\nbool alignof is 1\nstring alignof is 8\nint alignof is 8\nint32 alignof is 4\nfloat32 alignof is 4\nfloat alignof is 8\n\n优点\n\n提高可移植性，有些 CPU 可以访问任意地址上的任意数据，而有些 CPU 只能在特定地址访问数据，因此不同硬件平台具有差异性，这样的代码就不具有移植性，如果在编译时，将分配的内存进行对齐，这就具有平台可以移植性了\n提高内存的访问效率，32 位 CPU 下一次可以从内存中读取 32 位（4 个字节）的数据，64 位 CPU 下一次可以从内存中读取 64 位（8 个字节）的数据，这个长度也称为 CPU 的字长。CPU 一次可以读取 1 个字长的数据到内存中，如果所需要读取的数据正好跨了 1 个字长，那就得花两个 CPU 周期的时间去读取了。因此在内存中存放数据时进行对齐，可以提高内存访问效率。\n\n缺点\n\n存在内存空间的浪费，实际上是空间换时间\n\n结构体对齐\n对齐原则：\n\n结构体变量中成员的偏移量必须是成员大小的整数倍\n整个结构体的地址必须是最大字节的整数倍（结构体的内存占用是 1/4/8/16 byte…)\n\npackage main\n\nimport (\n    &quot;fmt&quot;\n    &quot;runtime&quot;\n    &quot;unsafe&quot;\n)\n\ntype T1 struct {\n    i16  int16 // 2 byte\n    bool bool  // 1 byte\n}\n\ntype T2 struct {\n    i8  int8  // 1 byte\n    i64 int64 // 8 byte\n    i32 int32 // 4 byte\n}\n\ntype T3 struct {\n    i8  int8  // 1 byte\n    i32 int32 // 4 byte\n    i64 int64 // 8 byte\n}\n\nfunc main() {\n    fmt.Println(runtime.GOARCH) // amd64\n\n    t1 := T1{}\n    fmt.Println(unsafe.Sizeof(t1)) // 4 bytes\n\n    t2 := T2{}\n    fmt.Println(unsafe.Sizeof(t2)) // 24 bytes\n\n    t3 := T3{}\n    fmt.Println(unsafe.Sizeof(t3)) // 16 bytes\n}\n\n以 T 1 结构体为例，实际存储数据的只有 3 字节，但实际用了 4 字节，浪费了 1 个字节：\nI 16 并没有直接放在 bool 的后面，而是在 bool 中填充了一个空白后，放到了偏移量为 2 的位置上。如果 i 16 从偏移量为 1 的位置开始占用 2 个字节，根据对齐原则 2：构体变量中成员的偏移量必须是成员大小的整数倍，套用公式 1 % 2 = 1，就不满足对齐的要求，所以 i 16 从偏移量为2的位置开始\n\n以 T 2 结构体为例，实际存储数据的只有 13 字节，但实际用了 24 字节，浪费了 11 个字节：\n\n以 T 3 结构体为例，实际存储数据的只有 13 字节，但实际用了 16 字节，浪费了 3 个字节：\n\nGo GC 实现原理？\n什么是 GC？\n垃圾回收也称为 GC（Garbage Collection），是一种自动内存管理机制。由垃圾收集器以类似守护协程的方式在后台运作，按照既定的策略为用户回收那些不再被使用的对象，释放对应的内存空间\n现代高级编程语言管理内存的方式分为两种：自动和手动，\n\n像 C、C++ 等编程语言使用手动管理内存的方式，工程师编写代码过程中需要主动申请或者释放内存；\n而 PHP、Java 和 Go 等语言使用自动的内存管理系统，有内存分配器和垃圾收集器来代为分配和回收内存，其中垃圾收集器就是我们常说的 GC。\n\n在应用程序中会使用到两种内存，分别为堆（Heap）和栈（Stack），\n\n\nGC 负责回收堆内存，而不负责回收栈中的内存：\n\n\n栈是线程的专用内存，专门为了函数执行而准备的，存储着函数中的局部变量以及调用栈，函数执行完后，编译器可以将栈上分配的内存可以直接释放，不需要通过 GC 来回收。\n\n\n堆是程序共享的内存，需要 GC 进行回收在堆上分配的内存。\n垃圾回收器的执行过程被划分为两个半独立的组件：\n\n赋值器（Mutator）：这一名称本质上是在指代用户态的代码。因为对垃圾回收器而言，用户态的代码仅仅只是在修改对象之间的引用关系，也就是在对象图（对象之间引用关系的一个有向图）上进行操作。\n回收器（Collector）：负责执行垃圾回收的代码。\n\n主流 GC 算法\n目前比较常见的垃圾回收算法有三种：\n\n\n引用计数：为每个对象维护一个引用计数，当引用该对象的对象销毁时，引用计数 -1，当对象引用计数为 0 时回收该对象。\n\n\n代表语言：Python、PHP、Swift\n优点：对象回收快，不会出现内存耗尽或达到某个阈值时才回收。\n缺点：不能很好的处理循环引用，而实时维护引用计数也是有损耗的。\n\n\n\n分代收集：按照对象生命周期长短划分不同的代空间，生命周期长的放入老年代，短的放入新生代，不同代有不同的回收算法和回收频率。\n\n代表语言：Java\n优点：回收性能好\n缺点：算法复杂\n\n\n\n标记-清除：从根变量开始遍历所有引用的对象，标记引用的对象，没有被标记的进行回收。\n\n\n\n- 代表语言：**Golang**（三色标记法）\n- 优点：解决了引用计数的缺点。\n- 缺点：需要 STW，暂时停掉程序运行。 \n\n\n4. 标记-压缩：是在标记清扫算法的基础上做了升级，在第二步”清扫“的同时还会对存活对象进行压缩整合，使得整体空间更为紧凑，从而解决内存碎片问题.\n\n\n半空间复制:\n\n\n分配两片相等大小的空间，称为 fromspace 和 tospace\n每轮只使用 fromspace 空间，以GC作为分水岭划分轮次\nGC时，将fromspace存活对象转移到tospace中，并以此为契机对空间进行压缩整合\n GC后，交换fromspace和tospace，开启新的轮次\n\n\n三色标记法\n此算法是在 Go 1.5 版本开始使用，Go 语言采用的是标记清除算法，并在此基础上使用了三色标记法和混合写屏障技术，GC 过程和其他用户 goroutine 可并发运行，但需要一定时间的 STW\n这里的三色，对应了垃圾回收过程中对象的三种状态：\n\n灰色：对象还在标记队列中等待\n黑色：对象已被标记，gcmarkBits 对应位为 1 （该对象不会在本次 GC 中被回收）\n白色：对象未被标记，gcmarkBits 对应位为 0 （该对象将会在本次 GC 中被清理）\n\n简单概括：\n\n\n标记开始前，将根对象（全局对象、栈上局部变量等）置黑，将其所指向的对象置灰\n\n\n标记规则是，从灰对象出发，将其所指向的对象都置灰. 所有指向对象都置灰后，当前灰对象置黑\n\n\n 标记结束后，白色对象就是不可达的垃圾对象，需要进行清扫.\n\n\n执行的步骤\n\n\nStep 1: 创建：白、灰、黑三个集合\n\n\nStep 2: 将所有对象放入白色集合中\n\n\nStep 3: 遍历所有root 对象，把遍历到的对象从白色集合放入灰色集合 (这里放入灰色集合的都是根节点的对象)\n\n\nStep 4: 遍历灰色集合，将灰色对象引用的对象从白色集合放入灰色集合，自身标记为黑色\n\n\nStep 5: 重复步骤 4，直到灰色中无任何对象，其中用到 2 个机制：\n\n写屏障（Write Barrier）：上面说到的 STW 的目的是防止 GC 扫描时内存变化引起的混乱，而写屏障就是让 goroutine 与 GC 同时运行的手段，虽然不能完全消除 STW，但是可以大大减少 STW 的时间。写屏障在 GC 的特定时间开启，开启后指针传递时会把指针标记，即本轮不回收，下次 GC 时再确定。\n辅助 GC（Mutator Assist）：为了防止内存分配过快，在 GC 执行过程中，GC 过程中 mutator 线程会并发运行，而 mutator assist 机制会协助 GC 做一部分的工作。\n\n\n\n\nStep 6: 收集所有白色对象（垃圾）\n\n并发垃圾回收会遇到的问题\n漏标问题\n\n\n条件：初始时刻，对象 B 持有对象 C 的引用\n moment1：GC协程下，对象A被扫描完成，置黑；此时对象B是灰色，还未完成扫描\n momen2：用户协程下，对象A建立指向对象C的引用\n moment3：用户协程下，对象B删除指向对象C的引用\n moment4：GC 协程下，开始执行对对象 B 的扫描\n\n漏标问题是无法接受，其引起的误删现象可能会导致程序出现致命的错误. 针对漏标问题，Golang 给出的解决方案是屏障机制的使用\n多标问题\n\n\n 条件：初始时刻，对象 A 持有对象 B 的引用\nmoment1：GC协程下，对象A被扫描完成，置黑；对象B被对象A引用，因此被置灰\n momen2：用户协程下，对象 A 删除指向对象 B 的引用\n\n内存碎片\n标记清扫算法会存在产生“内存碎片”的缺陷\nGolang 采用 TCMalloc 机制，依据对象的大小将其归属为到事先划分好的 spanClass 当中，这样能够消解外部碎片的问题，将问题限制在相对可控的内部碎片当中..\n为什么不选择分代垃圾回收机制\nGolang中存在内存逃逸机制，会在编译过程中将生命周期更长的对象转移到堆中，将生命周期短的对象分配在栈上，并以栈为单位对这部分对象进行回收.\nGolang中存在内存逃逸机制，会在编译过程中将生命周期更长的对象转移到堆中，将生命周期短的对象分配在栈上，并以栈为单位对这部分对象进行回收.\nroot 对象\n根对象在垃圾回收的术语中又叫做根集合，它是垃圾回收器在标记过程时最先检查的对象，包括：\n\n全局变量：程序在编译期就能确定的那些存在于程序整个生命周期的变量。\n执行栈：每个 goroutine 都包含自己的执行栈，这些执行栈上指向堆内存的指针。\n寄存器：寄存器的值可能表示一个指针，参与计算的这些指针可能指向某些赋值器分配的堆内存区块。\n\n强弱三色不变式\n漏标问题的本质就是，一个已经扫描完成的黑对象指向了一个被灰\\白对象删除引用的白色对象.\n构成这一场景的要素拆分如下：\n（1）黑色对象指向了白色对象\n（2）灰、白对象删除了白色对象\n（3）（1）、（2）步中谈及的白色对象是同一个对象\n（4）（1）发生在（2）之前\n一套用于解决漏标问题的方法论称之为强弱三色不变式：\n\n\n• 强三色不变式：白色对象不能被黑色对象直接引用（直接破坏（1））\n\n\n• 弱三色不变式：白色对象可以被黑色对象引用，但要从某个灰对象出发仍然可达该白对象（间接破坏了（1）、（2）的联动）\n\n\n插入写屏障\n\n保证当一个黑色对象指向一个白色对象前，会先触发屏障将白色对象置为灰色，再建立引用.\n对象被引用时触发的机制（只在堆内存中生效）：赋值器这一行为通知给并发执行的回收器，被引用的对象标记为灰色\n缺点：结束时需要 STW 来重新扫描栈，标记栈上引用的白色对象的存活\n删除写屏障\n\n保证当一个白色对象即将被上游删除引用前，会触发屏障将其置灰，之后再删除上游指向其的引用.\n对象被删除时触发的机制（只在堆内存中生效）：赋值器将这一行为通知给并发执行的回收器，被删除的对象，如果自身为灰色或者白色，那么标记为灰色\n缺点：一个对象的引用被删除后，即使没有其他存活的对象引用它，它仍然会活到下一轮，会产生很大冗余扫描成本，且降低了回收精度\n混合写屏障\n插入写屏障、删除写屏障二者择其一，即可解决并发GC的漏标问题，至于错标问题，则采用容忍态度，放到下一轮GC中进行延后处理即可.\nGC 没有混合写屏障前，一直是插入写屏障；混合写屏障是插入写屏障 + 删除写屏障，写屏障只应用在堆上应用，栈上不启用（栈上启用成本很高）\n\n\n• GC 开始前，以栈为单位分批扫描，将栈中所有对象置黑\n\n\n• GC 期间，栈上新创建对象直接置黑\n\n\n• 堆对象正常启用插入写屏障\n\n\n• 堆对象正常启用删除写屏障\n\n\nshow case\n（1）case 1：堆对象删除引用，栈对象建立引用\n\n\n背景：存在栈上对象A，黑色（扫描完）；\n\n存在堆上对象B，白色（未被扫描）；\n存在堆上对象C，被堆上对象B引用，白色（未被扫描）\n\n\nmoment1：A建立对C的引用，由于栈无屏障机制，因此正常建立引用，无额外操作\n\n\nmoment2：B尝试删除对C的引用，删除写屏障被触发，C被置灰，因此不会漏标\n\n\n（2）case 2：一个堆对象删除引用，成为另一个堆对象下游\n\n\n• 背景：存在堆上对象A，白色（未被扫描）；\n\n存在堆上对象B，黑色（已完成扫描）；\n存在堆上对象C，被堆上对象B引用，白色（未被扫描）\n\n\n• moment1：B尝试建立对C的引用，插入写屏障被触发，C被置灰\n\n\n• moment2：A删除对C的引用，此时C已置灰，因此不会漏标\n\n\n（3）case 3：栈对象删除引用，成为堆对象下游\n\n\n• 背景：存在栈上对象A，白色（未完成扫描，说明对应的栈未扫描）；\n\n存在堆上对象B，黑色（已完成扫描）；\n存在堆上对象C，被栈上对象A引用，白色（未被扫描）\n\n\n• moment1：B尝试建立对C的引用，插入写屏障被触发，C被置灰\n\n\n• moment2：A删除对C的引用，此时C已置灰，因此不会漏标\n\n\n（4）case 4：一个栈中对象删除引用，另一个栈中对象建立引用\n\n\n• 背景：存在栈上对象A，白色（未扫描，这是因为对应的栈还未开始扫描）；\n\n存在栈上对象B，黑色（已完成扫描，说明对应的栈均已完成扫描）；\n存在堆上对象C，被栈上对象A引用，白色（未被扫描）\n\n\n• moment1：B建立对C的引用；\n\n\n• moment2：A删除对C的引用.\n\n\n• 结论：这种场景下，C要么已然被置灰，要么从某个灰对象触发仍然可达C.\n\n\n• 原因在于，对象的引用不是从天而降，一定要有个来处. 当前 case 中，对象B能建立指向C的引用，至少需要满足如下三个条件之一：\n\n\nI 栈对象B原先就持有C的引用，如若如此，C就必然已处于置灰状态（因为B已是黑色）\nII 栈对象B持有A的引用，通过A间接找到C. 然而这也是不可能的，因为倘若A能同时被另一个栈上的B引用到，那样A必然会升级到堆中，不再满足作为一个栈对象的前提；\nIII B同栈内存在其他对象X可达C，此时从X出发，必然存在一个灰色对象，从其出发存在可达C的路线.\n综上，我们得以证明混合写屏障是能够胜任并发GC场景的解决方案，并且满足栈无须添加屏障的前提.\nGC 流程\n一次完整的垃圾回收会分为四个阶段，分别是标记准备、标记开始、标记终止、清理：\n\n标记准备（Mark Setup）：打开写屏障（Write Barrier），需 STW（stop the world)\n标记开始（Marking）：使用三色标记法并发标记，与用户程序并发执行\n标记终止（Mark Termination）：对触发写屏障的对象进行重新扫描标记，关闭写屏障（Write Barrier），需 STW（stop the world)\n清理（Sweeping）：将需要回收的内存归还到堆中，将过多的内存归还给操作系统，与用户程序并发执行\n\n\nGC 触发时机\n主动触发：\n\n调用 runtime.GC () 方法，触发 GC\n\n被动触发：\n\n定时触发，该触发条件由 runtime.forcegcperiod 变量控制，默认为 2 分钟。当超过两分钟没有产生任何 GC 时，触发 GC\n根据内存分配阈值触发，该触发条件由环境变量 GOGC 控制，默认值为 100（100%），当前堆内存占用是上次 GC 结束后占用内存的 2 倍时，触发 GC\n\nGo GC 如何调优？\n\n控制内存分配的速度，限制 Goroutine 的数量，提高赋值器 mutator 的 CPU 利用率（降低 GC 的 CPU 利用率）\n少量使用 + 连接 string\nSlice 提前分配足够的内存来降低扩容带来的拷贝\n避免 map key 对象过多，导致扫描时间增加\n变量复用，减少对象分配，例如使用 sync. Pool 来复用需要频繁创建临时对象、使用全局变量等\n增大 GOGC 的值，降低 GC 的运行频率\n\nGo 如何查看 GC 信息？\n1. GODEBUG=’gctrace=1’\npackage main\nfunc main() {\n    for n := 1; n &lt; 100000; n++ {\n        _ = make([]byte, 1&lt;&lt;20)\n    }\n}\n\n$ GODEBUG=&#039;gctrace=1&#039; go run main.go\n\ngc 1 @0.003s 4%: 0.013+1.7+0.008 ms clock, 0.10+0.67/1.2/0.018+0.064 ms cpu, 4-&gt;6-&gt;2 MB, 5 MB goal, 8 P\ngc 2 @0.006s 2%: 0.006+4.5+0.058 ms clock, 0.048+0.070/0.027/3.6+0.47 ms cpu, 4-&gt;5-&gt;1 MB, 5 MB goal, 8 P\ngc 3 @0.011s 3%: 0.021+1.3+0.009 ms clock, 0.17+0.041/0.41/0.046+0.072 ms cpu, 4-&gt;6-&gt;2 MB, 5 MB goal, 8 P\ngc 4 @0.013s 5%: 0.025+0.38+0.26 ms clock, 0.20+0.054/0.15/0.009+2.1 ms cpu, 4-&gt;6-&gt;2 MB, 5 MB goal, 8 P\ngc 5 @0.014s 5%: 0.021+0.16+0.002 ms clock, 0.17+0.098/0.028/0.001+0.016 ms cpu, 4-&gt;5-&gt;1 MB, 5 MB goal, 8 P\ngc 6 @0.014s 7%: 0.025+1.6+0.003 ms clock, 0.20+0.061/2.9/1.5+0.025 ms cpu, 4-&gt;6-&gt;2 MB, 5 MB goal, 8 P\ngc 7 @0.016s 7%: 0.019+1.0+0.002 ms clock, 0.15+0.053/1.0/0.018+0.017 ms cpu, 4-&gt;6-&gt;2 MB, 5 MB goal, 8 P\ngc 8 @0.017s 7%: 0.029+0.17+0.002 ms clock, 0.23+0.037/0.10/0.063+0.022 ms cpu, 4-&gt;4-&gt;0 MB, 5 MB goal, 8 P\ngc 9 @0.018s 7%: 0.019+0.23+0.002 ms clock, 0.15+0.040/0.16/0.023+0.018 ms cpu, 4-&gt;5-&gt;1 MB, 5 MB goal, 8 P\ngc 10 @0.018s 7%: 0.022+0.23+0.003 ms clock, 0.17+0.061/0.13/0.006+0.024 ms cpu, 4-&gt;6-&gt;2 MB, 5 MB goal, 8 P\ngc 11 @0.018s 7%: 0.019+0.11+0.001 ms clock, 0.15+0.033/0.051/0.013+0.015 ms cpu, 4-&gt;5-&gt;1 MB, 5 MB goal, 8 P\ngc 12 @0.019s 7%: 0.018+0.19+0.001 ms clock, 0.14+0.035/0.10/0.018+0.014 ms cpu, 4-&gt;5-&gt;1 MB, 5 MB goal, 8 P\ngc 13 @0.019s 7%: 0.018+0.35+0.002 ms clock, 0.15+0.21/0.054/0.013+0.016 ms cpu, 4-&gt;5-&gt;1 MB, 5 MB goal, 8 P\ngc 14 @0.019s 8%: 0.024+0.27+0.002 ms clock, 0.19+0.022/0.13/0.014+0.017 ms cpu, 4-&gt;5-&gt;1 MB, 5 MB goal, 8 P\ngc 15 @0.020s 8%: 0.019+0.42+0.038 ms clock, 0.15+0.060/0.28/0.007+0.31 ms cpu, 4-&gt;17-&gt;13 MB, 5 MB goal, 8 P\ngc 16 @0.021s 8%: 0.018+0.53+0.060 ms clock, 0.14+0.045/0.39/0.005+0.48 ms cpu, 21-&gt;28-&gt;7 MB, 26 MB goal, 8 P\ngc 17 @0.021s 10%: 0.020+0.91+0.64 ms clock, 0.16+0.050/0.36/0.027+5.1 ms cpu, 12-&gt;16-&gt;4 MB, 14 MB goal, 8 P\ngc 18 @0.023s 10%: 0.020+0.55+0.002 ms clock, 0.16+0.053/0.50/0.081+0.023 ms cpu, 7-&gt;9-&gt;2 MB, 8 MB goal, 8 P\n\n字段含义由下表所示：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n字段含义gc 2第二个 GC 周期0.006程序开始后的 0.006 秒2%该 GC 周期中 CPU 的使用率0.006标记开始时， STW 所花费的时间（wall clock）4.5标记过程中，并发标记所花费的时间（wall clock）0.058标记终止时， STW 所花费的时间（wall clock）0.048标记开始时， STW 所花费的时间（cpu time）0.070标记过程中，标记辅助所花费的时间（cpu time）0.027标记过程中，并发标记所花费的时间（cpu time）3.6标记过程中，GC 空闲的时间（cpu time）0.47标记终止时， STW 所花费的时间（cpu time）4标记开始时，堆的大小的实际值5标记结束时，堆的大小的实际值1标记结束时，标记为存活的对象大小5标记结束时，堆的大小的预测值8P 的数量\n2. Go tool trace\npackage main\n\nimport (\n    &quot;os&quot;\n    &quot;runtime/trace&quot;\n)\n\nfunc main() {\n    f, _ := os.Create(&quot;trace.out&quot;)\n    defer f.Close()\n    trace.Start(f)\n    defer trace.Stop()\n    for n := 1; n &lt; 100000; n++ {\n        _ = make([]byte, 1&lt;&lt;20)\n    }\n}\n\n$ go run main.go\n$ go tool trace trace.out\n\n打开浏览器后，可以看到如下统计：\n\n点击 View trace，可以查看当时的 trace 情况\n\n点击 Minimum mutator utilization，可以查看到赋值器 mutator （用户程序）对 CPU 的利用率 74.1%，接近 100%则代表没有针对 GC 的优化空间了\n\n3. Debug. ReadGCStats\npackage main\n\nimport (\n    &quot;fmt&quot;\n    &quot;runtime/debug&quot;\n    &quot;time&quot;\n)\n\nfunc printGCStats() {\n    t := time.NewTicker(time.Second)\n    s := debug.GCStats{}\n    for {\n        select {\n        case &lt;-t.C:\n            debug.ReadGCStats(&amp;s)\n            fmt.Printf(&quot;gc %d last@%v, PauseTotal %v\\n&quot;, s.NumGC, s.LastGC, s.PauseTotal)\n        }\n    }\n}\nfunc main() {\n    go printGCStats()\n    for n := 1; n &lt; 100000; n++ {\n        _ = make([]byte, 1&lt;&lt;20)\n    }\n}\n\n$ go run main.go\n\ngc 3392 last@2022-05-04 19:22:52.877293 +0800 CST, PauseTotal 117.524907ms\ngc 6591 last@2022-05-04 19:22:53.876837 +0800 CST, PauseTotal 253.254996ms\ngc 10028 last@2022-05-04 19:22:54.87674 +0800 CST, PauseTotal 376.981595ms\ngc 13447 last@2022-05-04 19:22:55.87689 +0800 CST, PauseTotal 511.420111ms\ngc 16938 last@2022-05-04 19:22:56.876955 +0800 CST, PauseTotal 649.293449ms\ngc 20350 last@2022-05-04 19:22:57.876756 +0800 CST, PauseTotal 788.003014ms\n\n字段含义由下表所示：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n字段含义NumGCGC 总次数LastGC上次 GC 时间PauseTotalSTW 总耗时\n4. Runtime. ReadMemStats\npackage main\n\nimport (\n    &quot;fmt&quot;\n    &quot;runtime&quot;\n    &quot;time&quot;\n)\n\nfunc printMemStats() {\n    t := time.NewTicker(time.Second)\n    s := runtime.MemStats{}\n    for {\n        select {\n        case &lt;-t.C:\n            runtime.ReadMemStats(&amp;s)\n            fmt.Printf(&quot;gc %d last@%v, heap_object_num: %v, heap_alloc: %vMB, next_heap_size: %vMB\\n&quot;,\n                s.NumGC, time.Unix(int64(time.Duration(s.LastGC).Seconds()), 0), s.HeapObjects, s.HeapAlloc/(1&lt;&lt;20), s.NextGC/(1&lt;&lt;20))\n        }\n    }\n}\nfunc main() {\n    go printMemStats()\n    fmt.Println(1 &lt;&lt; 20)\n    for n := 1; n &lt; 100000; n++ {\n        _ = make([]byte, 1&lt;&lt;20)\n    }\n}\n\n\n$ go run main.go\n\ngc 2978 last@2022-05-04 19:38:04 +0800 CST, heap_object_num: 391, heap_alloc: 20MB, next_heap_size: 28MB\ngc 5817 last@2022-05-04 19:38:05 +0800 CST, heap_object_num: 370, heap_alloc: 4MB, next_heap_size: 4MB\ngc 9415 last@2022-05-04 19:38:06 +0800 CST, heap_object_num: 392, heap_alloc: 7MB, next_heap_size: 8MB\ngc 11429 last@2022-05-04 19:38:07 +0800 CST, heap_object_num: 339, heap_alloc: 4MB, next_heap_size: 5MB\ngc 14706 last@2022-05-04 19:38:08 +0800 CST, heap_object_num: 436, heap_alloc: 6MB, next_heap_size: 8MB\ngc 18253 last@2022-05-04 19:38:09 +0800 CST, heap_object_num: 375, heap_alloc: 4MB, next_heap_size: 6M\n\n字段含义由下表所示：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n字段含义NumGCGC 总次数LastGC上次 GC 时间HeapObjects堆中已经分配的对象总数，GC 内存回收后 HeapObjects 取值相应减小HeapAlloc堆中已经分配给对象的字节数，GC 内存回收后 HeapAlloc 取值相应减小NextGC下次 GC 目标堆的大小"},"GO/八股文/并发":{"title":"并发","links":["GO/八股文/Channel","GO/八股文/Mutex和RWMutex","GO/八股文/Map-和Sync.map","GO/八股文/Context"],"tags":["GO/八股文"],"content":"go 语言怎么支持的并发请求\nGo 中有 goroutine，所以可以采用多协程来解决并发问题。Accept 连接后，将连接丢给 goroutine 处理后续的读写操作。在开发者看到的这个 goroutine 中业务逻辑是同步的，也不用考虑 IO 是否阻塞。\nGolang 的协程通信有哪些方式\n1）共享内存\n\n共享内存是指多个协程直接访问共享变量的方式，这种方式不需要显式地进行通信，但需要考虑并发访问时的竞态问题，需要使用互斥锁等机制来确保同步和一致性。\n\n2）通道\n\n通道是 Go 语言中一个重要的并发原语，它是一种线程安全的、带缓冲的 FIFO 队列。通道支持阻塞式读写，可以用来在不同的协程之间传递数据，也可以用来进行同步操作。通道在多个协程之间传递数据时，会自动进行同步，不需要程序员显式地进行加锁和解锁操作。\n\n3）选择器\n\n选择器是 Go 语言中的一种控制结构，可以同时监听多个通道的操作，并选择其中一个可以进行操作的通道。选择器可以用来实现非阻塞的通信操作，避免了因等待某个通道操作而导致的阻塞。选择器通常与通道配合使用，用于多个协程之间的协作和同步。\n\n4）条件变量（Cond）\n\n条件变量用于在协程之间进行复杂的通信和协调。在 Go 中，可以使用 sync 包中的 Cond 类型来实现条件变量。它通常与互斥锁一起使用，以便协程可以在特定条件下等待或被唤醒。\n\n5）原子操作（Atomic Operations）\n\nGo 语言提供了 sync/atomic 包，用于执行原子操作，这些操作通常用于共享资源的更新，以避免竞态条件。原子操作可以用于对变量的读取、写入、加法等操作，而不需要额外的锁定。\n\n总之，Go 协程之间的通信是非常重要的，不同的应用场景需要选择不同的通信方式，以确保程序的正确性和性能。共享内存通常用于需要高性能的并发场景，但需要注意线程安全和同步问题；通道是一种简单、安全、高效的通信方式，适用于大多数并发场景；选择器则适用于多通道协作和同步的场景。\nGo 常用的并发模型？\n并发模型说的是系统中的线程如何协作完成并发任务，不同的并发模型，线程以不同的方式进行通信和协作。\n线程间通信方式\n线程间通信方式有两种：共享内存和消息传递，无论是哪种通信模型，线程或者协程最终都会从内存中获取数据，所以更为准确的说法是直接共享内存、发送消息的方式来同步信息\n共享内存\n抽象层级：抽象层级低，当我们遇到对资源进行更细粒度的控制或者对性能有极高要求的场景才应该考虑抽象层级更低的方法\n耦合：高，线程需要在读取或者写入数据时先获取保护该资源的互斥锁\n线程竞争：需要加锁，才能避免线程竞争和数据冲突\n发送消息\n抽象层级：抽象层级高，提供了更良好的封装和与领域更相关和契合的设计，比如 Go 语言中的 Channel 就提供了 Goroutine 之间用于传递信息的方式，它在内部实现时就广泛用到了共享内存和锁，通过对两者进行的组合提供了更高级的同步机制\n耦合：低，生产消费者模型\n线程竞争：保证同一时间只有一个活跃的线程能够访问数据，channel 维护所有被该 chanel 阻塞的协程，保证有资源的时候只唤醒一个协程，从而避免竞争\nGo 语言中实现了两种并发模型，一种是共享内存并发模型，另一种则是 CSP 模型。\n共享内存并发模型\n通过直接共享内存 + 锁的方式同步信息，传统多线程并发\n\nCSP 并发模型\n通过发送消息的方式来同步信息，Go 语言推荐使用的_通信顺序进程_（communicating sequential processes）并发模型，通过 goroutine 和 channel 来实现\n\ngoroutine 是 Go 语言中并发的执行单位，可以理解为”线程“\nchannel 是 Go 语言中各个并发结构体 (goroutine)之前的通信机制。通俗的讲，就是各个 goroutine 之间通信的”管道“，类似于 Linux 中的管道\n\n\nGo 为啥使用 CSP 模型来实现并发?\nGo 语言使用 CSP（Communicating Sequential Processes，通信顺序进程）模型来实现并发，这是由 Go 语言设计者选择的一种并发模型，有以下几个重要的原因：\n\n简单性和清晰性：CSP 模型提供了一种清晰且直观的方式来表达并发程序。它基于协程之间的通信来进行协作，通过通道（channel）进行消息传递，使得并发程序的结构和逻辑更加简单和可读。\n避免共享状态：CSP 模型强调避免共享状态，而是通过通信共享数据。共享状态是许多并发程序中的错误和难点来源之一，而 CSP 模型可以减少竞态条件（race condition）等问题的出现。\n安全性：Go 的 CSP 模型通过通道提供了一种安全的并发机制。通道的发送和接收操作都是原子的，不需要额外的锁定，因此减少了程序中出现的锁定问题，如死锁和竞态条件。\n可扩展性：CSP 模型可以轻松扩展到大量的协程，因为通道和协程的创建成本相对较低。这使得 Go 非常适合构建高并发的系统，如 Web 服务器、分布式系统和网络服务。\n编译器和运行时支持：Go 编译器和运行时系统针对 CSP 模型进行了优化。Go 的并发原语在语言级别得到支持，而不是通过库的方式实现，这使得并发编程更加容易。\n\n总之，Go 选择 CSP 模型是为了提供一种简单、安全、高效和可扩展的并发编程模型，以便开发者能够更轻松地构建并发程序，同时避免共享状态和典型的并发问题。这使得 Go 成为了一个流行的选择，特别适用于需要高度并发性能的应用程序和系统。\n有没有什么线程安全的办法？\n在 Go 语言中，线程安全一般指协程安全，因为 Go 一般使用协程进行调度；而 Go 中为了保证其协程安全，有以下几种机制：\n1、互斥锁：在 Go 的标准库中有 sync 包，sync. Mutex 就是解决并发冲突导致的安全性问题的一种方式。\n2、读写锁：是在互斥锁上的进一步升级版本，主要为了解决并发多写少读、少写多读两种高并发的情况\n3、如果不是需要强制使用同一个对象，那么也可以采用创建对象副本的方式，每个协程独占一个对象，相互之间不关联，但是这显然不符合我们的要求。\n综上，使用互斥锁或者读写锁就能很好的解决问题。\nselect 可以用于什么\nGo 的通道有两种操作方式，一种是带 range 子句的 for 语句，另一种则是 select 语句，它是专门为了操作通道而存在的。这里主要介绍 select 的用法。\nSelect 的语法如下：\nselect {\n   case &lt;-ch1 :\n     statement(s)   \n   case ch2 &lt;- 1 :\n      statement(s)\n    …\n   default : /* 可选 */\n      statement(s)\n}\n\n这里要注意：\n\n每个 case 都必须是一个通信。由于 select 语句是专为通道设计的，所以每个 case 表达式中都只能包含操作通道的表达式，比如接收表达式。\n如果有多个 case 都可以运行，select 会随机公平地选出一个执行，其他不会执行。\n如果多个 case 都不能运行，若有 default 子句，则执行该语句，反之，select 将阻塞，直到某个 case 可以运行。\n所有 channel 表达式都会被求值。\nSelect 机制⽤来处理异步 IO 问题。\nSelect 机制最⼤的⼀条限制就是每个 case 语句⾥必须是⼀个 IO 操作。\n\n实例\npackage main\n\nimport (\n    &quot;fmt&quot;\n    &quot;math/rand&quot;\n)\n\nfunc main() {\n    // 准备好几个通道。\n    intChannels := [5]chan int{\n        make(chan int, 1),\n        make(chan int, 1),\n        make(chan int, 1),\n        make(chan int, 1),\n        make(chan int, 1)，\n    }\n    // 随机选择一个通道，并向它发送元素值。\n    index := rand.Intn(5)\n    fmt.Printf(&quot;The index: %d&quot;, index)\n    intChannels[index] &lt;- index\n    // 哪一个通道中有可取的元素值，哪个对应的分支就会被执行。\n    select {\n        case &lt;-intChannels[0]:\n            fmt.Println(&quot;The first candidate case is selected.&quot;)\n        case &lt;-intChannels[1]:\n            fmt.Println(&quot;The second candidate case is selected.&quot;)\n        case elem := &lt;-intChannels[2]:\n            fmt.Printf(&quot;The third candidate case is selected. The element is %d.&quot;, elem)\n        default:\n            fmt.Println(&quot;No candidate case is selected!&quot;)\n    }\n}\n\nselect 死锁\nSelect 使用不当会发生死锁。如果通道没有数据发送，但 select 中有存在接收通道数据的语句，将发生死锁。\nfunc main() {  \n        ch := make(chan string)\n        select {\n            case &lt;-ch:\n        }\n}\n/*\nfatal error: all goroutines are asleep - deadlock!\ngoroutine 1 [chan receive]:\nmain.main()\n/workspace/src/test.go:5 +0x52\nexit status 2\n*/\n//可以添加 default 语句来避免产生死锁。\n\n空 select{}\n对于空的 select 语句，程序会被阻塞，确切的说是当前协程被阻塞，同时 Go 自带死锁检测机制，当发现当前协程再也没有机会被唤醒时，则会发生 panic。所以上述程序会 panic。\nfunc main() {  \n        select {}\n}\n\n/*\nfatal error: all goroutines are asleep - deadlock!\ngoroutine 1 [select (no cases)]:\nmain.main()\n\t/workspace/src/test.go:3 +0x20\nexit status 2\n*/\n\nselect 和 for 结合使用\nSelect 语句只能对其中的每一个 case 表达式各求值一次。所以，如果想连续或定时地操作其中的通道的话，就需要通过在 for 语句中嵌入 select 语句的方式实现。\nfunc main() {\n    tick := time.Tick(time.Second)\n    for {\n        select {\n            case t := &lt;-tick:\n                fmt.Println(t)\n                break\n            }\n    }\n    fmt.Println(&quot;end&quot;)\n}\n\n你会发现 break 只跳出了 select，无法跳出 for。解决办法有两种：\n使用 goto 跳出循环\nfunc main() {\n    tick := time.Tick(time.Second)\n    for {\n        select {\n            case t := &lt;-tick:\n                fmt.Println(t)\n                //跳到指定位置\n                goto END\n            }\n        }\nEND:\n        fmt.Println(&quot;end&quot;)\n    }\n\n使用标签\nfunc main() {\n    tick := time.Tick(time.Second)\n//这是标签\nFOREND:\n    for {\n        select {\n            case t := &lt;-tick:\n                fmt.Println(t)\n                //跳出FOREND标签\n                break ForEnd\n            }\n        }\nEND:\n        fmt.Println(&quot;end&quot;)\n    }\n\nselect 实现超时机制\n主要使用的 time. After 实现超时控制。\nfunc main() {\n    ch := make(chan int)\n    quit := make(chan bool)\n\n    go func() {\n        for {\n            select {\n                case num := &lt;-ch:  //如果有数据，下面打印。但是有可能ch一直没数据\n                 fmt.Println(&quot;num = &quot;, num)\n                case &lt;-time.After(3 * time.Second): //上面的ch如果一直没数据会阻塞，那么select也会检测其他case条件，检测到后3秒超时\n                 fmt.Println(&quot;超时&quot;)\n                 quit &lt;- true  //写入\n            }\n        }\n\n    }()\n\n    for i := 0; i &lt; 5; i++ {\n        ch &lt;- i\n        time.Sleep(time.Second)\n    }\n    &lt;-quit //这里暂时阻塞，直到可读\n    fmt.Println(&quot;程序结束&quot;)\n}\n\n执行后，可以观察到：依次打印出 0-4，几秒过后打印出“超时”和“程序结束”，打印结果如下：\nnum =  0\nnum =  1\nnum =  2\nnum =  3\nnum =  4\n超时\n程序结束\n\nSelect 底层原理\nselect 的底层原理：Go select使用与底层原理 \n\n每一个 case 对应的 channl 都会被封装到一个结构体中；\n当第一次执行到 select 时，会锁住所有的 channl 并且，打乱 case 结构体的顺序；\n按照打乱的顺序遍历，如果有就绪的信号，就直接走对应 case 的代码段，之后跳出 select；\n如果没有就绪的代码段，但是有 default 字段，那就走 default 的代码段，之后跳出 select；\n如果没有 default，那就将当前 goroutine 加入所有 channl 的对应等待队列；\n当某一个等待队列就绪时，再次锁住所有的 channl，遍历一遍，将所有等待队列中的 goroutine 取出，之后执行就绪的代码段，跳出select。\n\n数据结构\n每一个 case 对应的数据结构如下：\ntype scase struct {\n    c           *hchan         // chan\n    elem        unsafe.Pointer // 读或者写的缓冲区地址\n    kind        uint16   //case语句的类型，是default、传值写数据(channel &lt;-) 还是  取值读数据(&lt;- channel)\n    pc          uintptr // race pc (for race detector / msan)\n    releasetime int64\n}\n\nGo 有哪些并发同步原语？\nGo 是一门以并发编程见长的语言，它提供了一系列的同步原语方便开发者使用\n\n原子操作\nMutex、RWMutex 等并发原语的底层实现是通过 atomic 包中的一些原子操作来实现的，原子操作是最基础的并发原语. Go atomic 包是最轻量级的锁（也称无锁结构），可以在不形成临界区和创建互斥量的情况下完成并发安全的值替换操作，不过这个包只支持 int 32/int 64/uint 32/uint 64/uintptr 这几种数据类型的一些基础操作（增减、交换、载入、存储等）\n概念\n原子操作仅会由一个独立的 CPU 指令代表和完成。原子操作是无锁的，常常直接通过 CPU 指令直接实现。事实上，其它同步技术的实现常常依赖于原子操作。\n使用场景\n当我们想要对某个变量并发安全的修改，除了使用官方提供的 mutex，还可以使用 sync/atomic 包的原子操作，它能够保证对变量的读取或修改期间不被其他的协程所影响。\nAtomic 包提供的原子操作能够确保任一时刻只有一个 goroutine 对变量进行操作，善用 atomic 能够避免程序中出现大量的锁操作。\npackage main\n\nimport (\n    &quot;fmt&quot;\n    &quot;sync/atomic&quot;\n)\n\nvar opts int64 = 0\n\nfunc main() {\n    add(&amp;opts, 3)\n    load(&amp;opts)\n    compareAndSwap(&amp;opts, 3, 4)\n    swap(&amp;opts, 5)\n    store(&amp;opts, 6)\n}\n\nfunc add(addr *int64, delta int64) {\n    atomic.AddInt64(addr, delta) //加操作\n    fmt.Println(&quot;add opts: &quot;, *addr)\n}\n\nfunc load(addr *int64) {\n    fmt.Println(&quot;load opts: &quot;, atomic.LoadInt64(&amp;opts))\n}\n\nfunc compareAndSwap(addr *int64, oldValue int64, newValue int64) {\n    if atomic.CompareAndSwapInt64(addr, oldValue, newValue) {\n        fmt.Println(&quot;cas opts: &quot;, *addr)\n        return\n    }\n}\n\nfunc swap(addr *int64, newValue int64) {\n    atomic.SwapInt64(addr, newValue)\n    fmt.Println(&quot;swap opts: &quot;, *addr)\n}\n\nfunc store(addr *int64, newValue int64) {\n    atomic.StoreInt64(addr, newValue)\n    fmt.Println(&quot;store opts: &quot;, *addr)\n}\n\n常见操作\n\n增减 Add\n载入 Load\n比较并交换 CompareAndSwap\n交换 Swap\n存储 Store\n\nAtomic 操作的对象是一个地址，你需要把可寻址的变量的地址作为参数传递给方法，而不是把变量的值传递给方法\n下面将分别介绍这些操作：\n增减操作\n此类操作的前缀为 Add\nfunc AddInt32(addr *int32, delta int32) (new int32)\n\nfunc AddInt64(addr *int64, delta int64) (new int64)\n\nfunc AddUint32(addr *uint32, delta uint32) (new uint32)\n\nfunc AddUint64(addr *uint64, delta uint64) (new uint64)\n\nfunc AddUintptr(addr *uintptr, delta uintptr) (new uintptr)\n\n需要注意的是，第一个参数必须是指针类型的值，通过指针变量可以获取被操作数在内存中的地址，从而施加特殊的 CPU 指令，确保同一时间只有一个 goroutine 能够进行操作。\n使用举例：\nfunc add(addr *int64, delta int64) {\n    atomic.AddInt64(addr, delta) //加操作\n    fmt.Println(&quot;add opts: &quot;, *addr)\n}\n\n载入操作\n此类操作的前缀为 Load\nfunc LoadInt32(addr *int32) (val int32)\n\nfunc LoadInt64(addr *int64) (val int64)\n\nfunc LoadPointer(addr *unsafe.Pointer) (val unsafe.Pointer)\n\nfunc LoadUint32(addr *uint32) (val uint32)\n\nfunc LoadUint64(addr *uint64) (val uint64)\n\nfunc LoadUintptr(addr *uintptr) (val uintptr)\n\n// 特殊类型： Value类型，常用于配置变更\nfunc (v *Value) Load() (x interface{}) {}\n\n载入操作能够保证原子的读变量的值，当读取的时候，任何其他 CPU 操作都无法对该变量进行读写，其实现机制受到底层硬件的支持。\n使用示例:\nfunc load(addr *int64) {\n    fmt.Println(&quot;load opts: &quot;, atomic.LoadInt64(&amp;opts))\n}\n\n比较并交换\n此类操作的前缀为 CompareAndSwap, 该操作简称 CAS，可以用来实现乐观锁\nfunc CompareAndSwapInt32(addr *int32, old, new int32) (swapped bool)\n\nfunc CompareAndSwapInt64(addr *int64, old, new int64) (swapped bool)\n\nfunc CompareAndSwapPointer(addr *unsafe.Pointer, old, new unsafe.Pointer) (swapped bool)\n\nfunc CompareAndSwapUint32(addr *uint32, old, new uint32) (swapped bool)\n\nfunc CompareAndSwapUint64(addr *uint64, old, new uint64) (swapped bool)\n\nfunc CompareAndSwapUintptr(addr *uintptr, old, new uintptr) (swapped bool)\n\n该操作在进行交换前首先确保变量的值未被更改，即仍然保持参数 old 所记录的值，满足此前提下才进行交换操作。CAS 的做法类似操作数据库时常见的乐观锁机制。\n需要注意的是，当有大量的 goroutine 对变量进行读写操作时，可能导致 CAS 操作无法成功，这时可以利用 for 循环多次尝试。\n使用示例：\nfunc compareAndSwap(addr *int64, oldValue int64, newValue int64) {\n    if atomic.CompareAndSwapInt64(addr, oldValue, newValue) {\n        fmt.Println(&quot;cas opts: &quot;, *addr)\n        return\n    }\n}\n\n交换\n此类操作的前缀为 Swap：\nfunc SwapInt32(addr *int32, new int32) (old int32)\n\nfunc SwapInt64(addr *int64, new int64) (old int64)\n\nfunc SwapPointer(addr *unsafe.Pointer, new unsafe.Pointer) (old unsafe.Pointer)\n\nfunc SwapUint32(addr *uint32, new uint32) (old uint32)\n\nfunc SwapUint64(addr *uint64, new uint64) (old uint64)\n\nfunc SwapUintptr(addr *uintptr, new uintptr) (old uintptr)\n\n相对于 CAS，明显此类操作更为暴力直接，并不管变量的旧值是否被改变，直接赋予新值然后返回背替换的值。\nfunc swap(addr *int64, newValue int64) {\n    atomic.SwapInt64(addr, newValue)\n    fmt.Println(&quot;swap opts: &quot;, *addr)\n}\n\n存储\n此类操作的前缀为 Store：\nfunc StoreInt32(addr *int32, val int32)\n\nfunc StoreInt64(addr *int64, val int64)\n\nfunc StorePointer(addr *unsafe.Pointer, val unsafe.Pointer)\n\nfunc StoreUint32(addr *uint32, val uint32)\n\nfunc StoreUint64(addr *uint64, val uint64)\n\nfunc StoreUintptr(addr *uintptr, val uintptr)\n\n// 特殊类型： Value类型，常用于配置变更\nfunc (v *Value) Store(x interface{})\n\n此类操作确保了写变量的原子性，避免其他操作读到了修改变量过程中的脏数据。\nfunc store(addr *int64, newValue int64) {\n    atomic.StoreInt64(addr, newValue)\n    fmt.Println(&quot;store opts: &quot;, *addr)\n}\n\nGo 原子操作和锁的区别？\n\n原子操作由底层硬件支持，而锁是基于原子操作+信号量完成的。若实现相同的功能，前者通常会更有效率\n原子操作是单个指令的互斥操作；互斥锁/读写锁是一种数据结构，可以完成临界区（多个指令）的互斥操作，扩大原子操作的范围\n原子操作是无锁操作，属于乐观锁；说起锁的时候，一般属于悲观锁\n原子操作存在于各个指令/语言层级，比如“机器指令层级的原子操作”，“汇编指令层级的原子操作”，“Go 语言层级的原子操作”等。\n锁也存在于各个指令/语言层级中，比如“机器指令层级的锁”，“汇编指令层级的锁”，“Go 语言层级的锁”等\n\nChannel\nChannel\nchannel 管道，高级同步原语，goroutine 之间通信的桥梁\n使用场景：消息队列、数据传递、信号通知、任务编排、锁\npackage main\n\nimport (\n    &quot;fmt&quot;\n    &quot;time&quot;\n)\n\nfunc main() {\n    c := make(chan struct{}, 1)\n    for i := 0; i &lt; 10; i++ {\n        go func() {\n            c &lt;- struct{}{}\n            time.Sleep(1 * time.Second)\n            fmt.Println(&quot;通过ch访问临界区&quot;)\n            &lt;-c\n        }()\n    }\n    for {\n    }\n}\n\n基本并发原语\nGo 语言在 sync 包中提供了用于同步的一些基本原语，这些基本原语提供了较为基础的同步功能，但是它们是一种相对原始的同步机制，在多数情况下，我们都应该使用抽象层级更高的 Channel 实现同步。\n常见的并发原语如下：sync.Mutex、sync.RWMutex、sync.WaitGroup、sync.Cond、sync.Once、sync.Pool、sync.Context\nsync. Mutex\nMutex和RWMutex\nsync.Mutex （互斥锁） 可以限制对临界资源的访问，保证只有一个 goroutine 访问共享资源\n使用场景：大量读写，比如多个 goroutine 并发更新同一个资源，像计数器\npackage main\n\nimport (\n    &quot;fmt&quot;\n    &quot;sync&quot;\n)\n\nfunc main() {\n    // 封装好的计数器\n    var counter Counter\n    var wg sync.WaitGroup\n    var gNum = 1000\n    wg.Add(gNum)\n    // 启动10个goroutine\n    for i := 0; i &lt; gNum; i++ {\n        go func() {\n            defer wg.Done()\n            counter.Incr() // 受到锁保护的方法\n        }()\n    }\n    wg.Wait()\n    fmt.Println(counter.Count())\n}\n\n// 线程安全的计数器类型\ntype Counter struct {\n    mu    sync.Mutex\n    count uint64\n}\n\n// 加1的方法，内部使用互斥锁保护\nfunc (c *Counter) Incr() {\n    c.mu.Lock()\n    c.count++\n    c.mu.Unlock()\n}\n\n// 得到计数器的值，也需要锁保护\nfunc (c *Counter) Count() uint64 {\n    c.mu.Lock()\n    defer c.mu.Unlock()\n    return c.count\n}\n\nsync. RWMutex\nMutex和RWMutex\nsync.RWMutex （读写锁） 可以限制对临界资源的访问，保证只有一个 goroutine 写共享资源，可以有多个 goroutine 读共享资源\n使用场景：大量并发读，少量并发写，有强烈的性能要求\npackage main\n\nimport (\n    &quot;fmt&quot;\n    &quot;sync&quot;\n    &quot;time&quot;\n)\n\nfunc main() {\n    // 封装好的计数器\n    var counter Counter\n    var gNum = 1000\n    // 启动10个goroutine\n    for i := 0; i &lt; gNum; i++ {\n        go func() {\n            counter.Count() // 受到锁保护的方法\n        }()\n    }\n    for { // 一个writer\n        counter.Incr() // 计数器写操作\n        fmt.Println(&quot;incr&quot;)\n        time.Sleep(time.Second)\n    }\n}\n\n// 线程安全的计数器类型\ntype Counter struct {\n    mu    sync.RWMutex\n    count uint64\n}\n\n// 加1的方法，内部使用互斥锁保护\nfunc (c *Counter) Incr() {\n    c.mu.Lock()\n    c.count++\n    c.mu.Unlock()\n}\n\n// 得到计数器的值，也需要锁保护\nfunc (c *Counter) Count() uint64 {\n    c.mu.RLock()\n    defer c.mu.RUnlock()\n    return c.count\n}\n\nsync. WaitGroup\nsync.WaitGroup 可以等待一组 Goroutine 的返回\n// A WaitGroup must not be copied after first use.\ntype WaitGroup struct {\n noCopy noCopy\n state1 [3]uint32\n}\n\n底层数据结构\n其中 noCopy 是 golang 源码中检测禁止拷贝的技术。如果程序中有 WaitGroup 的赋值行为，使用 go vet 检查程序时，就会发现有报错。但需要注意的是，noCopy 不会影响程序正常的编译和运行。\nstate 1 主要是存储着状态和信号量，状态维护了 2 个计数器，一个是请求计数器 counter ，另外一个是等待计数器 waiter（已调用 WaitGroup. Wait 的 goroutine 的个数）\n当数组的首地址是处于一个 8 字节对齐的位置上时，那么就将这个数组的前 8 个字节作为 64 位值使用表示状态，后 4 个字节作为 32 位值表示信号量 (semaphore)；同理如果首地址没有处于 8 字节对齐的位置上时，那么就将前 4 个字节作为 semaphore，后 8 个字节作为 64 位数值。\n\n使用场景\n并发等待，任务编排，一个比较常见的使用场景是批量发出 RPC 或者 HTTP 请求\n使用方法\n在 WaitGroup 里主要有 3 个方法：\n\nWaitGroup.Add ()：可以添加或减少请求的 goroutine 数量，Add (n) 将会导致 counter += n\nWaitGroup.Done ()：相当于 Add (-1)，Done () 将导致 counter -=1，请求计数器 counter 为 0 时通过信号量调用 runtime_Semrelease 唤醒 waiter 线程\nWaitGroup.Wait ()：会将 waiter++，同时通过信号量调用 runtime_Semacquire (semap) 阻塞当前 goroutine\n\nfunc main() {\n    var wg sync.WaitGroup\n    for i := 1; i &lt;= 5; i++ {\n        wg.Add(1)\n        go func() {\n            defer wg.Done()\n            println(&quot;hello&quot;)\n        }()\n    }\n\n    wg.Wait()\n}\n\nWaitGroup 的坑\n\nAdd 一个负数\n\n\n如果计数器的值小于 0 会直接 panic\n\n\nAdd 在 Wait 之后调用\n\n\n比如一些子协程开头调用 Add 结束调用 Wait，这些 Wait 无法阻塞子协程。正确做法是在开启子协程之前先 Add 特定的值。\n\n\n未置为 0 就重用\n\n\nWaitGroup 可以完成一次编排任务，计数值降为 0 后可以继续被其他任务所用，但是不要在还没使用完的时候就用于其他任务，这样由于带着计数值，很可能出问题。\n\n\n复制 waitgroup\n\n\nWaitGroup 有 nocopy 字段，不能被复制。也意味着 WaitGroup 不能作为函数的参数。\n\n深入理解 sync. Waitgroup\njuejin.cn/post/7181812988461252667 \nWaitGroup 内部通过一个计数器来统计有多少协程被等待。\n\n这个计数器的值在我们启动 goroutine 之前先写入（使用 Add 方法），\n然后在 goroutine 结束的时候，将这个计数器减 1（使用 Done 方法）。\n除此之外，在启动这些 goroutine 的协程中，会调用 Wait 来进行等待，在 Wait 调用的地方会阻塞，直到 WaitGroup 内部的计数器减到 0。 也就实现了等待一组 goroutine 的目的\n\nsync. Cond\nsync.Cond 可以让一组的 Goroutine 都在满足特定条件时被唤醒, Go 标准库提供了 Cond 原语\ntype Cond struct {\n    noCopy noCopy\n\n    // L is held while observing or changing the condition\n    L Locker\n\n    notify  notifyList\n    checker copyChecker\n}\n\ntype notifyList struct {\n    wait   uint32\n    notify uint32\n    lock   uintptr // key field of the mutex\n    head   unsafe.Pointer\n    tail   unsafe.Pointer\n}\n\n底层数据结构\n主要有 4 个字段：\n\nnocopy ： golang 源码中检测禁止拷贝的技术。如果程序中有 WaitGroup 的赋值行为，使用 go vet 检查程序时，就会发现有报错，但需要注意的是，noCopy 不会影响程序正常的编译和运行\nchecker：用于禁止运行期间发生拷贝，双重检查 (Double check)\nL：可以传入一个读写锁或互斥锁，当修改条件或者调用 Wait 方法时需要加锁\nnotify：通知链表，调用 Wait () 方法的 Goroutine 会放到这个链表中，从这里获取需被唤醒的 Goroutine 列表\n\n使用场景\n利用等待 / 通知机制实现阻塞或者唤醒\n使用方法\n在 Cond 里主要有 3 个方法：\n\nsync.NewCond (l Locker): 新建一个 sync. Cond 变量，注意该函数需要一个 Locker 作为必填参数，这是因为在 cond.Wait () 中底层会涉及到 Locker 的锁操作\nCond.Wait (): 阻塞等待被唤醒，调用 Wait 函数前需要先加锁；并且由于 Wait 函数被唤醒时存在虚假唤醒等情况，导致唤醒后发现，条件依旧不成立，因此需要使用 for 语句来循环地进行等待，直到条件成立为止\nCond.Signal (): 只唤醒一个最先 Wait 的 goroutine，可以不用加锁\nCond.Broadcast (): 唤醒所有 Wait 的 goroutine，可以不用加锁\n\npackage main\n\nimport (\n    &quot;fmt&quot;\n    &quot;sync&quot;\n    &quot;sync/atomic&quot;\n    &quot;time&quot;\n)\n\n\n\nvar status int64\n\n  \n\nfunc TestCond(t *testing.T) {\n\n    c := sync.NewCond(&amp;sync.Mutex{})\n\n    for i := 0; i &lt; 10; i++ {\n\n        go listen(c)\n\n    }\n\n    time.Sleep(1 * time.Second)\n\n    go broadcast(c)\n\n    time.Sleep(1 * time.Second)\n\n}\n\n  \n\nfunc broadcast(c *sync.Cond) {\n\n    // 原子操作\n\n    atomic.StoreInt64(&amp;status, 1)\n\n    c.Broadcast()\n\n}\n\n  \n\nfunc listen(c *sync.Cond) {\n\n    c.L.Lock()\n\n    fmt.Println(&quot;wait&quot;)\n\n    c.Wait()\n\n     // Wait 内部会先调用 c.L.Unlock()，来先释放锁，如果调用方不先加锁的话，会报错\n\n    fmt.Println(&quot;listen&quot;)\n\n    c.L.Unlock()\n\n}\n\nsync. Once\n什么是 sync. Once\nOnce 可以用来执行且仅仅执行一次动作，常常用于单例对象的初始化场景。\nOnce 常常用来初始化单例资源，或者并发访问只需初始化⼀次的共享资源，或者在测试的时候初始化⼀次测试资源。\n源码\ntype Once struct {\n\tm    Mutex\n\tdone uint32\n}\n\nfunc (o *Once) Do(f func()) {\n\tif atomic.LoadUint32(&amp;o.done) == 1 {\n\t\treturn\n\t}\n\to.m.Lock()\n\tdefer o.m.Unlock()\n\tif o.done == 0 {\n\t\tdefer atomic.StoreUint32(&amp;o.done, 1)\n\t\tf()\n\t}\n}\n\nsync.Once 可以保证在 Go 程序运行期间的某段代码只会执行一次\n使用场景：常常用于单例对象的初始化场景\npackage main\n\nimport (\n    &quot;fmt&quot;\n    &quot;sync&quot;\n)\n\nfunc main() {\n    o := &amp;sync.Once{}\n    for i := 0; i &lt; 10; i++ {\n        o.Do(func() {\n            fmt.Println(&quot;only once&quot;)\n        })\n    }\n}\n\nsync. Pool\n对于很多需要重复分配、回收内存的地方，sync. Pool 是一个很好的选择。频繁地分配、回收内存会给 GC 带来一定的负担，严重的时候会引起 CPU 的毛刺，而sync. Pool 可以将暂时不用的对象缓存起来，待下次需要的时候直接使用，不用再次经过内存分配，复用对象的内存，减轻 GC 的压力，提升系统的性能。\nsync.Pool 是 sync 包下的一个组件，可以作为保存临时取还对象的一个“池子”。个人觉得它的名字有一定的误导性，因为 Pool 里装的对象可以被无通知地被回收，可能 sync.Cache 是一个更合适的名字。\nsync.Pool底层原理 \n# 深度解密 Go 语言之 sync.Pool\n使用场景\n对于很多需要重复分配、回收内存的地方，sync.Pool 是一个很好的选择。频繁地分配、回收内存会给 GC 带来一定的负担，严重的时候会引起 CPU 的毛刺，而 sync.Pool 可以将暂时不用的对象缓存起来，待下次需要的时候直接使用，不用再次经过内存分配，复用对象的内存，减轻 GC 的压力，提升系统的性能。\n对象池化， TCP 连接池、数据库连接池、Worker Pool\n使用方法\n首先，sync.Pool 是协程安全的，这对于使用者来说是极其方便的。使用前，设置好对象的 New 函数，用于在 Pool 里没有缓存的对象时，创建一个。之后，在程序的任何地方、任何时候仅通过 Get()、Put() 方法就可以取、还对象了。\n首先来看一个简单的例子：\npackage main\nimport (\n    &quot;fmt&quot;\n    &quot;sync&quot;\n)\n \nvar pool *sync.Pool\n \ntype Person struct {\n    Name string\n}\n \nfunc initPool() {\n    pool = &amp;sync.Pool {\n        New: func()interface{} {\n            fmt.Println(&quot;Creating a new Person&quot;)\n            return new(Person)\n        },\n    }\n}\n \nfunc main() {\n    initPool()\n \n    p := pool.Get().(*Person)\n    fmt.Println(&quot;首次从 pool 里获取：&quot;, p)\n \n    p.Name = &quot;first&quot;\n    fmt.Printf(&quot;设置 p.Name = %s\\n&quot;, p.Name)\n \n    pool.Put(p)\n \n    fmt.Println(&quot;Pool 里已有一个对象：&amp;{first}，调用 Get: &quot;, pool.Get().(*Person))\n    fmt.Println(&quot;Pool 没有对象了，调用 Get: &quot;, pool.Get().(*Person))\n}\n运行结果：\nCreating a new Person\n首次从 pool 里获取： &amp;{}\n设置 p.Name = first\nPool 里已有一个对象：&amp;{first}，Get:  &amp;{first}\nCreating a new Person\nPool 没有对象了，Get:  &amp;{}\nsync. Map\nMap 和Sync.map\nsync.Map 线程安全的 map\n使用场景：map 并发读写\npackage main\n\nimport (\n    &quot;fmt&quot;\n    &quot;sync&quot;\n)\n\nfunc main() {\n    var scene sync.Map\n    // 将键值对保存到sync.Map\n    scene.Store(&quot;1&quot;, 1)\n    scene.Store(&quot;2&quot;, 2)\n    scene.Store(&quot;3&quot;, 3)\n    // 从sync.Map中根据键取值\n    fmt.Println(scene.Load(&quot;1&quot;))\n    // 根据键删除对应的键值对\n    scene.Delete(&quot;1&quot;)\n    // 遍历所有sync.Map中的键值对\n    scene.Range(func(k, v interface{}) bool {\n        fmt.Println(&quot;iterate:&quot;, k, v)\n        return true\n    })\n}\n\nsync. Context\nContext\nsync.Context 可以进行上下文信息传递、提供超时和取消机制、控制子 goroutine 的执行\n使用场景：取消一个 goroutine 的执行\npackage main\n\nimport (\n    &quot;context&quot;\n    &quot;fmt&quot;\n    &quot;time&quot;\n)\n\nfunc main() {\n    ctx, cancel := context.WithCancel(context.Background())\n    go func() {\n        defer func() {\n            fmt.Println(&quot;goroutine exit&quot;)\n        }()\n        for {\n            select {\n            case &lt;-ctx.Done():\n                fmt.Println(&quot;receive cancel signal!&quot;)\n                return\n            default:\n                fmt.Println(&quot;default&quot;)\n                time.Sleep(time.Second)\n            }\n        }\n    }()\n    time.Sleep(time.Second)\n    cancel()\n    time.Sleep(2 * time.Second)\n}\n\n扩展并发原语\nErrGroup\nerrgroup 可以在一组 Goroutine 中提供了同步、错误传播以及上下文取消的功能\n如果协程中 panic 依然会\n使用场景：只要一个 goroutine 出错我们就不再等其他 goroutine 了，减少资源浪费，并且返回错误\npackage main\n\nimport (\n    &quot;fmt&quot;\n    &quot;net/http&quot;\n\n    &quot;golang.org/x/sync/errgroup&quot;\n)\n\nfunc main() {\n    var g errgroup.Group\n    var urls = []string{\n        &quot;www.baidu.com/&quot;,\n        &quot;www.sina.com.cn/&quot;,\n    }\n    for i := range urls {\n        url := urls[i]\n        g.Go(func() error {\n            resp, err := http.Get(url)\n            if err == nil {\n                resp.Body.Close()\n            }\n            return err\n        })\n    }\n    err := g.Wait()\n    if err == nil {\n        fmt.Println(&quot;Successfully fetched all URLs.&quot;)\n    } else {\n        fmt.Println(&quot;fetched error:&quot;, err.Error())\n    }\n}\n\nSemaphore\nSemaphore 带权重的信号量，控制多个 goroutine 同时访问资源\n使用场景：控制 goroutine 的阻塞和唤醒\npackage main\n\nimport (\n    &quot;context&quot;\n    &quot;fmt&quot;\n    &quot;log&quot;\n    &quot;runtime&quot;\n    &quot;time&quot;\n\n    &quot;golang.org/x/sync/semaphore&quot;\n)\n\nvar (\n    maxWorkers = runtime.GOMAXPROCS(0)\n    sema       = semaphore.NewWeighted(int64(maxWorkers)) //信号量\n    task       = make([]int, maxWorkers*4)\n\n// 任务数，是worker的四\n)\n\nfunc main() {\n    ctx := context.Background()\n    for i := range task {\n        // 如果没有worker可用，会阻塞在这里，直到某个worker被释放\n        if err := sema.Acquire(ctx, 1); err != nil {\n            break\n        }\n        // 启动worker goroutine\n        go func(i int) {\n            defer sema.Release(1)\n            time.Sleep(100 * time.Millisecond) // 模拟一个耗时操作\n            task[i] = i + 1\n        }(i)\n    }\n    // 请求所有的worker,这样能确保前面的worker都执行完\n    if err := sema.Acquire(ctx, int64(maxWorkers)); err != nil {\n        log.Printf(&quot;获取所有的worker失败: %v&quot;, err)\n    }\n    fmt.Println(maxWorkers, task)\n}\n\nSingleFlight\n用于抑制对下游的重复请求\n使用场景：访问缓存、数据库等场景，缓存过期时只有一个请求去更新数据库\npackage main\n\nimport (\n    &quot;fmt&quot;\n    &quot;sync&quot;\n    &quot;sync/atomic&quot;\n    &quot;time&quot;\n\n    &quot;golang.org/x/sync/singleflight&quot;\n)\n\n// 模拟从数据库读取\nfunc getArticle(id int) (article string, err error) {\n    // 假设这里会对数据库进行调用, 模拟不同并发下耗时不同\n    atomic.AddInt32(&amp;count, 1)\n    time.Sleep(time.Duration(count) * time.Millisecond)\n\n    return fmt.Sprintf(&quot;article: %d&quot;, id), nil\n}\n\n// 模拟优先读缓存，缓存不存在读取数据库，并且只有一个请求读取数据库，其它请求等待\nfunc singleflightGetArticle(sg *singleflight.Group, id int) (string, error) {\n    v, err, _ := sg.Do(fmt.Sprintf(&quot;%d&quot;, id), func() (interface{}, error) {\n        return getArticle(id)\n    })\n\n    return v.(string), err\n}\n\nvar count int32\n\nfunc main() {\n    time.AfterFunc(1*time.Second, func() {\n        atomic.AddInt32(&amp;count, -count)\n    })\n\n    var (\n        wg  sync.WaitGroup\n        now = time.Now()\n        n   = 1000\n        sg  = &amp;singleflight.Group{}\n    )\n\n    for i := 0; i &lt; n; i++ {\n        wg.Add(1)\n        go func() {\n            res, _ := singleflightGetArticle(sg, 1)\n            // res, _ := getArticle(1)\n            if res != &quot;article: 1&quot; {\n                panic(&quot;err&quot;)\n            }\n            wg.Done()\n        }()\n    }\n\n    wg.Wait()\n    fmt.Printf(&quot;同时发起 %d 次请求，耗时: %s&quot;, n, time.Since(now))\n}\n\nGo 有哪些方式安全读写共享变量？\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n方法并发原语备注不要修改变量sync. Once不要去写变量，变量只初始化一次只允许一个 goroutine 访问变量Channel不要通过共享变量来通信，通过通信 (channel)来共享变量允许多个 goroutine 访问变量，但是同一时间只允许一个 goroutine 访问sync. Mutex、sync. RWMutex、原子操作实现锁机制，同时只有一个线程能拿到\nGo 如何排查数据竞争问题？\n概念\n只要有两个以上的 goroutine 并发访问同一变量，且至少其中的一个是写操作的时候就会发生数据竞争；全是读的情况下是不存在数据竞争的。\n排查方式\npackage main\n\nimport &quot;fmt&quot;\n\nfunc main() {\n    i := 0\n\n    go func() {\n        i++ // write i\n    }()\n\n    fmt.Println(i) // read i\n}\n\ngo 命令行有个参数race可以帮助检测代码中的数据竞争\n$ go run -race main.go\n\nWARNING: DATA RACE\nWrite at 0x00c0000ba008 by goroutine 7:\nexit status 66\n\nGo 语言怎么做的连接复用\nGo 的 netpoll 是怎么实现的像阻塞 read 一样去使用底层的非阻塞 read\nGolang的IO多路复用的netpoll模型 \nGo 语言中 IO 多路复用使用 netpoll 模型\nNetpoll 本质上是对 I/O 多路复用技术的封装，所以自然也是和 epoll 一样脱离不了下面几步：\n\nNetpoll 创建及其初始化；\n向 netpoll 中加入待监控的任务；\n从 netpoll 获取触发的事件；\n在 go 中对 epoll 提供的三个函数进行了封装\n\nfunc netpollinit()\nfunc netpollopen(fd uintptr, pd *pollDesc) int32\nfunc netpoll(delay int64) gList\n\nNetpollinit 函数负责初始化 netpoll；\nNetpollopen 负责监听文件描述符上的事件；\nNetpoll 会阻塞等待返回一组已经准备就绪的 Goroutine；\nData Race 问题怎么解决？能不能不加锁解决这个问题？\n\nruntime 提供常见的方法\n\n\nGosched ()：让当前线程让出 cpu 以让其它线程运行，它不会挂起当前线程，因此当前线程未来会继续执行。\n\n\nNumCPU ()：返回当前系统的 CPU 核数量。\n\n\nGOMAXPROCS ()：设置最大的可同时使用的 CPU 核数。\n\n通过 runtime. GOMAXPROCS 函数，应用程序可以设置运行时系统中的 P 最大数量。注意，如果在运行期间设置该值的话，会引起“Stop the World”。所以，应在应用程序最早期调用，并且最好是在运行 Go 程序之前设置好操作程序的环境变量 GOMAXPROCS，而不是在程序中调用 runtime. GOMAXPROCS 不能作为函数的参数。\n无论我们传递给函数的整数值是什么值，运行时系统的 P 最大值总会在 1~256 之间。\nGo 1.8 后，默认让程序运行在多个核上，可以不用设置了。\nGo 1.8 前，还是要设置一下，可以更高效的利用 cpu。\n\n\n\nGoexit ()：退出当前 goroutine（但是 defer 语句会照常执行）。\n\n\nNumGoroutine：返回正在执行和排队的任务总数。\n\nRuntime. NumGoroutine 函数在被调用后，会返回系统中的处于特定状态的 Goroutine 的数量。这里的特定状态是指 GrunnableGruningGsyscallGwaition。处于这些状态的 Goroutine 即被看做是活跃的或者说正在被调度。\n注意：垃圾回收所在 Goroutine 的状态也处于这个范围内的话，也会被纳入该计数器。\n\n\n\nGOOS：查看目标操作系统。很多时候，我们会根据平台的不同实现不同的操作，就可以用 GOOS 来查看自己所在的操作系统。\n\n\nruntime. GC：会让运行时系统进行一次强制性的垃圾收集。\n强制的垃圾回收：不管怎样，都要进行的垃圾回收。非强制的垃圾回收：只会在一定条件下进行的垃圾回收（即运行时，系统自上次垃圾回收之后新申请的堆内存的单元（也成为单元增量）达到指定的数值）。\n\n\nGOROOT ()：获取 goroot 目录。\n\n\nruntime. LockOSThread 和 runtime. UnlockOSThread 函数：前者调用会使调用他的 Goroutine 与当前运行它的 M 锁定到一起，后者调用会解除这样的锁定。\n\n"},"Java/Java":{"title":"☆Java","links":["Java/基础/Java-overview","Java/基础/Java-的数据结构","Java/基础/Java-基础语法","Java/基础/Java-面向对象","Java/基础/Java-常用类","Java/基础/Java-异常","Java/基础/Java-泛型","Java/基础/Java-反射","Java/基础/Java-注解","Java/基础/Java-SPI","Java/基础/Java-序列化与反序列化","Java/基础/Java-面试题","Java/集合/Java-集合-overview","Java/集合/List","Java/集合/Set","Java/集合/Queue","Java/集合/Map","Java/集合/集合面试题","Java/多线程/多线程基础","Java/多线程/可见性、原子性和有序性问题：并发编程Bug的源头","Java/多线程/安全性、活跃性以及性能问题","Java/多线程/等待通知机制优化循环等待","Java/多线程/Java-内存模型","Java/多线程/Java内存模型：解决可见性、有序性问题","Java/多线程/Java线程","Java/多线程/锁","Java/多线程/锁相关的工具类","Java/多线程/死锁","Java/多线程/管程","Java/多线程/ThreadLocal","Java/多线程/线程池","Java/多线程/常用类/Lock和Condition","Java/多线程/常用类/信号量（Semaphore）","Java/多线程/常用类/读写锁（ReadWriteLock）","Java/多线程/常用类/印章锁（StampedLock）,比读写锁更快的锁","Java/多线程/常用类/CountDownLatch和CyclicBarrier让线程步调一致","Java/多线程/常用类/原子类：无锁工具类的典范","Java/多线程/常用类/并发容器","Java/多线程/常用类/Executor-和线程池","Java/多线程/常用类/Future","Java/多线程/常用类/CompletableFuture：异步编程工具类","Java/多线程/常用类/CompletionService：批量执行异步任务","Java/多线程/常用类/Fork-Join单机版的MapReduce","Java/多线程/设计模式/Immutability模式：如何利用不变性解决并发问题","Java/多线程/设计模式/Copy-on-Write","Java/多线程/设计模式/线程本地存储模式-ThreadLocal","Java/JVM/Java内存区域","Java/JVM/JVM垃圾回收","Java/JVM/类文件结构","Java/JVM/类加载过程","Java/JVM/类加载器","Java/JVM/JVM-调优","Java/IO/Java-IO-overview","Java/IO/IO模型详解","Java/IO/AIO","Java/IO/NIO","Java/IO/BIO","Java/netty/概念和体系结构","Java/netty/传输和Channel","Java/netty/BootStrap","Java/netty/EventLoop-和线程模型","Java/netty/ByteBuf","Java/netty/ChannelHandler、ChannelPipeline、ChannelContext","Java/netty/编解码器","Java/netty/面试题","Java/netty/实现一个rpc框架/1-什么是RPC？原理是什么？","Java/netty/实现一个rpc框架/2-常见的RPC框架","Java/netty/实现一个rpc框架/3-如何实现一个RPC框架","Java/netty/实现一个rpc框架/4-序列化和序列化框架","Java/netty/实现一个rpc框架/5-Socket-通信","Java/netty/实现一个rpc框架/6-Netty","Java/netty/实现一个rpc框架/7-静态代理+JDK-CGLIB-动态代理实战","Java/netty/实现一个rpc框架/8-Zookeeper和Curator","Java/netty/实现一个rpc框架/9-网络模块","Java/netty/实现一个rpc框架/10-注册中心","Java/netty/实现一个rpc框架/11-代理与注解","Java/netty/实现一个rpc框架/12-使用CompletableFuture优化接受服务提供端返回结果","Java/Mybatis/mybatis","Java/Spring/spring-boot/基础","Java/Spring/spring-boot/SpringBoot-自动装配原理详解","Java/Spring/spring-MVC/J2EE","Java/Spring/spring-MVC/基础","Java/Spring/spring-framework/基础","Java/Spring/spring-framework/AOP","Java/Spring/spring-framework/IOC","Java/Spring/spring-framework/事务","Java/Spring/spring-framework/常用注解","Java/Spring/spring-framework/spring-中的设计模式","Java/Spring/Spring-cloud/spring-cloud-alibaba","Java/Spring/Spring-cloud/Spring-Cloud-Gateway常见问题总结","Java/Spring/Spring-Data/JPA","Java/Spring/Spring-Security/基础"],"tags":["Java"],"content":"基础\n\nJava overview\n\n\nJava 的数据结构\nJava 基础语法\nJava 面向对象\nJava 常用类\nJava 异常\nJava 泛型\nJava 反射\nJava 注解\nJava SPI\nJava 序列化与反序列化\nJava 面试题\n\n集合\n\nJava 集合 overview\nList\nSet\nQueue\nMap\n集合面试题\n\n多线程\n\n多线程基础\n可见性、原子性和有序性问题：并发编程Bug的源头\n安全性、活跃性以及性能问题\n等待通知机制优化循环等待\nJava 内存模型\nJava内存模型：解决可见性、有序性问题\nJava线程\n锁\n锁相关的工具类\n死锁\n管程\nThreadLocal\n线程池\n常用类\n\nLock和Condition\n信号量（Semaphore）\n读写锁（ReadWriteLock）\n印章锁（StampedLock）,比读写锁更快的锁\nCountDownLatch和CyclicBarrier让线程步调一致\n原子类：无锁工具类的典范\n并发容器\nExecutor 和线程池\nFuture\nCompletableFuture：异步编程工具类\nCompletionService：批量执行异步任务\nFork Join单机版的MapReduce\n\n\n设计模式\n\nImmutability模式：如何利用不变性解决并发问题\nCopy-on-Write\n线程本地存储模式 ThreadLocal\n\n\n\nJVM\n\nJava内存区域\nJVM垃圾回收\n类文件结构\n类加载过程\n类加载器\nJVM 调优\n\nIO\n\nJava IO overview\nIO模型详解\nAIO\nNIO\nBIO\n\nNetty\n\n概念和体系结构\n传输和Channel\nBootStrap\nEventLoop 和线程模型\nByteBuf\nChannelHandler、ChannelPipeline、ChannelContext\n编解码器\n面试题\n实现 Rpc 框架\n\n1 什么是RPC？原理是什么？\n2 常见的RPC框架\n3 如何实现一个RPC框架\n4 序列化和序列化框架\n5 Socket 通信\n6 Netty\n7 静态代理+JDK CGLIB 动态代理实战\n8 Zookeeper和Curator\n9 网络模块\n10 注册中心\n11 代理与注解\n12 使用CompletableFuture优化接受服务提供端返回结果\n\n\n\nMybatis\n\nmybatis\n\nSpring\n\nSpring boot\n\n基础\nSpringBoot 自动装配原理详解\n\n\nSpring Mvc\n\nJ2EE\n基础\n\n\nSpring framework\n\n基础\nAOP\nIOC\n事务\n常用注解\nspring 中的设计模式\n\n\nspring clound\n\nspring cloud alibaba\nSpring Cloud Gateway常见问题总结\n\n\nspring data\n\nJPA\n\n\nsring security\n\n基础\n\n\n"},"Kubernetes/Kubernetes":{"title":"Kubernetes","links":["Kubernetes/容器-容器的本质，隔离的进程","Kubernetes/容器-docker","Kubernetes/容器编排与Kubernetes","Kubernetes/作业管理-YAML","Kubernetes/作业管理-Pod","Kubernetes/作业管理-Deployment","Kubernetes/作业管理-DaemonSet","Kubernetes/作业管理-StatefulSet","Kubernetes/网络-Service","Kubernetes/网络-Ingress","Kubernetes/网络-CNI","Kubernetes/存储-PersistentVolume","Kubernetes/配置-ConfigMap-Secret","Kubernetes/系统监控：Metrics-Server和Prometheus","Kubernetes/资源和探针","Kubernetes/滚动更新","Kubernetes/命名空间"],"tags":["Kubernetes"],"content":"容器\n\n容器-容器的本质，隔离的进程\n容器-docker\n容器编排与Kubernetes\n\n作业管理\n\n作业管理-YAML\n作业管理-Pod\n作业管理-Deployment\n作业管理-DaemonSet\n作业管理-StatefulSet\n\n网络\n\n网络-Service\n网络-Ingress\n网络-CNI\n\n存储\n\n存储-PersistentVolume\n\n配置\n\n配置-ConfigMap Secret\n\n监控\n\n系统监控：Metrics Server和Prometheus\n资源和探针\n\n其他\n\n滚动更新\n命名空间\n"},"MySQL/MySQL":{"title":"MySQL","links":["MySQL/基础/SQL的执行过程","MySQL/基础/数据存储","MySQL/基础/数据存储_行结构","MySQL/基础/数据存储-数据页结构","MySQL/基础/数据存储_Change-buffer-和-buffer-pool","MySQL/基础/索引","MySQL/基础/索引-理解-B-树、B+-树特点及使用场景","MySQL/基础/索引-MySQL-单表不要超过-2000W-行，靠谱吗","MySQL/基础/索引-Count效率","MySQL/基础/索引-MySQL-使用-like-“-percentx“，索引一定会失效吗？","MySQL/基础/索引-常见面试题","MySQL/基础/日志","MySQL/基础/锁","MySQL/基础/锁-MySQL-是如何加锁的？","MySQL/基础/锁-MySQL-可以防止删除操作导致的幻读吗？","MySQL/基础/锁-Update没加索引会锁全表吗？","MySQL/基础/锁-MySQL死锁了，怎么办","MySQL/实践/1.普通索引和唯一索引","MySQL/实践/2.如何给字符串字段加索引","MySQL/实践/3.MySQL-错选","MySQL/实践/4.为什么我的MySQL会“抖”一下---Flush","MySQL/实践/5.为什么表数据删掉一半，表文件大小不变---数据库表的空间回收","MySQL/实践/7.-order-by-是怎么工作的？","MySQL/实践/8.如何正确显示随机消息","MySQL/实践/9.为什么这些SQL语句逻辑相同，性能却差异巨大？","MySQL/实践/10.为什么我只查一行的语句，也执行这么慢？","MySQL/实践/11.幻读是什么，幻读有什么问题","MySQL/实践/12.为什么我只改一行的语句，锁这么多","MySQL/实践/13.MySQL有哪些“饮鸩止渴”提高性能的方法？","MySQL/实践/14.MySQL是怎么保证数据不丢的","MySQL/实践/15.MySQL是怎么保证主备一致的","MySQL/实践/16.MySQL是怎么保证高可用的","MySQL/实践/17.备库为什么会延迟好几个小时","MySQL/实践/18.主库出问题了，从库怎么办？","MySQL/实践/19.读写分离的坑","MySQL/实践/20.如何判断数据库是否出问题-了","MySQL/实践/21.还有kill不掉的语句","MySQL/实践/22.我查这么多数据，会不会把数据库内存打爆？","MySQL/实践/23.到底可不可以用join","MySQL/实践/24.join语句怎么优化","MySQL/实践/25.为啥临时表可以重名？","MySQL/实践/26.还要不要使用Memory引擎？","MySQL/实践/27.自增主键为啥不连续","MySQL/实践/28.insert为啥锁那么多？","MySQL/实践/29怎么最快地复制一张表","MySQL/实践/30.grant之后要跟着flush-privileges吗","MySQL/实践/31-要不要使用分区表","MySQL/实践/32.自增id用完怎么办？"],"tags":["MySQL"],"content":"SQL 执行过程\n\nSQL的执行过程\n\n数据存储\n\n数据存储\n数据存储_行结构\n数据存储-数据页结构\n数据存储_Change buffer 和 buffer pool\n\n索引\n\n索引\n索引-理解 B 树、B+ 树特点及使用场景\n索引-MySQL 单表不要超过 2000W 行，靠谱吗\n索引-Count效率\n索引-MySQL 使用 like “%x“，索引一定会失效吗？\n索引-常见面试题\n\n日志\n\n日志\n\n锁\n\n锁\n锁-MySQL 是如何加锁的？\n锁-MySQL 可以防止删除操作导致的幻读吗？\n锁-Update没加索引会锁全表吗？\n锁-MySQL 可以防止删除操作导致的幻读吗？\n锁-MySQL死锁了，怎么办\n\n应用\n\n1.普通索引和唯一索引\n2.如何给字符串字段加索引\n3.MySQL 错选\n4.为什么我的MySQL会“抖”一下 —Flush\n5.为什么表数据删掉一半，表文件大小不变---数据库表的空间回收\n7. order by 是怎么工作的？\n8.如何正确显示随机消息\n9.为什么这些SQL语句逻辑相同，性能却差异巨大？\n10.为什么我只查一行的语句，也执行这么慢？\n11.幻读是什么，幻读有什么问题\n12.为什么我只改一行的语句，锁这么多\n13.MySQL有哪些“饮鸩止渴”提高性能的方法？\n14.MySQL是怎么保证数据不丢的\n15.MySQL是怎么保证主备一致的\n16.MySQL是怎么保证高可用的\n17.备库为什么会延迟好几个小时\n18.主库出问题了，从库怎么办？\n19.读写分离的坑\n20.如何判断数据库是否出问题 了\n21.还有kill不掉的语句\n22.我查这么多数据，会不会把数据库内存打爆？\n23.到底可不可以用join\n24.join语句怎么优化\n25.为啥临时表可以重名？\n26.还要不要使用Memory引擎？\n27.自增主键为啥不连续\n28.insert为啥锁那么多？\n29怎么最快地复制一张表\n30.grant之后要跟着flush privileges吗\n31 要不要使用分区表\n32.自增id用完怎么办？\n"},"Obsidian/Front-Matter":{"title":"Front Matter","links":[],"tags":["Obsidian"],"content":"使用 Front Matter 可以保存 note 待元数据，推荐使用 Hugo 的配置 Front matter | Hugo (gohugo.io)"},"Obsidian/Obsidian-plugin":{"title":"Obsidian-plugin","links":[],"tags":["Obsidian"],"content":"\nadvanced-table\nbanners\ncalendar\ncommander\ndataview\nemoji-shortcodes\nemoji-toolbar\nexcel-to-markdown-table\nhomepage\nhover-editor\nicon-folder)\nicons\nimage-toolkit\nminimal-settings\nobsidian-git\nrecent-files\nsettings-search\nstyle-settings\ntag-wrangler\nexcalidraw\n"},"Obsidian/dataview":{"title":"dataview","links":["tags/Tag/1/A","tags/Tag/1"],"tags":["Obsidian","Tag/1/A","Tag/1"],"content":"官方地址\n\n代码仓库\n文档地址\n\n其他教程\n\nObsidian DataView 入门保姆级引导手册\n\n元数据\n元数据是一系列的键值对,可以给笔记，可以给note,list item ,task 添加元数据\n如何添加元数据\nFrontmatter\n\nfrontmatter 是markdown的一种扩展，可以使用yaml 来添加元数据\n\n --- \n alias: &quot;document&quot; \n last-reviewed: 2021-08-17 \n thoughts: \n\t rating: 8 \n\t reviewable: false \n ---\n\ninline fields\n\n使用方法为在文件的任意位置添加\n\n \nBasic Field:: Some random Value \n**Bold Field**:: Nice!\n  \n\n如果你需要标注list itme 或者 task 需要使用中括号\n\n- [ ] Send an mail to David about the deadline [due:: 2022-04-05].\n\n另外还有隐含的元数据\npage 中的元数据\n# Metadata on Pages\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nField NameData TypeDescriptionfile.nameTextThe file name as seen in Obsidians sidebar.file.folderTextThe path of the folder this file belongs to.file.pathTextThe full file path, including the files name.file.extTextThe extension of the file type; generally md.file.linkLinkA link to the file.file.sizeNumberThe size (in bytes) of the file.file.ctimeDate with TimeThe date that the file was created.file.cdayDateThe date that the file was created.file.mtimeDate with TimeThe date that the file was last modified.file.mdayDateThe date that the file was last modified.file.tagsListA list of all unique tags in the note. Subtags are broken down by each level, soA will be stored in the list as [#Tag,1,A].file.etagsListA list of all explicit tags in the note; unlike file.tags, does not break subtags down, i.e. [#Tag/1/A]file.inlinksListA list of all incoming links to this file, meaning all files that contain a link to this file.file.outlinksListA list of all outgoing links from this file, meaning all links the file contains.file.aliasesListA list of all aliases for the note as defined via the YAML frontmatter.file.tasksListA list of all tasks (I.e., | [ ] some task) in this file.file.listsListA list of all list elements in the file (including tasks); these elements are effectively tasks and can be rendered in task views.file.frontmatterListContains the raw values of all frontmatter in form of key | value text values; mainly useful for checking raw frontmatter values or for dynamically listing frontmatter keys.file.dayDateOnly available if the file has a date inside its file name (of form yyyy-mm-dd or yyyymmdd), or has a Date field/inline field.file.starredBooleanif this file has been starred via the Obsidian Core Plugin “Starred Files”.\n列表和任务中的元数据\n# Metadata on Tasks and Lists\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nField nameData TypeDescriptionstatusTextThe completion status of this task, as determined by the character inside the [ ] brackets. Generally a space ” ” for incomplete tasks and a “x” for complete tasks, but allows for plugins which support alternative task statuses.checkedBooleanWhether or not this task status is empty, meaning it has a space in its [ ] bracketscompletedBooleanWhether or not this specific task has been completed; this does not consider the completionnon-completion of any child tasks. A task is explicitly considered “completed” if it has been marked with an ‘x’. If you use a custom status, i.e. [-], checked will be true, whereas completed will be false.fullyCompletedBooleanWhether or not this task and all of its subtasks are completed.textTextThe plain text of this task, including any metadata field annotations.visualTextThe text of this task, which is rendered by Dataview. It can be modified to render arbitary text.lineNumberThe line of the file this task shows up on.lineCountNumberThe number of Markdown lines that this task takes up.pathTextThe full path of the file this task is in. Equals to file.path for pagessectionLinklink to the section this task is contained in.tagsListAny tags inside of the text task.outlinksListAny links defined in this task.linkLinklink to the closest linkable block near this task; useful for making links which go to the task.childrenListny subtasks or sublists of this task.taskBooleanIf true, this is a task; otherwise, it is a regular list element.annotatedBooleanTrue if the task text contains any metadata fields, false otherwise.parentNumberThe line number of the task above this task, if present; will be null if this is a root-level task.blockIdTextThe block ID of this task / list element, if one has been defined with the ^blockId syntax; otherwise null.\nDQL\n比较类似于sql, 可是实现以下的功能\n\nChoosing an output format of your output (the Query Type)\nFetch pages from a certain source, i.e. a tag, folder or link\nFiltering pages/data by simple operations on fields, like comparison, existence checks, and so on\nTransforming fields for displaying, i.e. with calculations or splitting up multi-value fields\nSorting results based on fields\nGrouping results based on fields\nLimiting your result count\n\n查询语法\n```dataview \n\t&lt;QUERY-TYPE&gt; &lt;fields&gt; \n\tFROM &lt;source&gt; \n\t&lt;DATA-COMMAND&gt; &lt;expression&gt; \n\t&lt;DATA-COMMAND&gt; &lt;expression&gt; \n\t...\n\n输出类型\n\nTABLE: A table of results with one row per result and one or many columns of field data.\nLIST: A bullet point list of pages which match the query. You can output one field for each page alongside their file links.\nTASK: An interactive task list of tasks that match the given query.\nCALENDAR: A calendar view displaying each hit via a dot on its referred date.\n\nLists all pages in your vault as a bullet point list\n\t```dataview \n\tLIST \n\t```\n\t\nLists all tasks (completed or not) in your vault \n\t```dataview \n\tTASK \n\t```\n\t\nRenders a Calendar view where each page is represented as a dot on its creation date. \n\t```dataview \n\tCALENDAR file.cday \n\t```\n\t\nShows a table with all pages of your vault, their field value of due, the files&#039; tags and an average of the values of multi-value field working-hours \n\t```dataview \n\tTABLE due, file.tags AS &quot;tags&quot;, average(working-hours)\n\t ```\n \n数据来源\n\ntags\nfolders\nnote\nlint\n\nLists all pages inside the folder Books and its sub folders \n\t```dataview \n\tLIST FROM &quot;Books&quot; \n\t``` \n\t\nLists all pages that include the tag #status/open or #status/wip \n\t```dataview \n\tLIST FROM #status/open OR #status/wip \n\t``` \n\t\nLists all pages that have either the tag #assignment and are inside folder &quot;30 School&quot; (or its sub folders), or are inside folder &quot;30 School/32 Homeworks&quot; and are linked on the page School Dashboard Current To Dos \n\n\t```dataview \n\tLIST FROM (#assignment AND &quot;30 School&quot;) OR (&quot;30 School/32 Homeworks&quot; AND outgoing([[School Dashboard Current To Dos]])) \n\t```\n\n\nFilter, sort, group or limit results\n\n*FROM like explained above.\nWHERE: Filter notes based on information inside notes, the meta data fields.\nSORT: Sorts your results depending on a field and a direction.\nGROUP BY: Bundles up several results into one result row per group.\nLIMIT: Limits the result count of your query to the given number.\nFLATTEN: Splits up one result into multiple results based on a field or calculation.\n\nLists all pages that have a metadata field `due` and where `due` is before today \n\n\t```dataview \n\tLIST WHERE due AND due &lt; date(today) \n\t``` \nLists the 10 most recently created pages in your vault that have the tag #status/open \n\t```dataview \n\tLIST FROM #status/open SORT file.ctime DESC LIMIT 10 \n\t``` \nLists the 10 oldest and incompleted tasks of your vault as an interactive task list, grouped by their containing file and sorted from oldest to newest file. \n\t```dataview \n\tTASK WHERE !completed SORT created ASC LIMIT 10 GROUP BY file.link SORT rows.file.ctime ASC \n\t```\n\n\n"},"Obsidian/excalidraw":{"title":"excalidraw","links":[],"tags":["Obsidian"],"content":"\n代码仓库\nnote 中插入excalidraw 语法\n\n![[excalidraw]]\n"},"Obsidian/obsidian-overview":{"title":"obsidian overview","links":[],"tags":["Obsidian"],"content":"主页内容\nobsidian 相关内容，包括插件\n结构"},"Obsidian/publish":{"title":"publish","links":[],"tags":["Obsidian"],"content":"obsidian 目前最完美的免费发布方案 渐进式教程 by oldwinter"},"Obsidian/template":{"title":"template","links":[],"tags":["Obsidian"],"content":"\n*模板的使用方法\n默认存放的文件夹 /template\n"},"Obsidian/使用quartz发布obsidian--vault":{"title":"使用quartz发布obsidian  vault","links":[],"tags":[],"content":""},"Python/python":{"title":"python","links":["Python/1.Pipenv-and-虚拟环境","Python/2.工程的结构","Python/3.类型","Python/4.容器","Python/5.函数","Python/6.模块、包","Python/7.类","Python/8.异常","Python/9.标准库","Python/10.测试","Python/11.日志"],"tags":["Python"],"content":"\n1.Pipenv&amp;虚拟环境\n2.工程的结构\n\n\n3.类型\n4.容器\n5.函数\n6.模块、包\n7.类\n8.异常\n9.标准库\n10.测试\n11.日志\n"},"Redis/Redis":{"title":"★Redis","links":["Redis/Redis概览","Redis/基础/基本架构：一个键值数据库的组成","Redis/基础/redis-的慢操作","Redis/基础/高性能IO模型：为什么单线程Redis能那么快","Redis/基础/AOF日志：宕机了，Redis如何避免数据丢失","Redis/基础/RDB：内存快照","Redis/基础/哨兵机制：主库挂了，如何不间断服务","Redis/基础/哨兵集群：哨兵挂了，主从库切换","Redis/基础/切片集群：数据增多了，是该加内存还是加实例","Redis/基础/数据同步：主从库","Redis/实践/String-的局限","Redis/实践/集合数据类型和其集合统计模式","Redis/实践/GEO是什么？","Redis/实践/保存时间序列","Redis/实践/消息队列，Redis的解决方案","Redis/实践/异步机制：如何避免单线程模型的阻塞","Redis/实践/CPU结构也会影响Redis的性能","Redis/实践/波动的响应延迟：如何应对变慢的Redis？","Redis/实践/删除数据后，为啥内存占用率还是很高","Redis/实践/缓冲区：一个可能引发“惨案”的地方","Redis/实践/旁路缓存：Redis是如何工作的？","Redis/实践/替换策略：缓存满了怎么办","Redis/实践/缓存异常：缓存和数据库的一致性问题","Redis/实践/缓存被污染如何处理）——-LFU","Redis/实践/Pika：如何基于SSD实现大容量Redis","Redis/实践/无锁的原子操作：Redis如何应对并发访问","Redis/实践/如何使用Redis实现分布式锁","Redis/实践/事务机制","Redis/实践/Redis-主从同步与故障切换，有哪些坑？"],"tags":["Redis"],"content":"概览\n\nRedis概览\n\n基础\n\n基本架构：一个键值数据库的组成\nredis 的慢操作\n高性能IO模型：为什么单线程Redis能那么快\nAOF日志：宕机了，Redis如何避免数据丢失\nRDB：内存快照\n哨兵机制：主库挂了，如何不间断服务\n哨兵集群：哨兵挂了，主从库切换\n切片集群：数据增多了，是该加内存还是加实例\n数据同步：主从库\n\n实践\n\nString 的局限\n集合数据类型和其集合统计模式\nGEO是什么？\n保存时间序列\n消息队列，Redis的解决方案\n异步机制：如何避免单线程模型的阻塞\nCPU结构也会影响Redis的性能\n波动的响应延迟：如何应对变慢的Redis？\n删除数据后，为啥内存占用率还是很高\n缓冲区：一个可能引发“惨案”的地方\n旁路缓存：Redis是如何工作的？\n替换策略：缓存满了怎么办\n缓存异常：缓存和数据库的一致性问题\n缓存被污染如何处理）—— LFU\nPika：如何基于SSD实现大容量Redis\n无锁的原子操作：Redis如何应对并发访问\n如何使用Redis实现分布式锁\n事务机制\nRedis 主从同步与故障切换，有哪些坑？\n"},"docker/Docker-基础":{"title":"Docker 初学者命令","links":[],"tags":["docker"],"content":"docs.docker.com/reference/\n一、基础命令\n帮助命令\ndocker --version  # 显示docker的版本信息\ndocker info    # 显示docker的系统信息\ndocker 命令 --help    # 显示帮助命令\n搜索镜像\n# 搜索镜像\ndocker search mysql\n# 条件过滤搜索结果\ndocker search --filter=STARS=5000\n\n「列表解释」\n\n\n「NAME: 镜像名称」\n\n\n「DESCRIPTION: 镜像介绍」\n\n\n「STARS: 镜像的stars」\n\n\n「OFFICIAL: 是否是官方提供的」\n\n\n「AUTOMATED: 是不是自动化的」\n\n\n拉取镜像\n# 默认拉取最新的镜像\ndocker pull mysql\n# 指定版本下载\ndocker pull mysql:5.7\n查看所有镜像\n# 查看所有镜像信息\ndocker images -a\n# 查看所有的镜像id\ndocker images -aq\n\n「列表解释」\n\n\n「REPOSITORY: 镜像的仓库源」\n\n\n「TAG: 镜像的标签」\n\n\n「IMAGE ID: 镜像的id」\n\n\n「CREATE: 镜像的创建时间」\n\n\n「SIZE: 镜像的大小」\n\n\n删除镜像\n#删除指定id的镜像\ndocker rmi 镜像id\ndocker rmi 镜像id 镜像id 镜像id 镜像id\n#删除指定名称的镜像\ndocker rmi mysql:5.7\n#迭代删除所有的镜像\ndocker rmi -f $(docker images  -aq)\n运行镜像\ndocker run [可选参数] image\n# 运行实例\ndocker run --name=mycat -d -p 8080:8080 tomcat\n# 用完即删\ndocker run -it --rm tomcat\n# 指定环境变量（实例）\ndocker run -d --name elasticsearch -p 9200:9200 -p 9300:9300 -e &quot;discovery.type=single-node&quot; -e ES_JAVA_OPTS=&quot;-Xms64m -Xmx512m&quot;  elasticsearch:7.6.2\n「参数说明」\n\n\n「—name=“Name”：容器名字 tomacat01、tomacat02区分容器」\n\n\n-「e」: 「指定环境变量」\n\n\n「-d：后台守护进程运行」\n\n\n「-it：使用交互方式运行，进入容器查看内容」\n\n\n「-p：指定容器的端口 -p 8080:8080」\n\n\n「-p ：主机端口：容器端口」\n\n\n「-p ：容器端口」\n\n\n\n\n「-P：随机指定端口」\n\n\n「-v: 指定数据卷」\n\n「-v 容器文件位置:宿主机文件位置」\n\n\n\n「—volumes-from: 指定容器的数据卷共享（指定谁，就同步谁的数据！继承！）」\n\n「—volumes-from:继承自那个容器」（父容器删除不影响已存在数据）\n\n\n\n「—net: 缺省 bridge」\n\n\n进入容器\n# 运行一个centos并进入到容器里面\ndocker run -it centos /bin/bash\n# 退出容器\nexit\n查看容器\n# 查看正在运行中的容器\ndocker ps\n# 查看所有容器\ndocker ps -a\n退出容器\nexit   # 直接容器停止并退出\nCtrl + P + Q  # 容器退出不停止\n删除容器\n# 删除指定容器\ndocker rm bde00bc086cf\n# 强制删除运行中的容器\ndocker rm -f bde00bc086cf\n# 迭代删除全部的容器\ndocker rm -f $(docker ps -aq)\n容器的启动与停止\n# 启动容器\ndocker start 容器id\n# 重启容器\ndocker restart 容器id\n# 停止容器\ndocker stop 容器id\n# 强制杀死容器\ndocker kill 容器id\n进入当前在正在运行中的命令\n# 进入到指定容器内部进行修改  开启一个新的终端\ndocker exec -it 0cd4d9d94de2 /bin/bash\n# 进入到正在执行中的终端\ndocker attach 容器id\n将文件从容器拷贝到宿主机\ndocker cp 容器id:容器内文件的路径 宿主机路径\n#实例\ndocker cp 0cd4d9d94de2:/Test.java /Test.java\n其他常用命令\n「查看日志命令」\n# 查看容器运行产生的日志\ndocker logs -ft --tail 10 容器id\n复制\n「参数解析：」\n\n\n「f: 格式化日志」\n\n\n「t: 携带日志时间戳」\n\n\n查看进程\n# 查看cpu等信息\ndocker top 0cd4d9d94de2\n# 查看容器元信息\ndocker inspect 容器id\n二、可视化面板\n安装\n# 安装可视化面板 portainer （数据卷路径不可改变）\ndocker run -d -p 8088:9000 --restart=always -v /var/run/docker.sock:/var/run/docker.sock --privileged=true portainer/portainer\n\nimage-20200906161505532\n三、提交容器为一个镜像\n\n\n提交容器\n\n\n# 提交一个容器为一个镜像（将容器打包）\ndocker commit [可选参数] 服务id 自定义镜像名称[:版本标签]\n# 示例代码提交\ndocker commit  -a=&quot;huangfu&quot; -m=&quot;增加了主页&quot; 19329ae6df90  diytomcat:1.0\n「参数解释：」\n\n\n「-a: 作者」\n\n\n「-m: 备注」\n\n\n「-c: 将Dockerfile指令应用于创建的映像」\n\n\n「-p: 提交期间暂停容器（默认为true）」\n\n\n四、Docker数据卷使用\n数据卷的基本使用\n# 关联数据卷\ndocker run [可选参数] -v /主机路径/:/容器路径/ 镜像名称\n# 关联数据卷的实例命令\ndocker run -d -p 8080:8080 --name mytomcat -v /home/tomcat/webapps/:/usr/local/tomcat/webapps tomcat\nmysql安装实战\ndocker run -d -p 3366:3306 -v /home/mysql/conf:/etc/mysql/conf.d -v /home/mysql/data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 --name mysql01 mysql:5.7\n「命令解析：」\n\n\n「-d: 守护进程运行」\n\n\n「-v: 添加数据卷（宿主机位置和容器位置映射）」\n\n\n「-p: 堆对外映射端口」\n\n\n「-e: 指定环境变量」\n\n\n「—name: 容器名称」\n\n\n五、Dockerfile\n构建镜像文件\n# 创建一个Dockerfile\nvim Dockerfile\n \nFROM centos\n \nVOLUME [&quot;volume01&quot;,&quot;volume02&quot;]CMD echo &quot;-----end---&quot;CMD /bin/bash\n \n:x\n \n# 构建docker镜像\n# -f dockerfile的路径   \n# -t 生成的镜像名称\n# . 以当前路径为上下文打包\ndocker build -f /home/docker-volom/Dockerfile -t huangfu/centos:1.0 .\n \n# 构建基本命令\ndocker build [OPTIONS] PATH | URL | -\nDockerfile概念\n\n\n每个保留关键字（指令）都必须是大写字母\n\n\n执行顺序从上到下\n\n\n# 表示注释\n\n\n每一个指令都会创建提交一个新的镜像层并提交！\n\n\nDockerfile语法浅析\n\n\n\n「FROM: 基础镜像，一切都从这里开始构建」\n\n\n「MAINTAINER: 镜像是谁写的，姓名+邮箱」\n\n\n「RUN: 镜像构建需要运行的命令」\n\n\n「ADD: 添加一个内容，比如需要添加一个tomcat，则需要传递一个压缩包，便于在容器内构建！」\n\n\n「WORKDIR: 镜像的工作目录」\n\n\n「VOLUME: 挂在的目录」\n\n\n「EXPOSE: 暴露端口」\n\n\n「CMD: 一个指令，指定这个容器启动的时候要运行的命令」\n\n\n「ENTRYPOINT: 指定这个容器启动的时候要运行的命令！可以追加命令！」\n\n\n「ONBUILD: 当构建一个被继承的Dockerfile 这个时候就会运行指令，触发命令！」\n\n\n「COPY: 类似与ADD，将文件拷贝到镜像中」\n\n\n「ENV：构建的时候设置环境变量」\n\n\n# 构建一个具有复杂命令行的centos\nvim Dockerfile\n \n# 镜像继承自centos\nFROM centos\n# 作者信息\nMAINTAINER huangfu&lt;huangfusuper@163.com&gt;\n# 设置环境变量\nENV MYPATH /usr/local\n# 设置工作目录\nWORKDIR $MYPATH\n# 执行命令安装指令\nRUN yum -y install vim\nRUN yum -y install net-tools\n# 暴露端口\nEXPOSE 80\n# 执行一些指令\nCMD echo &quot;-------end------&quot;CMD echo $MYPATHCMD /bin/bash\n \n:x\n \n# 构建镜像\ndocker build -f /home/docker-volom/Dockerfile -t huangfu/diycentos:1.0 .\n六、自定义网络\n网络模式详解\n\n\n「bridge: 桥接网络（默认）」\n\n\n「host：和宿主机共享」\n\n\n「none：不配置网络」\n\n\n「container：容器网络联通」\n\n\n查看所有的网络模式\n# 查看所有的网络模式\ndocker network ls\n创建自定义的网络\n# 创建一个网络\ndocker network create [OPTIONS] NETWORK\n \n# 创建一个mynet\n# create 创建\n# driver 使用的网络模式\n# subnet 子网掩码\n# gateway 网关\n# mynety 自定义的名称\ndocker netywork create --driver bridge --subnet 192.168.0.0/16 --gateway 192.168.0.1 mynety\n使用自定义网络\ndocker run -d --net mynety --name tom01  tomcat\ndocker run -d --net mynety --name tom02  tomcat\n \n# 进入到tom02\ndocker exec -it 7d75a637a90b865fe70259bd4e0b3f5c95133dc65693b05abaf078d31a362529 /bin/bash\n# 结果是互通的\nping tom01\n\n容器网络互通\n# 把自定义网络和容器打通    容器一个容器两个ip\n# 把不在该网络的容器加入当前网络\ndocker network connect 自定义网络 容器\n\n七、打包SpringBoot jar项目\nDockerfile编写\nFROM java:8COPY *.jar /app.jar\n \nCMD [&quot;--server.port=8080&quot;]EXPOSE 8080ENTRYPOINT [&quot;java&quot;,&quot;-jar&quot;,&quot;/app.jar&quot;]\n构建镜像\nmkdir idea\n \ncd idea\n \n# 将 Dockerfile与jar包发送到idea目录\n# 构建镜像\ndocker build -t huangfutest:1.0 .\n# 后面运行不说了\n八、如何容器化应用\n镜像是容器的静态形式，它打包了应用程序的所有运行依赖项，方便保存和传输。使用容器技术运行镜像，就形成了动态的容器，由于镜像只读不可修改，所以应用程序的运行环境总是一致的。\n容器化的应用就是指以镜像的形式打包应用程序，然后在容器环境里从镜像启动容器。\n我这里就对今天的镜像操作和容器操作做个小结：\n\n\n常用的镜像操作有 docker pull、docker images、docker rmi，分别是拉取镜像、查看镜像和删除镜像。\n\n\n用来启动容器的 docker run 是最常用的命令，它有很多参数用来调整容器的运行状态，对于后台服务来说应该使用 -d。\n\n\nDocker exec 命令可以在容器内部执行任意程序，对于调试排错特别有用。\n\n\n其他常用的容器操作还有 docker ps、docker stop、docker rm，用来查看容器、停止容器和删除容器。\n\n\n九、 与外界资源共享\n如何拷贝容器内的数据\nCp 命令，它可以在宿主机和容器之间拷贝文件，是最基本的一种数据交换功能。\nDocker cp 的用法很简单，很类似 Linux 的“cp”“scp”，指定源路径（src path）和目标路径（dest path）就可以了。如果源路径是宿主机那么就是把文件拷贝进容器，如果源路径是容器那么就是把文件拷贝出容器，注意需要用容器名或者容器 ID 来指明是哪个容器的路径。\n \ndocker cp a.txt 062:/tmp\n如何共享主机上的文件\n只需要在 docker run 命令启动容器的时候使用 -v 参数就行，具体的格式是“宿主机路径: 容器内路径”。\n我还是以 Redis 为例，启动容器，使用 -v 参数把本机的“/tmp”目录挂载到容器里的“/tmp”目录，也就是说让容器共享宿主机的“/tmp”目录\n \ndocker run -d --rm -v /tmp:/tmp redis\n如何实现网络互通\nDocker 提供了三种网络模式，分别是 null、host 和 bridge。\n\n\nNull 是最简单的模式，也就是没有网络，但允许其他的网络插件来自定义网络连接，这里就不多做介绍了。\n\n\nHost 的意思是直接使用宿主机网络，相当于去掉了容器的网络隔离（其他隔离依然保留），所有的容器会共享宿主机的 IP 地址和网卡。这种模式没有中间层，自然通信效率高，但缺少了隔离，运行太多的容器也容易导致端口冲突。Host 模式需要在 docker run 时使用 —net=host 参数，下面我就用这个参数启动 Nginx：\n\n\n \ndocker run -d --rm --net=host nginx:alpine\n\n第三种 bridge，也就是桥接模式，它有点类似现实世界里的交换机、路由器，只不过是由软件虚拟出来的，容器和宿主机再通过虚拟网卡接入这个网桥（图中的 docker 0），那么它们之间也就可以正常的收发网络数据包了\n\n如何分配服务端口号\n使用 host 模式或者 bridge 模式，我们的容器就有了 IP 地址，建立了与外部世界的网络连接，接下来要解决的就是网络服务的端口号问题。\n一台主机上的端口号数量是有限的，而且多个服务之间还不能够冲突，但我们打包镜像应用的时候通常都使用的是默认端口，容器实际运行起来就很容易因为端口号被占用而无法启动。\n解决这个问题的方法就是加入一个“中间层”，由容器环境例如 Docker 来统一管理分配端口号，在本机端口和容器端口之间做一个“映射”操作\n端口号映射需要使用 bridge 模式，并且在 docker run 启动容器时使用 -p 参数，形式和共享目录的 -v 参数很类似，用 : 分隔本机端口和容器端口\n \ndocker run -d -p 80:80 --rm nginx:alpine\ndocker run -d -p 8080:80 --rm nginx:alpine\n \n# 这样就把本机的 80 和 8080 端口分别“映射”到了两个容器里的 80 端口\n十、镜像仓库\n什么是镜像仓库（Registry）\n\n右边的区域就是镜像仓库，术语叫 Registry，直译就是“注册中心”，意思是所有镜像的 Repository 都在这里登记保管，就像是一个巨大的档案馆。\n然后我们再来看左边的“docker pull”，虚线显示了它的工作流程，先到“Docker daemon”，再到 Registry，只有当 Registry 里存有镜像才能真正把它下载到本地。\n什么是 Docker Hub\n什么是 Docker Hub\n“Docker Hub”（ hub.docker.com/ ）。\n如何在 Docker Hub 上挑选镜像\nDocker Hub 上有官方镜像、认证镜像和非官方镜像的区别。\n\n\n官方镜像（Official image）：是指 Docker 公司官方提供的高质量镜像（ github.com/docker-library/official-images ），都经过了严格的漏洞扫描和安全检测，支持 x 86_64、arm 64 等多种硬件架构，还具有清晰易读的文档，一般来说是我们构建镜像的首选，也是我们编写 Dockerfile 的最佳范例。\n\n\n认证镜像（Verified publisher）：也就是认证发行商，比如 Bitnami、Rancher、Ubuntu 等。它们都是颇具规模的大公司，具有不逊于 Docker 公司的实力，所以就在 Docker Hub 上开了个认证账号\n\n\n非官方镜像\n\n\n“半官方”镜像。因为成为“Verified publisher”是要给 Docker 公司交钱的，而很多公司不想花这笔“冤枉钱”，所以只在 Docker Hub 上开了公司账号（比如 OpenResty ）\n\n\n第二类就是纯粹的“民间”镜像了，通常是个人上传到 Docker Hub 的，因为条件所限，测试不完全甚至没有测试，质量上难以得到保证，下载的时候需要小心谨慎。\n\n\n\n\nDocker Hub 上镜像命名的规则是什么\n\n\nDocker Hub 也使用了同样的规则，就是“用户名 / 应用名”的形式，比如 bitnami/nginx、ubuntu/nginx、rancher/nginx 等等。\n\n\n因为镜像还会有许多不同的版本，也就是“标签”（tag）。\n\n\n直接使用默认的“latest”虽然简单方便\n\n\n通常来说，镜像标签的格式是应用的版本号加上操作系统。\n\n\n\n\n另外，有的标签还会加上 slim、fat，来进一步表示这个镜像的内容是经过精简的，还是包含了较多的辅助工具。\n\n\n\n离线环境该怎么办\n\n\n在内网环境里仿造 Docker Hub，创建一个自己的私有 Registry 服务，比如 Docker Registry，还有 CNCF Harbor，\n\n\nDocker 提供了 save 和 load 这两个镜像归档命令，可以把镜像导出成压缩包，或者从压缩包导入 Docker，而压缩包是非常容易保管和传输的，可以联机拷贝，FTP 共享，甚至存在 U 盘上随身携带。\n\n\n \ndocker save ngx-app:latest -o ngx.tar\ndocker load -i ngx.tar"},"docker/docker":{"title":"docker","links":[],"tags":["docker"],"content":""},"index":{"title":"index","links":["Obsidian/使用quartz发布obsidian--vault","Java/Java","GO/GO","Python/python","lua/lua","shell/shell","MySQL/MySQL","MongoDB/MongoDB","Redis/Redis","ElasticSearch/ElasticSearch","消息队列/消息队列","微服务/微服务","分布式/分布式","高可用/高可用","高性能/高性能","操作系统/操作系统","网络/计算机网络","编译原理/编译原理","linux/Linux-基础知识总结","Docker/Docker","Kubernetes/Kubernetes","工具/工具","obsidian/Obsidian","zookeeper/ZooKeeper","statistic/Java面试资料1.pdf","statistic/Java面试资料2.pdf","statistic/分布式面试题.pdf"],"tags":[],"content":"😀😁😲🌞🙀\n这是我的 Obsidian 的 vault ,我使用了 quartz 搭建了这个页面。同时可以算是我的博客，用于记录我的心得体会。\n\n关于如何搭建可以看这篇文章 使用quartz发布obsidian  vault\n\n编程语言\n\nJava\nGO\npython\nlua\nshell\n\n数据库和缓存\n\nMySQL\nMongoDB\nRedis\nElasticSearch\n\n消息队列\n\n消息队列\n\n系统设计\n\n微服务\n分布式\n高可用\n高性能\n\n计算机基础\n\n操作系统\n计算机网络\n编译原理\n\n运维\n\nLinux 基础知识总结\nDocker\nKubernetes\n\n常用工具\n\n工具\nObsidian\n\n其他\n\nZooKeeper\nJava面试资料1\nJava面试资料2\n分布式面试题\n"},"linux/Linux-基础知识总结":{"title":"Linux 基础知识总结","links":[],"tags":["linux"],"content":"简单介绍一下 Java 程序员必知的 Linux 的一些概念以及常见命令。\n初探 Linux\nLinux 简介\n通过以下三点可以概括 Linux 到底是什么：\n\n类 Unix 系统：Linux 是一种自由、开放源码的类似 Unix 的操作系统\nLinux 本质是指 Linux 内核：严格来讲，Linux 这个词本身只表示 Linux 内核，单独的 Linux 内核并不能成为一个可以正常工作的操作系统。所以，就有了各种 Linux 发行版。\nLinux 之父 (林纳斯·本纳第克特·托瓦兹 Linus Benedict Torvalds)：一个编程领域的传奇式人物，真大佬！我辈崇拜敬仰之楷模。他是 Linux 内核 的最早作者，随后发起了这个开源项目，担任 Linux 内核的首要架构师。他还发起了 Git 这个开源项目，并为主要的开发者。\n\n\nLinux 诞生\n1989 年，Linus Torvalds 进入芬兰陆军新地区旅，服 11 个月的国家义务兵役，军衔为少尉，主要服务于计算机部门，任务是弹道计算。服役期间，购买了安德鲁·斯图尔特·塔能鲍姆所著的教科书及 minix 源代码，开始研究操作系统。1990 年，他退伍后回到大学，开始接触 Unix。\n\nMinix 是一个迷你版本的类 Unix 操作系统，由塔能鲍姆教授为了教学之用而创作，采用微核心设计。它启发了 Linux 内核的创作。\n\n1991 年，Linus Torvalds 开源了 Linux 内核。Linux 以一只可爱的企鹅作为标志，象征着敢作敢为、热爱生活。\n\n常见的 Linux 发行版本\n\nLinus Torvalds 开源的只是 Linux 内核，我们上面也提到了操作系统内核的作用。一些组织或厂商将 Linux 内核与各种软件和文档包装起来，并提供系统安装界面和系统配置、设定与管理工具，就构成了 Linux 的发行版本。\n\n内核主要负责系统的内存管理，硬件设备的管理，文件系统的管理以及应用程序的管理。\n\nLinux 的发行版本可以大体分为两类：\n\n商业公司维护的发行版本：比如 Red Hat 公司维护支持的 Red Hat Enterprise Linux (RHEL)。\n社区组织维护的发行版本：比如基于 Red Hat Enterprise Linux（RHEL）的 CentOS、基于 Debian 的 Ubuntu。\n\n对于初学者学习 Linux ，推荐选择 CentOS，原因如下：\n\nCentOS 免费且开放源代码；\nCentOS 基于 RHEL，功能与 RHEL 高度一致，安全稳定、性能优秀。\n\nLinux 文件系统\nLinux 文件系统简介\n在 Linux 操作系统中，一切被操作系统管理的资源，如网络接口卡、磁盘驱动器、打印机、输入输出设备、普通文件或目录等，都被视为文件。这是 Linux 系统中一个重要的概念，即”一切都是文件”。\n这种概念源自 UNIX 哲学，即将所有资源都抽象为文件的方式来进行管理和访问。Linux 的文件系统也借鉴了 UNIX 文件系统的设计理念。这种设计使得 Linux 系统可以通过统一的文件接口来管理和操作不同类型的资源，从而实现了一种统一的文件操作方式。例如，可以使用类似于读写文件的方式来对待网络接口、磁盘驱动器、设备文件等，使得操作和管理这些资源更加统一和简便。\n这种文件为中心的设计理念为 Linux 系统带来了灵活性和可扩展性，使得 Linux 成为一种强大的操作系统。同时，这也是 Linux 系统的一大特点，深受广大用户和开发者的喜欢和推崇。\nInode 介绍\nInode 是 Linux/Unix 文件系统的基础。那 inode 到是什么? 有什么作用呢?\n通过以下五点可以概括 inode 到底是什么：\n\n硬盘的最小存储单位是扇区 (Sector)，块 (block)由多个扇区组成。文件数据存储在块中。块的最常见的大小是 4 kb，约为 8 个连续的扇区组成（每个扇区存储 512 字节）。一个文件可能会占用多个 block，但是一个块只能存放一个文件。虽然，我们将文件存储在了块 (block)中，但是我们还需要一个空间来存储文件的 元信息 metadata：如某个文件被分成几块、每一块在的地址、文件拥有者，创建时间，权限，大小等。这种 存储文件元信息的区域就叫 inode，译为索引节点：i（index）+node。 每个文件都有一个唯一的 inode，存储文件的元信息。\nInode 是一种固定大小的数据结构，其大小在文件系统创建时就确定了，并且在文件的生命周期内保持不变。\nInode 的访问速度非常快，因为系统可以直接通过 inode 号码定位到文件的元数据信息，无需遍历整个文件系统。\nInode 的数量是有限的，每个文件系统只能包含固定数量的 inode。这意味着当文件系统中的 inode 用完时，无法再创建新的文件或目录，即使磁盘上还有可用空间。因此，在创建文件系统时，需要根据文件和目录的预期数量来合理分配 inode 的数量。\n可以使用 stat 命令可以查看文件的 inode 信息，包括文件的 inode 号、文件类型、权限、所有者、文件大小、修改时间。\n\n简单来说：inode 就是用来维护某个文件被分成几块、每一块在的地址、文件拥有者，创建时间，权限，大小等信息。\n再总结一下 inode 和 block：\n\ninode：记录文件的属性信息，可以使用 stat 命令查看 inode 信息。\nblock：实际文件的内容，如果一个文件大于一个块时候，那么将占用多个 block，但是一个块只能存放一个文件。（因为数据是由 inode 指向的，如果有两个文件的数据存放在同一个块中，就会乱套了）\n\n\n可以看出，Linux/Unix 操作系统使用 inode 区分不同的文件。这样做的好处是，即使文件名被修改或删除，文件的 inode 号码不会改变，从而可以避免一些因文件重命名、移动或删除导致的错误。同时，inode 也可以提供更高的文件系统性能，因为 inode 的访问速度非常快，可以直接通过 inode 号码定位到文件的元数据信息，无需遍历整个文件系统。\n不过，使用 inode 号码也使得文件系统在用户和应用程序层面更加抽象和复杂，需要通过系统命令或文件系统接口来访问和管理文件的 inode 信息。\n硬链接和软链接\n在 Linux/类 Unix 系统上，文件链接（File Link）是一种特殊的文件类型，可以在文件系统中指向另一个文件。常见的文件链接类型有两种：\n1、硬链接（Hard Link）\n\n在 Linux/类 Unix 文件系统中，每个文件和目录都有一个唯一的索引节点（inode）号，用来标识该文件或目录。硬链接通过 inode 节点号建立连接，硬链接和源文件的 inode 节点号相同，两者对文件系统来说是完全平等的（可以看作是互为硬链接，源头是同一份文件），删除其中任何一个对另外一个没有影响，可以通过给文件设置硬链接文件来防止重要文件被误删。\n只有删除了源文件和所有对应的硬链接文件，该文件才会被真正删除。\n硬链接具有一些限制，不能对目录以及不存在的文件创建硬链接，并且，硬链接也不能跨越文件系统。\nln 命令用于创建硬链接。\n\n2、软链接（Symbolic Link 或 Symlink）\n\n软链接和源文件的 inode 节点号不同，而是指向一个文件路径。\n源文件删除后，软链接依然存在，但是指向的是一个无效的文件路径。\n软连接类似于 Windows 系统中的快捷方式。\n不同于硬链接，可以对目录或者不存在的文件创建软链接，并且，软链接可以跨越文件系统。\nln -s 命令用于创建软链接。\n\n硬链接为什么不能跨文件系统？\n我们之前提到过，硬链接是通过 inode 节点号建立连接的，而硬链接和源文件共享相同的 inode 节点号。\n然而，每个文件系统都有自己的独立 inode 表，且每个 inode 表只维护该文件系统内的 inode。如果在不同的文件系统之间创建硬链接，可能会导致 inode 节点号冲突的问题，即目标文件的 inode 节点号已经在该文件系统中被使用。\nLinux 文件类型\nLinux 支持很多文件类型，其中非常重要的文件类型有: 普通文件，目录文件，链接文件，设备文件，管道文件，Socket 套接字文件 等。\n\n普通文件（-）：用于存储信息和数据， Linux 用户可以根据访问权限对普通文件进行查看、更改和删除。比如：图片、声音、PDF、text、视频、源代码等等。\n目录文件（d，directory file）：目录也是文件的一种，用于表示和管理系统中的文件，目录文件中包含一些文件名和子目录名。打开目录事实上就是打开目录文件。\n符号链接文件（l，symbolic link）：保留了指向文件的地址而不是文件本身。\n字符设备（c，char）：用来访问字符设备比如键盘。\n设备文件（b，block）：用来访问块设备比如硬盘、软盘。\n管道文件 (p，pipe) : 一种特殊类型的文件，用于进程之间的通信。\n套接字文件 (s，socket)：用于进程间的网络通信，也可以用于本机之间的非网络通信。\n\n每种文件类型都有不同的用途和属性，可以通过命令如 ls、file 等来查看文件的类型信息。\n# 普通文件（-）\n-rw-r--r--  1 user  group  1024 Apr 14 10:00 file.txt\n \n# 目录文件（d，directory file）*\ndrwxr-xr-x  2 user  group  4096 Apr 14 10:00 directory/\n \n# 套接字文件(s，socket)\nsrwxrwxrwx  1 user  group    0 Apr 14 10:00 socket\nLinux 目录树\nLinux 使用一种称为目录树的层次结构来组织文件和目录。目录树由根目录（/）作为起始点，向下延伸，形成一系列的目录和子目录。每个目录可以包含文件和其他子目录。结构层次鲜明，就像一棵倒立的树。\n\n常见目录说明：\n\n/bin： 存放二进制可执行文件 (ls、cat、mkdir 等)，常用命令一般都在这里；\n/etc： 存放系统管理和配置文件；\n/home： 存放所有用户文件的根目录，是用户主目录的基点，比如用户 user 的主目录就是/home/user，可以用~user 表示；\n/usr： 用于存放系统应用程序；\n/opt： 额外安装的可选应用程序包所放置的位置。一般情况下，我们可以把 tomcat 等都安装到这里；\n/proc： 虚拟文件系统目录，是系统内存的映射。可直接访问这个目录来获取系统信息；\n/root： 超级用户（系统管理员）的主目录（特权阶级^o^）；\n/sbin: 存放二进制可执行文件，只有 root 才能访问。这里存放的是系统管理员使用的系统级别的管理命令和程序。如 ifconfig 等；\n/dev： 用于存放设备文件；\n/mnt： 系统管理员安装临时文件系统的安装点，系统提供这个目录是让用户临时挂载其他的文件系统；\n/boot： 存放用于系统引导时使用的各种文件；\n/lib 和/lib 64： 存放着和系统运行相关的库文件；\n/tmp： 用于存放各种临时文件，是公用的临时文件存储点；\n/var： 用于存放运行时需要改变数据的文件，也是某些大文件的溢出区，比方说各种服务的日志文件（系统启动日志等。）等；\n/lost+found： 这个目录平时是空的，系统非正常关机而留下“无家可归”的文件（windows 下叫什么. Chk）就在这里。\n\nLinux 常用命令\n下面只是给出了一些比较常用的命令。\n推荐一个 Linux 命令快查网站，非常不错，大家如果遗忘某些命令或者对某些命令不理解都可以在这里得到解决。Linux 命令在线速查手册： wangchujiang.com/linux-command/ 。\n\n另外，shell.how 这个网站可以用来解释常见命令的意思，对你学习 Linux 基本命令以及其他常用命令（如 Git、NPM）。\n\n目录切换\n\ncd usr：切换到该目录下 usr 目录\ncd ..（或cd../）：切换到上一层目录\ncd /：切换到系统根目录\ncd ~：切换到用户主目录\ncd -： 切换到上一个操作所在目录\n\n目录操作\n\nls：显示目录中的文件和子目录的列表。例如：ls /home，显示 /home 目录下的文件和子目录列表。\nll：ll 是 ls -l 的别名，ll 命令可以看到该目录下的所有目录和文件的详细信息\nmkdir [选项] 目录名：创建新目录（增）。例如：mkdir -m 755 my_directory，创建一个名为 my_directory 的新目录，并将其权限设置为 755，即所有用户对该目录有读、写和执行的权限。\nfind [路径] [表达式]：在指定目录及其子目录中搜索文件或目录（查），非常强大灵活。例如：① 列出当前目录及子目录下所有文件和文件夹: find .；② 在 /home 目录下查找以 .txt 结尾的文件名: find /home -name &quot;*.txt&quot; ,忽略大小写: find /home -i name &quot;*.txt&quot; ；③ 当前目录及子目录下查找所有以 .txt 和 .pdf 结尾的文件: find . \\( -name &quot;*.txt&quot; -o -name &quot;*.pdf&quot; \\) 或 find . -name &quot;*.txt&quot; -o -name &quot;*.pdf&quot;。\npwd：显示当前工作目录的路径。\nrmdir [选项] 目录名：删除空目录（删）。例如：rmdir -p my_directory，删除名为 my_directory 的空目录，并且会递归删除 my_directory 的空父目录，直到遇到非空目录或根目录。\nrm [选项] 文件或目录名：删除文件/目录（删）。例如：rm -r my_directory，删除名为 my_directory 的目录，-r (recursive, 递归) 表示会递归删除指定目录及其所有子目录和文件。\ncp [选项] 源文件/目录 目标文件/目录：复制文件或目录（移）。例如：cp file.txt /home/file.txt，将 file.txt 文件复制到 /home 目录下，并重命名为 file.txt。cp -r source destination，将 source 目录及其下的所有子目录和文件复制到 destination 目录下，并保留源文件的属性和目录结构。\nmv [选项] 源文件/目录 目标文件/目录：移动文件或目录（移），也可以用于重命名文件或目录。例如：mv file.txt /home/file.txt，将 file.txt 文件移动到 /home 目录下，并重命名为 file.txt。mv 与 cp 的结果不同，mv 好像文件“搬家”，文件个数并未增加。而 cp 对文件进行复制，文件个数增加了。\n\n文件操作\n像 mv、cp、rm 等文件和目录都适用的命令，这里就不重复列举了。\n\ntouch [选项] 文件名..：创建新文件或更新已存在文件（增）。例如：touch file1.txt file2.txt file3.txt ，创建 3 个文件。\nln [选项] &lt;源文件&gt; &lt;硬链接/软链接文件&gt;：创建硬链接/软链接。例如：ln -s file.txt file_link，创建名为 file_link 的软链接，指向 file.txt 文件。-s 选项代表的就是创建软链接，s 即 symbolic（软链接又名符号链接） 。\ncat/more/less/tail 文件名：文件的查看（查） 。命令 tail -f 文件 可以对某个文件进行动态监控，例如 Tomcat 的日志文件，会随着程序的运行，日志会变化，可以使用 tail -f catalina-2016-11-11.log 监控文件的变化。\nvim 文件名：修改文件的内容（改）。Vim 编辑器是 Linux 中的强大组件，是 vi 编辑器的加强版，vim 编辑器的命令和快捷方式有很多，但此处不一一阐述，大家也无需研究的很透彻，使用 vim 编辑修改文件的方式基本会使用就可以了。在实际开发中，使用 vim 编辑器主要作用就是修改配置文件，下面是一般步骤：vim 文件------&gt;进入文件-----&gt;命令模式------&gt;按i进入编辑模式-----&gt;编辑文件 -------&gt;按Esc进入底行模式-----&gt;输入：wq/q! （输入 wq 代表写入内容并退出，即保存；输入 q! 代表强制退出不保存）。\n\n文件压缩\n1）打包并压缩文件：\nLinux 中的打包文件一般是以 .tar 结尾的，压缩的命令一般是以 .gz 结尾的。而一般情况下打包和压缩是一起进行的，打包并压缩后的文件的后缀名一般 .tar.gz。\n命令：tar -zcvf 打包压缩后的文件名 要打包压缩的文件 ，其中：\n\nZ：调用 gzip 压缩命令进行压缩\nC：打包文件\nV：显示运行过程\nF：指定文件名\n\n比如：假如 test 目录下有三个文件分别是：aaa.txt、 bbb.txt、ccc.txt，如果我们要打包 test 目录并指定压缩后的压缩包名称为 test.tar.gz 可以使用命令：tar -zcvf test.tar.gz aaa.txt bbb.txt ccc.txt 或 tar -zcvf test.tar.gz /test/ 。\n2）解压压缩包：\n命令：tar [-xvf] 压缩文件\n其中 x 代表解压\n示例：\n\n将 /test 下的 test.tar.gz 解压到当前目录下可以使用命令：tar -xvf test.tar.gz\n将 /test 下的 test. Tar. Gz 解压到根目录/usr 下: tar -xvf test.tar.gz -C /usr（-C 代表指定解压的位置）\n\n文件传输\n\nscp [选项] 源文件 远程文件 （scp 即 secure copy，安全复制）：用于通过 SSH 协议进行安全的文件传输，可以实现从本地到远程主机的上传和从远程主机到本地的下载。例如：scp -r my_directory user@remote:/home/user ，将本地目录 my_directory 上传到远程服务器 /home/user 目录下。scp -r user@remote:/home/user/my_directory ，将远程服务器的 /home/user 目录下的 my_directory 目录下载到本地。需要注意的是，scp 命令需要在本地和远程系统之间建立 SSH 连接进行文件传输，因此需要确保远程服务器已经配置了 SSH 服务，并且具有正确的权限和认证方式。\nrsync [选项] 源文件 远程文件 : 可以在本地和远程系统之间高效地进行文件复制，并且能够智能地处理增量复制，节省带宽和时间。例如：rsync -r my_directory user@remote:/home/user，将本地目录 my_directory 上传到远程服务器 /home/user 目录下。\nftp (File Transfer Protocol)：提供了一种简单的方式来连接到远程 FTP 服务器并进行文件上传、下载、删除等操作。使用之前需要先连接登录远程 FTP 服务器，进入 FTP 命令行界面后，可以使用 put 命令将本地文件上传到远程主机，可以使用 get 命令将远程主机的文件下载到本地，可以使用 delete 命令删除远程主机的文件。这里就不进行演示了。\n\n文件权限\n操作系统中每个文件都拥有特定的权限、所属用户和所属组。权限是操作系统用来限制资源访问的机制，在 Linux 中权限一般分为读 (readable)、写 (writable)和执行 (excutable)，分为三组。分别对应文件的属主 (owner)，属组 (group)和其他用户 (other)，通过这样的机制来限制哪些用户、哪些组可以对特定的文件进行什么样的操作。\n通过 ls -l 命令我们可以查看某个目录下的文件或目录的权限\n示例：在随意某个目录下 ls -l\n\n第一列的内容的信息解释如下：\n\n\n下面将详细讲解文件的类型、Linux 中权限以及文件有所有者、所在组、其它组具体是什么？\n\n文件的类型：\n\nD：代表目录\n-：代表文件\nL：代表软链接（可以认为是 window 中的快捷方式）\n\nLinux 中权限分为以下几种：\n\nR：代表权限是可读，r 也可以用数字 4 表示\nW：代表权限是可写，w 也可以用数字 2 表示\nX：代表权限是可执行，x 也可以用数字 1 表示\n\n文件和目录权限的区别：\n对文件和目录而言，读写执行表示不同的意义。\n对于文件：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n权限名称可执行操作r可以使用 cat 查看文件的内容w可以修改文件的内容x可以将其运行为二进制文件\n对于目录：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n权限名称可执行操作r可以查看目录下列表w可以创建和删除目录下文件x可以使用 cd 进入目录\n需要注意的是：超级用户可以无视普通用户的权限，即使文件目录权限是 000，依旧可以访问。\n在 linux 中的每个用户必须属于一个组，不能独立于组外。在 linux 中每个文件有所有者、所在组、其它组的概念。\n\n所有者 (u)：一般为文件的创建者，谁创建了该文件，就天然的成为该文件的所有者，用 ls ‐ahl 命令可以看到文件的所有者也可以使用 chown 用户名文件名来修改文件的所有者。\n文件所在组 (g)：当某个用户创建了一个文件后，这个文件的所在组就是该用户所在的组用 ls ‐ahl 命令可以看到文件的所有组也可以使用 chgrp 组名文件名来修改文件所在的组。\n其它组 (o)：除开文件的所有者和所在组的用户外，系统的其它用户都是文件的其它组。\n\n\n我们再来看看如何修改文件/目录的权限。\n\n修改文件/目录的权限的命令：chmod\n示例：修改/test 下的 aaa. Txt 的权限为文件所有者有全部权限，文件所有者所在的组有读写权限，其他用户只有读的权限。\nchmod u=rwx,g=rw,o=r aaa.txt 或者 chmod 764 aaa.txt\n\n补充一个比较常用的东西:\n假如我们装了一个 zookeeper，我们每次开机到要求其自动启动该怎么办？\n\n新建一个脚本 zookeeper\n为新建的脚本 zookeeper 添加可执行权限，命令是: chmod +x zookeeper\n把 zookeeper 这个脚本添加到开机启动项里面，命令是：chkconfig --add zookeeper\n如果想看看是否添加成功，命令是：chkconfig --list\n\n用户管理\nLinux 系统是一个多用户多任务的分时操作系统，任何一个要使用系统资源的用户，都必须首先向系统管理员申请一个账号，然后以这个账号的身份进入系统。\n用户的账号一方面可以帮助系统管理员对使用系统的用户进行跟踪，并控制他们对系统资源的访问；另一方面也可以帮助用户组织文件，并为用户提供安全性保护。\nLinux 用户管理相关命令:\n\nuseradd [选项] 用户名: 创建用户账号。使用 useradd 指令所建立的帐号，实际上是保存在 /etc/passwd 文本文件中。\nuserdel [选项] 用户名: 删除用户帐号。\nusermod [选项] 用户名: 修改用户账号的属性和配置比如用户名、用户 ID、家目录。\npasswd [选项] 用户名: 设置用户的认证信息，包括用户密码、密码过期时间等。。例如：passwd -S 用户名 ，显示用户账号密码信息。passwd -d 用户名: 清除用户密码，会导致用户无法登录。passwd 用户名，修改用户密码，随后系统会提示输入新密码并确认密码。\nsu [选项] 用户名（su 即 Switch User，切换用户）：在当前登录的用户和其他用户之间切换身份。\n\n用户组管理\n每个用户都有一个用户组，系统可以对一个用户组中的所有用户进行集中管理。不同 Linux 系统对用户组的规定有所不同，如 Linux 下的用户属于与它同名的用户组，这个用户组在创建用户时同时创建。\n用户组的管理涉及用户组的添加、删除和修改。组的增加、删除和修改实际上就是对 /etc/group 文件的更新。\nLinux 系统用户组的管理相关命令:\n\ngroupadd [选项] 用户组 : 增加一个新的用户组。\ngroupdel 用户组: 要删除一个已有的用户组。\ngroupmod [选项] 用户组 : 修改用户组的属性。\n\n系统状态\n\ntop [选项]：用于实时查看系统的 CPU 使用率、内存使用率、进程信息等。\nhtop [选项]：类似于 top，但提供了更加交互式和友好的界面，可让用户交互式操作，支持颜色主题，可横向或纵向滚动浏览进程列表，并支持鼠标操作。\nuptime [选项]：用于查看系统总共运行了多长时间、系统的平均负载等信息。\nvmstat [间隔时间] [重复次数]：vmstat （Virtual Memory Statistics） 的含义为显示虚拟内存状态，但是它可以报告关于进程、内存、I/O 等系统整体运行状态。\nfree [选项]：用于查看系统的内存使用情况，包括已用内存、可用内存、缓冲区和缓存等。\ndf [选项] [文件系统]：用于查看系统的磁盘空间使用情况，包括磁盘空间的总量、已使用量和可用量等，可以指定文件系统上。例如：df -a，查看全部文件系统。\ndu [选项] [文件]：用于查看指定目录或文件的磁盘空间使用情况，可以指定不同的选项来控制输出格式和单位。\nsar [选项] [时间间隔] [重复次数]：用于收集、报告和分析系统的性能统计信息，包括系统的 CPU 使用、内存使用、磁盘 I/O、网络活动等详细信息。它的特点是可以连续对系统取样，获得大量的取样数据。取样数据和分析的结果都可以存入文件，使用它时消耗的系统资源很小。\nps [选项]：用于查看系统中的进程信息，包括进程的 ID、状态、资源使用情况等。ps -ef / ps -aux：这两个命令都是查看当前系统正在运行进程，两者的区别是展示格式不同。如果想要查看特定的进程可以使用这样的格式：ps aux|grep redis （查看包括 redis 字符串的进程），也可使用 pgrep redis -a。\nsystemctl [命令] [服务名称]：用于管理系统的服务和单元，可以查看系统服务的状态、启动、停止、重启等。\n\n网络通信\n\nping [选项] 目标主机：测试与目标主机的网络连接。\nifconfig 或 ip：用于查看系统的网络接口信息，包括网络接口的 IP 地址、MAC 地址、状态等。\nnetstat [选项]：用于查看系统的网络连接状态和网络统计信息，可以查看当前的网络连接情况、监听端口、网络协议等。\nss [选项]：比 netstat 更好用，提供了更快速、更详细的网络连接信息。\n\n其他\n\nsudo + 其他命令：以系统管理者的身份执行指令，也就是说，经由 sudo 所执行的指令就好像是 root 亲自执行。\ngrep 要搜索的字符串 要搜索的文件 --color：搜索命令，—color 代表高亮显示。\nkill -9 进程的pid：杀死进程（-9 表示强制终止）先用 ps 查找进程，然后用 kill 杀掉。\nshutdown：shutdown -h now：指定现在立即关机；shutdown +5 &quot;System will shutdown after 5 minutes&quot;：指定 5 分钟后关机，同时送出警告信息给登入用户。\nreboot：reboot：重开机。reboot -w：做个重开机的模拟（只有纪录并不会真的重开机）。\n\nLinux 环境变量\n在 Linux 系统中，环境变量是用来定义系统运行环境的一些参数，比如每个用户不同的主目录（HOME）。\n环境变量分类\n按照作用域来分，环境变量可以简单的分成:\n\n用户级别环境变量 : ~/.bashrc、~/.bash_profile。\n系统级别环境变量 : /etc/bashrc、/etc/environment、/etc/profile、/etc/profile.d。\n\n上述配置文件执行先后顺序为：/etc/environment –&gt; /etc/profile –&gt; /etc/profile.d –&gt; ~/.bash_profile –&gt; /etc/bashrc –&gt; ~/.bashrc\n如果要修改系统级别环境变量文件，需要管理员具备对该文件的写入权限。\n建议用户级别环境变量在 ~/.bash_profile 中配置，系统级别环境变量在 /etc/profile.d 中配置。\n按照生命周期来分，环境变量可以简单的分成:\n\n永久的：需要用户修改相关的配置文件，变量永久生效。\n临时的：用户利用 export 命令，在当前终端下声明环境变量，关闭 shell 终端失效。\n\n读取环境变量\n通过 export 命令可以输出当前系统定义的所有环境变量。\n# 列出当前的环境变量值\nexport -p\n除了 export 命令之外， env 命令也可以列出所有环境变量。\necho 命令可以输出指定环境变量的值。\n# 输出当前的PATH环境变量的值\necho $PATH\n# 输出当前的HOME环境变量的值\necho $HOME\n环境变量修改\n通过 export 命令可以修改指定的环境变量。不过，这种方式修改环境变量仅仅对当前 shell 终端生效，关闭 shell 终端就会失效。修改完成之后，立即生效。\nexport CLASSPATH=./JAVA_HOME/lib;$JAVA_HOME/jre/lib\n通过 vim 命令修改环境变量配置文件。这种方式修改环境变量永久有效。\nvim ~/.bash_profile\n如果修改的是系统级别环境变量则对所有用户生效，如果修改的是用户级别环境变量则仅对当前用户生效。\n修改完成之后，需要 source 命令让其生效或者关闭 shell 终端重新登录。\nsource /etc/profile"},"lua/lua":{"title":"lua基础","links":["/","tags/NAME"],"tags":["lua","NAME"],"content":"Lua 简介\nLua 是一个小巧的脚本语言。是巴西里约热内卢天主教大学（Pontifical Catholic University of Rio de Janeiro）里的一个研究小组并于 1993 年开发。其设计目的是为了嵌入应用程序中，从而为应用程序提供灵活的扩展和定制功能。Lua 由标准 C 编写而成，几乎在所有操作系统和平台上都可以编译、运行。Lua 并没有提供强大的库，这是由它的定位决定的。所以 Lua 不适合作为开发独立应用程序的语言。Lua 有一个同时进行的 JIT 项目，提供在特定平台上的即时编译功能。\n\n\nLua 脚本可以很容易的被 C/C++ 代码调用，也可以反过来调用 C/C++ 的函数，这使得 Lua 在应用程序中可以被广泛应用。\n\n\n不仅仅作为扩展脚本，也可以作为普通的配置文件，代替 XML、ini 等文件格式，并且更容易理解和维护。\n\n\n标准 Lua 5.1 解释器由标准 C 编写而成，代码简洁优美，几乎在所有操作系统和平台上都可以编译和运行；\n\n\n一个完整的标准 Lua 5.1 解释器不足 200 KB。而本书推荐使用的 LuaJIT 2 的代码大小也只有不足 500 KB\n\n\n同时也支持大部分常见的体系结构。在目前所有脚本语言引擎中，LuaJIT 2 实现的速度应该算是最快的之一。这一切都决定了 Lua 是作为嵌入式脚本的最佳选择。\n\n\nLua 语言的各个版本是不相兼容的。因此本书只介绍 Lua 5.1 语言，这是为标准 Lua 5.1 解释器和 LuaJIT 2 所共同支持的。LuaJIT 支持的对 Lua 5.1 向后兼容的 Lua 5.2 和 Lua 5.3 的特性，我们也会在方便的时候予以介绍。\nLua 环境搭建\nopenresty.org\nHelloworld\n# cat hello.lua\nprint(&quot;hello world&quot;)\n# luajit hello.lua\nhello world\n基本数据类型\nprint(type(&quot;helloworld&quot;))\nprint(type(&#039;helloworld&#039;))\nprint(type(&#039;true&#039;))\nprint(type(1))\nprint(type(2.1))\nprint(type(nil))\nfunction hello()\n    print(&quot;hello&quot;)\nend\nprint(type(hello))\n输出\nstring\nstring\nstring\nnumber\nnumber\nnil\nfunction\nNil\nNil 是一种类型，Lua 将 nil 用于表示“无效值”。\n\n\n一个变量在第一次赋值前的默认值是 nil，\n\n\n将 nil 赋予给一个全局变量就等同于删除它。\n\n\nlocal num\nprint(num)        --&gt;output:nil\n \nnum = 100\nprint(num)        --&gt;output:100\nBoolean (布尔)\n布尔类型，可选值 true/false；\n\n\nLua 中 nil 和 false 为“假”\n\n\n其它所有值均为“真”。比如 0 和空字符串就是“真”；\n\n\nlocal a = true\nlocal b = 0\nlocal c = nil\nif a then\n    print(&quot;a&quot;)        --&gt;output:a\nelse\n    print(&quot;not a&quot;)    --这个没有执行\nend\n \nif b then\n    print(&quot;b&quot;)        --&gt;output:b\nelse\n    print(&quot;not b&quot;)    --这个没有执行\nend\n \nif c then\n    print(&quot;c&quot;)        --这个没有执行\nelse\n    print(&quot;not c&quot;)    --&gt;output:not c\nend\nnumber（数字）\nNumber 类型用于表示实数，和 C/C++ 里面的 double 类型很类似。可以使用数学函数 math. Floor（向下取整）和 math. Ceil（向上取整）进行取整操作。\n一般地，Lua 的 number 类型就是用双精度浮点数来实现的。值得一提的是，LuaJIT 支持所谓的“dual-number”（双数）模式，\n\n即 LuaJIT 会根据上下文用整型来存储整数，而用双精度浮点数来存放浮点数。\n\nlocal order = 3.99\nlocal score = 98.01\nprint(math.floor(order))   --&gt;output:3\nprint(math.ceil(score))    --&gt;output:99\nprint(9223372036854775807LL - 1)  --&gt;output:9223372036854775806LL\nString（字符串）\nLua 中有三种方式表示字符串:\n\n\n使用一对匹配的单引号。例：‘hello’。\n\n\n使用一对匹配的双引号。例：“abclua”。\n\n\n字符串还可以用一种长括号（即 ）括起来的方式定义\n\n\n我们把两个正的方括号（即[[）间插入 n 个等号定义为第 n 级正长括号。\n\n\n0 级正的长括号写作 [[ ，一级正的长括号写作 [=[\n\n\n反的长括号也作类似定义；举个例子，4 级反的长括号写作 ]====]\n\n\n一个长字符串可以由任何一级的正的长括号开始，而由第一个碰到的同级反的长括号结束。整个词法分析过程将不受分行限制，不处理任何转义符，并且忽略掉任何不同级别的长括号\n\n\n\n\nlocal str1 = &#039;hello world&#039;\nlocal str2 = &quot;hello lua&quot;\nlocal str3 = [[&quot;add\\name&quot;,&#039;hello&#039;]]\nlocal str4 = [=[string have a [[]].]=]\nlocal str5 = [=[asdfasd]=]\n \nprint(str1)    --&gt;output:hello world\nprint(str2)    --&gt;output:hello lua\nprint(str3)    --&gt;output:&quot;add\\name&quot;,&#039;hello&#039;\nprint(str4)    --&gt;output:string have a [[]].\nprint(str5)    --&gt;output:asdfasd\n在 Lua 实现中，Lua 字符串一般都会经历一个“内化”（intern）的过程，即两个完全一样的 Lua 字符串在 Lua 虚拟机中只会存储一份。每一个 Lua 字符串在创建时都会插入到 Lua 虚拟机内部的一个全局的哈希表中\n\n\n创建相同的 Lua 字符串并不会引入新的动态内存分配操作，所以相对便宜（但仍有全局哈希表查询的开销），\n\n\n内容相同的 Lua 字符串不会占用多份存储空间，\n\n\n已经创建好的 Lua 字符串之间进行相等性比较时是 O(1) 时间度的开销，而不是通常见到的 O(n).\n\n\nTable (表)\nTable 类型实现了一种抽象的“关联数组”。“关联数组”是一种具有特殊索引方式的数组，\n\n索引通常是字符串（string）或者 number 类型，但也可以是除 nil 以外的任意类型的值\n\n \nlocal corp = {\n    web = &quot;www.google.com&quot;,   --索引为字符串，key = &quot;web&quot;,\n    --            value = &quot;www.google.com&quot;\n    telephone = &quot;12345678&quot;,   --索引为字符串\n    staff = {&quot;Jack&quot;, &quot;Scott&quot;, &quot;Gary&quot;}, --索引为字符串，值也是一个表\n    100876,              --相当于 [1] = 100876，此时索引为数字\n    --      key = 1, value = 100876\n    100191,              --相当于 [2] = 100191，此时索引为数字\n    [10] = 360,          --直接把数字索引给出\n    [&quot;city&quot;] = &quot;Beijing&quot; --索引为字符串\n}\n \nprint(corp.web)               --&gt;output:www.google.com\nprint(corp[&quot;web&quot;])               --&gt;output:www.google.com\nprint(corp[&quot;telephone&quot;])      --&gt;output:12345678\nprint(corp[2])                --&gt;output:100191\nprint(corp[&quot;city&quot;])           --&gt;output:&quot;Beijing&quot;\nprint(corp.staff[1])          --&gt;output:Jack\nprint(corp[&quot;staff&quot;][1])          --&gt;output:Jack\nprint(corp[10])               --&gt;output:360\n在内部实现上，table 通常实现为一个哈希表、一个数组、或者两者的混合。具体的实现为何种形式，动态依赖于具体的 table 的键分布特点。\nFunction (函数)\n在 Lua 中，函数 也是一种数据类型，函数可以存储在变量中，可以通过参数传递给其他函数，还可以作为其他函数的返回值\nlocal function foo()\n    print(&quot;in the function&quot;)\n    --dosomething()\n    local x = 10\n    local y = 20\n    return x + y\nend\n \nlocal a = foo    --把函数赋给变量\n \nprint(a())\n \n--output:\n--in the function\n--30\n \nfunction foo()\nend\n--等价于\n \nfoo = function ()\nend\n \nlocal function foo()\nend\n-- 等价于\n \nlocal foo = function ()\nend\n表达式\n算术运算符\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n算术运算符说明+加法-减法*乘法/除法^指数%取模\nprint(1 + 2)       --&gt;打印 3\nprint(5 / 10)      --&gt;打印 0.5。 这是Lua不同于c语言的\nprint(5.0 / 10)    --&gt;打印 0.5。 浮点数相除的结果是浮点数\n-- print(10 / 0)   --&gt;注意除数不能为0，计算的结果会出错\nprint(2 ^ 10)      --&gt;打印 1024。 求2的10次方\n \nlocal num = 1357\nprint(num % 2)       --&gt;打印 1\nprint((num % 2) == 1) --&gt;打印 true。 判断num是否为奇数\n关系运算符\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n关系运算符说明&lt;小于&gt;大于⇐小于等于&gt;=大于等于==等于~=不等于\nprint(1 &lt; 2)    --&gt;打印 true\nprint(1 == 2)   --&gt;打印 false\nprint(1 ~= 2)   --&gt;打印 true\nlocal a, b = true, false\nprint(a == b)  --&gt;打印 false\n\n在使用“==”做等于判断时，要注意对于 table, userdate 和函数， Lua 是作引用比较的。也就是说，只有当两个变量引用同一个对象时，才认为它们相等\n\nlocal a = { x = 1, y = 0}\nlocal b = { x = 1, y = 0}\nif a == b then\n    print(&quot;a==b&quot;)\nelse\n    print(&quot;a~=b&quot;)\nend\n---output:\na~=b\n\n\nLua 字符串总是会被“内化”，即相同内容的字符串只会被保存一份，因此 Lua 字符串之间的相等性比较可以简化为其内部存储地址的比较。\n\n\n这意味着 Lua 字符串的相等性比较总是为 O (1)\n\n\n逻辑运算符\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n逻辑运算符说明and逻辑与or逻辑或not逻辑非\n在 c 语言中，and 和 or 只得到两个值 1 和 0，其中 1 表示真，0 表示假。而 Lua 中 and 的执行过程是这样的：\n\n\na and b 如果 a 为 nil，则返回 a，否则返回 b;\n\n\na or b 如果 a 为 nil，则返回 b，否则返回 a。\n\n\n所有逻辑操作符将 false 和 nil 视作假，其他任何值视作真，对于 and 和 or，“短路求值”，对于 not，永远只返回 true 或者 false。\n\n\nlocal c = nil\nlocal d = 0\nlocal e = 100\nprint(c and d)  --&gt;打印 nil\nprint(c and e)  --&gt;打印 nil\nprint(d and e)  --&gt;打印 100\nprint(c or d)   --&gt;打印 0\nprint(c or e)   --&gt;打印 100\nprint(not c)    --&gt;打印 true\nprint(not d)    --&gt;打印 false\n字符串连接\nLua 中连接两个字符串，可以使用操作符“..”（两个点）\n\n\n如果其任意一个操作数是数字的话，Lua 会将这个数字转换成字符串。\n\n\n注意，连接操作符只会创建一个新字符串，而不会改变原操作数\n\n\n也可以使用 string 库函数 string.format 连接字符串\n\n\nprint(&quot;Hello &quot; .. &quot;World&quot;)    --&gt;打印 Hello Worldprint(0 .. 1)                 --&gt;打印 01\n \nstr1 = string.format(&quot;%s-%s&quot;,&quot;hello&quot;,&quot;world&quot;)\nprint(str1)              --&gt;打印 hello-world\n \nstr2 = string.format(&quot;%d-%s-%.2f&quot;,123,&quot;world&quot;,1.21)\nprint(str2)              --&gt;打印 123-world-1.21\n于 Lua 字符串本质上是只读的，因此字符串连接运算符几乎总会创建一个新的（更大的）字符串。这意味着如果有很多这样的连接操作（比如在循环中使用 .. 来拼接最终结果），则性能损耗会非常大。在这种情况下，推荐使用 table 和 table.concat() 来进行很多字符串的拼接\nlocal pieces = {}\nfor i, elem in ipairs(my_list) do\n    pieces[i] = my_process(elem)\nend\nlocal res = table.concat(pieces)\n上面的例子还可以使用 LuaJIT 独有的 table.new 来恰当地初始化 pieces 表的空间，以避免该表的动态生长。\n优先级\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nf^not # -* / %+ -..&lt; &gt; ⇐ &gt;= == ~=andor\nlocal a, b = 1, 2\nlocal x, y = 3, 4\nlocal i = 10\nlocal res = 0\nres = a + i &lt; b/2 + 1  --&gt;等价于res =  (a + i) &lt; ((b/2) + 1)\nres = 5 + x^2*8        --&gt;等价于res =  5 + ((x^2) * 8)\nres = a &lt; y and y &lt;=x  --&gt;等价于res =  (a &lt; y) and (y &lt;= x)\n控制结构\nIf-else\n单个 if 分支型\nx = 10\nif x &gt; 0 then\n    print(&quot;x is a positive number&quot;)\nend\n两个分支 if-else 型\nx = 10\nif x &gt; 0 then\n    print(&quot;x is a positive number&quot;)\nelse\n    print(&quot;x is a non-positive number&quot;)\nend\n多个分支的 if-elseif-else\n \nscore = 90\nif score == 100 then\n    print(&quot;Very good!Your score is 100&quot;)\nelseif score &gt;= 60 then\n    print(&quot;Congratulations, you have passed it,your score greater or equal to 60&quot;)\n    --此处可以添加多个elseif\nelse\n    print(&quot;Sorry, you do not pass the exam! &quot;)\nend\n与 C 语言的不同之处是 else 与 if 是连在一起的，若将 else 与 if 写成 “else if” 则相当于在 else 里嵌套另一个 if 语句，如下代码：\nscore = 0\nif score == 100 then\n    print(&quot;Very good!Your score is 100&quot;)\nelseif score &gt;= 60 then\n    print(&quot;Congratulations, you have passed it,your score greater or equal to 60&quot;)\nelse\n    if score &gt; 0 then\n        print(&quot;Your score is better than 0&quot;)\n    else\n        print(&quot;My God, your score turned out to be 0&quot;)\n    end --与上一示例代码不同的是，此处要添加一个end\nend\nWhile\nwhile 表达式 do\n    --body\nend\nRepeat\nLua 中的 repeat 控制结构类似于其他语言（如：C++ 语言）中的 do-while，但是控制方式是刚好相反的。简单点说，执行 repeat 循环体后，直到 until 的条件为真时才结束\n-- 以下代码会死循环\nx = 10\nrepeat\n    print(x)\nuntil false\nFor\nfor 数字型\nfor var = begin, finish, step do\n    --body\nend\n\n\nVar 从 begin 变化到 finish，每次变化都以 step 作为步长递增 var\n\n\nBegin、finish、step 三个表达式只会在循环开始时执行一次\n\n\n第三个表达式 step 是可选的，默认为 1\n\n\n控制变量 var 的作用域仅在 for 循环内，需要在外面控制，则需将值赋给一个新的变量\n\n\n循环过程中不要改变控制变量的值，那样会带来不可预知的影响\n\n\nfor i = 1, 5 do\n    print(i)\nend\n-- output:\n1\n2\n3\n4\n5\n \nfor i = 1, 10, 2 do\n    print(i)\nend\n-- output:\n1\n3\n5\n7\n9\nFor 泛型\n泛型 for 循环通过一个迭代器（iterator）函数来遍历所有值：\n-- 打印数组a的所有值local a = {&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;}\nfor i, v in ipairs(a) do\n    print(&quot;index:&quot;, i, &quot; value:&quot;, v)\nend\n-- output:\nindex:  1  value: a\nindex:  2  value: b\nindex:  3  value: c\nindex:  4  value: d\nLua 的基础库提供了 ipairs，这是一个用于遍历数组的迭代器函数。在每次循环中，i 会被赋予一个索引值，同时 v 被赋予一个对应于该索引的数组元素值。\n-- 打印table t中所有的\nkeyfor k in pairs(t) do\n    print(k)\nend\n通过不同的迭代器，几乎可以遍历所有的东西，而且写出的代码极具可读性。标准库提供了几种迭代器，包括用于迭代文件中每行的（io. Lines）、迭代 table 元素的（pairs）、迭代数组元素的（ipairs）、迭代字符串中单词的（string. Gmatch）\n泛型 for 循环与数字型 for 循环有两个相同点：\n\n\n循环变量是循环体的局部变量；\n\n\n决不应该对循环变量作任何赋值。\n\n\n在 LuaJIT 2.1 中，ipairs() 内建函数是可以被 JIT 编译的，而 pairs() 则只能被解释执行。因此在性能敏感的场景，应当合理安排数据结构，避免对哈希表进行遍历\nBreak\n语句 break 用来终止 while、repeat 和 for 三种循环的执行，并跳出当前循环体，继续执行当前循环之后的语句\n-- 计算最小的x,使从1到x的所有数相加和大于100\nsum = 0\ni = 1while true do\n    sum = sum + i\n    if sum &gt; 100 then\n        break\n    end\n    i = i + 1\nend\nprint(&quot;The result is &quot; .. i)  \n--&gt;output:The result is 14\nReturn\nreturn 主要用于从函数中返回结果，或者用于简单的结束一个函数的执行。\nlocal function add(x, y)\n    return x + y\n    --print(&quot;add: I will return the result &quot; .. (x + y))\n    --因为前面有个return，若不注释该语句，则会报错\nend\n \nlocal function is_positive(x)\n    if x &gt; 0 then\n        return x .. &quot; is positive&quot;\n    else\n        return x .. &quot; is non-positive&quot;\n    end\n \n    --由于return只出现在前面显式的语句块，所以此语句不注释也不会报错\n    --，但是不会被执行，此处不会产生输出\n    print(&quot;function end!&quot;)\nend\n \nlocal sum = add(10, 20)\nprint(&quot;The sum is &quot; .. sum)  --&gt;output:The sum is 30\nlocal answer = is_positive(-10)\nprint(answer)                --&gt;output:-10 is non-positive\nGoto\n有了 goto，我们可以实现 continue 的功能：\nfor i=1, 3 do\n    if i &lt;= 2 then\n        print(i, &quot;yes continue&quot;)\n        goto continue\n    end\n    print(i, &quot; no continue&quot;)\n \n    ::continue::\n    print([[i&#039;m end]])\nend\n输出结果\n$ luajit test.lua\n1   yes continue\ni&#039;m end\n2   yes continue\ni&#039;m end\n3    no continue\ni&#039;m end\n函数\n定义\nfunction function_name (arc)  -- arc 表示参数列表，函数的参数列表可以为空\n    -- body\nend\n上面的语法定义了一个全局函数，名为 function_name. 全局函数本质上就是函数类型的值赋给了一个全局变量，即上面的语法等价于\nfunction_name = function (arc)\n     -- body\nend\n由于全局变量一般会污染全局名字空间，同时也有性能损耗（即查询全局环境表的开销），因此我们应当尽量使用“局部函数”，其记法是类似的，只是开头加上 local 修饰符：\nlocal function function_name (arc)\n    -- body\nend\n定义函数\n\n\n利用名字来解释函数、变量的目的，使人通过名字就能看出来函数、变量的作用。\n\n\n每个函数的长度要尽量控制在一个屏幕内，一眼可以看明白。\n\n\n让代码自己说话，不需要注释最好。\n\n\n由于函数定义等价于变量赋值，我们也可以把函数名替换为某个 Lua 表的某个字段，例如\nlocal foo = {}\nfunction foo.pr()\n    print(&quot;ssss&quot;)\nend\n \nfoo.pr()\n参数\n按值传递\nLua 函数的参数大部分是按值传递的。当函数参数是 table 类型时，传递进来的是实际参数的引用\n值传递就是调用函数时，实参把它的值通过赋值运算传递给形参，然后形参的改变和实参就没有关系了。在这个过程中，实参是通过它在参数表中的位置与形参匹配起来的。\nlocal function swap(a, b) --定义函数swap,函数内部进行交换两个变量的值\n    local temp = a\n    a = b\n    b = temp\n    print(a, b)\nend\n \nlocal x = &quot;hello&quot;\nlocal y = 20\nprint(x, y)\nswap(x, y)    --调用swap函数\nprint(x, y)   --调用swap函数后，x和y的值并没有交换\n \n--&gt;output\nhello 20\n20  hello\nhello 20\n在调用函数的时候，若形参个数和实参个数不同时，Lua 会自动调整实参个数。调整规则：\n\n\n若实参个数大于形参个数，从左向右，多余的实参被忽略；\n\n\n若实参个数小于形参个数，从左向右，没有被实参初始化的形参会被初始化为 nil\n\n\nlocal function fun1(a, b)       --两个形参，多余的实参被忽略掉\n    print(a, b)\nend\n \nlocal function fun2(a, b, c, d) --四个形参，没有被实参初始化的形参，用nil初始化\n    print(a, b, c, d)\nend\n \nlocal x = 1\nlocal y = 2\nlocal z = 3\n \nfun1(x, y, z)         -- z被函数fun1忽略掉了，参数变成 x, y\nfun2(x, y, z)         -- 后面自动加上一个nil，参数变成 x, y, z, nil\n \n--&gt;output\n1   2\n1   2   3   nil\n变长参数\n其实 Lua 还支持变长参数。若形参为 ...，表示该函数可以接收不同长度的参数。访问参数的时候也要使用 ...\n \nlocal function func( ... )                -- 形参为 ... ,表示函数采用变长参数\n \n    local temp = {...}                     -- 访问的时候也要使用 ...\n    local ans = table.concat(temp, &quot; &quot;)    -- 使用 table.concat 库函数对数\n    -- 组内容使用 &quot; &quot; 拼接成字符串。\n    print(ans)\nend\n \nfunc(1, 2)        -- 传递了两个参数\nfunc(1, 2, 3, 4)  -- 传递了四个参数\n \n--&gt;output\n1 2\n \n1 2 3 4\n具名参数\nLua 还支持通过名称来指定实参，这时候要把所有的实参组织到一个 table 中，并将这个 table 作为唯一的实参传给函数。\nlocal function change(arg) -- change 函数，改变长方形的长和宽，使其各增长一倍\n  arg.width = arg.width * 2\n  arg.height = arg.height * 2return arg\nendlocal rectangle = { width = 20, height = 15 }\nprint(&quot;before change:&quot;, &quot;width  =&quot;, rectangle.width,\n                        &quot;height =&quot;, rectangle.height)\nrectangle = change(rectangle)\nprint(&quot;after  change:&quot;, &quot;width  =&quot;, rectangle.width,\n                        &quot;height =&quot;, rectangle.height)\n \n--&gt;output\nbefore change: width = 20  height =  15\nafter  change: width = 40  height =  30\n按引用传递\n当函数参数是 table 类型时，传递进来的是实际参数的引用，此时在函数内部对该 table 所做的修改，会直接对调用者所传递的实际参数生效，而无需自己返回结果和让调用者进行赋值\nfunction change(arg) --change函数，改变长方形的长和宽，使其各增长一倍\n  arg.width = arg.width * 2  --表arg不是表rectangle的拷贝，他们是同一个表\n  arg.height = arg.height * 2end                  -- 没有return语句了local rectangle = { width = 20, height = 15 }\nprint(&quot;before change:&quot;, &quot;width = &quot;, rectangle.width,\n                        &quot; height = &quot;, rectangle.height)\nchange(rectangle)\nprint(&quot;after change:&quot;, &quot;width = &quot;, rectangle.width,\n                       &quot; height =&quot;, rectangle.height)\n \n--&gt; output\nbefore change: width = 20  height = 15\nafter  change: width = 40  height = 30\n函数返回值\nLua 具有一项与众不同的特性，允许函数返回多个值。\nlocal function swap(a, b)   \n    -- 定义函数 swap，实现两个变量交换值\n    return b, a              \n    -- 按相反顺序返回变量的值\nend\n \nlocal x = 1\nlocal y = 20\nx, y = swap(x, y)           -- 调用 swap 函数\nprint(x, y)                 --&gt; output   20     1\n当函数返回值的个数和接收返回值的变量的个数不一致时，Lua 也会自动调整参数个数调整规则：\n\n\n若返回值个数大于接收变量的个数，多余的返回值会被忽略掉；\n\n\n若返回值个数小于参数个数，从左向右，没有被返回值初始化的变量会被初始化为 nil。\n\n\nfunction init()             \n    --init 函数 返回两个值 1 和 &quot;lua&quot;\n    return 1, &quot;lua&quot;\nend\n \nx = init()\nprint(x)\n \nx, y, z = init()\nprint(x, y, z)\n \n--output\n1\n1 lua nil\n当一个函数有一个以上返回值，且函数调用不是一个列表表达式的最后一个元素，那么函数调用只会产生一个返回值, 也就是第一个返回值。\nlocal function init()       -- init 函数 返回两个值 1 和 &quot;lua&quot;\n    return 1, &quot;lua&quot;\nend\n \nlocal x, y, z = init(), 2   -- init 函数的位置不在最后，此时只返回 1\nprint(x, y, z)              --&gt;output  1  2  nil\n \nlocal a, b, c = 2, init()   -- init 函数的位置在最后，此时返回 1 和 &quot;lua&quot;\nprint(a, b, c)              --&gt;output  2  1  lua\n函数调用的实参列表也是一个列表表达式。考虑下面的例子：\nlocal function init()\n    return 1, &quot;lua&quot;\nend\n \nprint(init(), 2)   --&gt;output  1  2\nprint(2, init())   --&gt;output  2  1  lua\n如果你确保只取函数返回值的第一个值，可以使用括号运算符\nlocal function init()\n    return 1, &quot;lua&quot;\nend\nprint((init()), 2)   --&gt;output  1  2\nprint(2, (init()))   --&gt;output  2  1\n值得一提的是，如果实参列表中某个函数会返回多个值，同时调用者又没有显式地使用括号运算符来筛选和过滤，则这样的表达式是不能被 LuaJIT 2 所 JIT 编译的，而只能被解释执行。\n全动态函数调用\n调用回调函数，并把一个数组参数作为回调函数的参数。\nlocal args = {...} or {}\nmethod_name(unpack(args, 1, table.maxn(args)))\nlocal function run(x, y)\n    print(&#039;run&#039;, x, y)\nend\n \nlocal function attack(targetId)\n    print(&#039;targetId&#039;, targetId)\nend\n \nlocal function do_action(method, ...)\n    local args = {...} or {}\n    method(unpack(args, 1, table.maxn(args)))\nend\n \ndo_action(run, 1, 2)         -- output: run 1 2\ndo_action(attack, 1111)      -- output: targetId    1111\n模块\n从 Lua 5.1 语言添加了对模块和包的支持。一个 Lua 模块的数据结构是用一个 Lua 值（通常是一个 Lua 表或者 Lua 函数）。一个 Lua 模块代码就是一个会返回这个 Lua 值的代码块\n\n\n可以使用内建函数 require() 来加载和缓存模块。\n\n\n简单的说，一个代码模块就是一个程序库，可以通过 require 来加载。模块加载后的结果通过是一个 Lua table\n\n\n这个表就像是一个命名空间，其内容就是模块中导出的所有东西，比如函数和变量。require 函数会返回 Lua 模块加载后的结果，即用于表示该 Lua 模块的 Lua 值。\n\n\nLua 提供了一个名为 require 的函数用来加载模块。要加载一个模块，只需要简单地调用 require “file” 就可以了，file 指模块所在的文件名。这个调用会返回一个由模块函数组成的 table，并且还会定义一个包含该 table 的全局变量。\n在 Lua 中创建一个模块最简单的方法是：创建一个 table，并将所有需要导出的函数放入其中，最后返回这个 table 就可以了。相当于将导出的函数作为 table 的一个字段，在 Lua 中函数是第一类值，提供了天然的优势。\n\n创建 my. Lua\n\nlocal _M = {}\n \nlocal function get_name()\n    return &quot;Lucy&quot;\n    end\nfunction _M.greeting()\n    print(&quot;hello &quot; .. get_name())\nend\n \nreturn _M\n\n把下面代码保存在文件 main. Lua 中，然后执行 main. Lua，调用上述模块。\n\nlocal my_module = require(&quot;my&quot;)\nmy_module.greeting()     --&gt;output: hello Lucy\n\n\n\n对于需要导出给外部使用的公共模块，处于安全考虑，是要避免全局变量的出现。我们可以使用 lj-releng 或 luacheck 工具完成全局变量的检测。至于如何做，到后面再讲。\n\n\n另一个要注意的是，由于在 LuaJIT 中，require 函数内不能进行上下文切换，所以不能够在模块的顶级上下文中调用 cosocket 一类的 API。否则会报 attempt to yield across C-call boundary 错误。\n\n\n\nString\nLua 字符串总是由字节构成的。Lua 核心并不尝试理解具体的字符集编码（比如 GBK 和 UTF-8 这样的多字节字符编码）\nLua 字符串内部用来标识各个组成字节的下标是从 1 开始的，这不同于像 C 和 Perl 这样的编程语言。这样数字符串位置的时候再也不用调整，对于非专业的开发者来说可能也是一个好事情，string.Sub (str, 3, 7) 直接表示从第三个字符开始到第七个字符（含）为止的子串。\nstring.Byte (s [, i [, j ]])\n返回字符 s[i]、s[i + 1]、s[i + 2]、······、s[j] 所对应的 ASCII 码\nprint(string.byte(&quot;abc&quot;, 1, 3))\nprint(string.byte(&quot;abc&quot;, 3)) -- 缺少第三个参数，第三个参数默认与第二个相同，此时为 3\nprint(string.byte(&quot;abc&quot;))    -- 缺少第二个和第三个参数，此时这两个参数都默认为 1\n \n--&gt;output\n97    98    99\n99\n97\nstring. Char (…)\n接收 0 个或更多的整数（整数范围：0~255），返回这些整数所对应的 ASCII 码字符组成的字符串。当参数为空时，默认是一个 0。\nprint(string.char(96, 97, 98))\nprint(string.char())        -- 参数为空，默认是一个0，-- 你可以用string.byte(string.char())测试一下print(string.char(65, 66))\n \n--&gt; output\n`ab\n \nAB\nstring.Upper (s)\n接收一个字符串 s，返回一个把所有小写字母变成大写字母的字符串。\nprint(string.upper(&quot;Hello Lua&quot;))  --&gt;output  HELLO LUA\nstring.Lower (s)\n接收一个字符串 s，返回一个把所有大写字母变成小写字母的字符串。\nprint(string.lower(&quot;Hello Lua&quot;))  --&gt;output   hello lua\nstring.Len (s)\n接收一个字符串，返回它的长度。\nprint(string.len(&quot;hello lua&quot;)) --&gt;output  9\n使用此函数是不推荐的。应当总是使用 # 运算符来获取 Lua 字符串的长度\nstring.Find (s, p [, init [, plain]])\n在 s 字符串中第一次匹配 p 字符串。若匹配成功，则返回 p 字符串在 s 字符串中出现的开始位置和结束位置；若匹配失败，则返回 nil,\n第三个参数第三个参数 init 默认为 1，并且可以为负整数，\n当 init 为负数时，表示从 s 字符串的 string.Len (s) + init + 1 索引处开始向后匹配字符串 p 。\n第四个参数默认为 false，当其为 true 时，只会把 p 看成一个字符串对待。\nlocal find = string.find\nprint(find(&quot;abc cba&quot;, &quot;ab&quot;))\nprint(find(&quot;abc cba&quot;, &quot;ab&quot;, 2))     -- 从索引为2的位置开始匹配字符串：ab\nprint(find(&quot;abc cba&quot;, &quot;ba&quot;, -1))    -- 从索引为7的位置开始匹配字符串：ba\nprint(find(&quot;abc cba&quot;, &quot;ba&quot;, -3))    -- 从索引为5的位置开始匹配字符串：ba\nprint(find(&quot;abc cba&quot;, &quot;(%a+)&quot;, 1))  -- 从索引为1处匹配最长连续且只含字母的字符串\nprint(find(&quot;abc cba&quot;, &quot;(%a+)&quot;, 1, true)) --从索引为1的位置开始匹配字符串：(%a+)\n \n--&gt;output\n1   2\nnil\nnil\n6   7\n1   3   abc\nnil\nstring.Format (formatstring, …)\n按照格式化参数 formatstring，返回后面 ... 内容的格式化版本\nprint(string.format(&quot;%.4f&quot;, 3.1415926))     -- 保留4位小数\nprint(string.format(&quot;%d %x %o&quot;, 31, 31, 31))-- 十进制数31转换成不同进制\nd = 29; m = 7; y = 2015                     -- 一行包含几个语句，用；分开\nprint(string.format(&quot;%s %02d/%02d/%d&quot;, &quot;today is:&quot;, d, m, y))\n \n--&gt;output\n3.1416\n31 1f 37\ntoday is: 29/07/2015\nstring.Match (s, p [, init])\n在字符串 s 中匹配（模式）字符串 p，若匹配成功，则返回目标字符串中与模式匹配的子串；否则返回 nil。第三个参数 init 默认为 1，并且可以为负整数，当 init 为负数时，表示从 s 字符串的 string.Len (s) + init + 1 索引处开始向后匹配字符串 p。\nprint(string.match(&quot;hello lua&quot;, &quot;lua&quot;))\nprint(string.match(&quot;lua lua&quot;, &quot;lua&quot;, 2))  --匹配后面那个luaprint(string.match(&quot;lua lua&quot;, &quot;hello&quot;))\nprint(string.match(&quot;today is 27/7/2015&quot;, &quot;%d+/%d+/%d+&quot;))\n \n--&gt;output\nlua\nlua\nnil27/7/2015\nstring.Gmatch (s, p)\n返回一个迭代器函数，通过这个迭代器函数可以遍历到在字符串 s 中出现模式串 p 的所有地方。\ns = &quot;hello world from Lua&quot;\nfor w in string.gmatch(s, &quot;%a+&quot;) do  --匹配最长连续且只含字母的字符串\n    print(w)\nend\n \n--&gt;output\nhello\nworld\nfrom\nLua\n \n \nt = {}\ns = &quot;from=world, to=Lua&quot;\nfor k, v in string.gmatch(s, &quot;(%a+)=(%a+)&quot;) do  --匹配两个最长连续且只含字母的\n    t[k] = v                                    --字符串，它们之间用等号连接\nend\nfor k, v in pairs(t) do\n    print (k,v)\nend\n \n--&gt;output\nto      Lua\nfrom    worl\nstring.Rep (s, n)\n返回字符串 s 的 n 次拷贝。\nprint(string.rep(&quot;abc&quot;, 3)) \n \n--拷贝3次&quot;abc&quot;--&gt;output  abcabcabc\nstring.Sub (s, i [, j])\n返回字符串 s 中，索引 i 到索引 j 之间的子字符串。当 j 缺省时，默认为 -1，也就是字符串 s 的最后位置。I 可以为负数。当索引 i 在字符串 s 的位置在索引 j 的后面时，将返回一个空字符串。\nprint(string.sub(&quot;Hello Lua&quot;, 4, 7))\nprint(string.sub(&quot;Hello Lua&quot;, 2))\nprint(string.sub(&quot;Hello Lua&quot;, 2, 1))    --看到返回什么了吗print(string.sub(&quot;Hello Lua&quot;, -3, -1))\n \n--&gt;output\nlo L\nello Lua\n \nLua\nstring.Gsub (s, p, r [, n])\n将目标字符串 s 中所有的子串 p 替换成字符串 r。可选参数 n，表示限制替换次数。返回值有两个，第一个是被替换后的字符串，第二个是替换了多少次。\nprint(string.gsub(&quot;Lua Lua Lua&quot;, &quot;Lua&quot;, &quot;hello&quot;))\nprint(string.gsub(&quot;Lua Lua Lua&quot;, &quot;Lua&quot;, &quot;hello&quot;, 2)) --指明第四个参数--&gt;output\nhello hello hello   3\nhello hello Lua     2\nstring. Reverse (s)\n接收一个字符串 s，返回这个字符串的反转\nprint(string.reverse(&quot;Hello Lua&quot;))  --&gt; output: auL olleH\nTable\n下标从 1 开始\n数组下标从 1 开始计数。\n而 Lua 最初设计是一种类似 XML 的数据描述语言，所以索引（index）反应的是数据在里面的位置，而不是偏移量。\n在初始化一个数组的时候，若不显式地用键值对方式赋值，则会默认用数字作为下标，从 1 开始。由于在 Lua 内部实际采用哈希表和数组分别保存键值对、普通值，所以不推荐混合使用这两种赋值方式\nlocal color={first=&quot;red&quot;, &quot;blue&quot;, third=&quot;green&quot;, &quot;yellow&quot;}\nprint(color[&quot;first&quot;])                 --&gt; output: red\nprint(color[1])                       --&gt; output: blue\nprint(color[&quot;third&quot;])                 --&gt; output: green\nprint(color[2])                       --&gt; output: yellow\nprint(color[3])                       --&gt; output: nil\n\n\n当我们把 table 当作栈或者队列使用的时候，容易犯错，追加到 table 的末尾用的是 s[#s+1] = something****, 而不是 s[#s] = something\n\n\n而且如果这个 something 是一个 nil 的话**，会导致这一次压栈（或者入队列）没有存入任何东西**， s 的值没有变\n\n\n如果 s = { 1, 2, 3, 4, 5, 6 }，你令 s[4] = nil， s 会令你“匪夷所思”地变成 3。\n\n\ntable. Getn 获取长度\n取长度操作符写作一元操作 。字符串的长度是它的字节数（就是以一个字符一个字节计算的字符串长度）\n\n\n对于常规的数组，里面从 1 到 n 放着一些非空的值的时候，它的长度就精确的为 n，即最后一个值的下标\n\n\n如果数组有一个“空洞”（就是说，nil 值被夹在非空值之间），那么 t 可能是指向任何一个是 nil 值的前一个位置的下标\n\n\n这也就说明对于有“空洞”的情况，table 的长度存在一定的 不可确定性\n\n\nlocal tblTest1 = { 1, a = 2, 3 }\nprint(&quot;Test1 &quot; .. table.getn(tblTest1))\n \nlocal tblTest2 = { 1, nil }\nprint(&quot;Test2 &quot; .. table.getn(tblTest2))\n \nlocal tblTest3 = { 1, nil, 2 }\nprint(&quot;Test3 &quot; .. table.getn(tblTest3))\n \nlocal tblTest4 = { 1, nil, 2, nil }\nprint(&quot;Test4 &quot; .. table.getn(tblTest4))\n \nlocal tblTest5 = { 1, nil, 2, nil, 3, nil }\nprint(&quot;Test5 &quot; .. table.getn(tblTest5))\n \nlocal tblTest6 = { 1, nil, 2, nil, 3, nil, 4, nil }\nprint(&quot;Test6 &quot; .. table.getn(tblTest6))\n我们使用 Lua 5.1 和 LuaJIT 2.1 分别执行这个用例，结果如下：\n# lua test.lua\nTest1 2\nTest2 1\nTest3 3\nTest4 1\nTest5 3\nTest6 1\n# luajit test.lua\nTest1 2\nTest2 1\nTest3 1\nTest4 1\nTest5 1\nTest6 1\n不要在 Lua 的 table 中使用 nil 值，如果一个元素要删除，直接 remove，不要用 nil 去代替。\ntable. Concat (table [, sep [, i [, j ] ] ])\n对于元素是 string 或者 number 类型的表 table，返回 table[i]..sep..table[i+1] ··· sep..table[j] 连接成的字符串。填充字符串 sep 默认为空白字符串。起始索引位置 i 默认为 1，结束索引位置 j 默认是 table 的长度。\nlocal a = {1, 3, 5, &quot;hello&quot; }\nprint(table.concat(a))              -- output: 135hello\nprint(table.concat(a, &quot;|&quot;))         -- output: 1|3|5|hello\nprint(table.concat(a, &quot; &quot;, 4, 2))   -- output:\nprint(table.concat(a, &quot; &quot;, 2, 4))   -- output: 3 5 hello\ntable. Insert (table, [pos ,] value)\n在（数组型）表 table 的 pos 索引位置插入 value，其它元素向后移动到空的地方。Pos 的默认值是表的长度加一，即默认是插在表的最后\nlocal a = {1, 8}             --a[1] = 1,a[2] = 8\ntable.insert(a, 1, 3)   --在表索引为1处插入3\nprint(a[1], a[2], a[3])\ntable.insert(a, 10)    --在表的最后插入10\nprint(a[1], a[2], a[3], a[4])\n \n--&gt;output\n3    1    8\n3    1    8    10\ntable. Maxn (table)\n返回（数组型）表 table 的最大索引编号；如果此表没有正的索引编号，返回 0。\nlocal a = {}\na[-1] = 10\nprint(table.maxn(a))\na[5] = 10\nprint(table.maxn(a))\n \n--&gt;output05\ntable. Remove (table [, pos])\n在表 table 中删除索引为 pos（pos 只能是 number 型）的元素，并返回这个被删除的元素，它后面所有元素的索引值都会减一。Pos 的默认值是表的长度，即默认是删除表的最后一个元素。\nlocal a = { 1, 2, 3, 4}\nprint(table.remove(a, 1)) --删除速索引为1的元素print(a[1], a[2], a[3], a[4])\n \nprint(table.remove(a))   --删除最后一个元素print(a[1], a[2], a[3], a[4])\n \n--&gt;output12    3    4    nil42    3    nil    nil\ntable. Sort (table [, comp])\n按照给定的比较函数 comp 给表 table 排序，也就是从 table[1] 到 table[n]，这里 n 表示 table 的长度。比较函数有两个参数，如果希望第一个参数排在第二个的前面，就应该返回 true，否则返回 false。如果比较函数 comp 没有给出，默认从小到大排序。\n \nlocal function compare(x, y) --从大到小排序\n    return x &gt; y         --如果第一个参数大于第二个就返回true，否则返回false\nend\n \nlocal a = { 1, 7, 3, 4, 25}\ntable.sort(a)           --默认从小到大排序\nprint(a[1], a[2], a[3], a[4], a[5])\ntable.sort(a, compare) --使用比较函数进行排序\nprint(a[1], a[2], a[3], a[4], a[5])\n \n--&gt;output\n1    3    4    7    25\n25    7    4    3    1\n其他\nLuaJIT 2.1 新增加的 table.new 和 table.clear 函数是非常有用的。前者主要用来预分配 Lua table 空间，后者主要用来高效的释放 table 空间，并且它们都是可以被 JIT 编译的\n日期时间\n函数 time、date 和 difftime 提供了所有的日期和时间功能。\n在 OpenResty 的世界里，不推荐使用这里的标准时间函数，因为这些函数通常会引发不止一个昂贵的系统调用，同时无法为 LuaJIT JIT 编译，对性能造成较大影响。推荐使用 ngx_lua 模块提供的带缓存的时间接口，如 ngx.today, ngx.time, ngx.utctime, ngx.localtime, ngx.now, ngx.http_time，以及 ngx.cookie_time 等。\nos. Time ([table])\n如果不使用参数 table 调用 time 函数，\n\n\n它会返回当前的时间和日期（它表示从某一时刻到现在的秒数）。\n\n\n如果用 table 参数，它会返回一个数字，表示该 table 中所描述的日期和时间（它表示从某一时刻到 table 中描述日期和时间的秒数）。Table 的字段如下：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n字段名称取值范围year四位数字month1—12day1—31hour0—23min0—59sec0—61isdstboolean（true 表示夏令时）\n对于 time 函数，如果参数为 table，那么 table 中必须含有 year、month、day 字段。其他字缺省时段默认为中午（12:00:00）。\n\n示例代码：（地点为北京）\n\nprint(os.time())    --&gt;output  1438243393\na = { year = 1970, month = 1, day = 1, hour = 8, min = 1 }\nprint(os.time(a))   --&gt;output  60\nos. Difftime (t 2, t 1)\n返回 t 1 到 t 2 的时间差，单位为秒。\n\n示例代码:\n\nlocal day1 = { year = 2015, month = 7, day = 30 }\nlocal t1 = os.time(day1)\n \nlocal day2 = { year = 2015, month = 7, day = 31 }\nlocal t2 = os.time(day2)\nprint(os.difftime(t2, t1))   --&gt;output  86400\nos. Date ([format [, time]])\n把一个表示日期和时间的数值，转换成更高级的表现形式。\n\n\n其第一个参数 format 是一个格式化字符串，描述了要返回的时间形式。\n\n\n第二个参数 time 就是日期和时间的数字表示，缺省时默认为当前的时间。\n\n\n使用格式字符 “*t”，创建一个时间表。\n\n\n\n示例代码：\n\nlocal tab1 = os.date(&quot;*t&quot;)  --返回一个描述当前日期和时间的表\nlocal ans1 = &quot;{&quot;\nfor k, v in pairs(tab1) do  --把tab1转换成一个字符串\n    ans1 = string.format(&quot;%s %s = %s,&quot;, ans1, k, tostring(v))\nend\n \nans1 = ans1 .. &quot;}&quot;\nprint(&quot;tab1 = &quot;, ans1)\n \n \nlocal tab2 = os.date(&quot;*t&quot;, 360)  --返回一个描述日期和时间数为360秒的表\nlocal ans2 = &quot;{&quot;\nfor k, v in pairs(tab2) do      --把tab2转换成一个字符串\n    ans2 = string.format(&quot;%s %s = %s,&quot;, ans2, k, tostring(v))\nend\n \nans2 = ans2 .. &quot;}&quot;\nprint(&quot;tab2 = &quot;, ans2)\n \n--&gt;output\ntab1 = { hour = 17, min = 28, wday = 5, day = 30, month = 7, year = 2015, sec = 10, yday = 211, isdst = false,}\ntab2 = { hour = 8, min = 6, wday = 5, day = 1, month = 1, year = 1970, sec = 0, yday = 1, isdst = false,}\n该表中除了使用到了 time 函数参数 table 的字段外，这还提供了星期（wday，星期天为 1）和一年中的第几天（yday，一月一日为 1）。除了使用 “*t” 格式字符串外，如果使用带标记（见下表）的特殊字符串，os. Date 函数会将相应的标记位以时间信息进行填充，得到一个包含时间的字符串。表如下：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n格式字符含义%a一星期中天数的简写（例如：Wed）%A一星期中天数的全称（例如：Wednesday）%b月份的简写（例如：Sep）%B月份的全称（例如：September）%c日期和时间（例如：07/30/15 16:57:24）%d一个月中的第几天[01 ~ 31]%H24 小时制中的小时数[00 ~ 23]%I12 小时制中的小时数[01 ~ 12]%j一年中的第几天[001 ~ 366]%M分钟数[00 ~ 59]%m月份数[01 ~ 12]%p“上午（am）”或“下午（pm）”%S秒数[00 ~ 59]%w一星期中的第几天[1 ~ 7 = 星期天 ~ 星期六]%x日期（例如：07/30/15）%X时间（例如：16:57:24）%y两位数的年份[00 ~ 99]%Y完整的年份（例如：2015）%%字符’%‘\n\n示例代码：\n\nprint(os.date(&quot;today is %A, in %B&quot;))\nprint(os.date(&quot;now is %x %X&quot;))\n \n--&gt;output\ntoday is Thursday, in July\nnow is 07/30/15 17:39:22\n数学库\nUa 数学库由一组标准的数学函数构成。数学库的引入丰富了 Lua 编程语言的功能，同时也方便了程序的编写。常用数学函数见下表：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nasdsdfa函数名函数功能math.Rad (x)角度 x 转换成弧度math.Deg (x)弧度 x 转换成角度math.Max (x, …)返回参数中值最大的那个数，参数必须是 number 型math.Min (x, …)返回参数中值最小的那个数，参数必须是 number 型math. Random ([m [, n]])不传入参数时，返回一个在区间[0,1)内均匀分布的伪随机实数；只使用一个整数参数 m 时，返回一个在区间[1, m]内均匀分布的伪随机整数；使用两个整数参数时，返回一个在区间[m, n]内均匀分布的伪随机整数math. Randomseed (x)为伪随机数生成器设置一个种子 x，相同的种子将会生成相同的数字序列math.Abs (x)返回 x 的绝对值math.Fmod (x, y)返回 x 对 y 取余数math.Pow (x, y)返回 x 的 y 次方math.Sqrt (x)返回 x 的算术平方根math.Exp (x)返回自然数 e 的 x 次方math.Log (x)返回 x 的自然对数math. Log 10 (x)返回以 10 为底，x 的对数math.Floor (x)返回最大且不大于 x 的整数math.Ceil (x)返回最小且不小于 x 的整数math. Pi圆周率math.Sin (x)求弧度 x 的正弦值math.Cos (x)求弧度 x 的余弦值math.Tan (x)求弧度 x 的正切值math.Asin (x)求 x 的反正弦值math.Acos (x)求 x 的反余弦值math.Atan (x)求 x 的反正切值\nprint(math.pi)           --&gt;output  3.1415926535898\nprint(math.rad(180))     --&gt;output  3.1415926535898\nprint(math.deg(math.pi)) --&gt;output  180\n \nprint(math.sin(1))       --&gt;output  0.8414709848079\nprint(math.cos(math.pi)) --&gt;output  -1\nprint(math.tan(math.pi / 4))  --&gt;output  1\n \nprint(math.atan(1))      --&gt;output  0.78539816339745\nprint(math.asin(0))      --&gt;output  0\n \nprint(math.max(-1, 2, 0, 3.6, 9.1))     --&gt;output  9.1\nprint(math.min(-1, 2, 0, 3.6, 9.1))     --&gt;output  -1\n \nprint(math.fmod(10.1, 3))   --&gt;output  1.1\nprint(math.sqrt(360))      --&gt;output  18.97366596101\n \nprint(math.exp(1))         --&gt;output  2.718281828459\nprint(math.log(10))        --&gt;output  2.302585092994\nprint(math.log10(10))      --&gt;output  1\n \nprint(math.floor(3.1415))  --&gt;output  3\nprint(math.ceil(7.998))    --&gt;output  8\n使用 math.random() 函数获得伪随机数时，如果不使用 math.randomseed() 设置伪随机数生成种子或者设置相同的伪随机数生成种子，那么得得到的伪随机数序列是一样的。\nmath.randomseed (100) --把种子设置为100\nprint(math.random())         --&gt;output  0.0012512588885159\nprint(math.random(100))      --&gt;output  57\nprint(math.random(100, 360)) --&gt;output  150\n稍等片刻，再次运行上面的代码。\nmath.randomseed (100) --把种子设置为100\nprint(math.random())         --&gt;output  0.0012512588885159\nprint(math.random(100))      --&gt;output  57\nprint(math.random(100, 360)) --&gt;output  150\n两次运行的结果一样。为了避免每次程序启动时得到的都是相同的伪随机数序列，通常是使用当前时间作为种子。\n\n修改上例中的代码：\n\nmath.randomseed (os.time())   --把100换成os.time()\nprint(math.random())          --&gt;output 0.88369396038697\nprint(math.random(100))       --&gt;output 66\nprint(math.random(100, 360))  --&gt;output 228\n稍等片刻，再次运行上面的代码。\nmath.randomseed (os.time())   --把100换成os.time()\nprint(math.random())          --&gt;output 0.88946195867794\nprint(math.random(100))       --&gt;output 68\nprint(math.random(100, 360))  --&gt;output 129\n文件\nLua I/O 库提供两种不同的方式处理文件：隐式文件描述，显式文件描述。\n这些文件 I/O 操作，在 OpenResty 的上下文中对事件循环是会产生阻塞效应。OpenResty 比较擅长的是高并发网络处理，在这个环境中，任何文件的操作，都将阻塞其他并行执行的请求。实际中的应用，在 OpenResty 项目中应尽可能让网络处理部分、文件 I/0 操作部分相互独立，不要揉和在一起。\n隐式文件描述\n设置一个默认的输入或输出文件，然后在这个文件上进行所有的输入或输出操作。所有的操作函数由 io 表提供。\n\n打开已经存在的 test1.txt 文件，并读取里面的内容\n\nfile = io.input(&quot;test1.txt&quot;)    -- 使用 io.input() 函数打开文件repeat\n    line = io.read()            -- 逐行读取内容，文件结束时返回nil\n    if nil == line then\n        break\n    end\n    print(line)\nuntil (false)\n \nio.close(file)                  -- 关闭文件--&gt; output\nmy test file\nhello\nlua\n\n在 test1.txt 文件的最后添加一行 “hello world”\n\nfile = io.open(&quot;test1.txt&quot;, &quot;a+&quot;)   -- 使用 io.open() 函数，以添加模式打开文件\nio.output(file)                     -- 使用 io.output() 函数，设置默认输出文件\nio.write(&quot;\\nhello world&quot;)           -- 使用 io.write() 函数，把内容写到文件\nio.close(file)\n在相应目录下打开 test1.txt 文件，查看文件内容发生的变化。\n显式文件描述\n使用 file: XXX () 函数方式进行操作, 其中 file 为 io.Open () 返回的文件句柄。\n\n打开已经存在的 test 2. Txt 文件，并读取里面的内容\n\nfile = io.open(&quot;test2.txt&quot;, &quot;r&quot;)    -- 使用 io.open() 函数，以只读模式打开文件\n \nfor line in file:lines() do         -- 使用 file:lines() 函数逐行读取文件\n    print(line)\nend\n \nfile:close()\n \n--&gt;output\nmy test2\nhello lua\n\n在 test 2. Txt 文件的最后添加一行 “hello world”\n\nfile = io.open(&quot;test2.txt&quot;, &quot;a&quot;)  -- 使用 io.open() 函数，以添加模式打开文件\nfile:write(&quot;\\nhello world&quot;)       -- 使用 file:write() 函数，在文件末尾追加内容\nfile:close()\n在相应目录下打开 test2.txt 文件，查看文件内容发生的变化。\n文件操作函数\nio. Open (filename [, mode])\n按指定的模式 mode，打开一个文件名为 filename 的文件，成功则返回文件句柄，失败则返回 nil 加错误信息。模式：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n模式含义文件不存在时”r”读模式 (默认)返回 nil 加错误信息”w”写模式创建文件”a”添加模式创建文件”r+“更新模式，保存之前的数据返回 nil 加错误信息”w+“更新模式，清除之前的数据创建文件”a+“添加更新模式，保存之前的数据, 在文件尾进行添加创建文件\n模式字符串后面可以有一个 ‘b’，用于在某些系统中打开二进制文件。\n注意 “w” 和 “wb” 的区别\n\n\n”w” 表示文本文件。某些文件系统 (如 Linux 的文件系统)认为 0 x 0 A 为文本文件的换行符，Windows 的文件系统认为 0 x 0 D 0 A 为文本文件的换行符。为了兼容其他文件系统（如从 Linux 拷贝来的文件），Windows 的文件系统在写文件时，会在文件中 0 x 0 A 的前面加上 0 x 0 D。使用 “w”，其属性要看所在的平台。\n\n\n“wb” 表示二进制文件。文件系统会按纯粹的二进制格式进行写操作，因此也就不存在格式转换的问题。（Linux 文件系统下 “w” 和 “wb” 没有区别）\n\n\nfile: close ()\n关闭文件。注意：当文件句柄被垃圾收集后，文件将自动关闭。句柄将变为一个不可预知的值。\nio. Close ([file])\n关闭文件，和 file: close () 的作用相同。没有参数 file 时，关闭默认输出文件。\nfile: flush ()\n把写入缓冲区的所有数据写入到文件 file 中。\nio. Flush ()\n相当于 file: flush ()，把写入缓冲区的所有数据写入到默认输出文件。\nio. Input ([file])\n当使用一个文件名调用时，打开这个文件（以文本模式），并设置文件句柄为默认输入文件；当使用一个文件句柄调用时，设置此文件句柄为默认输入文件；当不使用参数调用时，返回默认输入文件句柄。\nfile: lines ()\n返回一个迭代函数, 每次调用将获得文件中的一行内容, 当到文件尾时，将返回 nil，但不关闭文件。\nio. Lines ([filename])\n打开指定的文件 filename 为读模式并返回一个迭代函数, 每次调用将获得文件中的一行内容, 当到文件尾时，将返回 nil，并自动关闭文件。若不带参数时 io.Lines () 等价于 io.Input (): lines () 读取默认输入设备的内容，结束时不关闭文件。\nio. Output ([file])\n类似于 io. Input，但操作在默认输出文件上。\nfile: read (…)\n按指定的格式读取一个文件。按每个格式将返回一个字符串或数字, 如果不能正确读取将返回 nil，若没有指定格式将指默认按行方式进行读取。格式：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n格式含义”*n”读取一个数字”*a”从当前位置读取整个文件。若当前位置为文件尾，则返回空字符串”*l”读取下一行的内容。若为文件尾，则返回 nil。(默认)number读取指定字节数的字符。若为文件尾，则返回 nil。如果 number 为 0, 则返回空字符串，若为文件尾, 则返回 nil\nio. Read (…)\n相当于 io.Input ():read\nio. Type (obj)\n检测 obj 是否一个可用的文件句柄。如果 obj 是一个打开的文件句柄，则返回 “file” 如果 obj 是一个已关闭的文件句柄，则返回 “closed file” 如果 obj 不是一个文件句柄，则返回 nil。\nfile: write (…)\n把每一个参数的值写入文件。参数必须为字符串或数字，若要输出其它值，则需通过 tostring 或 string. Format 进行转换。\nio. Write (…)\n相当于 io.Output (): write。\nfile: seek ([whence] [, offset])\n设置和获取当前文件位置，成功则返回最终的文件位置 (按字节，相对于文件开头), 失败则返回 nil 加错误信息。缺省时，whence 默认为 “cur”，offset 默认为 0 。参数 whence：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nwhence含义”set”文件开始”cur”文件当前位置 (默认)“end”文件结束\nfile: setvbuf (mode [, size])\n设置输出文件的缓冲模式。模式：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n模式含义”no”没有缓冲，即直接输出”full”全缓冲，即当缓冲满后才进行输出操作 (也可调用 flush 马上输出)“line”以行为单位，进行输出\n最后两种模式，size 可以指定缓冲的大小（按字节），忽略 size 将自动调整为最佳的大小。\n元表\n元表 (metatable) 的表现行为类似于 C++ 语言中的操作符重载，例如我们可以重载 “__add” 元方法 (metamethod)，来计算两个 Lua 数组的并集；或者重载 “__index” 方法，来定义我们自己的 Hash 函数。Lua 提供了两个十分重要的用来处理元表的方法\n\n\nSetmetatable (table, metatable)：此方法用于为一个表设置元表。\n\n\nGetmetatable (table)：此方法用于获取表的元表对象\n\n\n设置元表\nlocal mytable = {}\nlocal mymetatable = {}\nsetmetatable(mytable, mymetatable)\n修改表的操作符行为\n通过重载 “__add” 元方法来计算集合的并集实例\nlocal set1 = {10, 20, 30}   -- 集合\nlocal set2 = {20, 40, 50}   -- 集合\n \n-- 将用于重载__add的函数，注意第一个参数是self\nlocal union = function (self, another)\n    local set = {}\n    local result = {}\n \n    -- 利用数组来确保集合的互异性\n    for i, j in pairs(self) do set[j] = true end\n    for i, j in pairs(another) do set[j] = true end\n \n    -- 加入结果集合\n    for i, j in pairs(set) do table.insert(result, i) end\n    return result\nend\nsetmetatable(set1, {__add = union}) -- 重载 set1 表的 __add 元方法\n \nlocal set3 = set1 + set2\nfor _, j in pairs(set3) do\n    io.write(j..&quot; &quot;)               --&gt;output：30 50 20 40 10\nend\n除了加法可以被重载之外，Lua 提供的所有操作符都可以被重载：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n元方法含义”__addNAME ?”__sub- 操作其行为类似于 “add” 操作”__mul* 操作其行为类似于 “add” 操作”__div/ 操作其行为类似于 “add” 操作”__mod% 操作其行为类似于 “add” 操作”__pow^ （幂）操作其行为类似于 “add” 操作”__unm”一元 - 操作”__concat”.. （字符串连接）操作”__len”# 操作”__eq”== 操作函数 getcomphandler 定义了 Lua 怎样选择一个处理器来作比较操作仅在两个对象类型相同且有对应操作相同的元方法时才起效”__lt”&lt; 操作”__le”⇐ 操作\n除了操作符之外，如下元方法也可以被重载，下面会依次解释使用方法：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n元方法含义”__index”取下标操作用于访问 table[key]“__newindex”赋值给指定下标 table[key] = value”__tostring”转换成字符串”__call”当 Lua 调用一个值时调用”__mode”用于弱表 (week table)“__metatable”用于保护 metatable 不被访问\n__index 元方法\nmytable = setmetatable({key1 = &quot;value1&quot;},   --原始表\n{__index = function(self, key)            --重载函数\n    if key == &quot;key2&quot; then\n        return &quot;metatablevalue&quot;\n    end\nend\n})\n \nprint(mytable.key1,mytable.key2)  --&gt; output：value1 metatablevalue\n关于 __index 元方法，有很多比较高阶的技巧，例如：__index 的元方法不需要非是一个函数，他也可以是一个表。\nt = setmetatable({[1] = &quot;hello&quot;}, {__index = {[2] = &quot;world&quot;}})\nprint(t[1], t[2])   --&gt;hello wor\n__tostring 元方法\n与 Java 中的 toString () 函数类似，可以实现自定义的字符串转换。\narr = {1, 2, 3, 4}\narr = setmetatable(arr, {__tostring = function (self)\n    local result = &#039;{&#039;\n    local sep = &#039;&#039;\n    for _, i in pairs(self) do\n        result = result ..sep .. i\n        sep = &#039;, &#039;\n    end\n    result = result .. &#039;}&#039;\n    return result\nend})\nprint(arr)  --&gt; {1, 2, 3, 4}\n__call 元方法\n__call 元方法的功能类似于 C++ 中的仿函数，使得普通的表也可以被调用。\nfunctor = {}\nfunction func1(self, arg)\n    print (&quot;called from&quot;, arg)\nend\nsetmetatable(functor, {__call = func1})\n \nfunctor(&quot;functor&quot;)  --&gt; called from functor\nprint(functor)      --&gt; output：0x00076fc8 （后面这串数字可能不一样）\n__metatable 元方法\n假如我们想保护我们的对象使其使用者既看不到也不能修改 metatables。我们可以对 metatable 设置了 __metatable 的值，getmetatable 将返回这个域的值，而调用 setmetatable 将会出错：\nbject = setmetatable({}, {__metatable = &quot;You cannot access here&quot;})\n \nprint(getmetatable(Object)) --&gt; You cannot access heresetmetatable(Object, {})    --&gt; 引发编译器报错\n面向对象\n类\n在 Lua 中，我们可以使用表和函数实现面向对象。将函数和相关的数据放置于同一个表中就形成了一个对象。\nlocal _M = {}\n \nlocal mt = { __index = _M }\n \nfunction _M.deposit (self, v)\n    self.balance = self.balance + v\nend\n \nfunction _M.withdraw (self, v)\n    if self.balance &gt; v then\n        self.balance = self.balance - v\n    else\n        error(&quot;insufficient funds&quot;)\n    end\nend\n \nfunction _M.new (self, balance)\n    balance = balance or 0\n    return setmetatable({balance = balance}, mt)\nend\n \nreturn _M\n引用\nlocal account = require(&quot;account&quot;)\n \nlocal a = account:new()\na:deposit(100)\n \nlocal b = account:new()\nb:deposit(50)\n \nprint(a.balance)  --&gt; output: 100\nprint(b.balance)  --&gt; output: 50\n上面这段代码 “setmetatable ({balance = balance}, mt)“，其中 mt 代表 { __index = _M } ，这句话值得注意。根据我们在元表这一章学到的知识，我们明白，setmetatable 将 _M 作为新建表的原型，所以在自己的表内找不到 ‘deposit’、‘withdraw’ 这些方法和变量的时候，便会到 __index 所指定的 _M 类型中去寻找。\n继承\n继承可以用元表实现，它提供了在父类中查找存在的方法和变量的机制。在 Lua 中是不推荐使用继承方式完成构造的，这样做引入的问题可能比解决的问题要多，下面一个是字符串操作类库，给大家演示一下。\n---------- s_base.lualocal _M = {}\n \nlocal mt = { __index = _M }\n \nfunction _M.upper (s)return string.upper(s)\nendreturn _M\n \n---------- s_more.lualocal s_base = require(&quot;s_base&quot;)\n \nlocal _M = {}\n_M = setmetatable(_M, { __index = s_base })\n \n \nfunction _M.lower (s)return string.lower(s)\nendreturn _M\n \n---------- test.lualocal s_more = require(&quot;s_more&quot;)\n \nprint(s_more.upper(&quot;Hello&quot;))   -- output: HELLOprint(s_more.lower(&quot;Hello&quot;))   -- output: hello\n成员私有性\n在动态语言中引入成员私有性并没有太大的必要，反而会显著增加运行时的开销，毕竟这种检查无法像许多静态语言那样在编译期完成。下面的技巧把对象作为各方法的 upvalue，本身是很巧妙的，但会让子类继承变得困难，同时构造函数动态创建了函数，会导致构造函数无法被 JIT 编译。\n在 Lua 中，成员的私有性，使用类似于函数闭包的形式来实现。在我们之前的银行账户的例子中，我们使用一个工厂方法来创建新的账户实例，通过工厂方法对外提供的闭包来暴露对外接口。而不想暴露在外的例如 balance 成员变量，则被很好的隐藏起来。\nfunction newAccount (initialBalance)\n    local self = {balance = initialBalance}\n    local withdraw = function (v)\n        self.balance = self.balance - v\n    end\n    local deposit = function (v)\n        self.balance = self.balance + v\n    end\n    local getBalance = function () \n        return self.balance \n    end\n    \n    return {\n        withdraw = withdraw,\n        deposit = deposit,\n        getBalance = getBalance\n    }\nend\n \na = newAccount(100)\na.deposit(100)\nprint(a.getBalance()) --&gt; 200print(a.balance)      --&gt; nil\n局部变量\nLua 的设计有一点很奇怪，在一个 block 中的变量，如果之前没有定义过，那么认为它是一个全局变量，而不是这个 block 的局部变量。这一点和别的语言不同。容易造成不小心覆盖了全局同名变量的错误。\n定义\nLua 中的局部变量要用 local 关键字来显式定义，不使用 local 显式定义的变量就是全局变量\ng_var = 1         -- global var\nlocal l_var = 2   -- local var\n作用域\n局部变量的生命周期是有限的，它的作用域仅限于声明它的块（block）。一个块是一个控制结构的执行体、或者是一个函数的执行体再或者是一个程序块（chunk）。\nx = 10\nlocal i = 1         -- 程序块中的局部变量 i\n \nwhile i &lt;=x do\n    local x = i * 2   -- while 循环体中的局部变量 x\n    print(x)          -- output： 2, 4, 6, 8, ...\n    i = i + 1\nend\n \nif i &gt; 20 then\n    local x           -- then 中的局部变量 x\n    x = 20\n    print(x + 2)      -- 如果i &gt; 20 将会打印 22，此处的 x 是局部变量\nelse\n    print(x)          -- 打印 10，这里 x 是全局变量\nend\n \nprint(x)            -- 打印 10\n使用局部变量的好处\n\n\n局部变量可以避免因为命名问题污染了全局环境\n\n\nLocal 变量的访问比全局变量更快\n\n\n由于局部变量出了作用域之后生命周期结束，这样可以被垃圾回收器及时释放\n\n\n检测模块的函数使用局部变量\nFoo. Lua\nlocal _M = { _VERSION = &#039;0.01&#039; }\n \nfunction _M.add(a, b)     --两个number型变量相加\n    return a + b\nend\n \nfunction _M.update_A()    --更新变量值\n    A = 365               -- A 是全局变量\nend\n \nreturn _M\nUse_foo. Lua\nA = 360     --定义全局变量\n \nlocal foo = require(&quot;foo&quot;)\n \nlocal b = foo.add(A, A)\nprint(&quot;b = &quot;, b)\n \nfoo.update_A()\nprint(&quot;A = &quot;, A)\n因为 A 是全局变量，改变了 A 的值\nLua 上下文中应当严格避免使用自己定义的全局变量。可以使用一个 lj-releng 工具来扫描 Lua 代码，定位使用 Lua 全局变量的地方。Lj-releng 的相关链接：github.com/openresty/openresty-devel-utils/blob/master/lj-releng\nWindows 用户把 lj-releng 文件所在的目录的绝对路径添加进 PATH 环境变量。然后进入你自己的 Lua 文件所在的工作目录，得到如下结果：\n#  lj-releng\nfoo.lua: 0.01 (0.01)\nChecking use of Lua global variables in file foo.lua...\nop no.  line  instruction args  ; code\n2  [8] SETGLOBAL 0 -1  ; A\nChecking line length exceeding 80...\nWARNING: No &quot;_VERSION&quot; or &quot;version&quot; field found in `use_foo.lua`.\nChecking use of Lua global variables in file use_foo.lua...\nop no.  line  instruction args  ; code\n2  [1] SETGLOBAL 0 -1  ; A\n7  [4] GETGLOBAL 2 -1  ; A\n8  [4] GETGLOBAL 3 -1  ; A\n18 [8] GETGLOBAL 4 -1  ; A\n当然，更推荐采用 luacheck 来检查项目中全局变量，之后的“代码静态分析”一节，我们还会讲到如何使用 luacheck。\n判断数组的大小\n\n\nTable.Getn (t) 等价于 t 但计算的是数组元素，不包括 hash 键值。而且数组是以第一个 nil 元素来判断数组结束。\n\n\n# 只计算 array 的元素个数，它实际上调用了对象的 metatable 的 __len 函数。对于有 __len 方法的函数返回函数返回值，不然就返回数组成员数目\n\n\nLua 内部实际采用哈希表和数组分别保存键值对、普通值，所以不推荐混合使用这两种赋值方式。\n\n\nLua 数组中允许 nil 值的存在，但是数组默认结束标志却是 nil。这类比于 C 语言中的字符串，字符串中允许 ‘\\0’ 存在，但当读到 ‘\\0’ 时，就认为字符串已经结束了。\n\n\n初始化是例外，在 Lua 相关源码中，初始化数组时首先判断数组的长度，若长度大于 0 ，并且最后一个值不为 nil，返回包括 nil 的长度；若最后一个值为 nil，则返回截至第一个非 nil 值的长度。\n\n\n如果你要删除一个数组中的元素，请使用 remove 函数，而不是用 nil 赋值\n\n\n-- test.lua\nlocal tblTest1 = { 1, a = 2, 3 }\nprint(&quot;Test1 &quot; .. #(tblTest1))\n \nlocal tblTest2 = { 1, nil }\nprint(&quot;Test2 &quot; .. #(tblTest2))\n \nlocal tblTest3 = { 1, nil, 2 }\nprint(&quot;Test3 &quot; .. #(tblTest3))\n \nlocal tblTest4 = { 1, nil, 2, nil }\nprint(&quot;Test4 &quot; .. #(tblTest4))\n \nlocal tblTest5 = { 1, nil, 2, nil, 3, nil }\nprint(&quot;Test5 &quot; .. #(tblTest5))\n \nlocal tblTest6 = { 1, nil, 2, nil, 3, nil, 4, nil }\nprint(&quot;Test6 &quot; .. #(tblTest6))\n我们分别使用 Lua 和 LuaJIT 来执行一下：\n➜ luajit test.lua\nTest1 2\nTest2 1\nTest3 1\nTest4 1\nTest5 1\nTest6 1\n \n➜ lua test.lua\nTest1 2\nTest2 1\nTest3 3\nTest4 1\nTest5 3\nTest6 1\n这一段的输出结果，就是这么 匪夷所思。不要在 Lua 的 table 中使用 nil 值，如果一个元素要删除，直接 remove，不要用 nil 去代替。\n非空判断\n有时候不小心引用了一个没有赋值的变量，这时它的值默认为 nil。如果对一个 nil 进行索引的话，会导致异常。\nlocal person = {name = &quot;Bob&quot;, sex = &quot;M&quot;}\n \n-- do something\nperson = nil\n-- do something\nprint(person.name)\n会报错\nstdin:1:attempt to index global &#039;person&#039; (a nil value)\nstack traceback:\n   stdin:1: in main chunk\n   [C]: ?\n在实际的工程代码中，我们很难这么轻易地发现我们引用了 nil 变量。因此，在很多情况下我们在访问一些 table 型变量时，需要先判断该变量是否为 nil，例如将上面的代码改成\nlocal person = {name = &quot;Bob&quot;, sex = &quot;M&quot;}\n \n-- do something\nperson = nil\n-- do something\nif person ~= nil and person.name ~= nil then\n    print(person.name)\nelse\n-- do somethingend\n对于简单类型的变量，我们可以用 if (var == nil) then 这样的简单句子来判断。但是对于 table 型的 Lua 对象，就不能这么简单判断它是否为空了。一个 table 型变量的值可能是 {}，这时它不等于 nil。我们来看下面这段代码：\nlocal next = next\nlocal a = {}\nlocal b = {name = &quot;Bob&quot;, sex = &quot;Male&quot;}\nlocal c = {&quot;Male&quot;, &quot;Female&quot;}\nlocal d = nil\n \nprint(#a)\nprint(#b)\nprint(#c)\n--print(#d)    -- error\n \nif a == nil then\n    Print (&quot;a == nil&quot;)\nEnd\n \nIf b == nil then\n    Print (&quot;b == nil&quot;)\nEnd\n \nIf c == nil then\n    Print (&quot;c == nil&quot;)\nEnd\n \nIf d== nil then\n    Print (&quot;d == nil&quot;)\nEnd\n \nIf next (a) == nil then\n    Print (&quot;next (a) == nil&quot;)\nEnd\n \nIf next (b) == nil then\n    Print (&quot;next (b) == nil&quot;)\nEnd\n \nIf next (c) == nil then\n    Print (&quot;next (c) == nil&quot;)\nEnd\n输出\n0\n0\n2\nD == nil\nNext (a) == nil\n因此，我们要判断一个 table 是否为 {}，不能采用  #table == 0 的方式来判断。可以用下面这样的方法来判断：\nFunction isTableEmpty (t)\n    Return t == nil or next (t) == nil\nEnd\n注意：next 指令是不能被 LuaJIT 的 JIT 编译优化，并且 LuaJIT 貌似没有明确计划支持这个指令优化，在不是必须的情况下，尽量少用。\n正则表达式\n同时存在两套正则表达式规范：Lua 语言的规范和 ngx. Re.* 的规范，即使您对 Lua 语言中的规范非常熟悉，我们仍不建议使用 Lua 中的正则表达式。\n\n\n一是因为 Lua 中正则表达式的性能并不如 ngx. Re.* 中的正则表达式优秀；\n\n\n二是 Lua 中的正则表达式并不符合 POSIX 规范，而 ngx. Re.* 中实现的是标准的 POSIX 规范，后者明显更具备通用性。\n\n\nngx. Re.* 中的 o 选项，指明该参数，被编译的 Pattern 将会在工作进程中缓存，并且被当前工作进程的每次请求所共享。Pattern 缓存的上限值通过 lua_regex_cache_max_entries 来修改，它的默认值为 1024。\nngx. Re.* 中的 j 选项，指明该参数，如果使用的 PCRE 库支持 JIT，OpenResty 会在编译 Pattern 时启用 JIT。启用 JIT 后正则匹配会有明显的性能提升。较新的平台，自带的 PCRE 库均支持 JIT。如果系统自带的 PCRE 库不支持 JIT，出于性能考虑，最好自己编译一份 libpcre. So，然后在编译 OpenResty 时链接过去。要想验证当前 PCRE 库是否支持 JIT，可以这么做\n\n\n编译 OpenResty 时在 ./configure 中指定 --with-debug 选项\n\n\n在 error_log 指令中指定日志级别为 debug\n\n\n运行正则匹配代码，查看日志中是否有 pcre JIT compiling result: 1\n\n\n即使运行在不支持 JIT 的 OpenResty 上，加上 j 选项也不会带来坏的影响。在 OpenResty 官方的 Lua 库中，正则匹配至少都会带上 jo 这两个选项。\nLocation /test {\n    Content_by_lua_block {\n        local regex = [[\\d+]]\n \n        -- 参数 &quot;j&quot; 启用 JIT 编译，参数 &quot;o&quot; 是开启缓存必须的\n        Local m = ngx.Re.Match (&quot;hello, 1234&quot;, regex, &quot;jo&quot;)\n        If m then\n            Ngx.Say (m[0])\n        Else\n            Ngx.Say (&quot;not matched!&quot;)\n        End\n    }\n}\nLua 正则简单汇总\nLua 中正则表达式语法上最大的区别，Lua 使用 ’%’ 来进行转义，而其他语言的正则表达式使用 ” 符号来进行转义。其次，Lua 中并不使用 ’?’ 来表示非贪婪匹配，而是定义了不同的字符来表示是否是贪婪匹配。定义如下：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n符号匹配次数匹配模式+匹配前一字符 1 次或多次非贪婪*匹配前一字符 0 次或多次贪婪-匹配前一字符 0 次或多次非贪婪?匹配前一字符 0 次或 1 次仅用于此，不用于标识是否贪婪\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n符号匹配模式.任意字符%a字母%c控制字符%d数字%l小写字母%p标点字符%s空白符%u大写字母%w字母和数字%x十六进制数字%z代表 0 的字符\n虚变量\n当一个方法返回多个值时，有些返回值有时候用不到，要是声明很多变量来一一接收，显然不太合适（不是不能）。Lua 提供了一个虚变量 (dummy variable)的概念，按照**惯例**以一个下划线（“_”）来命名，用它来表示丢弃不需要的数值，仅仅起到占位的作用。\n返回值\n-- string. Find (s, p) 从 string 变量 s 的开头向后匹配 string\n-- p，若匹配不成功，返回 nil，若匹配成功，返回第一次匹配成功\n-- 的起止下标。\n \nLocal start, finish = string.Find (&quot;hello&quot;, &quot;he&quot;) --start 值为起始下标，finish\n--值为结束下标\nPrint ( start, finish )                          --输出 1   2\n \nLocal start = string.Find (&quot;hello&quot;, &quot;he&quot;)      -- start 值为起始下标\nPrint ( start )                               -- 输出 1\n \n \nLocal _, finish = string.Find (&quot;hello&quot;, &quot;he&quot;)   --采用虚变量（即下划线），接收起\n--始下标值，然后丢弃，finish 接收\n--结束下标值\nPrint ( finish )                              --输出 2\nPrint ( _ )    \n迭代\n-- test. Lua 文件\nLocal t = {1, 3, 5}\n \nPrint (&quot;all  data: &quot;)\nFor i, v in ipairs (t) do\n    Print (i, v)\nEnd\n \nPrint (&quot;&quot;)\nPrint (&quot;part data: &quot;)\nFor _, v in ipairs (t) do\n    Print (v)\nEnd\n输出\n# Luajit test. Lua\nAll  data:\n1   1\n2   3\n3   5\n \nPart data:\n1\n3\n5\n抵制使用 module () 定义模块\n旧式的模块定义方式是通过 module (&quot;filename&quot;[, package. Seeall])* 来显式声明一个包，现在官方不推荐再使用这种方式\n这种方式将会返回一个由 filename 模块函数组成的 table，并且还会定义一个包含该 table 的全局变量。\n\n\npackage. Seeall 这种方式破坏了模块的高内聚，原本引入 “filename” 模块只想调用它的 foobar () 函数，但是它却可以读写全局属性，例如 &quot;filename. Os&quot;。\n\n\nmodule 函数压栈操作引发的副作用，污染了全局环境变量。例如 module (&quot;filename&quot;) 会创建一个 filename 的 table，并将这个 table 注入全局环境变量中，这样使得没有引用它的文件也能调用 filename 模块的方法。\n\n\n推荐的模块定义\n-- square. Lua 长方形模块\nLocal _M = {}           -- 局部的变量\n_M._VERSION = &#039;1.0&#039;     -- 模块版本\n \nLocal mt = { __index = _M }\n \nfunction _M.new (self, width, height)\n    Return setmetatable ({ width=width, height=height }, mt)\nEnd\n \nfunction _M.get_square (self)\n    Return self. Width * self. Height\nEnd\n \nfunction _M.get_circumference (self)\n    Return (self. Width + self. Height) * 2\nEnd\n \nReturn _M\n使用\nLocal square = require &quot;square&quot;\nLocal s 1 = square: new (1, 2)\nPrint (s 1: get_square ())          --output: 2\nPrint (s 1: get_circumference ())   --output: 6\n另一个跟 Lua 的 module 模块相关需要注意的点是，当 lua_code_cache on 开启时，require 加载的模块是会被缓存下来的，这样我们的模块就会以最高效的方式运行，直到被显式地调用如下语句（这里有点像模块卸载）：\nPackage. Loaded[&quot;square&quot;] = nil\n调用函数前先定义函数\nLua 里面的函数必须放在调用的代码之前，下面的代码是一个常见的错误：\n-- test. Lua 文件 local i = 100\nI = add_one (i)\n \nFunction add_one (i)\n    Return i + 1\nEnd\n因此在函数定义之前使用函数相当于在变量赋值之前使用变量，Lua 世界对于没有赋值的变量，默认都是 nil，所以这里也就产生了一个 nil 的错误。\n点号操作符和冒号操作符的区别\nLocal str = &quot;abcde&quot;\n \nPrint (&quot;case 1: &quot;, str: sub (1, 2))\nPrint (&quot;case 2: &quot;, str.Sub (str, 1, 2))\n输出\nCase 1: ab\nCase 2: ab\n\n\n冒号操作会带入一个 self 参数，用来代表 自己****。\n\n\n而点号操作，只是 内容 的展开。\n\n\n在函数定义时，使用冒号将默认接收一个 self 参数，而使用点号则需要显式传入 self 参数\n示例代码：\nObj = { x = 20 }\n \nFunction obj: fun 1 ()\n    Print (self. X)\nEnd\n等价于\nObj = { x = 20 }\n \nFunction obj. Fun 1 (self)\n    Print (self. X)\nEnd\nModule 的缺点\n由于 lua_code_cache off 情况下，缓存的代码会伴随请求完结而释放。Module 的最大好处缓存这时候是无法发挥的，所以本章的内容都是基于 lua_code_cache on 的情况下。\n先看看下面代码：\nLocal ngx_socket_tcp = ngx. Socket. Tcp           -- ①\n \nLocal _M = { _VERSION = &#039;0.06&#039; }                -- ②\nLocal mt = { __index = _M }                     -- ③\n \nfunction _M.new (self)\n    Local sock, err = ngx_socket_tcp ()          -- ④\n    If not sock then\n        Return nil, err\n    End\n    Return setmetatable ({ sock = sock }, mt)    -- ⑤\nEnd\n \nfunction _M.set_timeout (self, timeout)\n    Local sock = self. Sock\n    If not sock then\n        Return nil, &quot;not initialized&quot;\n    End\n \n    Return sock: settimeout (timeout)\nEnd\n \n-- ... 其他功能代码，这里简略\n \nReturn _M\n\n\n对于比较底层的模块，内部使用到的非本地函数，都需要 local 本地化，这样做的好处：\n\n\n避免命名冲突：防止外部是 require (...) 的方法调用造成全局变量污染\n\n\n访问局部变量的速度比全局变量更快、更快、更快（重要事情说三遍）\n\n\n\n\n每个基础模块最好有自己 _VERSION 标识，方便后期利用 _VERSION 完成热代码部署等高级特性，也便于使用者对版本有整体意识。\n\n\n其实 _M 和 mt 对于不同的请求实例（require 方法得到的对象）是相同的，因为 module 会被缓存到全局环境中。所以在这个位置千万不要放单请求内个性信息，例如 ngx. Ctx 等变量。\n\n\n这里需要实现的是给每个实例绑定不同的 tcp 对象，后面 setmetatable 确保了每个实例拥有自己的 socket 对象，所以必须放在 new 函数中。如果放在 ③ 的下面，那么这时候所有的不同实例内部将绑定了同一个 socket 对象。\n\n\nLocal mt = { __index = _M }                     -- ③\nLocal sock = ngx_socket_tcp ()                   -- ④ 错误的\n \nfunction _M.new (self)\n    Return setmetatable ({ sock = sock }, mt)    -- ⑤\nEnd\n\n\nLua 的 module 有两种类型：\n\n\n支持面向对象痕迹可以保留私有属性；静态方法提供者，没有任何私有属性。\n\n\n真正起到区别作用的就是 setmetatable 函数，是否有自己的个性元表，最终导致两种不同的形态。\n\n\n\n\nFFI\nmoonbingbing.gitbooks.io/openresty-best-practices/content/lua/FFI.html\nFFI 库，是 LuaJIT 中最重要的一个扩展库。它允许从纯 Lua 代码调用外部 C 函数，使用 C 数据结构。\nFFI 库最大限度的省去了使用 C 手工编写繁重的 Lua/C 绑定的需要。不需要学习一门独立/额外的绑定语言——它解析普通 C 声明。这样可以从 C 头文件或参考手册中，直接剪切，粘贴。它的任务就是绑定很大的库，但不需要捣鼓脆弱的绑定生成器。\nFFI 紧紧的整合进了 LuaJIT（几乎不可能作为一个独立的模块）。JIT 编译器在 C 数据结构上所产生的代码，等同于一个 C 编译器应该生产的代码。在 JIT 编译过的代码中，调用 C 函数，可以被内连处理，不同于基于 Lua/C API 函数调用。\nffi 库词汇\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnounExplanationcdeclA definition of an abstract C type (actually, is a lua string)ctypeC type objectcdataC data objectctC type format, is a template object, may be cdecl, cdata, ctypecbcallback objectVLAAn array of variable lengthVLSA structure of variable length\nffi. API*\n功能： Lua ffi 库的 API，与 LuaJIT 不可分割。\n毫无疑问，在 lua 文件中使用 ffi 库的时候，必须要有下面的一行。\nLocal ffi = require &quot;ffi&quot;\nJIT\n看一下 LuaJIT 官方的解释：LuaJIT is a Just-In-Time Compilerfor the Lua programming language。\nLuaJIT 的运行时环境包括一个用手写汇编实现的 Lua 解释器和一个可以直接生成机器代码的 JIT 编译器\n\n\n一开始的时候，Lua 字节码总是被 LuaJIT 的解释器解释执行。LuaJIT 的解释器会在执行字节码时同时记录一些运行时的统计信息，比如每个 Lua 函数调用入口的实际运行次数，还有每个 Lua 循环的实际执行次数。\n\n\n当这些次数超过某个预设的阈值时，便认为对应的 Lua 函数入口或者对应的 Lua 循环足够的“热”，这时便会触发 JIT 编译器开始工作。\n\n\nJIT 编译器会从热函数的入口或者热循环的某个位置开始尝试编译对应的 Lua 代码路径。编译的过程是把 LuaJIT 字节码先转换成 LuaJIT 自己定义的中间码（IR），然后再生成针对目标体系结构的机器码（比如 x 86_64 指令组成的机器码）\n\n\n如果当前 Lua 代码路径上的所有的操作都可以被 JIT 编译器顺利编译，则这条编译过的代码路径便被称为一个“trace”，在物理上对应一个 trace 类型的 GC 对象（即参与 Lua GC 的对象）。\n\n\nJIT 编译器不支持的原语被称为 NYI（Not Yet Implemented）原语。比较完整的 NYI 列表在这篇文档里面：\nwiki.luajit.org/NYI\n所谓“让更多的 Lua 代码被 JIT 编译”，其实就是帮助更多的 Lua 代码路径能为 JIT 编译器所接受。这一般通过两种途径来实现：\n\n\n调整对应的 Lua 代码，避免使用 NYI 原语。\n\n\n增强 JIT 编译器，让越来越多的 NYI 原语能够被编译。\n\n\n可以被 JIT 编译的元操作\n下面给大家列一下截止到目前已经可以被 JIT 编译的元操作。其他还有 IO、Bit、FFI、Coroutine、OS、Package、Debug、JIT 等分类，使用频率相对较低，这里就不罗列了，可以参考官网：wiki.luajit.org/NYI。\n基础库的支持情况\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n函数编译?备注assertyescollectgarbagenodofilenevererrornevergetfenv2.1 partial只有 getfenv (0) 能编译getmetatableyesipairsyesloadneverloadfileneverloadstringnevernextnopairsnopcallyesprintnorawequalyesrawgetyesrawlen (5.2)yesrawsetyesselectpartial第一个参数是静态变量的时候可以编译setfenvnosetmetatableyestonumberpartial不能编译非 10 进制，非预期的异常输入tostringpartial只能编译：字符串、数字、布尔、nil 以及支持 __tostring 元方法的类型typeyesunpacknoxpcallyes\n字符串库\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n函数编译?备注string. Byteyesstring. Char2.1string. Dumpneverstring. Find2.1 partial只有字符串样式查找（没有样式）string. Format2.1 partial不支持 %p 或非字符串参数的 %sstring. Gmatchnostring. Gsubnostring. Lenyesstring. Lower2.1string. Matchnostring. Rep2.1string. Reverse2.1string. Subyesstring. Upper2.1\n表\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n函数编译?备注table. Concat2.1table. Foreachno2.1: 内部编译，但还没有外放table. Foreachi2.1table. Getnyestable. Insertpartial只有 push 操作table. Maxnnotable. Pack (5.2)notable. Remove2.1部分，只有 pop 操作table. Sortnotable. Unpack (5.2)no\nmath 库\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n函数编译?备注math. Absyesmath. Acosyesmath. Asinyesmath. Atanyesmath. Atan 2yesmath. Ceilyesmath. Cosyesmath. Coshyesmath. Degyesmath. Expyesmath. Flooryesmath. Fmodnomath. Frexpnomath. Ldexpyesmath. Logyesmath. Log 10yesmath. Maxyesmath. Minyesmath. Modfyesmath. Powyesmath. Radyesmath. Randomyesmath. Randomseednomath. Sinyesmath. Sinhyesmath. Sqrtyesmath. Tanyesmath. Tanhyes"},"shell/shell":{"title":"shell overview","links":[],"tags":["shell"],"content":"Shell 综述\n所谓的Shell，就是运行在终端中的文本互动程序。Shell分析你的文本输入，然后把文本转换成相应的计算机动作。\n在后面的内容中，我将用$来表示Linux系统Shell的命令提示符。比如说输入date命令：\n$date\ndate用于日期时间的相关功能。敲击回车键Enter后，Shell会显示出系统当前的时间。\nshell是Unix体系下的文本交互界面。你只需要用键盘来输入文本，就可以和操作系统交互。但这还是不够具体。说到底，Shell其实是一个运行着的程序。这个程序接收到你按下回车键之间的输入，就会对输入的文本进行分析。比如下面这个命令：\n$free -h\n包括空格在内总共7个字符。Shell程序会通过空格，区分出命令的不同部分\n\n\n第一个部分是命令名。\n\n\n剩下的部分是选项和参数。\n\n\n在这个例子中，Shell会进一步分析第二个部分，发现这一部分的开头是”-“字符，从而知道它是一个选项。\n有了命令名，Shell下一步就要执行该命令名对应的动作。这听起来就像是在戏剧舞台上，演员按照脚本演戏。Shell命令可以分为如下三类：\n\n\nShell内建函数（built-in function）\n\nShell的内建函数是Shell自带的功能，\n\n\n\n可执行文件（executable file）\n\n\n可执行文件是保存在Shell之外的脚本，提供了额外的功能\n\n\nShell必须在系统中找到对应命令名的可执行文件，才能正确执行。\n\n\n我们可以用绝对路径来告诉Shell可执行文件所在的位置。\n\n\n如果用户只是给出了命令名，而没有给出准确的位置，那么Shell必须自行搜索一些特殊的位置，也就是所谓的默认路径。\n\n\nShell会执行第一个名字和命令名相同的可执行文件。这就相当于，Shell帮我们自动补齐了可执行文件的位置信息。\n\n\n我们可以通过which命令，来确定命令名对应的是哪个可执行文件：\n\n\n\n\n\n\n\n\n$which date\n\n\n别名（alias）\n\n别名是给某个命令一个简称，以后在Shell中就可以通过这个简称来调用对应的命令。在Shell中，我们可以用alias来定义别名：\n\n\n\n$alias freak=&quot;free -h&quot;\n我们可以通过type命令来了解命令的类型\n$type date\n$type pwd\nShell的选择\nShell是文本解释器程序的统称，所以包括了不止一种Shell。常见的Shell有sh、bash、ksh、rsh、csh等\n\nsh的全名是Bourne Shell。名字中的玻恩就是这个Shell的作者。\nbash的全名是Bourne Again Shell\n\n可以使用下面的命令查看sh 的版本\n$echo $SHELL\n\n\necho用于在终端打印出文本。\n\n\n而$是一个新的Shell特殊符号。它提示Shell，后面跟随的不是一般的文本，而是用于存储数据的变量。\n\n\n可以使用下面的命令更换shell\n# chsh -s /bin/csh //改变当前设置为 /bin/csh\nChanging shell for root.\nShell not changed.\n命令的选项和参数\n一行命令里还可以包含着选项和参数。总的来说，\n\n\n选项用于控制命令的行为，\n\n\n而参数说明了命令的作用对象。\n\n\n比如说：\n$uname -m\n选项-m影响了命令uname的行为，导致uname输出了树莓派的CPU型号。如果不是该选项的影响，uname输出的将是”Linux”。\n\n由一个”-“引领一个英文字母，这成为短选项。多个短选项的字母可以合在一起，跟在同一个”-“后面。比如，下面的两个命令就等价：\n\n$uname -m -r\n$uname -mr\n\n此外还有一种长选项，是用”—“引领一整个英文单词\n\n$date --version\n有的时候，选项也会携带变量\n$sudo date --set=&quot;1999-01-01 08:00:00&quot;\n值得注意的是，Shell对空格敏感。当一整个参数信息中包含了空格时，我们需要用引号把参数包裹起来，以便Shell能识别出这是一个整体。\n变量\n我们可以通过变量名来引用变量中保持的数据。借助变量，程序员可以复用出现过的数据。Bash中也有变量，但Bash的变量只能存储文本。\n定义变量\n定义变量时，变量名不加美元符号\nyour_name=&quot;a.com&quot;\n变量的命名规则\n\n\n命名只能使用英文字母，数字和下划线，首个字符不能以数字开头。\n\n\n中间不能有空格，可以使用下划线 _。\n\n\n不能使用标点符号。\n\n\n不能使用bash里的关键字（可用help命令查看保留关键字）\n\n\n变量赋值\n\n用“=”来表示赋值\n\nvar=World\n就是把文本World存入名为var的变量，即赋值。根据Bash的语法，赋值符号“=”的前后不留空格。赋值号右边的文本内容会存入赋值号左边的变量。\nyour_name=&quot;tom&quot;\necho $your_name\nyour_name=&quot;alibaba&quot;\necho $your_name\n但注意，第二次赋值的时候不能写$your_name=&quot;alibaba&quot;，使用变量的时候才加美元符（$）。\n\n如果文本中包含空格，那么你可以用单引号或双引号来包裹文本\n\nvar=&#039;abc bcd&#039;\n \n或者\n \nvar=&quot;abc bcd&quot;\n\n可以把一个命令输出的文本直接赋予给一个变量，借助“符号，date命令的输出存入了变量now\n\nnow=`date`\n\n我们还可以把一个变量中的数据赋值给另一个变量：\n\nanother=$var\n引用变量\n在Bash中，所谓的引用变量就是把变量翻译成变量中存储的文本，使用变量时，需要加美元符\n\n我们可以用$var的方式来引用变量。\n\nvar=World\n$echo $var\n\n在Bash中，你还可以在一段文本中嵌入变量。Bash也会把变量替换成变量中保存的文本\n\n$echo Hello$var\n\n为了避免变量名和尾随的普通文本混淆，我们也可以换用${}的方式来标识变量\n\n$echo $varIsGood\n \n由于Bash中并没有varIsGood这个变量，所以Bash将打印空白行。但如果将命令改为：\n$echo ${var}IsGood\n \nBash通过${}识别出变量var，并把它替换成数据。最终echo命令打印出WorldIsGood。\n\n\n在Bash中，为了把一段包含空格的文本当做单一参数，就需要用到单引号或双引号。\n\n\n你可以在双引号中使用变量。\n\n\n$echo &quot;Hello $var&quot;\n\n\nBash会忽视单引号中的变量引用，所以单引号中的变量名只会被当做普通文本\n\n\n$echo &#039;Hello $var&#039;\n \n将打印Hello $var。\n\n\n删除变量\n使用 unset 命令可以删除变量。语法：\nunset variable_name\n \n \nmyUrl=&quot;www.runoob.com&quot;\nunset myUrl\necho $myUrl\n变量类型\n\n\n1) 局部变量 局部变量在脚本或命令中定义，仅在当前shell实例中有效，其他shell启动的程序不能访问局部变量。\n\n\n2) 环境变量 所有的程序，包括shell启动的程序，都能访问环境变量，有些程序需要环境变量来保证其正常运行。必要的时候shell脚本也可以定义环境变量。\n\n\n3) shell变量 shell变量是由shell程序设置的特殊变量。shell变量中有一部分是环境变量，有一部分是局部变量，这些变量保证了shell的正常运行\n\n\n字符串\n字符串是shell编程中最常用最有用的数据类型（除了数字和字符串，也没啥其它类型好用了），\n\n\n字符串可以用单引号，\n\n\n也可以用双引号，\n\n\n也可以不用引号。\n\n\n单引号\nstr=&#039;this is a string&#039;\n单引号字符串的限制：\n\n\n单引号里的任何字符都会原样输出，单引号字符串中的变量是无效的；\n\n\n单引号字串中不能出现单独一个的单引号（对单引号使用转义符后也不行），但可成对出现，作为字符串拼接使用。\n\n\n双引号\nyour_name=&quot;runoob&quot;\nstr=&quot;Hello, I know you are \\&quot;$your_name\\&quot;! \\n&quot;\necho -e $str\n双引号的优点：\n\n\n双引号里可以有变量\n\n\n双引号里可以出现转义字符\n\n\n\n拼接字符串\n\nyour_name=&quot;runoob&quot;\n# 使用双引号拼接\ngreeting=&quot;hello, &quot;$your_name&quot; !&quot;\ngreeting_1=&quot;hello, ${your_name} !&quot;\necho $greeting  $greeting_1\n \n# 使用单引号拼接\ngreeting_2=&#039;hello, &#039;$your_name&#039; !&#039;\ngreeting_3=&#039;hello, ${your_name} !&#039;\necho $greeting_2  $greeting_3\n输出\nhello, runoob ! hello, runoob !\nhello, runoob ! hello, ${your_name} !\n\n获取字符串长度\n\nstring=&quot;abcd&quot;\necho ${#string}   # 输出 4\n\n提取子字符串\n\nstring=&quot;runoob is a great site&quot;\necho ${string:1:4} # 输出 unoo\n\n查找字符串\n\n查找字符 i 或 o 的位置(哪个字母先出现就计算哪个)：\nstring=&quot;runoob is a great site&quot;\necho `expr index &quot;$string&quot; io`  # 输出 4\n数组\nbash支持一维数组（不支持多维数组），并且没有限定数组的大小。\n数组元素的下标由 0 开始编号。获取数组中的元素要利用下标，下标可以是整数或算术表达式，其值应大于或等于 0\n定义数组\n数组名=(值1 值2 ... 值n)\narray_name=(value0 value1 value2 value3)\n或者\narray_name=(\nvalue0\nvalue1\nvalue2\nvalue3\n)\n或者\narray_name[0]=value0\narray_name[1]=value1\narray_name[n]=valuen\n读取数组\n${数组名[下标]}\nvaluen=${array_name[n]}\n使用 @ 符号可以获取数组中的所有元素\necho ${array_name[@]}\n获取数组长度\n# 取得数组元素的个数\nlength=${#array_name[@]}\n# 或者\nlength=${#array_name[*]}\n# 取得数组单个元素的长度\nlengthn=${#array_name[n]}\n关联数组\nBash 支持关联数组，可以使用任意的字符串、或者整数作为下标来访问数组元素。-A 选项就是用于声明一个关联数组。\ndeclare -A array_name\n关联数组的键是唯一的。\ndeclare -A site=([&quot;google&quot;]=&quot;www.google.com&quot; [&quot;runoob&quot;]=&quot;www.runoob.com&quot; [&quot;taobao&quot;]=&quot;www.taobao.com&quot;)\n或者\ndeclare -A site\nsite[&quot;google&quot;]=&quot;www.google.com&quot;\nsite[&quot;runoob&quot;]=&quot;www.runoob.com&quot;\nsite[&quot;taobao&quot;]=&quot;www.taobao.com&quot;\n \necho &quot;数组的键为: ${!site[*]}&quot;\necho &quot;数组的键为: ${!site[@]}&quot;\n \n \n输出\n \n数组的键为: google runoob taobao\n数组的键为: google runoob taobao\n注释\n单行注释\n#--------------------------------------------\n# 这是一个注释\n# author：菜鸟教程\n# site：www.runoob.com\n# slogan：学的不仅是技术，更是梦想！\n#--------------------------------------------\n##### 用户配置区 开始 #####\n#\n#\n# 这里可以添加脚本描述信息\n#\n#\n##### 用户配置区 结束  #####\n多行注释\n:&lt;&lt;EOF\n注释内容...\n注释内容...\n注释内容...\nEOF\n或者\n:&lt;&lt;&#039;\n注释内容...\n注释内容...\n注释内容...\n&#039;\n \n:&lt;&lt;!\n注释内容...\n注释内容...\n注释内容...\n!\nEcho\nShell 的 echo 指令与 PHP 的 echo 指令类似，都是用于字符串的输出。命令格式：\necho string\n您可以使用echo实现更复杂的输出格式控制。\n显示普通字符串:\necho &quot;It is a test&quot;\n这里的双引号完全可以省略，以下命令与上面实例效果一致：\necho It is a test\n显示转义字符\necho &quot;\\&quot;It is a test\\&quot;&quot;\n结果将是:\n&quot;It is a test&quot;\n同样，双引号也可以省略\n显示变量\nread 命令从标准输入中读取一行,并把输入行的每个字段的值指定给 shell 变量\n#!/bin/sh\nread name \necho &quot;$name It is a test&quot;\n以上代码保存为 test.sh，name 接收标准输入的变量，结果将是:\n[root@www ~]# sh test.sh\nOK                     #标准输入\nOK It is a test        #输出\n显示换行\n \necho -e &quot;OK! \\n&quot; # -e 开启转义\necho &quot;It is a test&quot;\n输出结果：\nOK!\n \nIt is a test\n显示不换行\n#!/bin/sh\necho -e &quot;OK! \\c&quot; # -e 开启转义 \\c 不换行\necho &quot;It is a test&quot;\n输出结果：\nOK! It is a test\n显示结果定向至文件\necho &quot;It is a test&quot; &gt; myfile\n原样输出字符串，不进行转义或取变量(用单引号)\necho &#039;$name\\&quot;&#039;\n输出结果：\n$name\\&quot;\n显示命令执行结果\necho `date`\n注意： 这里使用的是反引号 `, 而不是单引号 ‘。\n结果将显示当前日期\nWed Apr 5 00:52:17 CST 2023\n数学运算\n\n在Bash中，数字和运算符都被当做普通文本。所以你无法像C语言一样便捷地进行数学运算。比如执行下面的命令\n\n$result=1+2\n$echo $result\n \nBash并不会进行任何运算。它只会打印文本“1+2”。\n\n在Bash中，你还可以通过$(())语法来进行数值运算。在双括号中你可以放入整数的加减乘除表达式。Bash会对其中的内容进行数值运算。比如\n\n$echo $((2 + (5*2)))\n\n在$(())中，你也可以使用变量\n\n$var=1\n$echo $(($var + (5*2)))\n \n将打印运算结果11。\n\n可以把数学运算的结果存入变量\n\n$result=$(( 1 + 2 ))\n运算符-expr和**$((表达式))**\n**原生bash不支持简单的数学运算，**但是可以通过其他命令来实现，例如 awk 和 expr，expr 最常用。\n\n\nexpr 是一款表达式计算工具，使用它能完成表达式的求值操作。\n\n\n在 MAC 中 shell 的 expr 语法是：$((表达式))\n\n\n注意点\n\n\n表达式和运算符之间要有空格，例如 2+2 是不对的，必须写成 2 + 2，这与我们熟悉的大多数编程语言不一样。\n\n\n完整的表达式要被 “ 包含，注意这个字符不是常用的单引号，在 Esc 键下边。\n\n\n#!/bin/bash\n \nval=`expr 2 + 2`\necho &quot;两数之和为 : $val&quot;\n\n\n算数运算符\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n运算符说明举例+加法expr $a + $b 结果为 30。-减法expr $a - $b 结果为 -10。*乘法expr $a \\* $b 结果为 200。/除法expr $b / $a 结果为 2。%取余expr $b % $a 结果为 0。=赋值a=$b 把变量 b 的值赋给 a。==相等。用于比较两个数字，相同则返回 true。[ a==b ] 返回 false。!=不相等。用于比较两个数字，不相同则返回 true。[ a!=b ] 返回 true。\n#!/bin/bash\n# author:菜鸟教程\n# url:www.runoob.com\n \na=10\nb=20\n \nval=`expr $a + $b`\necho &quot;a + b : $val&quot;\n \nval=`expr $a - $b`\necho &quot;a - b : $val&quot;\n \nval=`expr $a \\* $b`\necho &quot;a * b : $val&quot;\n \nval=`expr $b / $a`\necho &quot;b / a : $val&quot;\n \nval=`expr $b % $a`\necho &quot;b % a : $val&quot;\n \nif [ $a == $b ]\nthen\n   echo &quot;a 等于 b&quot;\nfi\nif [ $a != $b ]\nthen\n   echo &quot;a 不等于 b&quot;\nfi\n注意\n\n\n乘号(*)前边必须加反斜杠()才能实现乘法运算；\n\n\n在 MAC 中 shell 的 expr 语法是：$((表达式))，此处表达式中的 ”*” 不需要转义符号 &quot;&quot; 。\n\n\n关系运算符\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n运算符说明举例-eq检测两个数是否相等，相等返回 true。[ a−eqb ] 返回 false。-ne检测两个数是否不相等，不相等返回 true。[ a−neb ] 返回 true。-gt检测左边的数是否大于右边的，如果是，则返回 true。[ a−gtb ] 返回 false。-lt检测左边的数是否小于右边的，如果是，则返回 true。[ a−ltb ] 返回 true。-ge检测左边的数是否大于等于右边的，如果是，则返回 true。[ a−geb ] 返回 false。-le检测左边的数是否小于等于右边的，如果是，则返回 true。[ a−leb ] 返回 true。\n#!/bin/bash\n# author:菜鸟教程\n# url:www.runoob.com\n \na=10\nb=20\n \nif [ $a -eq $b ]\nthen\n   echo &quot;$a -eq $b : a 等于 b&quot;\nelse\n   echo &quot;$a -eq $b: a 不等于 b&quot;\nfi\nif [ $a -ne $b ]\nthen\n   echo &quot;$a -ne $b: a 不等于 b&quot;\nelse\n   echo &quot;$a -ne $b : a 等于 b&quot;\nfi\nif [ $a -gt $b ]\nthen\n   echo &quot;$a -gt $b: a 大于 b&quot;\nelse\n   echo &quot;$a -gt $b: a 不大于 b&quot;\nfi\nif [ $a -lt $b ]\nthen\n   echo &quot;$a -lt $b: a 小于 b&quot;\nelse\n   echo &quot;$a -lt $b: a 不小于 b&quot;\nfi\nif [ $a -ge $b ]\nthen\n   echo &quot;$a -ge $b: a 大于或等于 b&quot;\nelse\n   echo &quot;$a -ge $b: a 小于 b&quot;\nfi\nif [ $a -le $b ]\nthen\n   echo &quot;$a -le $b: a 小于或等于 b&quot;\nelse\n   echo &quot;$a -le $b: a 大于 b&quot;\nfi\n布尔运算符\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n运算符说明举例!非运算，表达式为 true 则返回 false，否则返回 true。[ ! false ] 返回 true。-o或运算，有一个表达式为 true 则返回 true。[ a−lt20−ob -gt 100 ] 返回 true。-a与运算，两个表达式都为 true 才返回 true。[ a−lt20−ab -gt 100 ] 返回 false。\n#!/bin/bash\n# author:菜鸟教程\n# url:www.runoob.com\n \na=10\nb=20\n \nif [ $a != $b ]\nthen\n   echo &quot;$a != $b : a 不等于 b&quot;\nelse\n   echo &quot;$a == $b: a 等于 b&quot;\nfi\nif [ $a -lt 100 -a $b -gt 15 ]\nthen\n   echo &quot;$a 小于 100 且 $b 大于 15 : 返回 true&quot;\nelse\n   echo &quot;$a 小于 100 且 $b 大于 15 : 返回 false&quot;\nfi\nif [ $a -lt 100 -o $b -gt 100 ]\nthen\n   echo &quot;$a 小于 100 或 $b 大于 100 : 返回 true&quot;\nelse\n   echo &quot;$a 小于 100 或 $b 大于 100 : 返回 false&quot;\nfi\nif [ $a -lt 5 -o $b -gt 100 ]\nthen\n   echo &quot;$a 小于 5 或 $b 大于 100 : 返回 true&quot;\nelse\n   echo &quot;$a 小于 5 或 $b 大于 100 : 返回 false&quot;\nfi\n逻辑运算符\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n运算符说明举例&amp;&amp;逻辑的 AND[[ a -lt 100 &amp;&amp; b -gt 100 ]] 返回 false|逻辑的 OR[[ $a -lt 100 \\\n#!/bin/bash\n# author:菜鸟教程\n# url:www.runoob.com\n \na=10\nb=20\n \nif [[ $a -lt 100 &amp;&amp; $b -gt 100 ]]\nthen\n   echo &quot;返回 true&quot;\nelse\n   echo &quot;返回 false&quot;\nfi\n \nif [[ $a -lt 100 || $b -gt 100 ]]\nthen\n   echo &quot;返回 true&quot;\nelse\n   echo &quot;返回 false&quot;\nfi\n字符串运算符\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n运算符说明举例=检测两个字符串是否相等，相等返回 true。[ a=b ] 返回 false。!=检测两个字符串是否不相等，不相等返回 true。[ a!=b ] 返回 true。-z检测字符串长度是否为0，为0返回 true。[ -z $a ] 返回 false。-n检测字符串长度是否不为 0，不为 0 返回 true。[ -n “$a” ] 返回 true。$检测字符串是否不为空，不为空返回 true。[ $a ] 返回 true。\n#!/bin/bash\n# author:菜鸟教程\n# url:www.runoob.com\n \na=&quot;abc&quot;\nb=&quot;efg&quot;\n \nif [ $a = $b ]\nthen\n   echo &quot;$a = $b : a 等于 b&quot;\nelse\n   echo &quot;$a = $b: a 不等于 b&quot;\nfi\nif [ $a != $b ]\nthen\n   echo &quot;$a != $b : a 不等于 b&quot;\nelse\n   echo &quot;$a != $b: a 等于 b&quot;\nfi\nif [ -z $a ]\nthen\n   echo &quot;-z $a : 字符串长度为 0&quot;\nelse\n   echo &quot;-z $a : 字符串长度不为 0&quot;\nfi\nif [ -n &quot;$a&quot; ]\nthen\n   echo &quot;-n $a : 字符串长度不为 0&quot;\nelse\n   echo &quot;-n $a : 字符串长度为 0&quot;\nfi\nif [ $a ]\nthen\n   echo &quot;$a : 字符串不为空&quot;\nelse\n   echo &quot;$a : 字符串为空&quot;\nfi\n文件测试运算符\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nb file检测文件是否是块设备文件，如果是，则返回 true。[ -b $file ] 返回 false。-c file检测文件是否是字符设备文件，如果是，则返回 true。[ -c $file ] 返回 false。-d file检测文件是否是目录，如果是，则返回 true。[ -d $file ] 返回 false。-f file检测文件是否是普通文件（既不是目录，也不是设备文件），如果是，则返回 true。[ -f $file ] 返回 true。-g file检测文件是否设置了 SGID 位，如果是，则返回 true。[ -g $file ] 返回 false。-k file检测文件是否设置了粘着位(Sticky Bit)，如果是，则返回 true。[ -k $file ] 返回 false。-p file检测文件是否是有名管道，如果是，则返回 true。[ -p $file ] 返回 false。-u file检测文件是否设置了 SUID 位，如果是，则返回 true。[ -u $file ] 返回 false。-r file检测文件是否可读，如果是，则返回 true。[ -r $file ] 返回 true。-w file检测文件是否可写，如果是，则返回 true。[ -w $file ] 返回 true。-x file检测文件是否可执行，如果是，则返回 true。[ -x $file ] 返回 true。-s file检测文件是否为空（文件大小是否大于0），不为空返回 true。[ -s $file ] 返回 true。-e file检测文件（包括目录）是否存在，如果是，则返回 true。[ -e $file ] 返回 true。\n#!/bin/bash\n# author:菜鸟教程\n# url:www.runoob.com\n \nfile=&quot;/var/www/runoob/test.sh&quot;\nif [ -r $file ]\nthen\n   echo &quot;文件可读&quot;\nelse\n   echo &quot;文件不可读&quot;\nfi\nif [ -w $file ]\nthen\n   echo &quot;文件可写&quot;\nelse\n   echo &quot;文件不可写&quot;\nfi\nif [ -x $file ]\nthen\n   echo &quot;文件可执行&quot;\nelse\n   echo &quot;文件不可执行&quot;\nfi\nif [ -f $file ]\nthen\n   echo &quot;文件为普通文件&quot;\nelse\n   echo &quot;文件为特殊文件&quot;\nfi\nif [ -d $file ]\nthen\n   echo &quot;文件是个目录&quot;\nelse\n   echo &quot;文件不是个目录&quot;\nfi\nif [ -s $file ]\nthen\n   echo &quot;文件不为空&quot;\nelse\n   echo &quot;文件为空&quot;\nfi\nif [ -e $file ]\nthen\n   echo &quot;文件存在&quot;\nelse\n   echo &quot;文件不存在&quot;\nfi\n返回代码\nLinux中，每个可执行程序会有一个整数的返回代码。按照Linux惯例，当程序正常运行完毕并返回时，将返回整数0。\n比如foo.c\nint main(void) {\n    int a;\n    int b;\n    int c;\n    a = 6;\n    b = 2;\n    c = 6/2;\n    return 0;\n}\n这段程序可以正常运行。因此，它将在最后一句执行return语句，程序的返回代码是0\n\n在Shell中，我们运行了程序后，可以通过$?变量来获知返回码\n\n$gcc foo.c\n$./a.out\n$echo $?\n\n如果一个程序运行异常，那么这个程序将返回非0的返回代码。比如删除一个不存在的文件：\n\n$rm none_exist.file\n$echo $?\n\n\n在Linux中，可以在一个行命令中执行多个程序\n$touch demo.file; ls;\n\n\n我们可以让后一个程序的运行参考前一个程序的返回代码。比如说，只有前一个程序返回成功代码0，才让后一个程序运行：可以改写为\n$rm demo.file &amp;&amp; echo &quot;rm succeed&quot;\n\n\n还有一种情况，是等到前一个程序失败了，才运行后一个程序\n\n\n$rm demo.file || echo &quot;rm fail&quot;\n\n\nBash 脚本\n你还可以把多行的Bash命令写入一个文件，成为所谓的Bash脚本，当Bash脚本执行时，Shell将逐行执行脚本中的命令。\n一个脚本例子\n#!/bin/bash\necho Hello\necho World\n\n\n脚本的第一行说明了该脚本使用的Shell，即/bin/bash路径的Bash程序\n\n\n脚本正文是两行echo命令，两行命令将按照由上至下的顺序依次执行\n\n\n运行脚本的方式和运行可执行程序的方式类似，都是：\n$./hello_world.bash\n\n如果用户不具有执行Bash脚本文件的权限，那么他将无法执行Bash脚本。此时，用户必须更换文件权限，或者以其他身份登录，才能执行脚本。\n\nBash脚本是一种复用代码的方式。我们看一个简单的Bash脚本hw_info.bash，它将计算机的信息存入到名为log的文件中：\n#!/bin/bash\necho &quot;Information of Vamei&#039;s computer:&quot; &gt; log\nlscpu &gt;&gt; log\nuname –a &gt;&gt; log\nfree –h &gt;&gt; log\n脚本参数\n和可执行程序类似，Bash脚本运行时，也可以携带参数。这些参数可以在Bash脚本中以变量的形式使用。\n在Bash中，你可以用0、1、$2……的方式，来获得Bash脚本运行时的参数\n比如\n#!/bin/bash\necho $0 \necho $1 \necho $2\n我们用下面的方式运行Bash脚本：\n$./test_arg.bash hello world\n0是命令的第一部分，也就是./testa​rg.bash。1代表了参数hello，而$2代表了参数world。因此，上面程序将打印：\n./test_arg.bash\nhello\nworld\n如果变更参数，同一段脚本将有不同的行为。这大大提高了Bash脚本的灵活性。上面的hw_info.bash脚本中，我们把输出文件名写死成log\n#!/bin/bash\necho &quot;Information of Vamei&#039;s computer:&quot; &gt; $1\nlscpu &gt;&gt; $1 \nuname –a &gt;&gt; $1 \nfree –h &gt;&gt; $1\n可以这样执行代码\n$./hw_info.bash output.file\n\n\n脚本内获取参数的格式为：$n。n 代表一个数字，1 为执行脚本的第一个参数，2 为执行脚本的第二个参数，以此类推……\n\n\n另外，还有几个特殊字符用来处理参数：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n参数处理说明$#传递到脚本的参数个数$*以一个单字符串显示所有向脚本传递的参数。  如”∗&quot;用「&quot;」括起来的情况、以&quot;1 2…n”的形式输出所有参数。$$脚本运行的当前进程ID号$!后台运行的最后一个进程的ID号$@与∗相同，但是使用时加引号，并在引号中返回每个参数。&lt;br&gt;如&quot;@“用「“」括起来的情况、以”1&quot;&quot;2” … “$n” 的形式输出所有参数。$-显示Shell使用的当前选项，与set命令功能相同。$?显示最后命令的退出状态。0表示没有错误，其他任何值表明有错误。\n∗与@ 区别：\n\n\n相同点：都是引用所有参数。\n\n\n不同点：只有在双引号中体现出来。假设在脚本运行时写了三个参数 1、2、3，，则 ” * ” 等价于 “1 2 3”（传递了一个参数），而 ”@” 等价于 “1” “2” “3”（传递了三个参数）。\n\n\n脚本的返回代码\n和可执行程序类似，脚本也可以有返回代码。还是按照惯例，脚本正常退出时返回代码0在脚本的末尾，我们可以用exit命令来设置脚本的返回代码\n#!/bin/bash\necho Hello\necho World\nexit 0\n其实在脚本的末尾加一句exit 0并不必要。一个脚本如果正常运行完最后一句，会自动的返回代码0。\n在脚本运行后，我们可以通过$?变量查询脚本的返回代码\n$./hello_world.bash\n$echo $?\n如果在脚本中部出现exit命令，脚本会直接在这一行停止，并返回该exit命令给出的返回代码\n#!/bin/bash\necho hello\nexit 1 echo world\n \n不会打印 world\n运行Shell 脚本\n1、作为可执行程序\nchmod +x ./test.sh  #使脚本具有执行权限\n./test.sh  #执行脚本\n2、作为解释器参数\n/bin/sh test.sh\n/bin/php test.php\n函数\n在Bash中，脚本和函数有很多相似的地方。\n\n\n脚本实现了一整个脚本文件的程序复用，\n\n\n而函数复用了脚本内部的部分程序。\n\n\n在定义函数时，我们需要花括号来标识函数包括的部分：\n#!/bin/bash\nfunction my_info (){\n  lscpu &gt;&gt; log\n  uname –a &gt;&gt; log\n  free –h &gt;&gt; log\n}\n \nmy_info\n需要强调的是，函数定义只是食谱，并没有转化成具体的动作。脚本的最后一行是在调用函数。只有通过函数调用，函数内包含的命令才能真正执行\n函数参数\n像脚本一样，函数调用时还可以携带参数。在函数内部，我们同样可以用1、2这种形式的变量来使用参数：\n当n&gt;=10时，需要使用${n}来获取参数。\n#!/bin/bash\nfunction my_info (){\n  lscpu &gt;&gt; $1 \n  uname –a &gt;&gt; $1 \n  free –h &gt;&gt; $1\n }\n \nmy_info output.file\nmy_info another_output.file\n还有几个特殊字符用来处理参数：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n$#传递到脚本或函数的参数个数$*以一个单字符串显示所有向脚本传递的参数$$脚本运行的当前进程ID号$!后台运行的最后一个进程的ID号$@与$*相同，但是使用时加引号，并在引号中返回每个参数。$-显示Shell使用的当前选项，与set命令功能相同。$?显示最后命令的退出状态。0表示没有错误，其他任何值表明有错误。\n跨脚本调用\n在Bash中使用source命令，可以实现函数的跨脚本调用。命令source的作用是在同一个进程中执行另一个文件中的Bash脚本\n比如说，有两个脚本，my_info.bash和app.bash。脚本my_info.sh中的内容是：\n#!/bin/bash\nfunction my_info (){\n  lscpu &gt;&gt; $1 \n  uname –a &gt;&gt; $1 \n  free –h &gt;&gt; $1\n}\n脚本app.bash中的内容是：\n#!/bin/bash\nsource my_info.bash\nmy_info output.file\n逻辑判断\nBash除了可以进行数值运算，还可以进行逻辑判断。逻辑判断是决定某个说法的真假。逻辑判断就是对一个说法判断真假。在Bash中，我们可以用test命令来进行逻辑判断：\n$test 3 -gt 2; echo $?\n命令test后面跟有一个判断表达式，其中的-gt表示大于，即greater than。\n数值判断\n数值大小和相等关系的判断，是最常见的逻辑判断。除了上面的大于和小于判断，我们还可以进行以下的数值判断：\n\n\n等于： test3−eq3;echo?\n\n\n不等于： test3−ne1;echo?\n\n\n大于等于： test5−ge2;echo?\n\n\n小于等于： test3−le1;echo?\n\n\n大于：test3−gt2;echo?\n\n\n小于：test3−lt2;echo\n\n\n文本判断\nBash中最常见的数据形式是文本，因此也提供了很多关于文本的判断：\n\n\n文本相同: testabc=abx;echo?\n\n\n文本不同： testabc!=abx;echo?\n\n\n按照词典顺序，一个文本在另一个文本之前： testapple&gt;tea;echo?\n\n\n按照词典顺序，一个文本在另一个文本之后： testapple&lt;tea;echo?\n\n\n文件状态判断\n\n\n检查一个文件是否存在： test–ea.out;echo?\n\n\n检查一个文件是否存在，而且是普通文件： test–ffile.txt;echo?\n\n\n检查一个文件是否存在，而且是目录文件： test–dmyfiles;echo?\n\n\n检查一个文件是否存在，而且是软连接： test–La.out;echo?\n\n\n检查一个文件是否可读： test–rfile.txt;echo?\n\n\n检查一个文件是否可写： test–wfile.txt;echo?\n\n\n检查一个文件是否可执行： test–xfile.txt;echo?\n\n\n与或非\n\n非，与expression的真假相反：\n\n! expression\n\n与，必须expression1和expression2都为真时，结果才为真：\n\nexpression1 –a expression2\n\n或，只要expression1和expression2的一个为真时，结果就为真：\n\nexpression1 –o expression2\n选择结构\n选择结构是一种语法结构，可以让程序根据条件决定执行哪一部分的指令，我们可以根据条件来决定是否执行某一部分程序，比如下面的demo_if.bash脚本\nif-fi\nvar=`whoami`\n \nif [ $var = &quot;root&quot; ]then   \n  echo &quot;You are root&quot;   \n  echo &quot;You are my God.&quot;\nfi\nif - else-fi\n#!/bin/bash\nfilename=$1 \n \nif [ -e $filename ]then   \n  echo &quot;$filename exists&quot; \nelse   \n  echo &quot;$filename NOT exists&quot; \nfi \n \necho &quot;The End&quot;\ncase\n在Bash下，我们还可以用case语法来实现多程序块的选择执行。比如下面的脚本demo_case.bash：\n#!/bin/bash\nvar=`whoami`\necho &quot;You are $var&quot; \ncase $var in\nroot)\n    echo &quot;You are God.&quot;\n;;\nvamei)\n    echo &quot;You are a happy user.&quot;\n;;\n*)\n    echo &quot;You are the Others.&quot;\n;;\nesac\n关键字case后面不再是逻辑表达式，而是一个作为条件的文本。后面的代码块分为三个部分，都以文本标签)的形式开始，以;;结束。在case结构运行时，会逐个检查文本标签。当条件文本和文本标签可以对应上时，Bash就会执行隶属于该文本标签的代码块。\n如果是用户vamei执行该Bash脚本，那么条件文本和vamei标签对应上，脚本就会打印：\nYou are a happy user.\n文本标签\n注意）\n文本标签除了是一串具体的文本，还可以包含文本通配符。结构case中常用的通配符包括：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n通配符含义文本标签例子符合条件的文本*任意文本*)Xyz, 12a3, …?任意一个字符a?c)abc, axc, …[]范围内一个字符[1-5][b-d])2b, 3d, …\n循环结构\nwhile\n\n在while语法中，Bash会循环执行隶属于while的代码块，直到逻辑表达式不成立。比如下面的demo_while.bash\n\n#!/bin/bash\nnow=`date +&#039;%Y%m%d%H%M&#039;`\ndeadline=`date --date=&#039;1 hour&#039; +&#039;%Y%m%d%H%M&#039;`\nwhile [ $now -lt $deadline ]do\n   date\n   echo &quot;not yet&quot;\n   sleep 10\n   now=`date +&#039;%Y%m%d%H%M&#039;`\ndone \n\n如果while的条件始终是真，那么循环会一直进行下去。下面的程序就是以无限循环的形式\n\n#!/bin/bash\nwhile true\ndo\n  date\n  sleep 1 \ndone\n语法while的终止条件是一个逻辑判断。如果在循环过程中改变逻辑判断的内容，那么我们很难在程序执行之前预判循环进行的次数。\nfor\n\n与while语法对应的是for循环。这种语法会在程序进行前确定好循环进行的次数，比如demo_for.bash：\n\n#!/bin/bash\nfor var in `ls log*`\ndo \n  rm $var\ndone\n在这个例子中，命令ls log*将返回所有以log开头的文件名。这些文件名之间由空格分隔。循环进行时，Bash会依次取出一个文件名，赋值给变量var，并执行do和done之间隶属于for结构的程序块。\n由于ls命令返回的内容在是确定的，因此for循环进行的次数也会在一开始确定下来。\n\n在for语法中，我们也可以使用自己构建一个由空格分隔的文本。由空格区分出来的每个子文本会在循环中赋值给变量\n\n#!/bin/bash\nfor user in vamei anna yutian\ndo\n    echo $user\ndone\n\nfor循环还可以和seq命令配合使用。\n\n命令seq用于生成一个等差的整数序列，命令后面可以跟3个参数，第\n\n\n一个参数表示整数序列的开始数字，\n\n\n第二个参数表示每次增加多少，\n\n\n最后一个参数表示序列的终点\n\n\n$seq 1 2 10\n输出效果为\n1 3 5 7 9\n结合for循环和seq命令，我们可以解一些有趣的数学问题。比如高斯求和，是要计算从1到100的所有整数的和\n#!/bin/bash\n \ntotal=0 \nfor number in `seq 1 1 100`\ndo \n    total=$(( $total + $number ))\ndone \n \necho $total\n无限循环\n无限循环语法格式：\nwhile :\ndo\n    command\ndone\n或者\nwhile true\ndo\n    command\ndone\n或者\nfor (( ; ; ))\nuntil 循环\nuntil 循环执行一系列命令直至条件为 true 时停止。\nuntil 循环与 while 循环在处理方式上刚好相反。\n一般 while 循环优于 until 循环，但在某些时候—也只是极少数情况下，until 循环更加有用。\nuntil 语法格式:\nuntil condition\ndo\n    command\ndone\n#!/bin/bash\n \na=0\n \nuntil [ ! $a -lt 10 ]\ndo\n   echo $a\n   a=`expr $a + 1`\ndone\nbreak\n#!/bin/bash\n \ntotal=0\nnumber=1 \n \nwhile :\ndo \n  if [ $number -gt 100 ]\n  then\n      break\n  fi\n  total=$(( $total + $number ))\n  number=$(($number + 1))\ndone \n \necho $total\n这里break语句的作用是在满足条件时跳出循环。\ncontinue\n#!/bin/bash\n \ntotal=0 \n \nfor number in `seq 1 1 100`do \n  if (( $number % 3 == 0 )) \n  then\n      continue\n  fi\n  total=$(( $total + $number ))\ndone \n \necho $total\n输入输出重定向\n大多数 UNIX 系统命令从你的终端接受输入并将所产生的输出发送回到您的终端。一个命令通常从一个叫标准输入的地方读取输入，默认情况下，这恰好是你的终端\n重定向命令列表如下：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n命令说明command &gt; file将输出重定向到 file。command &lt; file将输入重定向到 file。command &gt;&gt; file将输出以追加的方式重定向到 file。n &gt; file将文件描述符为 n 的文件重定向到 file。n &gt;&gt; file将文件描述符为 n 的文件以追加的方式重定向到 file。n &gt;&amp; m将输出文件 m 和 n 合并。n &lt;&amp; m将输入文件 m 和 n 合并。&lt;&lt; tag将开始标记 tag 和结束标记 tag 之间的内容作为输入。\n一般情况下，每个 Unix/Linux 命令运行时都会打开三个文件：\n\n\n标准输入文件(stdin)：stdin的文件描述符为0，Unix程序默认从stdin读取数据。\n\n\n标准输出文件(stdout)：stdout 的文件描述符为1，Unix程序默认向stdout输出数据。\n\n\n标准错误文件(stderr)：stderr的文件描述符为2，Unix程序会向stderr流中写入错误信息。\n\n\n默认情况下，command &gt; file 将 stdout 重定向到 file，command &lt; file 将stdin 重定向到 file。\nBash 和C语言\nBash语言和C语言都是Linux下的常用语言。它们都能通过特定的语法来编写程序，而程序运行后都能实现某些功能。尽管在语法细节上存在差异，但两种语言都有以下语法：\n\n\n变量：在内存中储存数据\n\n\n循环结构：重复执行代码块\n\n\n选择结构：根据条件执行代码块\n\n\n函数：复用代码块\n\n\nBash和C的相似性，也来自于它们共同遵守的编程范式——面向过程编程。支持面向过程编程的语言，一般都会提供类似于函数的代码封装方式\n我们还应该注意到Bash和C程序的区别\n\n\nBash的变量只能是文本类型，C的变量却可以有整数、浮点数、字符等类型。\n\n\nBash的很多功能，如加减乘除运算，都是调用其他程序实现的。而C直接就可以进行加减乘除运算。\n\n\n**另一方面，Bash是一个Shell。它本质上是一个命令解释器程序，而不是编程语言。**用户可以通过命令行的方式，来调用该程序的某些功能。所谓的Bash编程，只是命令解释器程序提供的一种互动方法。Bash脚本只能和Bash进程互动。它不能像C语言一样，直接调用CPU的功能。因此，Bash能实现的功能会受限，运行速度上也比不上可执行文件。\n但另一反面，Bash脚本也有它的好处。 C语言能接触到很底层的东西，但使用起来也很复杂。有时候，即使你已经知道如何用C实现一个功能，写代码依然是一个很繁琐的过程。Bash正相反。由于Bash可以便捷地调用已有的程序，因此很多工作可以用数行的脚本解决。此外，Bash脚本不需要编辑，就可以由Bash进程理解并执行。因此，开发Bash脚本比写C程序要快很多。Linux的系统运维工作，如定期备份、文件系统管理等，就经常使用到Bash脚本。总之，Bash编程知识是晋级为资深Linux用户的必要条件。"},"工具/emacs/安装":{"title":"安装","links":[],"tags":["工具和环境/emacs"],"content":"github.com/kiennq/emacs-build\n添加到菜单栏\n\n需要打开 server-mode\n\n(server-mode 1)\n\n\n新建文件 emacs.reg\n\n\n注意修改路径\n\nWindows Registry Editor Version 5.00\n\n[HKEY_CLASSES_ROOT\\*\\shell]\n[HKEY_CLASSES_ROOT\\*\\shell\\openwemacs]\n@=&quot;&amp;Edit with Emacs&quot;\n[HKEY_CLASSES_ROOT\\*\\shell\\openwemacs\\command]\n@=&quot;C:\\\\emax64\\\\bin\\\\emacsclientw.exe -n \\&quot;%1\\&quot;&quot;\n[HKEY_CLASSES_ROOT\\Directory\\shell\\openwemacs]\n@=&quot;Edit &amp;with Emacs&quot;\n[HKEY_CLASSES_ROOT\\Directory\\shell\\openwemacs\\command]\n@=&quot;C:\\\\emax64\\\\bin\\\\emacsclientw.exe -n \\&quot;%1\\&quot;&quot;\n"},"工具/emacs/快捷键":{"title":"快捷键","links":["tags/name"],"tags":["工具和环境/emacs","name"],"content":"Emacs 这个东东听说功能很强大。不过感觉有些难学，还好网络上的资源还是比较丰富的。目前基于最基本的文本编辑来学习。而且它的快捷键很多，所以要在使用过程中学习会比较容易记住。这个是从网上搜索来的，总结的比较好的，贴在自己这里当做摘录了，方便查询。\nC = Control\nM = Meta = Alt\nS =  Super = APPs\nDel = Backspace\nRET = Enter\n我常用的\nM-x  所以命令\nC-x  C-r 最近的文件\nC-c C-l 重新加载配置\n 全屏\n 功能配置\nC-  mode-line功能配置\n基本快捷键 (Basic)\nC-x C-f  “find”文件, 即在缓冲区打开/新建一个文件\nC-x C-s 保存文件\nC-x C-w 使用其他文件名另存为文件\nC-x C-v 关闭当前缓冲区文件并打开新文件\nC-x i 在当前光标处插入文件\nC-x b 新建/切换缓冲区\nC-x C-b 显示缓冲区列表\nC-x k 关闭当前缓冲区\nC-z 挂起 emacs\nC-x C-c 关闭 emacs\n光标移动基本快捷键 (Basic Movement)\nC-f 后一个字符\nC-b 前一个字符\nC-p 上一行\nC-n 下一行\nM-f 后一个单词\nM-b 前一个单词\nC-a 行首\nC-e 行尾\nC-v 向下翻一页\nM-v 向上翻一页\nM-&lt; 到文件开头注意这里是‘&lt;’不是‘,’需要按 shift，遇到相同情况下同\nM→ 到文件末尾\n编辑 (Editint)\nM-n 重复执行后一个命令 n 次\nC-u 重复执行后一个命令 4 次\nC-u n 重复执行后一个命令 n 次\nC-d 删除 (delete)后一个字符\nM-d 删除后一个单词\nDel 删除前一个字符\nM-Del 删除前一个单词\nC-k 移除 (kill)一行\nC-Space 设置开始标记 (例如标记区域)\nC-@ 功能同上, 用于 C-Space 被操作系统拦截的情况\nC-w 移除 (kill)标记区域的内容\nM-w 复制标记区域的内容\nC-y 召回 (yank)复制/移除的区域/行\nM-y 召回更早的内容 (在 kill 缓冲区内循环)\nC-x C-x 交换光标和标记\nC-t 交换两个字符的位置\nM-t 交换两个单词的位置\nC-x C-t 交换两行的位置\nM-u 使从光标位置到单词结尾处的字母变成大写\nM-l 与 M-u 相反\nM-c 使从光标位置开始的单词的首字母变为大写\n重要快捷键 (Important)\nC-g 停止当前运行/输入的命令\nC-x u 撤销前一个命令\nM-x revert-buffer RETURN (照着这个输入)撤销上次存盘后所有改动\nM-x recover-file RETURN 从自动存盘文件恢复\nM-x recover-session RETURN 如果你编辑了几个文件, 用这个恢复\n在线帮助 (Online-Help)\nC-h c 显示快捷键绑定的命令\nC-h k 显示快捷键绑定的命令和它的作用\nC-h l 显示最后 100 个键入的内容\nC-h w 显示命令被绑定到哪些快捷键上\nC-h f 显示函数的功能\nC-h v 显示变量的含义和值\nC-h b 显示当前缓冲区所有可用的快捷键\nC-h t 打开 emacs 教程\nC-h i 打开 info 阅读器\nC-h C-f 显示 emacs FAQ\nC-h p 显示本机 Elisp 包的信息\n搜索/替换 (Seach/Replace)\nC-s 向后搜索\nC-r 向前搜索\nC-g 回到搜索开始前的位置 (如果你仍然在搜索模式中)\nM-% 询问并替换 (query replace)\nSpace 或 y 替换当前匹配\nDel 或 n 不要替换当前匹配\n. 仅仅替换当前匹配并退出 (替换)\n, 替换并暂停 (按 Space 或 y 继续)\n! 替换以下所有匹配\n^ 回到上一个匹配位置\nRETURN 或 q 退出替换\n使用正则表达式 (Regular expression)搜索/替换\n可在正则表达式中使用的符号:\n^ 行首\n$ 行尾\n. 单个字符\n.* 任意多个 (包括没有)字符\n/&lt; 单词开头\n/&gt; 单词结尾\n[] 括号中的任意一个字符 (例如[a-z]表示所有的小写字母)\nM C-s RETURN 使用正则表达式向后搜索\nM C-r RETURN 使用正则表达式向前搜索\nC-s 增量搜索\nC-s 重复增量搜索\nC-r 向前增量搜索\nC-r 重复向前增量搜索\nM-x query-replace-regexp 使用正则表达式搜索并替换\n窗口命令 (Window Commands)\nC-x 2 水平分割窗格\nC-x 3 垂直分割窗格\nC-x o 切换至其他窗格\nC-x 0 关闭窗格\nC-x 1 关闭除了光标所在窗格外所有窗格\nC-x ^ 扩大窗格\nM-x shrink-window 缩小窗格\nM C-v 滚动其他窗格内容\nC-x 4 f 在其他窗格中打开文件\nC-x 4 0 关闭当前缓冲区和窗格\nC-x 5 2 新建窗口 (frame)\nC-x 5 f 在新窗口中打开文件\nC-x 5 o 切换至其他窗口\nC-x 5 0 关闭当前窗口\n书签命令 (Bookmark commands)\nC-x r m 在光标当前位置创建书签\nC-x r b 转到书签\nM-x bookmark-rename 重命名书签\nM-x bookmark-delete 删除书签\nM-x bookmark-save 保存书签\nC-x r l 列出书签清单\nD 标记等待删除\nDel 取消删除标记\nX 删除被标记的书签\nR 重命名\nS 保存列表内所有书签\nF 转到当前书签指向的位置\nM 标记在多窗口中打开\nV 显示被标记的书签 (或者光标当前位置的书签)\nT 切换是否显示路径列表\nW 显示当前文件路径\nQ 退出书签列表\nM-x bookmark-write 将所有书签导出至指定文件\nM-x bookmark-load 从指定文件导入书签\nShell\nM-x shell 打开 shell 模式\nC-c C-c 类似 unix 里的 C-c (停止正在运行的程序)\nC-d 删除光标后一个字符\nC-c C-d 发送 EOF\nC-c C-z 挂起程序 (unix 下的 C-z)\nM-p 显示前一条命令\nM-n 显示后一条命令\nDIRectory EDitor (dired)\nC-x d 打开 dired\nC (大写 C) 复制\nD 标记等待删除\nD 立即删除\nE 或 f 打开文件或目录\nG 刷新当前目录\nG 改变文件所属组 (chgrp)\nK 从屏幕上的列表里删除一行 (不是真的删除)\nM 用*标记\nN 光标移动到下一行\nO 在另一个窗格打开文件并移动光标\nC-o 在另一个窗格打开文件但不移动光标\nP 打印文件\nQ 退出 dired\nQ 在标记的文件中替换\nR 重命名文件\nU 移除标记\nV 显示文件内容\nX 删除有 D 标记的文件\nZ 压缩/解压缩文件\nM-Del 移除标记 (默认为所有类型的标记)\n~ 标记备份文件 (文件名有~的文件)等待删除\n# 标记自动保存文件 (文件名形如name #)等待删除\n*/ 用*标记所有文件夹 (用 C-u */n 移除标记)\n= 将当前文件和标记文件 (使用 C-@标记而不是 dired 的 m 标记)比较\nM-= 将当前文件和它的备份比较\n! 对当前文件应用 shell 命令\nM-} 移动光标至下一个用*或 D 标记的文件\nM-{ 移动光标至上一个用*或 D 标记的文件\n% d 使用正则表达式标记文件等待删除\n% m 使用正则表达式标记文件为*\n+ 新建文件夹\n&gt; 移动光标至后一个文件夹\n&lt; 移动光标至前一个文件夹\nS 切换排序模式 (按文件名/日期)\n或许把这个命令归入这一类也很合适:\nM-x speedbar 打开一个独立的目录显示窗口\nTelnet（大致了解）\nM-x telnet 打开 telnet 模式\nC-d 删除后一个字符或发送 EOF\nC-c C-c 停止正在运行的程序 (和 unix 下的 C-c 类似)\nC-c C-d 发送 EOF\nC-c C-o 清除最后一个命令的输出\nC-c C-z 挂起正在运行的命令\nC-c C-u 移除前一行\nM-p 显示前一条命令\nText\n只能在 text 模式里使用\nM-s 使当前行居中\nM-S 使当前段落居中\nM-x center-region 使被选中的区域居中\n宏命令 (Macro-commands)（大致了解）\nC-x ( 开始定义宏\nC-x ) 结束定义宏\nC-x e 运行最近定义的宏\nM-n C-x e 运行最近定义的宏 n 次\nM-x name-last-kbd-macro 给最近定义的宏命名 (用来保存)\nM-x insert-kbd-macro 将已命名的宏保存到文件\nM-x load-file 载入宏\n编程 (Programming)\nM C-/ 自动缩进光标和标记间的区域\nM-m 移动光标到行首第一个 (非空格)字符\nM-^ 将当前行接到上一行末尾处\nM-; 添加缩进并格式化的注释\nC, C++和 Java 模式\nM-a 移动光标到声明的开始处\nM-e 移动光标到声明的结尾处\nM C-a 移动光标到函数的开始处\nM C-e 移动光标到函数的结尾处\nC-c RETURN 将光标移动到函数的开始处并标记到结尾处\nC-c C-q 根据缩进风格缩进整个函数\nC-c C-a 切换自动换行功能\nC-c C-d 一次性删除光标后的一串空格 (greedy delete)\n为了实现下面的一些技术, 你需要在保存源代码的目录里运行”etags\n*. C *. H *. Cpp”(或者源代码的其他的扩展名)\nM-. (点) 搜索标签\nM-x tags-search ENTER 在所有标签里搜索 (使用正则表达式)\nM-, (逗号) 在 tags-search 里跳至下一个匹配处\nM-x tags-query-replace 在设置过标签的所有文件里替换文本\nGDB (调试器)（大致了解）\nM-x gdb 在另一个的窗格中打开 gdb\n版本控制 (Version Control)（以后会用到现在大致了解就可以了）\nC-x v d 显示当前目录下所有注册过的文件 (show all registered files in this dir)\nC-x v = 比较不同版本间的差异 (show diff between versions)\nC-x v u 移除上次提交之后的更改 (remove all changes since last checkin)\nC-x v ~ 在不同窗格中显示某个版本 (show certain version in different window)\nC-x v l 打印日志 (print log)\nC-x v i 标记文件等待添加版本控制 (mark file for version control add)\nC-x v h 给文件添加版本控制文件头 (insert version control header into file)\nC-x v r 获取命名过的快照 (check out named snapshot)\nC-x v s 创建命名的快照 (create named snapshot)\nC-x v a 创建 gnu 风格的更改日志 (create changelog file in gnu-style)\n文件操作：\nC+x C+f\n打开文件\nC+x C+r\n以只读的方式打开文件\nC+x C+q\n进行只读/读写模式切换\nC+x C+v\n切换缓冲区\nC+x C+s\n保存文件\nC+x C+w\n文件另存为\nC+x i\n向缓冲区中插入文件\n移动操作：C+f\n前进一个字符 C+b\n后退一个字符 M+f\n前进一个单词 M+b\n后退一个单词 C+a\n移动到行首 C+e\n移动到行尾 M+a\n移动到句首 M+e\n移动到句尾 C+p\n后退一行 C+n\n前进一行 M+g g\n跳到指定行 C+v\n向下翻页 M+v\n向上翻页 M+&lt; 移动到缓冲区首M+&gt;\n移动到缓冲区尾 C+M+f\n向前匹配括号 C+M+b\n向后匹配括号标记/复制/剪切/粘贴：C+xh\n全选 C+@\n标记开始 M+w\n复制区域到 kill ring 中，但不删除 C+w\n删除区域 C+y\n将 kill ring 中的内容粘贴到缓冲区 C+Del\n剪切光标到单词结束 M+Del\n剪切光标到单词开始 C+k\n剪切光标到行结尾 M+k\n剪切光标到句结尾 (C+d)/Del\n删除光标上的字 M+d\n剪切光标到下一个单词结尾 ctrl-S (shift+s)-Backspace\n删除当前行\n缓冲区操作：\nC+x C+f 打开/创建一个文件，并创建一个新的缓冲区\nC+x C+s 保存缓冲区内容到文件\nC+x C+w 保存缓冲区内容到其它文件\nC+xk 关闭当前缓冲区\nC+x C+b 显示缓冲区列表，可以使用方向键来选择缓冲区\nC+x C+c 关闭所有缓冲区，并推出 emacs\nM+x 命令：\n查找和替换：\nC+s 向前查找 C+r 向后查找按下这两个快捷键后，\nM+p 显示上一个搜索词，\nM+n 显示下一个搜索词。输入查找内容后，按 C+s 跳到下一个结果，\nC+r 跳到上一个结果。\nEnter 结束查找光标在当前位置，C+g 取消查找光标返回原处。\n2，查找单词\n按 C - s RET C - w 或 C - r RET C - w 来使用单词搜索。\n3，查找及替换\n按 M - %启动查找替换，输入要被替换的词，回车，然后输入要替换的词，再回车。\n被替换的词会高亮起来，这时，输入 y 替换并跳到下一个，输入 n 忽略并跳到下一个，输入 q 结束，输入！替换剩下的全部。\n一些常用的选项：\nC - g 中断查找替换过程。\n^ 返回上一个替换点，按 y 继续下一个，如果不想替换上一个的话，用^返回到上一个，然后按 C - r 进入编辑，修改完后按 C- M - c 退出继续下一个。\nC - l 使当前匹配显示在文档中间。\nC - r 进入修改。\n4，列出匹配的模式\n有时候想列出匹配的全面模式，而不是在文档中浏览，这个可以使用 occur 这个函数。\n例子：M - x occur RET Create RET\n这时，emacs 会新开一个窗口来列出匹配的行，用鼠标点击或把光标移到一行按回车就会跳转到那里。\n执行 SHELL 命令\nM-x shell\n打开 shell 命令\nM-!\n执行 shell 命令（shell-command）\nM-1 M-!\n执行 Shell 命令，命令输出插入光标位置，不打开新输入窗口\nM-|\n针对某一特定区域执行命令 (shell-command-on-region), 比如 C-x h M-juuencode\n窗口操作\nC-x 0\n关闭本窗口\nC-x 1\n只留下一个窗口\nC-x 2\n垂直均分窗口\nC-x 3\n水平均分窗口\nC-x o\n切换到别的窗口\nC-x s\n保存所有窗口的缓冲\nC-x b\n选择当前窗口的缓冲区\nC-x ^\n纵向扩大窗口\nC-x }\n横向扩大窗口\n目录操作\nC-x d\n打开目录模式\nS\n按日期/文件名排序显示\nV\n阅读光标所在的文件\nQ\n退出阅读的文件\nD\n标记为删除\nX\n执行标记\nD\n马上删除当前文件\nC\n拷贝当前文件\nR\n重命名当前文件\n+\n新建文件\nZ\n压缩文件\n！\n对光标所在的文件执行 SHELL 命令\nG\n刷新显示\nI\n在当前缓冲区的末尾插入子目录的内容\n[n]m\n标记光标所在的文件，如果指定 n, 则从光标所在的文件后 n 个文件被标记\n[n]u\n取消当前光标标记的文件，n 的含义同上\nT\n反向标记文件\n%-m\n正则标记\nQ\n退出目录模式\n其他：\nC+x u 撤销\nC+x C+c 退出 emacs"},"工具/git/git":{"title":"git","links":[],"tags":["Git"],"content":"版本控制\n什么是版本控制\n版本控制是一种记录一个或若干文件内容变化，以便将来查阅特定版本修订情况的系统。除了项目源代码，你可以对任何类型的文件进行版本控制。\n为什么要版本控制\n有了它你就可以将某个文件回溯到之前的状态，甚至将整个项目都回退到过去某个时间点的状态，你可以比较文件的变化细节，查出最后是谁修改了哪个地方，从而找出导致怪异问题出现的原因，又是谁在何时报告了某个功能缺陷等等。\n本地版本控制系统\n许多人习惯用复制整个项目目录的方式来保存不同的版本，或许还会改名加上备份时间以示区别。这么做唯一的好处就是简单，但是特别容易犯错。有时候会混淆所在的工作目录，一不小心会写错文件或者覆盖意想外的文件。\n为了解决这个问题，人们很久以前就开发了许多种本地版本控制系统，大多都是采用某种简单的数据库来记录文件的历次更新差异。\n\n集中化的版本控制系统\n接下来人们又遇到一个问题，如何让在不同系统上的开发者协同工作？ 于是，集中化的版本控制系统（Centralized Version Control Systems，简称 CVCS）应运而生。\n集中化的版本控制系统都有一个单一的集中管理的服务器，保存所有文件的修订版本，而协同工作的人们都通过客户端连到这台服务器，取出最新的文件或者提交更新。\n\n这么做虽然解决了本地版本控制系统无法让在不同系统上的开发者协同工作的诟病，但也还是存在下面的问题：\n\n单点故障： 中央服务器宕机，则其他人无法使用；如果中心数据库磁盘损坏又没有进行备份，你将丢失所有数据。本地版本控制系统也存在类似问题，只要整个项目的历史记录被保存在单一位置，就有丢失所有历史更新记录的风险。\n必须联网才能工作： 受网络状况、带宽影响。\n\n分布式版本控制系统\n于是分布式版本控制系统（Distributed Version Control System，简称 DVCS）面世了。 Git 就是一个典型的分布式版本控制系统。\n这类系统，客户端并不只提取最新版本的文件快照，而是把代码仓库完整地镜像下来。这么一来，任何一处协同工作用的服务器发生故障，事后都可以用任何一个镜像出来的本地仓库恢复。因为每一次的克隆操作，实际上都是一次对代码仓库的完整备份。\n\n分布式版本控制系统可以不用联网就可以工作，因为每个人的电脑上都是完整的版本库，当你修改了某个文件后，你只需要将自己的修改推送给别人就可以了。但是，在实际使用分布式版本控制系统的时候，很少会直接进行推送修改，而是使用一台充当“中央服务器”的东西。这个服务器的作用仅仅是用来方便“交换”大家的修改，没有它大家也一样干活，只是交换修改不方便而已。\n分布式版本控制系统的优势不单是不必联网这么简单，后面我们还会看到 Git 极其强大的分支管理等功能。\n认识 Git\nGit 简史\nLinux 内核项目组当时使用分布式版本控制系统 BitKeeper 来管理和维护代码。但是，后来开发 BitKeeper 的商业公司同 Linux 内核开源社区的合作关系结束，他们收回了 Linux 内核社区免费使用 BitKeeper 的权力。 Linux 开源社区（特别是 Linux 的缔造者 Linus Torvalds）基于使用 BitKeeper 时的经验教训，开发出自己的版本系统，而且对新的版本控制系统做了很多改进。\nGit 与其他版本管理系统的主要区别\nGit 在保存和对待各种信息的时候与其它版本控制系统有很大差异，尽管操作起来的命令形式非常相近，理解这些差异将有助于防止你使用中的困惑。\n下面我们主要说一个关于 Git 与其他版本管理系统的主要差别：对待数据的方式。\nGit 采用的是直接记录快照的方式，而非差异比较。我后面会详细介绍这两种方式的差别。\n大部分版本控制系统（CVS、Subversion、Perforce、Bazaar 等等）都是以文件变更列表的方式存储信息，这类系统将它们保存的信息看作是一组基本文件和每个文件随时间逐步累积的差异。\n具体原理如下图所示，理解起来其实很简单，每当我们提交更新一个文件之后，系统都会记录这个文件做了哪些更新，以增量符号 Δ(Delta)表示。\n\n我们怎样才能得到一个文件的最终版本呢？\n很简单，高中数学的基本知识，我们只需要将这些原文件和这些增加进行相加就行了。\n这种方式有什么问题呢？\n比如我们的增量特别特别多的话，如果我们要得到最终的文件是不是会耗费时间和性能。\nGit 不按照以上方式对待或保存数据。反之，Git 更像是把数据看作是对小型文件系统的一组快照。每次你提交更新，或在 Git 中保存项目状态时，它主要对当时的全部文件制作一个快照并保存这个快照的索引。为了高效，如果文件没有修改，Git 不再重新存储该文件，而是只保留一个链接指向之前存储的文件。 Git 对待数据更像是一个 快照流。\n\nGit 的三种状态\nGit 有三种状态，你的文件可能处于其中之一：\n\n已提交（committed）：数据已经安全的保存在本地数据库中。\n已修改（modified）：已修改表示修改了文件，但还没保存到数据库中。\n已暂存（staged）：表示对一个已修改文件的当前版本做了标记，使之包含在下次提交的快照中。\n\n由此引入 Git 项目的三个工作区域的概念：Git 仓库 (. Git directory)、工作目录 (Working Directory) 以及 暂存区域 (Staging Area) 。\n\n基本的 Git 工作流程如下：\n\n在工作目录中修改文件。\n暂存文件，将文件的快照放入暂存区域。\n提交更新，找到暂存区域的文件，将快照永久性存储到 Git 仓库目录。\n\nGit 使用快速入门\n获取 Git 仓库\n有两种取得 Git 项目仓库的方法。\n\n在现有目录中初始化仓库: 进入项目目录运行 git init 命令, 该命令将创建一个名为 .git 的子目录。\n从一个服务器克隆一个现有的 Git 仓库: git clone [url] 自定义本地仓库的名字: git clone [url] directoryname\n\n记录每次更新到仓库\n\n检测当前文件状态 : git status\n提出更改（把它们添加到暂存区）：git add filename (针对特定文件)、git add * (所有文件)、git add *.txt（支持通配符，所有 .txt 文件）\n忽略文件：.gitignore 文件\n提交更新: git commit -m &quot;代码提交信息&quot; （每次准备提交前，先用 git status 看下，是不是都已暂存起来了，然后再运行提交命令 git commit）\n跳过使用暂存区域更新的方式 : git commit -a -m &quot;代码提交信息&quot;。 git commit 加上 -a 选项，Git 就会自动把所有已经跟踪过的文件暂存起来一并提交，从而跳过 git add 步骤。\n移除文件：git rm filename （从暂存区域移除，然后提交。）\n对文件重命名：git mv README.md README (这个命令相当于 mv README.md README、git rm README.md、git add README 这三条命令的集合)\n\n一个好的 Git 提交消息\n一个好的 Git 提交消息如下：\n标题行：用这一行来描述和解释你的这次提交\n\n主体部分可以是很少的几行，来加入更多的细节来解释提交，最好是能给出一些相关的背景或者解释这个提交能修复和解决什么问题。\n\n主体部分当然也可以有几段，但是一定要注意换行和句子不要太长。因为这样在使用 &quot;git log&quot; 的时候会有缩进比较好看。\n\n提交的标题行描述应该尽量的清晰和尽量的一句话概括。这样就方便相关的 Git 日志查看工具显示和其他人的阅读。\n推送改动到远程仓库\n\n\n如果你还没有克隆现有仓库，并欲将你的仓库连接到某个远程服务器，你可以使用如下命令添加：git remote add origin &lt;server&gt; ,比如我们要让本地的一个仓库和 GitHub 上创建的一个仓库关联可以这样 git remote add origin github.com/Snailclimb/test.git\n\n\n将这些改动提交到远端仓库：git push origin master (可以把 master 换成你想要推送的任何分支)\n如此你就能够将你的改动推送到所添加的服务器上去了。\n\n\n远程仓库的移除与重命名\n\n将 test 重命名为 test 1：git remote rename test test 1\n移除远程仓库 test 1:git remote rm test 1\n\n查看提交历史\n在提交了若干更新，又或者克隆了某个项目之后，你也许想回顾下提交历史。完成这个任务最简单而又有效的工具是 git log 命令。git log 会按提交时间列出所有的更新，最近的更新排在最上面。\n可以添加一些参数来查看自己希望看到的内容：\n只看某个人的提交记录：\nGit log --author=bob\n撤销操作\n有时候我们提交完了才发现漏掉了几个文件没有添加，或者提交信息写错了。此时，可以运行带有 --amend 选项的提交命令尝试重新提交：\nGit commit --amend\n取消暂存的文件\nGit reset filename\n撤消对文件的修改:\nGit checkout -- filename\n假如你想丢弃你在本地的所有改动与提交，可以到服务器上获取最新的版本历史，并将你本地主分支指向它：\nGit fetch origin\nGit reset --hard origin/master\n分支\n分支是用来将特性开发绝缘开来的。在你创建仓库的时候，master 是“默认”的分支。在其他分支上进行开发，完成后再将它们合并到主分支上。\n我们通常在开发新功能、修复一个紧急 bug 等等时候会选择创建分支。单分支开发好还是多分支开发好，还是要看具体场景来说。\n创建一个名字叫做 test 的分支\nGit branch test\n切换当前分支到 test（当你切换分支的时候，Git 会重置你的工作目录，使其看起来像回到了你在那个分支上最后一次提交的样子。 Git 会自动添加、删除、修改文件以确保此时你的工作目录和这个分支最后一次提交时的样子一模一样）\nGit checkout test\n你也可以直接这样创建分支并切换过去 (上面两条命令的合写)\nGit checkout -b feature_x\n切换到主分支\nGit checkout master\n合并分支 (可能会有冲突)\n Git merge test\n把新建的分支删掉\nGit branch -d feature_x\n将分支推送到远端仓库（推送成功后其他人可见）：\nGit push origin\n\nTitle: Github 实用小技巧总结\nCategory: 开发工具\nTag:\n\nGit\n\n\n我使用 Github 已经有 6 年多了，今天毫无保留地把自己觉得比较有用的 Github 小技巧送给关注 JavaGuide 的各位小伙伴。\n一键生成 Github 简历 &amp; Github 年报\n通过 resume.github.io/ 这个网站你可以一键生成一个在线的 Github 简历。\n当时我参加的校招的时候，个人信息那里就放了一个在线的 Github 简历。我觉得这样会让面试官感觉你是一个内行，会提高一些印象分。\n但是，如果你的 Github 没有什么项目的话还是不要放在简历里面了。生成后的效果如下图所示。\n\n通过 www.githubtrends.io/wrapped 这个网站，你可以生成一份 Github 个人年报，这个年报会列举出你在这一年的项目贡献情况、最常使用的编程语言、详细的贡献信息。\n\n个性化 Github 首页\nGithub 目前支持在个人主页自定义展示一些内容。展示效果如下图所示。\n\n想要做到这样非常简单，你只需要创建一个和你的 Github 账户同名的仓库，然后自定义 README.md 的内容即可。\n展示在你主页的自定义内容就是 README.md 的内容（不会 Markdown 语法的小伙伴自行面壁 5 分钟）。\n\n这个也是可以玩出花来的！比如说：通过 github-readme-stats 这个开源项目，你可以 README 中展示动态生成的 GitHub 统计信息。展示效果如下图所示。\n\n关于个性化首页这个就不多提了，感兴趣的小伙伴自行研究一下。\n自定义项目徽章\n你在 Github 上看到的项目徽章都是通过 shields.io/ 这个网站生成的。我的 JavaGuide 这个项目的徽章如下图所示。\n\n并且，你不光可以生成静态徽章，shield. Io 还可以动态读取你项目的状态并生成对应的徽章。\n\n生成的描述项目状态的徽章效果如下图所示。\n\n自动为项目添加贡献情况图标\n通过 repobeats 这个工具可以为 Github 项目添加如下图所示的项目贡献基本情况图表，挺不错的 👍\n\n地址：repobeats.axiom.co/ 。\nGithub 表情\n\n如果你想要在 Github 使用表情的话，可以在这里找找：www.webfx.com/tools/emoji-cheat-sheet/。\n\n高效阅读 Github 项目的源代码\nGithub 前段时间推出的 Codespaces 可以提供类似 VS Code 的在线 IDE，不过目前还没有完全开发使用。\n简单介绍几种我最常用的阅读 Github 项目源代码的方式。\nChrome 插件 Octotree\n这个已经老生常谈了，是我最喜欢的一种方式。使用了 Octotree 之后网页侧边栏会按照树形结构展示项目，为我们带来 IDE 般的阅读源代码的感受。\n\nChrome 插件 SourceGraph\n我不想将项目 clone 到本地的时候一般就会使用这种方式来阅读项目源代码。SourceGraph 不仅可以让我们在 Github 优雅的查看代码，它还支持一些骚操作，比如：类之间的跳转、代码搜索等功能。\n当你下载了这个插件之后，你的项目主页会多出一个小图标如下图所示。点击这个小图标即可在线阅读项目源代码。\n\n使用 SourceGraph 阅读代码的就像下面这样，同样是树形结构展示代码，但是我个人感觉没有 Octotree 的手感舒服。不过，SourceGraph 内置了很多插件，而且还支持类之间的跳转！\n\n克隆项目到本地\n先把项目克隆到本地，然后使用自己喜欢的 IDE 来阅读。可以说是最酸爽的方式了！\n如果你想要深入了解某个项目的话，首选这种方式。一个 git clone 就完事了。\n扩展 Github 的功能\nEnhanced GitHub 可以让你的 Github 更好用。这个 Chrome 插件可以可视化你的 Github 仓库大小，每个文件的大小并且可以让你快速下载单个文件。\n\n自动为 Markdown 文件生成目录\n如果你想为 Github 上的 Markdown 文件生成目录的话，通过 VS Code 的 Markdown Preview Enhanced 这个插件就可以了。\n生成的目录效果如下图所示。你直接点击目录中的链接即可跳转到文章对应的位置，可以优化阅读体验。\n\n不过，目前 Github 已经自动为 Markdown 文件生成了目录，只是需要通过点击的方式才能显示出来。\n\n善用 Github Explore\n其实，Github 自带的 Explore 是一个非常强大且好用的功能。不过，据我观察，国内很多 Github 用户都不知道这个到底是干啥的。\n简单来说，Github Explore 可以为你带来下面这些服务：\n\n可以根据你的个人兴趣为你推荐项目；\nGithunb Topics 按照类别/话题将一些项目进行了分类汇总。比如 Data visualization 汇总了数据可视化相关的一些开源项目，Awesome Lists 汇总了 Awesome 系列的仓库；\n通过 Github Trending 我们可以看到最近比较热门的一些开源项目，我们可以按照语言类型以及时间维度对项目进行筛选；\nGithub Collections 类似一个收藏夹集合。比如 Teaching materials for computational social science 这个收藏夹就汇总了计算机课程相关的开源资源，Learn to Code 这个收藏夹就汇总了对你学习编程有帮助的一些仓库；\n…\n\n\nGitHub Actions 很强大\n你可以简单地将 GitHub Actions 理解为 Github 自带的 CI/CD ，通过 GitHub Actions 你可以直接在 GitHub 构建、测试和部署代码，你还可以对代码进行审查、管理 API、分析项目依赖项。总之，GitHub Actions 可以自动化地帮你完成很多事情。\n关于 GitHub Actions 的详细介绍，推荐看一下阮一峰老师写的 GitHub Actions 入门教程 。\nGitHub Actions 有一个官方市场，上面有非常多别人提交的 Actions ，你可以直接拿来使用。\n\n后记\n这一篇文章，我毫无保留地把自己这些年总结的 Github 小技巧分享了出来，真心希望对大家有帮助，真心希望大家一定要利用好 Github 这个专属程序员的宝藏。\n另外，这篇文章中，我并没有提到 Github 搜索技巧。在我看来，Github 搜索技巧不必要记网上那些文章说的各种命令啥的，真没啥卵用。你会发现你用的最多的还是关键字搜索以及 Github 自带的筛选功能。\n学习资料推荐\n在线演示学习工具：\n「补充，来自 issue729 」Learn Git Branching oschina.gitee.io/learn-git-branching/ 。该网站可以方便的演示基本的 git 操作，讲解得明明白白。每一个基本命令的作用和结果。\n推荐阅读：\n\nGit 入门图文教程(1.5W 字 40 图)：超用心的一篇文章，内容全面且附带详细的图解，强烈推荐！\nGit - 简明指南：涵盖 Git 常见操作，非常清晰。\n图解 Git：图解 Git 中的最常用命令。如果你稍微理解 git 的工作原理，这篇文章能够让你理解的更透彻。\n猴子都能懂得 Git 入门：有趣的讲解。\nPro Git book：国外的一本 Git 书籍，被翻译成多国语言，质量很高。\n"},"工具/maven/maven基础":{"title":"maven基础","links":[],"tags":["开发工具/maven"],"content":"javaguide.cn/tools/maven/maven-core-concepts.html\n什么是 Maven\nMaven 是一种用来管理 Java 项目的工具，但不是那种用来管理资源规划和调度的工具。 相反，它处理的是管理一个具体的项目所涉及的各种任务，如编译、测试、打包、文档以及分发。\nMaven 包括以下的几个部分。\n\n\n一组用于处理依赖管理、目录结构以及构建工作流的约定。\n\n基于这些约定实现的标准化 ，可以极大地简化开发过程。例如，一个常用的目录结构使得开发者可以更加容易地跟上不熟悉的项目的节奏。\n\n\n\n一个用于项目配置的XML Schema：项目对象模型（Project Object Model），简称POM①。\n\n每一个Maven项目都拥有一个POM文件 ，默认命名为pom.xml，包含了Maven用于管理 该项目的所有的配置信息。\n\n\n\n一个委托外部组件来执行项目任务的插件架构。\n\n\n这简化了更新以及扩展 Maven 能力的过程。\n\n\n\n\nMaven 的基本概念\n标准的目录结构\n\nPOM大纲\n\n构建\n任何可以被 Maven 的坐标系统（参见接下来的关于 GAV 坐标的讨论）唯一标识的对象都是一个 Maven 构件。\n\n\n大多数情况下，构件是构建 Maven 项目所生成的文件，如 JAR。\n\n\n但是，只包 含其他 POM（该文件本身并不产生构件）使用的定义的 POM 文件也是 Maven 构件。\n\n\nMaven 构件的类型由其 POM 文件的&lt;packaging&gt;元素指定。最常用的值是 pom、jar、 ear、war 以及 maven-plugin\n\n\nPOM 文件的用例\n可以通过以下的方式来使用 POM 文件。\n\n\n默认的——用于构建一个构件。\n\n\n父 POM——提供一个由子项目继承的单个配置信息源——声明这个 POM 文件作为它们 的&lt;parent&gt;元素的值。\n\n\n聚合器——用于构建一组声明为&lt;modules&gt;的项目，这些子项目位于其当前聚合器项目的文件夹中，每个都包含有它自己的 POM 文件。\n\n\n作为父 POM 或者聚合器的 POM 文件的&lt;packaging&gt;元素的值将是 pom。注意，一个 POM\n文件可能同时提供两项功能。\nGAV 坐标\nPOM 定义了 5 种称为坐标的元素，用于标识 Maven 构件。首字母缩写 GAV 指的是必须始终指定的 3 个坐标&lt;groupId&gt;、&lt;artifactId&gt;以及&lt;version&gt;的首字\n\n\n&lt;groupId&gt;是项目或者项目组的全局的唯一标识符。这通常是 Java 源代码中使用的全限定的 Java 包名。例如，io.netty、com.google。\n\n\n&lt;artifactId&gt;用于标识和某个&lt;groupId&gt;相关的不同的构件。例如，netty-all、 netty-handler。\n\n\n&lt;type&gt;是指和项目相关的主要构件的类型（对应于构件的 POM 文件中的&lt;packaging&gt; 值）。它的默认值是 jar。例如，pom、war、ear。\n\n\n&lt;version&gt;标识了构件的版本。例如，1.1、2.0-SNAPSHOT①POM 文件必须声明它所管理的构件的坐标。一个具有如下坐标的项目： 、4.1.9.Final。\n\n\n&lt;classifier&gt;用于区分属于相同的 POM 但是却被以不同的方式构建的构件。例如，javadoc、sources、jdk16、jdk17\n\n\n一个GAV\n&lt;groupId&gt;io.netty&lt;/groupId&gt; \n&lt;artifactId&gt;netty-all&lt;/artifactId&gt; \n&lt;version&gt;4.1.9.Final&lt;/version&gt; \n&lt;packaging&gt;jar&lt;/packaging&gt;\n在这种情况下，它将产生这个构件：\nnetty-all\n-4.1.9.Final.jar\n依赖\n项目的依赖是指编译和执行它所需要的外部构件\n在大多数情况下，你的项目的依赖项也会有它自己的依赖。我们称这些依赖为你的项目的传递依赖。一个复杂的项目可能会有一个深层级 的依赖树；Maven提供了各种用于帮助理解和管理它的工具。\n&lt;dependencies&gt; \n    &lt;dependency&gt; \n        &lt;groupId/&gt; \n        &lt;artifactId/&gt; \n        &lt;version/&gt; \n        &lt;type/&gt; \n        &lt;scope/&gt; \n        &lt;systemPath/&gt; \n    &lt;/dependency&gt; \n    ... \n&lt;/dependencies&gt;\ntype以及scope元素对于那些值不分别是默认值jar和compile的依赖来说也是必需的\n&lt;scope&gt;元素可以具有以下值\n\n\ncompile—编译和执行需要的（默认值）。\n\n\nruntime—只有执行需要。\n\n\noptional——不被引用了这个项目所产生的构件的其他项目，视为传递依赖。\n\n\nprovided——不会被包含在由这个 POM 产生的 WAR 文件的 WEB_INF/lib 目录中。\n\n\ntest——只有编译和测试的执行需要。\n\n\nimport——这将在后面的“依赖管理”一节进行讨论。\n\n\n&lt;systemPath&gt;元素用来指定文件系统中的绝对位置。\n依赖管理\n引用了&lt;dependencyManagement&gt;元素的项目可以使用它所声明的依赖，而不需要指定它们的&lt;version&gt;坐标。如果&lt;dependencyManagement&gt;中的&lt;version&gt;在稍后有所改变，则它将被所有引用它的 POM 拾起。\n在下面的示例中，所使用的 Netty 版本是在 POM 的&lt;properties&gt;部分中定义，在 &lt;dependencyManagement&gt;中引用的\n&lt;properties&gt; \n    &lt;netty.version&gt;4.1.9&lt;/netty.version&gt; \n    ... \n    ... \n&lt;/properties&gt; \n&lt;dependencyManagement&gt; \n    &lt;dependencies&gt; \n        &lt;dependency&gt; \n            &lt;groupId&gt;io.netty&lt;/groupId&gt; \n            &lt;artifactId&gt;netty-all&lt;/artifactId&gt; \n            &lt;version&gt;${netty.version}&lt;/version&gt; \n        &lt;/dependency&gt; \n    &lt;/dependencies&gt; \n    ... \n&lt;/dependencyManagement&gt;\n对于这种使用场景，依赖的&lt;scope&gt;元素有一个特殊的 import 值：它将把外部 POM（没有被声明为&lt;parent&gt;）的&lt;dependencyManagement&gt;元素的内容导入到当前 POM 的&lt;dependencyManagement&gt;元素中\n构建的生命周期\nMaven 构建的生命周期是一个明确定义的用于构建和分发构件的过程。有 3 个内置的构建生命周期：clean、default 和 site。\n一个构建的生命周期由一系列的阶段所组成。下面是默认的构建生命周期的各个阶段的一个部分清单。\n\n\n validate——检查项目是否正确，所有必需的信息是否已经就绪。\n\n\n process-sources——处理源代码，如过滤任何值。\n\n\n compile——编译项目的源代码。\n\n\n process-test-resources——复制并处理资源到测试目标目录中。\n\n\n test-compile——将测试源代码编译到测试目标目录中。\n\n\n test——使用合适的单元测试框架测试编译的源代码。\n\n\n package——将编译的代码打包为它的可分发格式，如 JAR。\n\n\n integration-test——处理并将软件包部署到一个可以运行集成测试的环境中。\n\n\n verify——运行任何的检查以验证软件包是否有效，并且符合质量标准。\n\n\n install——将软件包安装到本地存储库中，在那里其他本地构建项目可以将它引用为依赖。\n\n\n deploy——将最终的构件上传到远程存储库，以与其他开发人员和项目共享。\n\n\n插件\n插件可能拥有多个内部步骤，或者目标，其也可以被单独调用。例如，在一个 JAR 项目中，默认的构建生命周期由 maven-jar-plugin 处理，其将构建的各个阶段映射到了它自己的以及其他插件的目标中，\n\n注意插件的声明，它被打包为 JAR 包，使用了和&lt;dependency&gt;的 GAV 坐标相同的 GAV 坐标。\n&lt;plugin&gt; \n    &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt; \n    &lt;artifactId&gt;exec-maven-plugin&lt;/artifactId&gt; \n    &lt;version&gt;1.2.1&lt;/version&gt; \n&lt;/plugin&gt;\n \n插件管理\n如同&lt;dependencyManagement&gt;，声明了其他 POM 可以使用的\n信息\n&lt;build&gt; \n    &lt;pluginManagement&gt; \n        &lt;plugins&gt; \n            &lt;plugin&gt; \n                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; \n                &lt;version&gt;3.2&lt;/version&gt; \n                &lt;configuration&gt; \n                &lt;source&gt;1.7&lt;/source&gt; \n                &lt;target&gt;1.7&lt;/target&gt; \n            &lt;/configuration&gt; \n            &lt;/plugin&gt; \n            &lt;plugin&gt; \n                &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt; \n                &lt;artifactId&gt;exec-maven-plugin&lt;/artifactId&gt; \n                &lt;version&gt;1.2.1&lt;/version&gt; \n            &lt;/plugin&gt; \n        &lt;/plugins&gt; \n    &lt;/pluginManagement&gt; \n&lt;/build&gt;\n配置文件\n配置文件（在中定义）是一组自定义的 POM 元素，可以通过自动或者手动启用（激活）来改变 POM 的行为。\n例如，你可以定义一个配置文件，它将根据 JDK 版本、操作系 统或者目标部署环境（如开发、测试或者生产环境）来设置构建参数。 可以通过命令行的-P 标志来显式地引用配置文件。下面的例子将激活一个将 POM 自定义为 使用 JDK1.6 的配置文件。\nmvn -P jdk16 clean install \n存储库\nMaven的构件存储库 ①\n\n\n远程存储库是一个 Maven 从其下载 POM 文件中所引用的依赖的服务。如果你有上传权 限，那么这些依赖中可能也会包含由你自己的项目所产生的构件。大量开放源代码的 Maven 项目（包含 Netty）都将它们的构件发布到可以公开访问的 Maven 存储库。\n\n\n本地存储库是一个本地的目录，其包含从远程存储库下载的构件，以及你在本地机器上构建并安装的构件。它通常放在你的主目录下，\n\n\nMaven 存储库的物理目录结构使用 GAV 坐标，如同 Java 编译器使用包名一样。例如，在 Maven 下载了下面的依赖之后：\nMaven 存储库的物理目录结构使用 GAV 坐标，如同 Java 编译器使用包名一样。例如，在 \nMaven 下载了下面的依赖之后：\nMaven 存储库的物理目录结构使用 GAV 坐标，如同 Java 编译器使用包名一样。例如，在 Maven 下载了下面的依赖之后：\n\n快照和发布\n远程存储库通常会为正在开发的构件，以及那些稳定发布或者生产发布的构件，定义不同的 区域。这些区域被分别称为快照存储库和发布存储库。\n\n\n一个&lt;version&gt;值由-SNAPSHOT 结尾的构件将被认为是还没有发布的**。这种构件可以重复 地使用相同的&lt;version&gt;值被上传到存储库**。每次它都会被分配一个唯一的时间戳。当项目检 索构件时，下载的是最新实例。\n\n\n一个&lt;version&gt;值不具有-SNAPSHOT 后缀的构件将会被认为是一个发布版本。通常，存储库策略只允某一特定的发布版本上传一次\n\n\nSNAPSHOT 的拉取\n\n\n当构建一个具有 SNAPSHOT 依赖的项目时，Maven 将检查本地存储库中是否有对应的副本。 如果没有，它将尝试从指定的远程存储库中检索，在这种情况下，它将接收到具有最新时间戳的构件。\n\n\n如果本地的确有这个构件，并且当前构建也是这一天中的第一个，那么 Maven 将默认尝试更新该本地副本。这个行为可以通过使用 Maven 配置文件（settings.xml）中的配置或者命令行 标志来进行配置\n\n\nPOM 实例\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;ISO-8859-15&quot;?&gt; \n&lt;project xmlns=&quot;maven.apache.org/POM/4.0.0&quot; \n    xmlns:xsi=&quot;www.w3.org/2001/XMLSchema-instance&quot; \n    xsi:schemaLocation=&quot;maven.apache.org/POM/4.0.0 \n    maven.apache.org/maven-v4_0_0.xsd&quot;&gt;\n    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; \n    &lt;groupId&gt;com.example&lt;/groupId&gt; \n    &lt;artifactId&gt;myproject&lt;/artifactId&gt; \n    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; \n    &lt;packaging&gt;jar&lt;/packaging&gt; \n    &lt;name&gt;My Jar Project&lt;/name&gt; \n    \n    &lt;dependencies&gt; \n        &lt;dependency&gt; \n        &lt;groupId&gt;io.netty&lt;/groupId&gt; \n        &lt;artifactId&gt;netty-all&lt;/artifactId&gt; \n        &lt;version&gt;4.1.9.Final&lt;/version&gt; \n        &lt;/dependency&gt; \n    &lt;/dependencies&gt; \n    &lt;build&gt; \n        &lt;plugins&gt; \n            &lt;plugin&gt; \n                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; \n                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; \n                &lt;version&gt;3.2&lt;/version&gt; \n                &lt;configuration&gt; \n                    &lt;source&gt;1.7&lt;/source&gt; \n                    &lt;target&gt;1.7&lt;/target&gt; \n                &lt;/configuration&gt; \n            &lt;/plugin&gt; \n        &lt;/plugins&gt; \n    &lt;/build&gt; \n&lt;/project&gt;\n继承和组合\n&lt;project&gt; \n    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; \n    &lt;parent&gt; \n        &lt;groupId&gt;nia&lt;/groupId&gt; \n        &lt;artifactId&gt;nia-samples-parent&lt;/artifactId&gt; \n        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; \n    &lt;/parent&gt; \n    &lt;artifactId&gt;chapter2&lt;/artifactId&gt; \n    &lt;packaging&gt;pom&lt;/packaging&gt; \n    &lt;name&gt;2. Echo Client and Server&lt;/name&gt; \n    &lt;modules&gt; \n        &lt;module&gt;Client&lt;/module&gt; \n        &lt;module&gt;Server&lt;/module&gt; \n    &lt;/modules&gt; \n    &lt;properties&gt; \n        &lt;echo-server.hostname&gt;localhost&lt;/echo-server.hostname&gt; \n        &lt;echo-server.port&gt;9999&lt;/echo-server.port&gt; \n        &lt;/properties&gt; \n    &lt;dependencies&gt; \n    &lt;dependency&gt; \n        &lt;groupId&gt;io.netty&lt;/groupId&gt; \n        &lt;artifactId&gt;netty-all&lt;/artifactId&gt; \n        &lt;/dependency&gt; \n    &lt;/dependencies&gt; \n    &lt;build&gt; \n        &lt;plugins&gt; \n            &lt;plugin&gt; \n                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; \n            &lt;/plugin&gt; \n            &lt;plugin&gt; \n                &lt;artifactId&gt;maven-failsafe-plugin&lt;/artifactId&gt; \n            &lt;/plugin&gt; \n            &lt;plugin&gt; \n                &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt; \n            &lt;/plugin&gt; \n            &lt;plugin&gt; \n                &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt; \n                &lt;artifactId&gt;exec-maven-plugin&lt;/artifactId&gt; \n            &lt;/plugin&gt; \n        &lt;/plugins&gt; \n    &lt;/build&gt; \n&lt;/project&gt;\nPOM 继承\n\n\nPOM 文件可能包含子项目要继承（并可能重写）的信息。\n\n\n通过parent 实现\n\n\nPOM 聚合\n\n\n聚合器 POM 会构建一个或者多个子项目，这些子项目驻留在该 POM 所在目录的子目录中。 子项目，或者&lt;modules&gt;标签，是由它们的目录名标识的：\n\n\n通过&lt;modules&gt; 实现\n\n"},"工具/msys2/pacman":{"title":"pacman","links":[],"tags":["工具和环境/msys2"],"content":"安装软件\n\npacman -S (软件名)：安装软件，若有多个软件包，空格分隔\npacman -S --needed （软件名）：安装软件，若存在，不重新安装最新的软件\npacman -Sy (软件名)：安装软件前，先从远程仓库下载软件包数据库\npacman -Sv (软件名)：输出操作信息后安装\npacman -Sw (软件名)：只下载软件包，而不安装\npacman -U (软件名.pkg.tar.gz)：安装本地软件包\npacman -U (www.xxx.com/xxx.pkg.tar.xz)：安装一个远程包\n\n卸载软件\n\npacman -R (软件名)：只卸载软件包不卸载依赖的软件\npacman -Rv (软件名)：卸载软件，并输出卸载信息\npacman -Rs (软件名)：卸载软件，并同时卸载该软件的依赖软件\npacman -Rsc (软件名)：卸载软件，并卸载依赖该软件的程序\npacman -Ru (软件名)：卸载软件，同时卸载不被任何软件所依赖\n\n搜索软件\n\npacman -Ss (关键字)：在仓库搜索包含关键字的软件包\npacman -Sl：显示软件仓库所有软件的列表\npacman -Qs (关键字)：搜索已安装的软件包\npacman -Qu：列出可升级的软件包\npacman -Qt：列出不被任何软件要求的软件包\npacman -Q (软件名)：查看软件包是否已安装\npacman -Qi (软件包)：查看某个软件包详细信息\npacman -Ql (软件名)：列出软件包所有文件安装路径\n\n软件包组\n\npacman -Sg：列出软件仓库上所有软件包组\npacman -Qg：列出本地已经安装的软件包组和子软件包\npacman -Sg (软件包组)：查看软件包组所包含的软件包\npacman -Qg (软件包组)：查看软件包组所包含的软件包\n\n更新系统\n\npacman -Sy：从服务器下载最新的软件包数据库到本地\npacman -Su：升级所有已安装的软件包\npacman -Syu：升级整个系统\n\n清理缓存\n\npacman -Sc：清理未安装的软件包文件\npacman -Scc：清理所有的缓存文件\n"},"工具/msys2/再-msys-中使用fish":{"title":"再 msys 中使用fish","links":[],"tags":["工具和环境/msys2"],"content":"MSYS 2\n如果用习惯了 Linux 上的 POSIX 兼容的命令行工具, 在切换到 CMD/Powershell 的编码风格无疑是痛苦的, 经典的方案是 MinGW/Cygwin 这样的转换工具, 这里我们使用一个比较新的类 MinGW 工具 MSYS2, 它不仅包含了 MinGW, 也有自己的一套 Linux 虚拟环境, 还从著名的 Arch Linux 借用了包管理器 pacman, 个人感觉比 MinGW 的包管理器 (类 apt)好用不是一点点, 也有国内的镜像可供选择.\nMSYS 2: Installation\n\nMSYS2 首页上就有下载链接, 直接下载安装即可.\n安装后就可以在开始菜单里找到 MSYS 2 虚拟环境了 (还附送了 MinGW 32/64)\n但是谁会喜欢黑底白字还是宋体的英文呢? 建议配合 Windows Terminal 食用, 这里有和 WT 配合的文档, 具体来讲, 在 Windows Terminal 里的设置中如下的修改, 不用重启 WT 就能在其中新建 MSYS2标签页了!\n\n&quot;defaultProfile&quot;: &quot;{17da3cac-b318-431e-8a3e-7fcdefe6d114}&quot;,  \n&quot;profiles&quot;: {  \n&quot;list&quot;:  \n[  \n    // ...(你原来的shells, 如CMD/PS)  \n    {  \n    &quot;guid&quot;: &quot;{17da3cac-b318-431e-8a3e-7fcdefe6d114}&quot;,  \n    &quot;name&quot;: &quot;MINGW64 / MSYS2&quot;,  \n    &quot;commandline&quot;: &quot;C:/msys64/msys2_shell.cmd -defterm -here -no-start -mingw64&quot;,  \n    &quot;startingDirectory&quot;: &quot;C:/msys64/home/%USERNAME%&quot;,  \n    &quot;icon&quot;: &quot;C:/msys64/mingw64.ico&quot;,  \n    &quot;fontFace&quot;: &quot;Lucida Console&quot;,  \n    &quot;fontSize&quot;: 9  \n    },  \n    {  \n    &quot;guid&quot;: &quot;{2d51fdc4-a03b-4efe-81bc-722b7f6f3820}&quot;,  \n    &quot;name&quot;: &quot;MINGW32 / MSYS2&quot;,  \n    &quot;commandline&quot;: &quot;C:/msys64/msys2_shell.cmd -defterm -here -no-start -mingw32&quot;,  \n    &quot;startingDirectory&quot;: &quot;C:/msys64/home/%USERNAME%&quot;,  \n    &quot;icon&quot;: &quot;C:/msys64/mingw32.ico&quot;,  \n    &quot;fontFace&quot;: &quot;Lucida Console&quot;,  \n    &quot;fontSize&quot;: 9  \n    },  \n    {  \n    &quot;guid&quot;: &quot;{71160544-14d8-4194-af25-d05feeac7233}&quot;,  \n    &quot;name&quot;: &quot;MSYS / MSYS2&quot;,  \n    &quot;commandline&quot;: &quot;C:/msys64/msys2_shell.cmd -defterm -here -no-start -msys&quot;,  \n    &quot;startingDirectory&quot;: &quot;C:/msys64/home/%USERNAME%&quot;,  \n    &quot;icon&quot;: &quot;C:/msys64/msys2.ico&quot;,  \n    &quot;fontFace&quot;: &quot;Lucida Console&quot;,  \n    &quot;fontSize&quot;: 9  \n    },  \n    // ...  \n]  \n}\n\n\n现在你就可以在 WT 中打开并使用 MSYS 2 了! Give it a try!\nWindodws 中设置环境 HOME 到用户目录\nNote: 在 MSYS 2 (MinGW 同样)中, 你的原磁盘文件都会被翻译成 Linux 风格的路径!\n\ne.g.: C:\\path\\to\\file =&gt; /c/path/to/file\n\n\n\nPacman 换源\n为了更快的获得软件包, 建议设置 pacman 镜像, 可以使用清华的 TUNA镜像或者是 BFSU 的 TUNA 镜像的镜像\n简而言之, 就是在 pacman 的 mirror list 里加入对应的镜像源  \nServer = mirrors.tuna.tsinghua.edu.cn/msys2/msys/$arch` \n管理员模式并且刷新 `pacman` 缓存:  \npacman -Sy\n\nfish Shell\nfish 是一个现代化的用户友好的 shell, 总之就是脚踢 bash, 拳打 zsh!\nInstallation\n\n安装 fish\n\n pacman -S fish\n\n\n将默认的 shell 从 bash 改成 fish, 修改 MSYS 2 的启动脚本, 它应该在 .../msys64安装路径/msys2_shell.cmd 这个位置:\n\nset &quot;LOGINSHELL=fish&quot; # 原来是bash\n\n\n并且你可能会想把 Windows 原来的 PATH 导入到 Linux 环境里, 同样修改上述启动脚本:\n\nset MSYS2_PATH_TYPE=inherit # 原来是被注释的\n\n\n安装 git, 这一步可能是可选的, 因为 oh-my-fish 可能需要非 Windows 的 git 实现.\n\npacman -S git\n\n\n进一步, 你可能需要配置 git 的全局代理, 否则无法 clone repository\n\ngit config --global http.proxy yourproxy:port\n\n\n安装 oh-my-fish, 一个 fish 的简易包管理器\n\n curl -L get.oh-my.fish | fish\n\n\n\n你基本上配置好了 fish 了! 现在你有了 omf (即 oh-my-fish 的缩写), 可以用来安装一些主题和插件!\n\n\nomf install agnoster  \nomf theme agnoster\n\n其他软件\n\nvim\nemacs\nfish\nmake\ngit\n"},"工具/工具":{"title":"工具","links":[],"tags":[],"content":""},"工具/环境搭建":{"title":"环境搭建","links":[],"tags":[],"content":""},"微服务/微服务":{"title":"微服务","links":["微服务/API网关","微服务/服务注册与发现","微服务/监控系统","微服务/负载均衡","微服务/RPC","微服务/CDN","微服务/配置管理"],"tags":["微服务"],"content":"\nAPI网关\n服务注册与发现\n监控系统\n负载均衡\nRPC\nCDN\n配置管理\n"},"消息队列/Kafka/Kafka-Broker":{"title":"Kafka Broker","links":[],"tags":[],"content":"第 4 章 Kafka Broker\nBroker设计\n​ 我们都知道kafka能堆积非常大的数据，一台服务器，肯定是放不下的。由此出现的集群的概念，集群不仅可以让消息负载均衡，还能提高消息存取的吞吐量。kafka集群中，会有多台broker，每台broker分别在不同的机器上。\n​ 为了提高吞吐量，每个topic也会都多个分区，同时为了保持可靠性，每个分区还会有多个副本。这些分区副本被均匀的散落在每个broker上，其中每个分区副本中有一个副本为leader，其他的为follower。\n\nZookeeper\nZookeeper作用\nZookeeper在Kafka中扮演了重要的角色，kafka使用zookeeper进行元数据管理，保存broker注册信息，包括主题（Topic）、分区（Partition）信息等，选择分区leader。\n\nBroker选举Leader\n​ 这里需要先明确一个概念leader选举，因为kafka中涉及多处选举机制，容易搞混，Kafka由三个方面会涉及到选举：\n\nbroker（控制器）选leader\n分区多副本选leader\n消费者选Leader\n\n​ 在kafka集群中由很多的broker（也叫做控制器），但是他们之间需要选举出一个leader，其他的都是follower。broker的leader有很重要的作用，诸如：创建、删除主题、增加分区并分配leader分区；集群broker管理，包括新增、关闭和故障处理；分区重分配（auto.leader.rebalance.enable=true，后面会介绍），分区leader选举。\n​ 每个broker都有唯一的brokerId，他们在启动后会去竞争注册zookeeper上的Controller结点，谁先抢到，谁就是broker leader。而其他broker会监听该结点事件，以便后续leader下线后触发重新选举。\n简图：\n\nbroker（控制器）选leader\n\n\n详细图：\n\nbroker（控制器）选leader\n分区多副本选leader\n\n\n模拟 Kafka 上下线，Zookeeper 中数据变化\n（1）查看/kafka/brokers/ids 路径上的节点。\n[zk: localhost:2181(CONNECTED) 2] ls /kafka/brokers/ids\n[0, 1, 2]\n（2）查看/kafka/controller 路径上的数据。\n[zk: localhost:2181(CONNECTED) 15] get /kafka/controller\n{&quot;version&quot;:1,&quot;brokerid&quot;:0,&quot;timestamp&quot;:&quot;1637292471777&quot;}\n（3）查看/kafka/brokers/topics/first/partitions/0/state 路径上的数据。\n[zk: localhost:2181(CONNECTED) 16] get  /kafka/brokers/topics/first/partitions/0/state\n{&quot;controller_epoch&quot;:24,&quot;leader&quot;:0,&quot;version&quot;:1,&quot;leader_epoch&quot;:18,&quot; isr&quot;:[0,1,2]}\n（4）停止 hadoop104 上的 kafka。\nkafka-server-stop.sh\n（5）再次查看/kafka/brokers/ids 路径上的节点。\n[zk: localhost:2181(CONNECTED) 3] ls /kafka/brokers/ids\n[0, 1]\n（6）再次查看/kafka/controller 路径上的数据。\n[zk: localhost:2181(CONNECTED) 15] get /kafka/controller\n{&quot;version&quot;:1,&quot;brokerid&quot;:0,&quot;timestamp&quot;:&quot;1637292471777&quot;}\n（7）再次查看/kafka/brokers/topics/first/partitions/0/state 路径上的数据。\n[zk: localhost:2181(CONNECTED) 16] get  /kafka/brokers/topics/first/partitions/0/state\n{&quot;controller_epoch&quot;:24,&quot;leader&quot;:0,&quot;version&quot;:1,&quot;leader_epoch&quot;:18,&quot; isr&quot;:[0,1]}\n（8）启动 hadoop104 上的 kafka。\nkafka-server-start.sh -daemon ./config/server.properties\n（9）再次观察（1）、（2）、（3）步骤中的内容。\nBroker重要参数\n\n\n节点服役和退役\n服役新节点\n(1) 启动一台新的KafKa服务端（加入原有的Zookeeper集群）\n(2) 查看原有的 分区信息 describe\n$ kafka-topics.sh --bootstrap-server 47.106.86.64:9092 --topic first --describe\n \nTopic: first\tTopicId: 4DtkHPe4R1KyXNF7QyVqBA\tPartitionCount: 3\tReplicationFactor: 3\tConfigs: segment.bytes=1073741824\n\tTopic: first\tPartition: 0\tLeader: 1\tReplicas: 2,1,0\tIsr: 1,0\n\tTopic: first\tPartition: 1\tLeader: 0\tReplicas: 0,1,2\tIsr: 0,1\n\tTopic: first\tPartition: 2\tLeader: 1\tReplicas: 1,2,0\tIsr: 1,0\n(3) 指定需要均衡的主题\n$ vim topics-to-move.json\n{\n &quot;topics&quot;: [\n {&quot;topic&quot;: &quot;first&quot;}\n ],\n &quot;version&quot;: 1\n}\n \n(4) 生成负载均衡计划(只是生成计划)\nbin/kafka-reassign-partitions.sh --bootstrap-server 47.106.86.64:9092 --topics-to-move-json-file topics-to-move.json --broker-list &quot;0,1,2,3&quot; --generate\nCurrent partition replica assignment\n{&quot;version&quot;:1,&quot;partitions&quot;:[{&quot;topic&quot;:&quot;first&quot;,&quot;partition&quot;:0,&quot;replic\nas&quot;:[0,2,1],&quot;log_dirs&quot;:[&quot;any&quot;,&quot;any&quot;,&quot;any&quot;]},{&quot;topic&quot;:&quot;first&quot;,&quot;par\ntition&quot;:1,&quot;replicas&quot;:[2,1,0],&quot;log_dirs&quot;:[&quot;any&quot;,&quot;any&quot;,&quot;any&quot;]},{&quot;to\npic&quot;:&quot;first&quot;,&quot;partition&quot;:2,&quot;replicas&quot;:[1,0,2],&quot;log_dirs&quot;:[&quot;any&quot;,&quot;\nany&quot;,&quot;any&quot;]}]}\nProposed partition reassignment configuration\n{&quot;version&quot;:1,&quot;partitions&quot;:[{&quot;topic&quot;:&quot;first&quot;,&quot;partition&quot;:0,&quot;replic\nas&quot;:[2,3,0],&quot;log_dirs&quot;:[&quot;any&quot;,&quot;any&quot;,&quot;any&quot;]},{&quot;topic&quot;:&quot;first&quot;,&quot;par\ntition&quot;:1,&quot;replicas&quot;:[3,0,1],&quot;log_dirs&quot;:[&quot;any&quot;,&quot;any&quot;,&quot;any&quot;]},{&quot;to\npic&quot;:&quot;first&quot;,&quot;partition&quot;:2,&quot;replicas&quot;:[0,1,2],&quot;log_dirs&quot;:[&quot;any&quot;,&quot;\nany&quot;,&quot;any&quot;]}]}\n（3）创建副本存储计划（所有副本存储在 broker0、broker1、broker2、broker3 中）。\nvim increase-replication-factor.json\n{&quot;version&quot;:1,&quot;partitions&quot;:[{&quot;topic&quot;:&quot;first&quot;,&quot;partition&quot;:0,&quot;replic\nas&quot;:[2,3,0],&quot;log_dirs&quot;:[&quot;any&quot;,&quot;any&quot;,&quot;any&quot;]},{&quot;topic&quot;:&quot;first&quot;,&quot;par\ntition&quot;:1,&quot;replicas&quot;:[3,0,1],&quot;log_dirs&quot;:[&quot;any&quot;,&quot;any&quot;,&quot;any&quot;]},{&quot;to\npic&quot;:&quot;first&quot;,&quot;partition&quot;:2,&quot;replicas&quot;:[0,1,2],&quot;log_dirs&quot;:[&quot;any&quot;,&quot;\nany&quot;,&quot;any&quot;]}]}\n(5) 执行副本计划\nkafka-reassign-partitions.sh --bootstrap-server 47.106.86.64:9092 --reassignment-json-file increase-replication-factor.json --execute\n(6) 验证计划\nkafka-reassign-partitions.sh --bootstrap-server 47.106.86.64:9092 --reassignment-json-file increase-replication-factor.json --verify\nStatus of partition reassignment:\nReassignment of partition first-0 is complete.\nReassignment of partition first-1 is complete.\nReassignment of partition first-2 is complete.\nClearing broker-level throttles on brokers 0,1,2,3\nClearing topic-level throttles on topic first\n退役旧节点\n1）执行负载均衡操作\n先按照退役一台节点，生成执行计划，然后按照服役时操作流程执行负载均衡。\n不同于服役计划的 --broker-list &quot;0,1,2&quot; 退役了 Broker3 ；\nkafka-reassign-partitions.sh --bootstrap-server 47.106.86.64:9092 --topics-to-move-json-file topics-to-move.json --broker-list &quot;0,1,2&quot; --generate\n副本机制\n副本基本信息\n\nReplica ：副本，同一分区的不同副本保存的是相同的消息，为保证集群中的某个节点发生故障时，该节点上的 partition 数据不丢失 ，提高副本可靠性，且 kafka 仍然能够继续工作，kafka 提供了副本机制，一个 topic 的每个分区都有若干个副本，一个 leader 和若干个 follower。\nLeader ：每个分区的多个副本中的”主副本”，生产者以及消费者只与 Leader 交互。\nFollower ：每个分区的多个副本中的”从副本”，负责实时从 Leader 中同步数据，保持和 Leader 数据的同步。Leader 发生故障时，从 Follower 副本中重新选举新的 Leader 副本对外提供服务。\n\n\n\nAR:分区中的所有 Replica 统称为 AR = ISR +OSR\nISR:所有与 Leader 副本保持一定程度同步的Replica(包括 Leader 副本在内)组成 ISR\nOSR:与 Leader 副本同步滞后过多的 Replica 组成了 OSR\nLEO:每个副本都有内部的LEO，代表当前队列消息的最后一条偏移量offset + 1。\nHW:高水位，代表所有ISR中的LEO最低的那个offset，也是消费者可见的最大消息offset。\n\n副本选举Leader\n​ Kafka 集群中有一个 broker 的 Controller 会被选举为 Controller Leader (4.2.2) ，负责管理集群Broker 的上下线，所有 topic 的分区副本分配和 Leader 选举等工作。\n​ Broker中Controller 的信息同步工作是依赖于 Zookeeper 的 ./broker/topic 目录下的信息。\n\n结论先行： 如果leader副本下线， 会在ISR队列中存活为前提，按照Replicas队列中前面优先的原则。\n↓↓↓\n（1）创建一个新的 topic，4 个分区，4 个副本\nkafka-topics.sh --bootstrap-server 47.106.86.64:9092 --create --topic atguigu1 --partitions 4 --replication-factor 4\n（2）查看 Leader 分布情况\nkafka-topics.sh --bootstrap-server 47.106.86.64:9092 --describe --topic atguigu1\nTopic: atguigu1 TopicId: awpgX_7WR-OX3Vl6HE8sVg PartitionCount: 4 ReplicationFactor: 4\nConfigs: segment.bytes=1073741824\nTopic: atguigu1 Partition: 0 Leader: 3 Replicas: 3,0,2,1 Isr: 3,0,2,1\nTopic: atguigu1 Partition: 1 Leader: 1 Replicas: 1,2,3,0 Isr: 1,2,3,0\nTopic: atguigu1 Partition: 2 Leader: 0 Replicas: 0,3,1,2 Isr: 0,3,1,2\nTopic: atguigu1 Partition: 3 Leader: 2 Replicas: 2,1,0,3 Isr: 2,1,0,3\n（3）停止掉 hadoop105 的 kafka 进程，并查看 Leader 分区情况\nkafka-server-stop.sh\nkafka-topics.sh --bootstrap-server 47.106.86.64:9092 --describe --topic atguigu1\nTopic: atguigu1 TopicId: awpgX_7WR-OX3Vl6HE8sVg PartitionCount: 4 ReplicationFactor: 4\nConfigs: segment.bytes=1073741824\nTopic: atguigu1 Partition: 0 Leader: 0 Replicas: 3,0,2,1 Isr: 0,2,1\nTopic: atguigu1 Partition: 1 Leader: 1 Replicas: 1,2,3,0 Isr: 1,2,0\nTopic: atguigu1 Partition: 2 Leader: 0 Replicas: 0,3,1,2 Isr: 0,1,2\nTopic: atguigu1 Partition: 3 Leader: 2 Replicas: 2,1,0,3 Isr: 2,1,0\n（4）停止掉 hadoop104 的 kafka 进程，并查看 Leader 分区情况\nkafka-server-stop.sh\nkafka-topics.sh --bootstrap-server 47.106.86.64:9092 --describe  --topic atguigu1\nTopic: atguigu1 TopicId: awpgX_7WR-OX3Vl6HE8sVg PartitionCount: 4 ReplicationFactor: 4\nConfigs: segment.bytes=1073741824\nTopic: atguigu1 Partition: 0 Leader: 0 Replicas: 3,0,2,1 Isr: 0,1\nTopic: atguigu1 Partition: 1 Leader: 1 Replicas: 1,2,3,0 Isr: 1,0\nTopic: atguigu1 Partition: 2 Leader: 0 Replicas: 0,3,1,2 Isr: 0,1\nTopic: atguigu1 Partition: 3 Leader: 1 Replicas: 2,1,0,3 Isr: 1,0\n副本故障处理\nfollower故障流程\n如果follower落后leader过多，体现在落后时间 repca.lag.time.max.ms ，或者落后偏移量repca.lag.max.messages(由于kafka生成速度不好界定，后面取消了该参数)，follower就会被移除ISR队列，等待该队列LEO追上HW，才会重新加入ISR中。\n\nleader故障流程\n旧Leader先被从ISR队列中踢出，然后从ISR中选出一个新的Leader来；此时为了保证多个副本之间的数据一致性，其他的follower会先将各自的log文件中高于HW的部分截取掉，然后从新的leader同步数据（由此可知这只能保证副本之间数据一致性，并不能保证数据不丢失或者不重复）。体现了设置ACK-all的重要性。\n\n分区副本分配\n如果 kafka 服务器只有 4 个节点，那么设置 kafka 的分区数大于服务器台数，在 kafka底层如何分配存储副本呢？\n1）创建 16 分区，3 个副本\n（1）创建一个新的 topic，名称为 second。\nkafka-topics.sh --bootstrap-server 47.106.86.64:9092 --create --partitions 16 --replication-factor 3 --topic second\n（2）查看分区和副本情况。\nkafka-topics.sh --bootstrap-server 47.106.86.64:9092  --describe --topic second\nTopic: second4 Partition: 0 Leader: 0 Replicas: 0,1,2 Isr: 0,1,2\nTopic: second4 Partition: 1 Leader: 1 Replicas: 1,2,3 Isr: 1,2,3\nTopic: second4 Partition: 2 Leader: 2 Replicas: 2,3,0 Isr: 2,3,0\nTopic: second4 Partition: 3 Leader: 3 Replicas: 3,0,1 Isr: 3,0,1\nTopic: second4 Partition: 4 Leader: 0 Replicas: 0,2,3 Isr: 0,2,3\nTopic: second4 Partition: 5 Leader: 1 Replicas: 1,3,0 Isr: 1,3,0\nTopic: second4 Partition: 6 Leader: 2 Replicas: 2,0,1 Isr: 2,0,1\nTopic: second4 Partition: 7 Leader: 3 Replicas: 3,1,2 Isr: 3,1,2\nTopic: second4 Partition: 8 Leader: 0 Replicas: 0,3,1 Isr: 0,3,1\nTopic: second4 Partition: 9 Leader: 1 Replicas: 1,0,2 Isr: 1,0,2\nTopic: second4 Partition: 10 Leader: 2 Replicas: 2,1,3 Isr: 2,1,3\nTopic: second4 Partition: 11 Leader: 3 Replicas: 3,2,0 Isr: 3,2,0\nTopic: second4 Partition: 12 Leader: 0 Replicas: 0,1,2 Isr: 0,1,2\nTopic: second4 Partition: 13 Leader: 1 Replicas: 1,2,3 Isr: 1,2,3\nTopic: second4 Partition: 14 Leader: 2 Replicas: 2,3,0 Isr: 2,3,0\nTopic: second4 Partition: 15 Leader: 3 Replicas: 3,0,1 Isr: 3,0,1\n \n\n手动调整分区副本\n\n手动调整分区副本存储的步骤如下：\n（1）创建一个新的 topic，名称为 three。\nkafka-topics.sh --bootstrap-server  47.106.86.64:9092  --create --partitions 4 --replication-factor 2 --topic three\n（3）创建副本存储计划（所有副本都指定存储在 broker0、broker1 中）。\n$ vim increase-replication-factor.json\n输入如下内容：\n{\n&quot;version&quot;:1,\n&quot;partitions&quot;:[\n{&quot;topic&quot;:&quot;three&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[0,1]},\n{&quot;topic&quot;:&quot;three&quot;,&quot;partition&quot;:1,&quot;replicas&quot;:[0,1]},\n{&quot;topic&quot;:&quot;three&quot;,&quot;partition&quot;:2,&quot;replicas&quot;:[1,0]},\n{&quot;topic&quot;:&quot;three&quot;,&quot;partition&quot;:3,&quot;replicas&quot;:[1,0]}]\n}\n（4）执行副本存储计划。\nkafka-reassign-partitions.sh --bootstrap-server  47.106.86.64:9092  --reassignment-json-file increase-replication-factor.json --execute\n（5）验证副本存储计划。\nkafka-reassign-partitions.sh --bootstrap-server  47.106.86.64:9092  --reassignment-json-file increase-replication-factor.json --verify\n分区自动调整\n​ 一般情况下，我们的分区都是平衡散落在broker的，随着一些broker故障，会慢慢出现leader集中在某台broker上的情况，造成集群负载不均衡，这时候就需要分区平衡。\n\n为了解决上述问题kafka出现了自动平衡的机制。kafka提供了下面几个参数进行控制：\n\nauto.leader.rebalance.enable：自动leader parition平衡，默认是true;\nleader.imbalance.per.broker.percentage：每个broker允许的不平衡的leader的比率，默认是10%，如果超过这个值，控制器将会触发leader的平衡\nleader.imbalance.check.interval.seconds：检查leader负载是否平衡的时间间隔，默认是300秒\n但是在生产环境中是不开启这个自动平衡，因为触发leader partition的自动平衡会损耗性能，或者可以将触发自动平和的参数leader.imbalance.per.broker.percentage的值调大点。\n\n我们也可以通过修改配置，然后手动触发分区的再平衡。\n增加副本因子\n在生产环境当中，由于某个主题的重要等级需要提升，我们考虑增加副本。副本数的增加需要先制定计划，然后根据计划执行。\n不能通过命令行的方法添加副本。\n1）创建 topic\nbin/kafka-topics.sh --bootstrap-server 47.106.86.64:9092 --create --partitions 3 --replication-factor 1 --topic four\n2）手动增加副本存储\n（1）创建副本存储计划（所有副本都指定存储在 broker0、broker1、broker2 中）。\nvim increase-replication-factor.json\n{&quot;version&quot;:1,&quot;partitions&quot;:[\n{&quot;topic&quot;:&quot;four&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[0,1,2]},\n{&quot;topic&quot;:&quot;four&quot;,&quot;partition&quot;:1,&quot;replicas&quot;:[0,1,2]},\n{&quot;topic&quot;:&quot;four&quot;,&quot;partition&quot;:2,&quot;replicas&quot;:[0,1,2]}]}\n（2）执行副本存储计划。\nkafka-reassign-partitions.sh --bootstrap-server 47.106.86.64:9092 --reassignment-json-file increase-replication-factor.json --execute\n文件存储\n存储结构\n在Kafka中主题（Topic）是一个逻辑上的概念，分区（partition）是物理上的存在的。每个partition对应一个log文件，该log文件中存储的就是Producer生产的数据。Producer生产的数据会被不断追加到该log文件末端。为防止log文件过大导致数据定位效率低下，Kafka采用了分片和索引机制，将每个partition分为多个segment，每个segment默认1G（ log.segment.bytes ）， 每个segment包括.index文件、.log文件和**.timeindex**等文件。这些文件位于文件夹下，该文件命名规则为：topic名称+分区号。\n\nSegment的三个文件需要通过特定工具打开才能看到信息\nkafka-run-class.sh kafka.tools.DumpLogSegments --files ./00000000000000000000.index\n \nkafka-run-class.sh kafka.tools.DumpLogSegments --files ./00000000000000000000.log\n​ 当log文件写入4k（这里可以通过log.index.interval.bytes设置）数据，就会写入一条索引信息到index文件中，这样的index索引文件就是一个稀疏索引，它并不会每条日志都建立索引信息。\n​ 当Kafka查询一条offset对应实际消息时，可以通过index进行二分查找，获取最近的低位offset，然后从低位offset对应的position开始，从实际的log文件中开始往后查找对应的消息。\n\n时间戳索引文件，它的作用是可以查询某一个时间段内的消息，它的数据结构是：时间戳（8byte）+ 相对offset（4byte），如果要使用这个索引文件，先要通过时间范围找到对应的offset，然后再去找对应的index文件找到position信息，最后在遍历log文件，这个过程也是需要用到index索引文件的。\n\n文件清理策略\n​ Kafka将消息存储在磁盘中，为了控制磁盘占用空间的不断增加就需要对消息做一定的清理操作。Kafka 中每一个分区副本都对应一个Log，而Log又可以分为多个日志分段，这样也便于日志的清理操作。Kafka提供了两种日志清理策略。\n\n日志删除(delete) :按照一定的保留策略直接删除不符合条件的日志分段。\n日志压缩(compact) :针对每个消息的key进行整合，对于有相同key的不同value值，只保留最后一个版本。\n\n我们可以通过修改broker端参数 log.cleanup.policy 来进行配置\n日志删除\nkafka中默认的日志保存时间为7天，可以通过调整如下参数修改保存时间。\n\nlog.retention.hours：最低优先级小时，默认7天\nlog.retention.minutes：分钟\nlog.retention.ms：最高优先级毫秒\nlog.retention.check.interval.ms：负责设置检查周期，默认5分钟\nfile.delete.delay.ms：延迟执行删除时间\nlog.retention.bytes：当设置为-1时表示运行保留日志最大值（相当于关闭）；当设置为1G时，表示日志文件最大值\n\n具体的保留日志策略有三种：\n基于时间策略\n​ 日志删除任务会周期检查当前日志文件中是否有保留时间超过设定的阈值来寻找可删除的日志段文件集合；这里需要注意log.retention参数的优先级：log.retention.ms &gt; log.retention.minutes &gt; log.retention.hours，默认只会配置log.retention.hours参数，值为168即为7天。\n​ 删除过期的日志段文件，并不是简单的根据日志段文件的修改时间计算，而是要根据该日志段中最大的时间戳来计算的，首先要查询该日志分段所对应的时间戳索引文件，查找该时间戳索引文件的最后一条索引数据，如果时间戳大于0就取值，否则才会使用最近修改时间。\n​ 在删除的时候先从Log对象所维护的日志段的跳跃表中移除要删除的日志段，用来确保已经没有线程来读取这些日志段；接着将日志段所对应的所有文件，包括索引文件都添加上**.deleted的后缀；最后交给一个以delete-file命名的延迟任务来删除这些以.deleted为后缀的文件，默认是1分钟执行一次，可以通过file.delete.delay.ms**来配置。\n基于日志大小策略\n日志删除任务会周期性检查当前日志大小是否超过设定的阈值（log.retention.bytes，默认是-1，表示无穷大），就从第一个日志分段中寻找可删除的日志段文件集合。如果超过阈值，\n基于日志起始偏移量\n该策略判断依据是日志段的下一个日志段的起始偏移量 baseOffset是否小于等于 logStartOffset，如果是，则可以删除此日志分段。这里说一下logStartOffset，一般情况下，日志文件的起始偏移量 logStartOffset等于第一个日志分段的 baseOffset，但这并不是绝对的，logStartOffset的值可以通过 DeleteRecordsRequest请求、使用 kafka-delete-records.sh 脚本、日志的清理和截断等操作进行修改。\n日志压缩\n​ 日志压缩对于有相同key的不同value值，只保留最后一个版本。如果应用只关心 key对应的最新 value值，则可以开启 Kafka相应的日志清理功能，Kafka会定期将相同 key的消息进行合并，只保留最新的 value值。\n\nlog.cleanup.policy = compact 所有数据启用压缩策略\n\n\n​ 这种策略只适合特殊场景，比如消息的key是用户ID，value是用户的资料，通过这种压缩策略，整个消息集里就保存了所有用户最新的资料。\nKafka高效读数据\nkafka之所以可以快速读写的原因如下：\n\nkafka是分布式集群，采用分区方式，并行操作\n读取数据采用稀疏索引，可以快速定位消费数据\n顺序写磁盘\n页缓冲和零拷贝\n\n顺序写磁盘\nKafka 的 producer 生产数据，要写入到 log 文件中，写的过程是一直追加到文件末端，为顺序写。官网有数据表明，同样的磁盘，顺序写能到 600M/s，而随机写只有 100K/s。这与磁盘的机械机构有关，顺序写之所以快，是因为其省去了大量磁头寻址的时间。\n\n页缓存与零拷贝\nkafka高效读写的原因很大一部分取决于页缓存和零拷贝\n页缓存\n在 Kafka 中，大量使用了 PageCache， 这也是 Kafka 能实现高吞吐的重要因素之一。\n​ 首先看一下读操作，当一个进程要去读取磁盘上的文件内容时，操作系统会先查看要读取的数据页是否缓冲在PageCache 中，如果存在则直接返回要读取的数据，这就减少了对于磁盘 I/O的 操作；但是如果没有查到，操作系统会向磁盘发起读取请求并将读取的数据页存入 PageCache 中，之后再将数据返回给进程，就和使用redis缓冲是一个道理。\n​ 接着写操作和读操作是一样的，如果一个进程需要将数据写入磁盘，操作系统会检查数据页是否在PageCache 中已经存在，如果不存在就在 PageCache中添加相应的数据页，接着将数据写入对应的数据页。另外被修改过后的数据页也就变成了脏页，操作系统会在适当时间将脏页中的数据写入磁盘，以保持数据的一致性。\n​ 具体的刷盘机制可以通过 log.flush.interval messages，log.flush .interval .ms 等参数来控制。同步刷盘可以提高消息的可靠性，防止由于机器 掉电等异常造成处于页缓存而没有及时写入磁盘的消息丢失。一般并不建议这么做，刷盘任务就应交由操作系统去调配，消息的可靠性应该由多副本机制来保障，而不是由同步刷盘这 种严重影响性能的行为来保障 。\n零拷贝\n零拷贝并不是不需要拷贝，而是减少不必要的拷贝次数，通常使用在IO读写过程中。常规应用程序IO过程如下图，会经过四次拷贝：\n\n数据从磁盘经过DMA(直接存储器访问)到内核的Read Buffer；\n内核态的Read Buffer到用户态应用层的Buffer\n用户态的Buffer到内核态的Socket Buffer\nSocket Buffer到网卡的NIC Buffer\n\n​ 从上面的流程可以知道内核态和用户态之间的拷贝相当于执行两次无用的操作，之间切换也会花费很多资源；当数据从磁盘经过DMA 拷贝到内核缓存（页缓存）后，为了减少CPU拷贝的性能损耗，操作系统会将该内核缓存与用户层进行共享，减少一次CPU copy过程，同时用户层的读写也会直接访问该共享存储，本身由用户层到Socket缓存的数据拷贝过程也变成了从内核到内核的CPU拷贝过程，更加的快速，这就是零拷贝，IO流程如下图。\n甚至如果我们的消息存在页缓存PageCache中，还避免了硬盘到内核的拷贝过程，更加一步提升了消息的吞吐量。 (大概就理解成传输的数据只保存在内核空间，不需要再拷贝到用户态的应用层)\n\n\nJava的JDK NIO中方法transferTo()方法就能够实现零拷贝操作，这个实现依赖于操作系统底层的sendFile()实现的"},"消息队列/Kafka/Kafka-快速入门":{"title":"Kafka 快速入门","links":[],"tags":[],"content":"安装部署\n集群规划\n\n2.1.2 集群部署\n0）官方下载地址：kafka.apache.org/downloads.html\n1）解压安装包\n[atguigu@hadoop102 software]$ tar -zxvf kafka_2.12-3.0.0.tgz -C /opt/module/\n \n2)修改解压后的文件名称\n[atguigu@hadoop102 module]$ mv kafka_2.12-3.0.0/ kafka\n \n\n3）进入到/opt/module/kafka 目录，修改配置文件\n[atguigu@hadoop102 kafka]$ cd config/\n[atguigu@hadoop102 config]$ vim server.properties\n输入以下内容：\n#broker 的全局唯一编号，不能重复，只能是数字。\nbroker.id=0\n#处理网络请求的线程数量\nnum.network.threads=3\n#用来处理磁盘 IO 的线程数量\nnum.io.threads=8\n#发送套接字的缓冲区大小\nsocket.send.buffer.bytes=102400\n#接收套接字的缓冲区大小\nsocket.receive.buffer.bytes=102400\n#请求套接字的缓冲区大小\nsocket.request.max.bytes=104857600\n#kafka 运行日志(数据)存放的路径，路径不需要提前创建，kafka 自动帮你创建，可以配置多个磁盘路径，路径与路径之间可以用&quot;，&quot;分隔\nlog.dirs=/opt/module/kafka/datas\n#topic 在当前 broker 上的分区个数\nnum.partitions=1\n#用来恢复和清理 data 下数据的线程数量\nnum.recovery.threads.per.data.dir=1\n# 每个 topic 创建时的副本数，默认时 1 个副本\noffsets.topic.replication.factor=1\n#segment 文件保留的最长时间，超时将被删除\nlog.retention.hours=168\n#每个 segment 文件的大小，默认最大 1G\nlog.segment.bytes=1073741824\n \n# 检查过期数据的时间，默认 5 分钟检查一次是否数据过期\nlog.retention.check.interval.ms=300000\n#配置连接 Zookeeper 集群地址（在 zk 根目录下创建/kafka，方便管理）\nzookeeper.connect=hadoop102:2181,hadoop103:2181,hadoop104:2181/kafka\n \n4）分发安装包\n[atguigu@hadoop102 module]$ xsync kafka/\n5）分别在 hadoop103 和 hadoop104 上修改配置文件/opt/module/kafka/config/server.properties中的 broker.id=1、broker.id=2\n\n注：broker.id 不得重复，整个集群中唯一。\n\n[atguigu@hadoop103 module]$ vim kafka/config/server.properties\n修改：\n# The id of the broker. This must be set to a unique integer for each broker.\nbroker.id=1\n[atguigu@hadoop104 module]$ vim kafka/config/server.properties\n修改:\n# The id of the broker. This must be set to a unique integer for each broker.\nbroker.id=2\n6）配置环境变量\n（1）在/etc/profile.d/my_env.sh 文件中增加 kafka 环境变量配置\n sudo vim /etc/profile.d/my_env.sh\n#KAFKA_HOME\nexport KAFKA_HOME=/opt/module/kafka\nexport PATH=$PATH:$KAFKA_HOME/bin\n刷新环境变量\nsource /etc/profile\n启动\n（1） Zookeeper启动 (默认守护进程)\n./zkServer.sh start\nZookeeper状态\n./zkServer.sh status\nZookeeper停止\n./zkServer.sh stop\nZookeeper客户端-常⽤命令    \n./zkCli.sh –server ip:port  //连接ZooKeeper服务端  \nquit  \t\t\t//断开连接    \n(2) 启动Kafka\nKafka 守护方式 (环境变量配置前提下)\n kafka-server-start.sh -daemon /home/environment/kafka/config/server.properties\nKafka关闭\nkafka-server-stop.sh \n\n**注意：**停止 Kafka 集群时，一定要等 Kafka 所有节点进程全部停止后再停止 Zookeeper 集群。因为 Zookeeper 集群当中记录着 Kafka 集群相关信息，Zookeeper 集群一旦先停止，Kafka 集群就没有办法再获取停止进程的信息，只能手动杀死 Kafka 进程了。\n\n2.2 Kafka命令行操作\n基础结构\n\n 主题命令行操作\n1）查看操作主题命令参数\n bin/kafka-topics.sh\n\n2）查看当前服务器中的所有 topic\nkafka-topics.sh --bootstrap-server 47.106.86.64:9092 --list\n3）创建 first topic\nkafka-topics.sh --bootstrap-server 47.106.86.64:9092 --create --partitions 1 --replication-factor 3 --topic first\n\n选项说明：\n--topic 定义 topic 名\n--replication-factor 定义副本数\n--partitions 定义分区数\n\n4）查看 first 主题的详情\nkafka-topics.sh --bootstrap-server 47.106.86.64:9092 --alter --topic first --partitions 3\n5）修改分区数（注意：分区数只能增加，不能减少）\nkafka-topics.sh --bootstrap-server 47.106.86.64:9092 --alter --topic first --partitions 3\n6）再次查看 first 主题的详情\nkafka-topics.sh --bootstrap-server 47.106.86.64:9092 --describe --topic first\n7）删除 topic(需要配置信息)\nkafka-topics.sh --bootstrap-server 47.106.86.64:9092 --delete --topic first\n生产者命令行操作\n1）查看操作生产者命令参数\n连接kafka生产者\nkafka-console-producer.sh --bootstrap-server 47.106.86.64:9092 --topic first\n\n\n参数 描述\n--bootstrap-server &lt;String: server toconnect to&gt; 连接的 Kafka Broker 主机名称和端口号。\n--topic &lt;String: topic&gt; 操作的 topic 名称。\n\n2）发送消息\n[atguigu@hadoop102 kafka]$ bin/kafka-console-producer.sh --\nbootstrap-server hadoop102:9092 --topic first\n&gt;hello world\n&gt;Hi HI\n消费者命令行操作\n1）查看操作消费者命令参数\n连接kafka消费者\nkafka-console-consumer.sh\n\n参数 描述\n–bootstrap-server &lt;String: server toconnect to&gt; 连接的 Kafka Broker 主机名称和端口号。\n–topic &lt;String: topic&gt; 操作的 topic 名称。\n–from-beginning 从头开始消费。\n–group &lt;String: consumer group id&gt; 指定消费者组名称。\n\n2）消费消息\n（1）消费 first 主题中的数据。\nkafka-console-consumer.sh --bootstrap-server 47.106.86.64:9092 --topic first\n（2）把主题中所有的数据都读取出来（包括历史数据）。\nkafka-console-consumer.sh --bootstrap-server 47.106.86.64:9092 --from-beginnin"},"消息队列/Kafka/Kafka-消费者":{"title":"Kafka 消费者","links":[],"tags":[],"content":"消费模式\n常见的消费模式有两种：\npoll(拉)：消费者主动向服务端拉取消息。\npush(推)：服务端主动推送消息给消费者。\n由于推模式很难考虑到每个客户端不同的消费速率,导致消费者无法消费消息而宕机，因此kafka采用的是poll的模式，该模式有个缺点，如果服务端没有消息，消费端就会一直空轮询。为了避免过多不必要的空轮询，kafka做了改进，如果没消息服务端就会暂时保持该请求，在一段时间内有消息再回应给客户端。\n消费工作流程\n消费者总体工作流程\n​ 消费者对消息进行消费，并且将已经消费的消息加入 _consumer_offsets 中。\n\n消费者组原理\nConsumer Group（CG）：消费者组，由多个consumer组成。形成一个消费者组的条件，是所有消费者的groupid相同。\n\n消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费。\n消费者组之间互不影响。所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者。\n\n\n​ 对于消息中间件而言，一般有两种消息投递模式：点对点(P2P, Point-to-Point)模式和发布／订阅(Pub/Sub)模式。点对点模式是基于队列的，消息生产者发送消息到队列，消息消费者从队列中接收消息。发布订阅模式定义了如何向一个内容节点发布和订阅消息，这个内容节点称为主题(Topic) , 主题可以认为是消息传递的中介，消息发布者将消息发布到某个主题， 而消息订阅者从主题中订阅消息。主题使得消息的订阅者和发布者互相保持独立，不需要进行 接触即可保证消息的传递，发布／订阅模式在消息的一对多广播时采用。Kafka同时支待两种消息投递模式，而这正是得益于消费者与消费组模型的契合：\n\n如果所有的消费者都隶属于同一个消费组，那么所有的消息都会被均衡地投递给每一个消费者，即每条消息只会被一个消费者处理，这就相当于点对点模式的应用。\n如果所有的消费者都隶属于不同的消费组，那么所有的消息都会被广播给所有的消费者，即每条消息会被所有的消费者处理，这就相当于发布／订阅模式的应用。\n\n消费者组选举Leader\n具体的消费者组初始化流程：\n​ 通过对GroupId进行Hash得到那台服务器的coordinator ，coordinator负责选出消费组中的Leader ，并且协调信息。真正存储消费记录的是 _consumer_offsets_partition 。\n\n\n\n\n消费者API\n消费组单消费者以及消费者组多消费者\n\n注意：在消费者 API 代码中必须配置消费者组 id。命令行启动消费者不填写消费者组id 会被自动填写随机的消费者组 id。\npublic class CustomConsumer {\n    public static void main(String[] args) {\n        //0.配置信息\n        Properties properties = new Properties();\n        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;47.106.86.64:9092&quot;);\n        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\n        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\n        properties.put(ConsumerConfig.GROUP_ID_CONFIG, &quot;test&quot;);\n \n        //1.创建消费者\n        KafkaConsumer&lt;String, String&gt; kafkaConsumer = new KafkaConsumer&lt;&gt;(properties);\n        ArrayList&lt;String&gt; topic = new ArrayList&lt;&gt;();\n        topic.add(&quot;first&quot;);\n        kafkaConsumer.subscribe(topic);\n \n \n        //2.消费信息\n        while (true) {\n            ConsumerRecords&lt;String, String&gt; records = kafkaConsumer.poll(Duration.ofSeconds(1));\n            records.forEach(record -&gt; {\n                System.out.println(record);\n            });\n        }\n        //3.关闭\n    }\n}\n分区平衡以及再平衡\n\n参数名称 描述\nheartbeat.interval.ms Kafka 消费者和 coordinator 之间的心跳时间，默认 3s。该条目的值必须小于 session.timeout.ms，也不应该高于session.timeout.ms 的 1/3。\nsession.timeout.ms Kafka 消费者和 coordinator 之间连接超时时间，默认 45s。超过该值，该消费者被移除，消费者组执行再平衡。\nmax.poll.interval.ms 消费者处理消息的最大时长，默认是 5 分钟。超过该值，该消费者被移除，消费者组执行再平衡。\npartition.assignment.strategy 消 费 者 分 区 分 配 策 略 ， 默 认 策 略 是 Range + CooperativeSticky。Kafka 可以同时使用多个分区分配策略。可 以 选 择 的 策 略 包 括 ： Range 、 RoundRobin 、 Sticky 、CooperativeSticky (协作者粘性)\n分区分配策略\n​ 我们知道一个 Consumer Group 中有多个 Consumer，一个 Topic 也有多个 Partition，所以必然会涉及到 Partition 的分配问题: 确定哪个 Partition 由哪个 Consumer 来消费的问题。\nKafka 客户端提供了3 种分区分配策略：RangeAssignor、RoundRobinAssignor 和 StickyAssignor，前两种 分配方案相对简单一些StickyAssignor分配方案相对复杂一些。\nRange\n\nRange 分区分配再平衡案例\n（1）停止掉 0 号消费者，快速重新发送消息观看结果（45s 以内，越快越好）。\n1 号消费者：消费到 3、4 号分区数据。\n2 号消费者：消费到 5、6 号分区数据。\n0 号消费者的任务会整体被分配到 1 号消费者或者 2 号消费者。 (被整体分配)\n说明：0 号消费者挂掉后，消费者组需要按照超时时间 45s 来判断它是否退出，所以需要等待，时间到了 45s 后，判断它真的退出就会把任务分配给其他 broker 执行。\n（2）再次重新发送消息观看结果（45s 以后）。\n1 号消费者：消费到 0、1、2、3 号分区数据。\n2 号消费者：消费到 4、5、6 号分区数据。\n说明：消费者 0 已经被踢出消费者组，所以重新按照 range 方式分配。\nRoundRobin\n\n// 修改分区分配策略\nproperties.put(ConsumerConfig.PARTITION_ASSIGNMENT_STRATEGY_CONFIG, &quot;org.apache.kafka.clients.consumer.RoundRobinAssignor&quot;);\n（1）停止掉 0 号消费者，快速重新发送消息观看结果（45s 以内，越快越好）。\n1 号消费者：消费到 2、5 号分区数据\n2 号消费者：消费到 4、1 号分区数据\n0 号消费者的任务会按照 RoundRobin 的方式，把数据轮询分成 0 、6 和 3 号分区数据，分别由 1 号消费者或者 2 号消费者消费。（采用轮训）\n说明：0 号消费者挂掉后，消费者组需要按照超时时间 45s 来判断它是否退出，所以需要等待，时间到了 45s 后，判断它真的退出就会把任务分配给其他 broker 执行。\n（2）再次重新发送消息观看结果（45s 以后）。\n1 号消费者：消费到 0、2、4、6 号分区数据\n2 号消费者：消费到 1、3、5 号分区数据\n说明：消费者 0 已经被踢出消费者组，所以重新按照 RoundRobin 方式分配。\nSticky\nStickyAssignor 分区分配算法是 Kafka 客户端提供的分配策略中最复杂的一种，可以通过 partition.assignment.strategy 参数去设置，从 0.11 版本开始引入，目的就是在执行新分配时，尽量在上一次分配结果上少做调整，其主要实现了以下2个目标：\n1)、Topic Partition 的分配要尽量均衡。\n2)、当 Rebalance(重分配，后面会详细分析) 发生时，尽量与上一次分配结果保持一致。\n该算法的精髓在于，重分配后，还能尽量与上一次结果保持一致，进而达到消费者故障下线，故障恢复后的均衡问题，在此就不举例了。\n// 修改分区分配策略\nproperties.put(ConsumerConfig.PARTITION_ASSIGNMENT_STRATEGY_CONFIG, &quot;org.apache.kafka.clients.consumer.StickyAssignor&quot;);\noffset位移提交\noffset 的默认维护位置\n​ Kafka 0.9 版本之前consumer默认将offset保存在Zookeeper中，从0.9版本之后consumer默认保存在Kafka一个内置的topic中，该topic为_consumer_offsets。\n​ 消费者提交的offset值维护在__consumer_offsets这个Topic中，具体维护在哪个分区中，是由消费者所在的消费者组groupid决定，计算方式是：groupid的hashCode值对50取余。当kafka环境正常而消费者不能消费时，有可能是对应的__consumer_offsets分区leader为none或-1，或者分区中的日志文件损坏导致。\n​ __consumer_offsets 主题里面采用 key 和 value 的方式存储数据。key 是 group.id+topic+ 分区号，value 就是当前 offset 的值。每隔一段时间，kafka 内部会对这个 topic 进行 compact，也就是每个 group.id+topic+分区号就保留最新数据。\n​ 一般情况下， 当集群中第一次有消费者消费消息时会自动创建主题_ consumer_ offsets, 不过它的副本因子还受offsets.topic .replication.factor参数的约束，这个参数的默认值为3 (下载安装的包中此值可能为1)，分区数可以通过offsets.topic.num.partitions参数设置，默认为50。\n​ 在配置文件 config/consumer.properties 中添加配置 exclude.internal.topics=false，默认是 true，表示不能消费系统主题。为了查看该系统主题数据，所以该参数修改为 false。\nkafka-console-consumer.sh --topic __consumer_offsets --bootstrap-server 47.106.86.64:9092 --consumer.config config/consumer.properties --formatter &quot;kafka.coordinator.group.GroupMetadataManager\\$OffsetsMessageFormatter&quot; --from-beginning\n[offset,atguigu,1]::OffsetAndMetadata(offset=7, \nleaderEpoch=Optional[0], metadata=, commitTimestamp=1622442520203, \nexpireTimestamp=None)\n[offset,atguigu,0]::OffsetAndMetadata(offset=8, \nleaderEpoch=Optional[0], metadata=, commitTimestamp=1622442520203, \nexpireTimestamp=None)\n消费者提交offset的方式有两种，自动提交和手动提交\n自动提交\n为了使我们能够专注于自己的业务逻辑，Kafka提供了自动提交offset的功能。\n\n\nenable.auto.commit：是否开启自动提交offset功能，默认是true\nauto.commit.interval.ms：自动提交offset的时间间隔，默认是5s\n\n自动提交有可能出现消息消费失败，但是却提交了offset的情况，导致消息丢失。为了能够实现消息消费offset的精确控制，更推荐手动提交。\n// 自动提交\nproperties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, true);\n// 提交时间间隔\nproperties.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG,1000);\n手动提交\n虽然自动提交offset十分简单便利，但由于其是基于时间提交的，开发人员难以把握offset提交的时机。因 此Kafka还提供了手动提交offset的API。手动提交offset的方法有两种：分别是commitSync（同步提交）和commitAsync（异步提交）。两者的相同点是，都会将本次提交的一批数据最高的偏移量提交；不同点是，同步提交阻塞当前线程，一直到提交成功，并且会自动失败重试（由不可控因素导致，也会出现提交失败）；而异步提交则没有失败重试机制，故有可能提交失败。\n\ncommitSync（同步提交）：必须等待offset提交完毕，再去消费下一批数据。 阻塞线程，一直到提交到成功，会进行失败重试\ncommitAsync（异步提交） ：发送完提交offset请求后，就开始消费下一批数据了。没有失败重试机制，会提交失败\n\n\n指定消费位置\n在kafka中当消费者查找不到所记录的消费位移时，会根据auto.offset.reset的配置，决定从何处消费。\nauto.offset.reset = earliest | latest | none 默认是 latest。\n\nearliest：自动将偏移量重置为最早的偏移量，–from-beginning。\nlatest（默认值）：自动将偏移量重置为最新偏移量\nnone：如果未找到消费者组的先前偏移量，则向消费者抛出异常。\n\n\n​ Kafka中的消费位移是存储在一个内部主题中的， 而我们可以使用**seek()**方法可以突破这一限制：消费位移可以保存在任意的存储介质中， 例如数据库、 文件系统等。以数据库为例， 我们将消费位移保存在其中的一个表中， 在下次消费的时候可以读取存储在数据表中的消费位移并通过seek()方法指向这个具体的位置 。\n//配置信息\nProperties properties = new Properties();\nproperties.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, &quot;latest&quot;);\n指定位移消费\n// 指定位置进行消费\nSet&lt;TopicPartition&gt; assignment = kafkaConsumer.assignment();\n \n//  保证分区分配方案已经制定完毕\nwhile (assignment.size() == 0){\n    kafkaConsumer.poll(Duration.ofSeconds(1));\n    assignment = kafkaConsumer.assignment();\n}\n \n// 指定消费的offset\nfor (TopicPartition topicPartition : assignment) {\n    kafkaConsumer.seek(topicPartition,600);\n}\n \n// 3  消费数据\nwhile (true){\n \n    ConsumerRecords&lt;String, String&gt; consumerRecords = kafkaConsumer.poll(Duration.ofSeconds(1));\n \n    for (ConsumerRecord&lt;String, String&gt; consumerRecord : consumerRecords) {\n        System.out.println(consumerRecord);\n    }\n}\n指定时间消费\n​ 原理就是查到时间对应的offset再去指定位移消费，为了确保同步到分区信息，我们还需要确保能获取到分区，再去查询分区时间\n// 指定位置进行消费\nSet&lt;TopicPartition&gt; assignment = kafkaConsumer.assignment();\n \n//  保证分区分配方案已经制定完毕\nwhile (assignment.size() == 0){\n    kafkaConsumer.poll(Duration.ofSeconds(1));\n \n    assignment = kafkaConsumer.assignment();\n}\n \n// 希望把时间转换为对应的offset\nHashMap&lt;TopicPartition, Long&gt; topicPartitionLongHashMap = new HashMap&lt;&gt;();\n \n// 封装对应集合\nfor (TopicPartition topicPartition : assignment) {\n    topicPartitionLongHashMap.put(topicPartition,System.currentTimeMillis() - 1 * 24 * 3600 * 1000);\n}\n \nMap&lt;TopicPartition, OffsetAndTimestamp&gt; topicPartitionOffsetAndTimestampMap = kafkaConsumer.offsetsForTimes(topicPartitionLongHashMap);\n \n// 指定消费的offset\nfor (TopicPartition topicPartition : assignment) {\n \n    OffsetAndTimestamp offsetAndTimestamp = topicPartitionOffsetAndTimestampMap.get(topicPartition);\n \n    kafkaConsumer.seek(topicPartition,offsetAndTimestamp.offset());\n}\n \n// 3  消费数据\nwhile (true){\n \n    ConsumerRecords&lt;String, String&gt; consumerRecords = kafkaConsumer.poll(Duration.ofSeconds(1));\n \n    for (ConsumerRecord&lt;String, String&gt; consumerRecord : consumerRecords) {\n \n        System.out.println(consumerRecord);\n    }\n}\n漏消费和重复消费\n重复消费：已经消费了数据，但是 offset 没提交。\n漏消费：先提交 offset 后消费，有可能会造成数据的漏消费。\n\n消费者事务\n\n数据积压（提高吞吐量）\n\n参数名称 描述\nfetch.max.bytes 默认Default: 52428800（50 m）。消费者获取服务器端一批消息最大的字节数。如果服务器端一批次的数据大于该值（50m）仍然可以拉取回来这批数据，因此，这不是一个绝对最大值。一批次的大小受 message.max.bytes （broker config）ormax.message.bytes （topic config）影响。\nmax.poll.records 一次 poll 拉取数据返回消息的最大条数，默认是 500 条\n拦截器\n与生产者对应，消费者也有拦截器。我们来看看拦截器具体的方法。\npublic interface ConsumerInterceptor&lt;K, V&gt; extends Configurable, AutoCloseable {\n \n    ConsumerRecords&lt;K, V&gt; onConsume(ConsumerRecords&lt;K, V&gt; records);\n \n    void onCommit(Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets);\n \n    void close();\n}\n​ Kafka Consumer会在poll()方法返回之前调用拦截器的onConsume()方法来对消息进行相应的定制化操作，比如修改返回的消息内容、按照某种规则过滤消息（可能会减少poll()方法返回 的消息的个数）。如果onConsume()方法中抛出异常， 那么会被捕获并记录到日志中， 但是异常不会再向上传递。\n​ Kafka Consumer会在提交完消费位移之后调用拦截器的**onCommit()**方法， 可以使用这个方法来记录跟踪所提交的位移信息，比如当消费者使用commitSync的无参方法时，我们不知道提交的消费位移的具体细节， 而使用拦截器的onCommit()方法却可以做到这 一点。"},"消息队列/Kafka/Kafka-生产者":{"title":"Kafka 生产者","links":[],"tags":[],"content":"生产者消息发送流程\n发送原理\n​ 在消息发送的过程中，涉及到两个线程，main线程和sender线程，其中main线程是消息的生产线程，而sender线程是jvm单例的线程，专门用于消息的发送。\n​ 在jvm的内存中开辟了一块缓存空间叫RecordAccumulator（消息累加器），用于将多条消息合并成一个批次，然后由sender线程发送给kafka集群。\n​ 我们的一条消息在生产过程会调用send方法然后经过拦截器经过序列化器，再经过分区器确定消息发送在具体topic下的哪个分区，然后发送到对应的消息累加器中，消息累加器是多个双端队列。并且每个队列和主题分区都具有一一映射关系。消息在累加器中，进行合并，达到了对应的size（batch.size）或者等待超过对应的等待时间(linger.ms)，都会触发sender线程的发送。sender线程有一个请求池，默认缓存五个请求（ max.in.flight.requests.per.connection ），发送消息后，会等待服务端的ack，如果没收到ack就会重试默认重试int最大值（ retries ）。如果ack成功就会删除累加器中的消息批次，并相应到生产端。\n\n当双端队列中的DQueue满足 batch.size 或者 linger.ms 条件时触发sender线程。\n\n生产者重要参数列表\n\n发送\n普通异步发送\n1）需求：创建 Kafka 生产者，采用异步的方式发送到 Kafka Broker\n\n\n2）代码编写\n（1）创建工程 kafka\n（2）导入依赖\n&lt;dependencies&gt;\n     &lt;dependency&gt;\n         &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt;\n         &lt;artifactId&gt;kafka-clients&lt;/artifactId&gt;\n         &lt;version&gt;3.0.0&lt;/version&gt;\n     &lt;/dependency&gt;\n&lt;/dependencies&gt;\n（4）编写不带回调函数的 API 代码\npublic class CustomProducer {\n \n    public static void main(String[] args) {\n \n        // 1. 给 kafka 配置对象添加配置信息：bootstrap.servers\n        Properties properties = new Properties();\n        //服务信息\n        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,&quot;47.106.86.64:9092&quot;);\n        //配置序列化\n        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());\n        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,StringSerializer.class.getName());\n        // 2. 创建 kafka 生产者的配置对象\n        KafkaProducer&lt;String, String&gt; kafkaProducer = new KafkaProducer&lt;String,String&gt;(properties);\n \n        // 3. 创建 kafka 生产者对象\n        for (int i = 0; i &lt; 5; i++) {\n            kafkaProducer.send(new ProducerRecord(&quot;first&quot;, &quot;one&quot; + i));\n        }\n        kafkaProducer.close();\n    }\n}\n测试：在Linux上开启Kafka验证\nkafka-console-consumer.sh --bootstrap-server 47.106.86.64:9092 --topic first\n带回调函数的异步发送\n​ 回调函数会在 producer 收到 ack 时调用，为异步调用，该方法有两个参数，分别是元数据信息（Record Metadata）和异常信息（Exception），如果 Exception 为 null，说明消息发送成功，如果 Exception 不为 null，说明消息发送失败。\n\n注意：消息发送失败会自动重试，不需要我们在回调函数中手动重试。\n\n \npublic class CustomProducer {\n \n    public static void main(String[] args) {\n \n        // 1. 给 kafka 配置对象添加配置信息：bootstrap.servers\n        Properties properties = new Properties();\n        //服务信息\n        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,&quot;47.106.86.64:9092&quot;);\n        //配置序列化\n        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());\n        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,StringSerializer.class.getName());\n        // 2. 创建 kafka 生产者的配置对象\n        KafkaProducer&lt;String, String&gt; kafkaProducer = new KafkaProducer&lt;String,String&gt;(properties);\n \n        // 3. 创建 kafka 生产者对象\n        for (int i = 0; i &lt; 5; i++) {\n            kafkaProducer.send(new ProducerRecord(&quot;first&quot;, &quot;one&quot; + i), new Callback() {\n                @Override\n                public void onCompletion(RecordMetadata recordMetadata, Exception e) {\n                    if (e == null) {\n                        System.out.println( &quot;分区 ： &quot; + recordMetadata.partition() + &quot; 主题： &quot; + recordMetadata.topic() );\n                    }\n                }\n            });\n        }\n        kafkaProducer.close();\n    }\n}\n同步发送API\n\n先处理已经堆积在DQueue中的数据。\nRecordAccumulator再处理外部数据。\n\n\n只需在异步发送的基础上，再调用一下 get()方法即可。\n\npublic class CustomProducerSync {\n    public static void main(String[] args) throws ExecutionException, InterruptedException {\n \n        // 1. 给 kafka 配置对象添加配置信息：bootstrap.servers\n        Properties properties = new Properties();\n        //服务信息\n        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,&quot;47.106.86.64:9092&quot;);\n        //配置序列化\n        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());\n        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,StringSerializer.class.getName());\n        // 2. 创建 kafka 生产者的配置对象\n        KafkaProducer&lt;String, String&gt; kafkaProducer = new KafkaProducer&lt;String,String&gt;(properties);\n \n        // 3. 创建 kafka 生产者对象\n        for (int i = 0; i &lt; 5; i++) {\n            kafkaProducer.send(new ProducerRecord(&quot;first&quot;, &quot;one&quot; + i), new Callback() {\n                @Override\n                public void onCompletion(RecordMetadata recordMetadata, Exception e) {\n                    if (e == null) {\n                        System.out.println( &quot;分区 ： &quot; + recordMetadata.partition() + &quot; 主题： &quot; + recordMetadata.topic() );\n                    }\n \n                }\n            }).get();\n            Thread.sleep(100);\n        }\n        kafkaProducer.close();\n    }\n}\n生产者拦截器\n生产者拦截器 （ProducerInterceptor）\n拦截器接口一共有三个方法。三个方法内的实现如果抛出异常，会被ProducerInterceptors内部捕获，并不会抛到上层。\npublic interface ProducerInterceptor&lt;K, V&gt; extends Configurable {\n    ProducerRecord&lt;K, V&gt; onSend(ProducerRecord&lt;K, V&gt; record);\n    void onAcknowledgement(RecordMetadata metadata, Exception exception);\n    void close();\n}\nonSend 方法在消息分区之前，可以对消息进行一定的修改，比如给key添加前缀，甚至可以修改我们的topic，如果需要使用kafka实现延时队列高级应用，我们就可以通过拦截器对消息进行判断，并修改，暂时放入我们的延时主题中，等时间达到再放回普通主题队列。\nonAcknowledgement该方法是在我们服务端对sender线程进行消息确认，或消息发送失败后的一个回调。优先于我们send方法的callback回调。我们可以对发送情况做一个统计。但是该方法在我们的sender线程也就是唯一的IO线程执行，逻辑越少越好。\nclose该方法可以在关闭拦截器时，进行一些资源的释放。\n（1） 实现自定义拦截器\npublic MyInterceptor implements ProducerInterceptor {\n    ProducerRecord&lt;K, V&gt; onSend(ProducerRecord&lt;K, V&gt; record);\n    void onAcknowledgement(RecordMetadata metadata, Exception exception);\n    void close();\n}\n（2）将自定义拦截器加入设置中\nproperties.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG,MyInterceptor.getClass.getName());\nKafka 拦截器分为生产者拦截器和消费者拦截器。生产者拦截器允许你在发送消息前以及消息提交成功后植入你的拦截器逻辑；而消费者拦截器支持在消费消息前以及提交位移后编写特定逻辑。值得一提的是，这两种拦截器都支持链的方式，即你可以将一组拦截器串连成一个大的拦截器，Kafka 会按照添加顺序依次执行拦截器逻辑。\n当前 Kafka 拦截器的设置方法是通过参数配置完成的。生产者和消费者两端有一个相同的参数，名字叫 interceptor. Classes\n \nProperties props = new Properties();\nList&lt;String&gt; interceptors = new ArrayList&lt;&gt;();\ninterceptors.add(&quot;com.yourcompany.kafkaproject.interceptors.AddTimestampInterceptor&quot;); // 拦截器1\ninterceptors.add(&quot;com.yourcompany.kafkaproject.interceptors.UpdateCounterInterceptor&quot;); // 拦截器2\nprops.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, interceptors);\n……\n暂时无法在飞书文档外展示此内容\n我们应该怎么编写 AddTimeStampInterceptor 和 UpdateCounterInterceptor 类呢？其实很简单，这两个类以及你自己编写的所有 Producer 端拦截器实现类都要继承 org. Apache. Kafka. Clients. Producer. ProducerInterceptor 接口。\n\n\nOnSend：该方法会在消息发送之前被调用。如果你想在发送之前对消息“美美容”，这个方法是你唯一的机会。\n\n\nOnAcknowledgement：该方法会在消息成功提交或发送失败之后被调用。还记得我在上一期中提到的发送回调通知 callback 吗？onAcknowledgement 的调用要早于 callback 的调用。值得注意的是，**这个方法和 onSend 不是在同一个线程中被调用的，因此如果你在这两个方法中调用了某个共享可变对象，一定要保证线程安全哦。**还有一点很重要，这个方法处在 Producer 发送的主路径中，所以最好别放一些太重的逻辑进去，否则你会发现你的 Producer TPS 直线下降\n\n\n具体来说就是用 CPU 时间去换磁盘空间或网络 I/O 传输量，希望以较小的 CPU 开销带来更少的磁盘占用或更少的网络 I/O 传输。\n生产者分区\n切记分区是实现负载均衡以及高吞吐量的关键\n为什么分区\nKafka 有主题（Topic）的概念，它是承载真实数据的逻辑容器，而在主题之下还分为若干个分区，也就是说 Kafka 的消息组织方式实际上是三级结构：**主题 - 分区 - 消息。**主题下的每条消息只会保存在某一个分区中，而不会在多个分区中被保存多份\n\n为啥要使用多个分区而不是直接使用多个主题？\n\n\n其实分区的作用就是提供负载均衡的能力\n\n\n为了实现系统的高伸缩性（Scalability）。不同的分区能够被放置到不同节点的机器上，而数据的读写操作也都是针对分区这个粒度而进行的，这样每个节点的机器都能独立地执行各自分区的读写请求处理。并且，我们还可以通过添加新的节点机器来增加整体系统的吞吐量。\n\n\n都有哪些分区策略\n所谓分区策略是决定生产者将消息发送到哪个分区的算法。\n自定义分区策略\n在编写生产者程序时，你可以编写一个具体的类实现 org. Apache. Kafka. Clients. Producer. Partitioner 接口。这个接口也很简单，只定义了两个方法：partition ()和 close ()，通常你只需要实现最重要的 partition 方法。我们来看看这个方法的方法签名：\n \nint partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster);\nTopic、key、keyBytes、value 和 valueBytes 都属于消息数据，cluster 则是集群信息（比如当前 Kafka 集群共有多少主题、多少 Broker 等）。\n要你自己的实现类定义好了 partition 方法，同时设置 partitioner. Class 参数为你自己实现类的 Full Qualified Name，\n轮训策略（默认的策略）\n也称 Round-robin 策略，即顺序分配。比如一个主题下有 3 个分区，那么第一条消息被发送到分区 0，第二条被发送到分区 1，第三条被发送到分区 2，以此类推。当生产第 4 条消息时又会重新开始，即将其分配到分区 0，\n\n轮询策略有非常优秀的负载均衡表现，它总是能保证消息最大限度地被平均分配到所有分区上，故默认情况下它是最合理的分区策略，也是我们最常用的分区策略之一。\n随机策略\n也称 Randomness 策略。所谓随机就是我们随意地将消息放置到任意一个分区上，如下面这张图所示。\n\n随机策略也是力求将数据均匀地打散到各个分区，但从实际表现来看，它要逊于轮询策略，所以如果追求数据的均匀分布，还是使用轮询策略比较好。事实上，随机策略是老版本生产者使用的分区策略，在新版本中已经改为轮询了。\n \nList&lt;PartitionInfo&gt; partitions = cluster.partitionsForTopic(topic);\nreturn ThreadLocalRandom.current().nextInt(partitions.size());\n按消息键保序策略\nKafka 允许为每条消息定义消息键，简称为 Key。这个 Key 的作用非常大，它可以是一个有着明确业务含义的字符串，比如客户代码、部门编号或是业务 ID 等\n一旦消息被定义了 Key，那么你就可以保证同一个 Key 的所有消息都进入到相同的分区里面，由于每个分区下的消息处理都是有顺序的，故这个策略被称为按消息键保序策略，\n\n \nList&lt;PartitionInfo&gt; partitions = cluster.partitionsForTopic(topic);\nreturn Math.abs(key.hashCode()) % partitions.size();\n如何实现消息的顺序问题。\n\n\n给 Kafka 主题设置单分区，也就是 1 个分区。这样所有的消息都只在这一个分区内读写，因此保证了全局的顺序性。这样做虽然实现了因果关系的顺序性，但也丧失了 Kafka 多分区带来的高吞吐量和负载均衡的优势。\n\n\n标志位设定专门的分区策略，保证同一标志位的所有消息都发送到同一分区，这样既可以保证分区内的消息顺序，也可以享受到多分区带来的性能红利。\n\n\n其他分区策略\n\n基于地理位置的分区策略\n\n分区的好处\n从存储的角度 → 合理使用存储资源，实现负载均衡\n从计算的角度 → 提高并行计算的可行性\n\n生产者发送消息分区策略\n1）默认的分区器 DefaultPartitioner\n在 IDEA 中 ctrl +n，全局查找 DefaultPartitioner。\n\nKafka支持三种分区策略 1) 指定分区； 2）指定key，计算hash得分区； 3）指定随机粘性分区；\n\n自定义分区器\n如果研发人员可以根据企业需求，自己重新实现分区器。\n1）需求\n例如我们实现一个分区器实现，发送过来的数据中如果包含 Hi，就发往 0 号分区，不包含 Hi，就发往 1 号分区。\n2）实现步骤\n（1）定义类实现 Partitioner 接口。\n（2）重写 partition()方法。\npublic class MyPartitioner implements Partitioner {\n    /**\n     * @param topic 主题\n     * @param key 消息的 key\n     * @param keyBytes 消息的 key 序列化后的字节数组\n     * @param value 消息的 value\n     * @param valueBytes 消息的 value 序列化后的字节数组\n     * @param cluster 集群元数据可以查看分区信息\n     */\n    @Override\n    public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) {\n        String string = value.toString();\n        if (string.contains(&quot;vi&quot;)){\n            return 2;\n        }else{\n            return 1;\n        }\n    }\n}\n（3）使用分区器的方法，在生产者的配置中添加分区器参数。\n//自定义分区规则 \nproperties.put(ProducerConfig.PARTITIONER_CLASS_CONFIG,MyPartitioner.class.getName());\n（4）开启测试\n生产者提高吞吐量\n通过提高吞吐量达到低延迟的效果\n\nBatch.size 与 linger.ms 配合使用，根据生成数据的大小指定。\nRecordAccumlator：在异步发送并且分区很多的情况下，32M的数据量容易被满足，进程交互加大，可以适当提高到64M。\n // batch.size：批次大小，默认 16K\nproperties.put(ProducerConfig.BATCH_SIZE_CONFIG, 16384);\n// linger.ms：等待时间，默认 0\nproperties.put(ProducerConfig.LINGER_MS_CONFIG, 1);\n// RecordAccumulator：缓冲区大小，默认 32M：buffer.memory\nproperties.put(ProducerConfig.BUFFER_MEMORY_CONFIG,33554432);\n \n// compression.type：压缩，默认 none，可配置值 gzip、snappy、lz4 和 zstd\nproperties.put(ProducerConfig.COMPRESSION_TYPE_CONFIG, &quot;snappy&quot;);\n消息累加器\n消息累加器（RecordAccumulator）\n\n​ 为了提高生产者的吞吐量，我们通过累加器将多条消息合并成一批统一发送。在broker中将消息批量存入。减少多次的网络IO。\n​ 消息累加器默认32m，如果生产者的发送速率大于sender发送的速率，消息就会堆满累加器。生产者就会阻塞，或者报错，报错取决于阻塞时间的配置。\n​ 累加器的存储形式为ConcurrentMap&lt;TopicPartition, Deque&lt;ProducerBatch&gt;&gt;，可以看出来就是一个分区对应一个双端队列，队列中存储的是ProducerBatch一般大小是16k根据batch.size配置，新的消息会append到ProducerBatch中，满16k就会创建新的ProducerBatch，并且触发sender线程进行发送。\n​ 如果消息量非常大，生成了大量的ProducerBatch，在发送后，又需要JVM通过GC回收这些ProducerBatch就变得非常影响性能，所以kafka通过 BufferPool作为内存池来管理ProducerBatch的创建和回收，需要申请一个新的ProducerBatch空间时，调用 free.allocate(size, maxTimeToBlock)找内存池申请空间。\n如果单条消息大于16k，那么就不会复用内存池了，会生成一个更大的ProducerBatch专门存放大消息，发送完后GC回收该内存空间。\n为了进一步减小网络中消息传输的带宽。我们也可以通过**消息压缩**的方式，在生产端将消息追加进`ProducerBatch`就对每一条消息进行压缩了。常用的有Gzip、Snappy、Lz4 和 Zstd，这是时间换空间的手段。压缩的消息会在消费端进行解压。\n\n消息发送线程（Sender）\n​ 消息保存在内存后，Sender线程就会把符合条件的消息按照批次进行发送。除了发送消息，元数据的加载也是通过Sender线程来处理的。\n​ Sender线程发送消息以及接收消息，都是基于java NIO的Selector。通过Selector把消息发出去，并通过Selector接收消息。\n​ Sender线程默认容纳5个未确认的消息，消息发送失败后会进行重试。\n生产经验—数据可靠性\n消息确认机制-ACK\nproducer提供了三种消息确认的模式，通过配置acks来实现\nacks为0时， 表示生产者将数据发送出去就不管了，不等待任何返回。这种情况下数据传输效率最高，但是数据可靠性最低，当 server挂掉的时候就会丢数据；\nacks为1时（默认），表示数据发送到Kafka后，经过leader成功接收消息的的确认，才算发送成功，如果leader宕机了，就会丢失数据。\nacks为-1/all时，表示生产者需要等待ISR中的所有follower都确认接收到数据后才算发送完成，这样数据不会丢失，因此可靠性最高，性能最低。\n\n数据完全可靠条件 = ACK级别设置为-1 + 分区副本大于等于2 + ISR里应答的最小副本数量大于等于2\n\n\nAR = ISR + ORS\n正常情况下，如果所有的follower副本都应该与leader副本保持一定程度的同步，则AR = ISR，OSR = null。\nISR 表示在指定时间内和leader保存数据同步的集合；\nORS表示不能在指定的时间内和leader保持数据同步集合，称为OSR(Out-Sync Relipca set)。\n// Ack 设置\nproperties.put(ProducerConfig.ACKS_CONFIG,&quot;1&quot;);\n \n// 重试次数, 默认的重试次数是 Max.Integer\nproperties.put(ProducerConfig.RETRIES_CONFIG,3);\n数据去重-幂等性\n1）幂等性原理\n在一般的MQ模型中，常有以下的消息通信概念\n\n至少一次（At Least Once）： ACK级别设置为-1 + 分区副本大于等于2 + ISR里应答的最小副本数量&gt;=2。可以保证数据不丢失，但是不能保证数据不重复。\n最多一次（At Most Once）：ACK级别设置为0 。可以保证数据不重复，但是不能保证数据不丢失。•\n精确一次（Exactly Once）：至少一次 + 幂等性 。 Kafka 0.11版本引入一项重大特性：幂等性和事务。\n\n​ 幂等性，简单地说就是对接口的多次调用所产生的结果和调用一次是一致的。生产者在进行重试的时候有可能会重复写入消息，而使用Kafka 的幂等性功能之后就可以避免这种情况。（不产生重复数据）\n​ 重复数据的判断标准：具有&lt;PID, Partition, SeqNumber&gt;相同主键的消息提交时，Broker只会持久化一条。其\n中ProducerId（pid）是Kafka每次重启都会分配一个新的；Partition 表示分区号；Sequence Number 序列化号，是单调自增的。\n​ broker中会在内存维护一个pid+分区对应的序列号。如果收到的序列号正好比内存序列号大一，才存储消息，如果小于内存序列号，意味着消息重复，那么会丢弃消息，并应答。如果远大于内存序列号，意味着消息丢失，会抛出异常。\n所以幂等解决的是sender到broker间，由于网络波动可能造成的重发问题。用幂等来标识唯一消息。\n并且幂等性只能保证的是在单分区单会话内不重复。\n2）如何使用幂等性\n​ 开启幂等性功能的方式很简单，只需要显式地将生产者客户端参数enable.idempotence设置为true即可(这个参数的默认值为true)，并且还需要确保生产者客户端的retries、acks、max.in.filght.request.per.connection参数不被配置错，默认值就是对的。\n消息事务\n\n由于幂等性不能跨分区运作，为了保证同时发的多条消息，要么全成功，要么全失败。kafka引入了事务的概念。\n开启事务需要producer设置transactional.id的值并同时开启幂等性。\n通过事务协调器，来实现事务，工作流程如下：\n// 1 初始化事务\nvoid initTransactions();\n// 2 开启事务\nvoid beginTransaction() throws ProducerFencedException;\n// 3 在事务内提交已经消费的偏移量（主要用于消费者）\nvoid sendOffsetsToTransaction(Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets,\n String consumerGroupId) throws \nProducerFencedException;\n// 4 提交事务\nvoid commitTransaction() throws ProducerFencedException;\n// 5 放弃事务（类似于回滚事务的操作）\nvoid abortTransaction() throws ProducerFencedException;\n\n客户端-无消息丢失如何配置\n一句话概括，Kafka 只对**“已提交”的消息（committed message）做有限度的持久化保证。**\n\n\n生产者\n\n要使用 producer. Send (msg)，而要使用 producer. Send (msg, callback)。记住，一定要使用带有回调通知的 send 方法。\n\n\n\nBroker\n\n\n设置 acks = all。Acks 是 Producer 的一个参数，代表了你对“已提交”消息的定义。**如果设置成 all，则表明所有副本 Broker 都要接收到消息，该消息才算是“已提交”。**这是最高等级的“已提交”定义\n\n\n设置 retries 为一个较大的值。这里的 retries 同样是 Producer 的参数，对应前面提到的 Producer 自动重试。当出现网络的瞬时抖动时，消息发送可能会失败，此时配置了 retries &gt; 0 的 Producer 能够自动重试消息发送，避免消息丢失。\n\n\n设置 unclean. Leader. Election. Enable = false。这是 Broker 端的参数，它控制的是哪些 Broker 有资格竞选分区的 Leader。如**果一个 Broker 落后原先的 Leader 太多，那么它一旦成为新的 Leader，必然会造成消息的丢失。**故一般都要将该参数设置成 false，即不允许这种情况的发生。\n\n\n设置 replication. Factor &gt;= 3。这也是 Broker 端的参数。其实这里想表述的是，最好将消息多保存几份，毕竟目前防止消息丢失的主要机制就是冗余。\n\n\n设置 min. Insync. Replicas &gt; 1。这依然是 Broker 端参数，**控制的是消息至少要被写入到多少个副本才算是“已提交”。**设置成大于 1 可以提升消息持久性。在实际环境中千万不要使用默认值 1。\n\n\n确保 replication. Factor &gt; min. Insync. Replicas。**如果两者相等，那么只要有一个副本挂机，整个分区就无法正常工作了。**我们不仅要改善消息的持久性，防止数据丢失，还要在不降低可用性的基础上完成。推荐设置成 replication. Factor = min. Insync. Replicas + 1。\n\n\n\n\n消费者\n\n确保消息消费完成再提交。Consumer 端有个参数 enable. Auto. Commit，最好把它设置成 false，并采用手动提交位移的方式。就像前面说的，这对于单 Consumer 多线程处理的场景而言是至关重要的。\n\n\n\n其基本思想就是允许应用程序在不修改逻辑的情况下，动态地实现一组可插拔的事件处理逻辑链。它能够在主业务操作的前后多个时间点上插入对应的“拦截”逻辑。Springmvcde 拦截器的工作原理\n\nKafka 拦截器借鉴了这样的设计思路。你可以在消息处理的前后多个时点动态植入不同的处理逻辑，比如在消息发送前或者在消息被消费后。\n消息顺序\n消息在单分区内有序，多分区内无序（如果对多分区进行排序，造成分区无法工作需要等待排序，浪费性能）\n\nkafka只能保证单分区下的消息顺序性，为了保证消息的顺序性，需要做到如下几点。\n如果未开启幂等性，需要 max.in.flight.requests.per.connection 设置为1。（缓冲队列最多放置1个请求）\n如果开启幂等性，需要 max.in.flight.requests.per.connection 设置为小于5。\n这是因为broker端会缓存producer主题分区下的五个request，保证最近5个request是有序的。\n\n如果Request3在失败重试后才发往到集群中，必然会导致乱序，但是集群会重新按照序列号进行排序（最对一次排序5个）。\n客户端-生产者压缩算法\n怎么压缩\nKafka 的消息层次都分为两层：\n\n\n消息集合（message set）\n\n\n消息（message）。一个消息集合中包含若干条日志项（record item）, 而日志项才是真正封装消息的地方\n\n\n目前 Kafka 共有两大类消息格式，社区分别称之为 V 1 版本和 V 2 版本。\n引入 V 2 版本的目的\n主要是针对 V 1 版本的一些弊端做了修正，\n\n\nCRC 校验\n\n\n在 V 1 版本中，每条消息都需要执行 CRC 校验，但有些情况下消息的 CRC 值是会发生变化的。比如在 Broker 端可能会对消息时间戳字段进行更新，那么重新计算之后的 CRC 值也会相应更新。\n\n\n在 V 2 版本中，消息的 CRC 校验工作就被移到了消息集合这一层\n\n\n\n\n压缩方式\n\n\nV 1 版本中保存压缩消息的方法是把多条消息进行压缩然后保存到外层消息的消息体字段中\n\n\nV 2 版本的做法是对整个消息集合进行压缩\n\n\n\n\n何时压缩\n压缩可能发生在两个地方：生产者端和 Broker 端。\n生产者程序中配置 compression. Type 参数即表示启用指定类型的压缩算法\n \n Properties props = new Properties();\n props.put(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;);\n props.put(&quot;acks&quot;, &quot;all&quot;);\n props.put(&quot;key.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);\n props.put(&quot;value.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);\n // 开启GZIP压缩\n props.put(&quot;compression.type&quot;, &quot;gzip&quot;);\n \n Producer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props);\n大部分情况下 Broker 从 Producer 端接收到消息后仅仅是原封不动地保存而不会对其进行任何修改\n有时 Broker 端需要重新压缩\n\n\nBroker 端指定了和 Producer 端不同的压缩算法。\n\n\nBroker 端发生了消息格式转换。\n\n\n何时解压缩\n通常来说解压缩发生在消费者程序中，也就是说 Producer 发送压缩消息到 Broker 后，Broker 照单全收并原样保存起来。当 Consumer 程序请求这部分消息时，Broker 依然原样发送出去，当消息到达 Consumer 端后，由 Consumer 自行解压缩还原成之前的消息。\n通常\nProducer 端压缩、Broker 端保持、Consumer 端解压缩。"},"消息队列/Kafka/Spring-整合-Kafka":{"title":"Spring 整合 Kafka","links":[],"tags":[],"content":"\n导包 -除了Spring Boot 之外还需要额外导入 Spring Web、Kafka\n\n\n2, 编写配置文件\nspring.kafka.bootstrap-servers=47.106.86.64:9092\n \n#序列化器 以及反序列化器\nspring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer\nspring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer\nspring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer\nspring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer\n \nspring.kafka.consumer.group-id=test2\n3、定义简单生产者\n@RestController\npublic class ProducerController {\n    @Autowired\n    KafkaTemplate&lt;String, String&gt; kafkaTemplate;\n \n    @RequestMapping(&quot;/hi&quot;)\n    public String  data(String msg){\n        kafkaTemplate.send(&quot;first&quot;,msg);\n        return &quot;ok&quot;;\n    }\n}\n编写具有回调函数的生产者\n@GetMapping(&quot;/kafka/callbackOne/{message}&quot;)\npublic void sendMessage2(@PathVariable(&quot;message&quot;) String callbackMessage) {\n    kafkaTemplate.send(&quot;first&quot;, callbackMessage).addCallback(success -&gt; {\n        // 消息发送到的topic\n        String topic = success.getRecordMetadata().topic();\n        // 消息发送到的分区\n        int partition = success.getRecordMetadata().partition();\n        // 消息在分区内的offset\n        long offset = success.getRecordMetadata().offset();\n        System.out.println(&quot;发送消息成功:&quot; + topic + &quot;-&quot; + partition + &quot;-&quot; + offset);\n    }, failure -&gt; {\n        System.out.println(&quot;发送消息失败:&quot; + failure.getMessage());\n    });\n}\n@GetMapping(&quot;/kafka/callbackTwo/{message}&quot;)\npublic void sendMessage3(@PathVariable(&quot;message&quot;) String callbackMessage) {\n    kafkaTemplate.send(&quot;first&quot;, callbackMessage).addCallback(\n        (ListenableFutureCallback&lt;? super SendResult&lt;String, String&gt;&gt;) new ListenableFutureCallback&lt;SendResult&lt;String, Object&gt;&gt;() {\n            @Override\n            public void onFailure(Throwable ex) {\n                System.out.println(&quot;发送消息失败：&quot;+ex.getMessage());\n            }\n \n            @Override\n            public void onSuccess(SendResult&lt;String, Object&gt; result) {\n                System.out.println(&quot;发送消息成功：&quot; + result.getRecordMetadata().topic() + &quot;-&quot;\n                                   + result.getRecordMetadata().partition() + &quot;-&quot; + result.getRecordMetadata().offset());\n            }\n        });\n}\n4、定义消费者 →启动监听线程\n@Configuration\npublic class KafkaConfiguration{\n \n \n    @KafkaListener(topics = {&quot;first&quot;})\n    public void message1(ConsumerRecord&lt;?, ?&gt; record){\n        // 消费的哪个topic、partition的消息,打印出消息内容\n        System.out.println(&quot;点对点消费1：&quot;+record.topic()+&quot;-&quot;+record.partition()+&quot;-&quot;+record.value());\n    }\n \n}\n参考 ：blog.csdn.net/prague6695/article/details/123869202\n​ mp.weixin.qq.com/s/ZG9e6-81cXhDSK4p05gR3A\n​ blog.csdn.net/weixin_55229531/article/details/125135400\nate;\n@RequestMapping(&quot;/hi&quot;)\npublic String  data(String msg){\n    kafkaTemplate.send(&quot;first&quot;,msg);\n    return &quot;ok&quot;;\n}\n\n}\n\n编写具有回调函数的生产者\n\n```java\n@GetMapping(&quot;/kafka/callbackOne/{message}&quot;)\npublic void sendMessage2(@PathVariable(&quot;message&quot;) String callbackMessage) {\n    kafkaTemplate.send(&quot;first&quot;, callbackMessage).addCallback(success -&gt; {\n        // 消息发送到的topic\n        String topic = success.getRecordMetadata().topic();\n        // 消息发送到的分区\n        int partition = success.getRecordMetadata().partition();\n        // 消息在分区内的offset\n        long offset = success.getRecordMetadata().offset();\n        System.out.println(&quot;发送消息成功:&quot; + topic + &quot;-&quot; + partition + &quot;-&quot; + offset);\n    }, failure -&gt; {\n        System.out.println(&quot;发送消息失败:&quot; + failure.getMessage());\n    });\n}\n\n@GetMapping(&quot;/kafka/callbackTwo/{message}&quot;)\npublic void sendMessage3(@PathVariable(&quot;message&quot;) String callbackMessage) {\n    kafkaTemplate.send(&quot;first&quot;, callbackMessage).addCallback(\n        (ListenableFutureCallback&lt;? super SendResult&lt;String, String&gt;&gt;) new ListenableFutureCallback&lt;SendResult&lt;String, Object&gt;&gt;() {\n            @Override\n            public void onFailure(Throwable ex) {\n                System.out.println(&quot;发送消息失败：&quot;+ex.getMessage());\n            }\n \n            @Override\n            public void onSuccess(SendResult&lt;String, Object&gt; result) {\n                System.out.println(&quot;发送消息成功：&quot; + result.getRecordMetadata().topic() + &quot;-&quot;\n                                   + result.getRecordMetadata().partition() + &quot;-&quot; + result.getRecordMetadata().offset());\n            }\n        });\n}\n4、定义消费者 →启动监听线程\n@Configuration\npublic class KafkaConfiguration{\n \n \n    @KafkaListener(topics = {&quot;first&quot;})\n    public void message1(ConsumerRecord&lt;?, ?&gt; record){\n        // 消费的哪个topic、partition的消息,打印出消息内容\n        System.out.println(&quot;点对点消费1：&quot;+record.topic()+&quot;-&quot;+record.partition()+&quot;-&quot;+record.value());\n    }\n \n}"},"消息队列/消息队列":{"title":"消息队列","links":["消息队列/消息队列基础","消息队列/Pulsar/1.Pulsar概述","消息队列/Pulsar/2.doccker-中启动-standalone-Pulsar","消息队列/Kafka/kafka概述","消息队列/Kafka/Kafka-快速入门","消息队列/Kafka/Kafka-生产者","消息队列/Kafka/Kafka-Broker","消息队列/Kafka/Kafka-消费者","消息队列/Kafka/Spring-整合-Kafka","消息队列/Kafka/Kafka-面试题"],"tags":["消息队列"],"content":"基础\n\n消息队列基础\n\nPulsar\n\n1.Pulsar概述\n2.doccker 中启动 standalone Pulsar\n\nKafka\nkafka概述\nKafka 快速入门\nKafka 生产者\nKafka Broker\nKafka 消费者\nSpring 整合 Kafka\nKafka 面试题"},"编译原理/编译原理":{"title":"编译原理","links":["编译原理/编译原理.pdf","编译原理/编译原理_ppt.pdf"],"tags":[],"content":"编译原理\n编译原理_ppt"},"资源/资源汇总":{"title":"资源汇总","links":[],"tags":[],"content":""},"高可用/高可用":{"title":"高可用","links":["高可用/冗余设计详解","高可用/性能测试入门","高可用/服务限流详解","高可用/超时-and-重试详解","高可用/高可用系统设计指南","高可用/高可用：如何设计一个高可用系统？","高可用/高可用：如何避免微服务中的雪崩问题？","高可用/高可用：灰度发布和回滚有什么用？","高可用/高可用：降级和熔断有什么区别？"],"tags":[],"content":"\n冗余设计详解\n性能测试入门\n服务限流详解\n超时&amp;重试详解\n高可用系统设计指南\n高可用：如何设计一个高可用系统？\n高可用：如何避免微服务中的雪崩问题？\n高可用：灰度发布和回滚有什么用？\n高可用：降级和熔断有什么区别？\n"}}