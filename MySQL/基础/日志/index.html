<!doctype html><html lang=en><head><meta charset=utf-8><meta name=description content="Update 的执行过程
1  UPDATEt_userSETname='xiaolin'WHEREid=1;    客户端先通过连接器建立连接，连接器自会判断用户身份；
  因为这是一条 update 语句，所以不需要经过查询缓存，但是表上有更新语句，是会把整个表的查询缓存清空的，所以说查询缓存很鸡肋，在 MySQL 8.0 就被移除这个功能了；
  解析器会通过词法分析识别出关键字 update，表名等等，构建出语法树，接着还会做语法分析，判断输入的语句是否符合 MySQL 语法；"><meta property="og:title" content><meta property="og:description" content="Update 的执行过程
1  UPDATEt_userSETname='xiaolin'WHEREid=1;    客户端先通过连接器建立连接，连接器自会判断用户身份；
  因为这是一条 update 语句，所以不需要经过查询缓存，但是表上有更新语句，是会把整个表的查询缓存清空的，所以说查询缓存很鸡肋，在 MySQL 8.0 就被移除这个功能了；
  解析器会通过词法分析识别出关键字 update，表名等等，构建出语法树，接着还会做语法分析，判断输入的语句是否符合 MySQL 语法；"><meta property="og:type" content="website"><meta property="og:image" content="https://googoo-s.github.io/icon.png"><meta property="og:url" content="https://googoo-s.github.io/MySQL/%E5%9F%BA%E7%A1%80/%E6%97%A5%E5%BF%97/"><meta property="og:width" content="200"><meta property="og:height" content="200"><meta name=twitter:card content="summary"><meta name=twitter:title content><meta name=twitter:description content="Update 的执行过程
1  UPDATEt_userSETname='xiaolin'WHEREid=1;    客户端先通过连接器建立连接，连接器自会判断用户身份；
  因为这是一条 update 语句，所以不需要经过查询缓存，但是表上有更新语句，是会把整个表的查询缓存清空的，所以说查询缓存很鸡肋，在 MySQL 8.0 就被移除这个功能了；
  解析器会通过词法分析识别出关键字 update，表名等等，构建出语法树，接着还会做语法分析，判断输入的语句是否符合 MySQL 语法；"><meta name=twitter:image content="https://googoo-s.github.io/icon.png"><title>googoo-s</title><meta name=viewport content="width=device-width,initial-scale=1"><link rel="shortcut icon" type=image/png href=https://googoo-s.github.io//icon.png><link href=https://googoo-s.github.io/styles.19109a40042e9f0e72e952fda4442a34.min.css rel=stylesheet><link href=https://googoo-s.github.io/styles/_light_syntax.86a48a52faebeaaf42158b72922b1c90.min.css rel=stylesheet id=theme-link><script src=https://googoo-s.github.io/js/darkmode.953af745b0f9342644d632fc167f3727.min.js></script>
<script src=https://googoo-s.github.io/js/util.00639692264b21bc3ee219733d38a8be.min.js></script>
<link rel=preload href=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css as=style onload='this.onload=null,this.rel="stylesheet"' integrity=sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js integrity=sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/contrib/copy-tex.min.js integrity=sha384-ww/583aHhxWkz5DEVn6OKtNiIaLi2iBRNZXfJRiY1Ai7tnJ9UXpEsyvOITVpTl4A crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/@floating-ui/core@1.2.1></script>
<script src=https://cdn.jsdelivr.net/npm/@floating-ui/dom@1.2.1></script>
<script defer src=https://googoo-s.github.io/js/popover.aa9bc99c7c38d3ae9538f218f1416adb.min.js></script>
<script defer src=https://googoo-s.github.io/js/code-title.ce4a43f09239a9efb48fee342e8ef2df.min.js></script>
<script defer src=https://googoo-s.github.io/js/clipboard.2913da76d3cb21c5deaa4bae7da38c9f.min.js></script>
<script defer src=https://googoo-s.github.io/js/callouts.7723cac461d613d118ee8bb8216b9838.min.js></script>
<script>const SEARCH_ENABLED=!1,LATEX_ENABLED=!0,PRODUCTION=!0,BASE_URL="https://googoo-s.github.io/",fetchData=Promise.all([fetch("https://googoo-s.github.io/indices/linkIndex.26897e4d1acf67c094aa607e8f2e6316.min.json").then(e=>e.json()).then(e=>({index:e.index,links:e.links})),fetch("https://googoo-s.github.io/indices/contentIndex.3ec8b971821571cb762e89228548f0c7.min.json").then(e=>e.json())]).then(([{index:e,links:t},n])=>({index:e,links:t,content:n})),render=()=>{const e=new URL(BASE_URL),t=e.pathname,n=window.location.pathname,s=t==n;addCopyButtons(),addTitleToCodeBlocks(),addCollapsibleCallouts(),initPopover("https://googoo-s.github.io",!0);const o=document.getElementById("footer");if(o){const e=document.getElementById("graph-container");if(!e)return requestAnimationFrame(render);e.textContent="";const t=s&&!1;drawGraph("https://googoo-s.github.io",t,[{"/moc":"#4388cc"}],t?{centerForce:1,depth:-1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.5,linkDistance:1,opacityScale:3,repelForce:1,scale:1.4}:{centerForce:1,depth:1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.6,linkDistance:1,opacityScale:3,repelForce:2,scale:1.2})}var i=document.getElementsByClassName("mermaid");i.length>0&&import("https://unpkg.com/mermaid@9/dist/mermaid.esm.min.mjs").then(e=>{e.default.init()});function a(n){const e=n.target,t=e.className.split(" "),s=t.includes("broken"),o=t.includes("internal-link");plausible("Link Click",{props:{href:e.href,broken:s,internal:o,graph:!1}})}const r=document.querySelectorAll("a");for(link of r)link.className.includes("root-title")&&link.addEventListener("click",a,{once:!0})},init=(e=document)=>{addCopyButtons(),addTitleToCodeBlocks(),renderMathInElement(e.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],macros:{'’':"'"},throwOnError:!1})}</script><script type=module>
    import { attachSPARouting } from "https:\/\/googoo-s.github.io\/js\/router.d6fe6bd821db9ea97f9aeefae814d8e7.min.js"
    attachSPARouting(init, render)
  </script><script defer data-domain=googoo-s.github.io src=https://plausible.io/js/script.js></script>
<script>window.plausible=window.plausible||function(){(window.plausible.q=window.plausible.q||[]).push(arguments)}</script></head><body><div id=search-container><div id=search-space><input autocomplete=off id=search-bar name=search type=text aria-label=Search placeholder="Search for something..."><div id=results-container></div></div></div><script src=https://cdn.jsdelivr.net/npm/flexsearch@0.7.21/dist/flexsearch.bundle.js integrity="sha256-i3A0NZGkhsKjVMzFxv3ksk0DZh3aXqu0l49Bbh0MdjE=" crossorigin=anonymous defer></script>
<script defer src=https://googoo-s.github.io/js/full-text-search.e6e2e0c213187ca0c703d6e2c7a77fcd.min.js></script><div class=singlePage><header><h1 id=page-title><a class=root-title href=https://googoo-s.github.io/>googoo-s</a></h1><div class=spacer></div><div id=search-icon><p>Search</p><svg tabindex="0" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search Icon</title><desc id="desc">Icon to open search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"/><circle cx="8" cy="8" r="7"/></g></svg></div><div class=darkmode><input class=toggle id=darkmode-toggle type=checkbox tabindex=-1>
<label id=toggle-label-light for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="dayIcon" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35"><title>Light Mode</title><path d="M6 17.5C6 16.672 5.328 16 4.5 16h-3C.672 16 0 16.672.0 17.5S.672 19 1.5 19h3C5.328 19 6 18.328 6 17.5zM7.5 26c-.414.0-.789.168-1.061.439l-2 2C4.168 28.711 4 29.086 4 29.5 4 30.328 4.671 31 5.5 31c.414.0.789-.168 1.06-.44l2-2C8.832 28.289 9 27.914 9 27.5 9 26.672 8.329 26 7.5 26zm10-20C18.329 6 19 5.328 19 4.5v-3C19 .672 18.329.0 17.5.0S16 .672 16 1.5v3C16 5.328 16.671 6 17.5 6zm10 3c.414.0.789-.168 1.06-.439l2-2C30.832 6.289 31 5.914 31 5.5 31 4.672 30.329 4 29.5 4c-.414.0-.789.168-1.061.44l-2 2C26.168 6.711 26 7.086 26 7.5 26 8.328 26.671 9 27.5 9zM6.439 8.561C6.711 8.832 7.086 9 7.5 9 8.328 9 9 8.328 9 7.5c0-.414-.168-.789-.439-1.061l-2-2C6.289 4.168 5.914 4 5.5 4 4.672 4 4 4.672 4 5.5c0 .414.168.789.439 1.06l2 2.001zM33.5 16h-3c-.828.0-1.5.672-1.5 1.5s.672 1.5 1.5 1.5h3c.828.0 1.5-.672 1.5-1.5S34.328 16 33.5 16zM28.561 26.439C28.289 26.168 27.914 26 27.5 26c-.828.0-1.5.672-1.5 1.5.0.414.168.789.439 1.06l2 2C28.711 30.832 29.086 31 29.5 31c.828.0 1.5-.672 1.5-1.5.0-.414-.168-.789-.439-1.061l-2-2zM17.5 29c-.829.0-1.5.672-1.5 1.5v3c0 .828.671 1.5 1.5 1.5s1.5-.672 1.5-1.5v-3C19 29.672 18.329 29 17.5 29zm0-22C11.71 7 7 11.71 7 17.5S11.71 28 17.5 28 28 23.29 28 17.5 23.29 7 17.5 7zm0 18c-4.136.0-7.5-3.364-7.5-7.5s3.364-7.5 7.5-7.5 7.5 3.364 7.5 7.5S21.636 25 17.5 25z"/></svg></label><label id=toggle-label-dark for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="nightIcon" viewBox="0 0 100 100" style="enable-background='new 0 0 100 100'"><title>Dark Mode</title><path d="M96.76 66.458c-.853-.852-2.15-1.064-3.23-.534-6.063 2.991-12.858 4.571-19.655 4.571C62.022 70.495 50.88 65.88 42.5 57.5 29.043 44.043 25.658 23.536 34.076 6.47c.532-1.08.318-2.379-.534-3.23-.851-.852-2.15-1.064-3.23-.534-4.918 2.427-9.375 5.619-13.246 9.491-9.447 9.447-14.65 22.008-14.65 35.369.0 13.36 5.203 25.921 14.65 35.368s22.008 14.65 35.368 14.65c13.361.0 25.921-5.203 35.369-14.65 3.872-3.871 7.064-8.328 9.491-13.246C97.826 68.608 97.611 67.309 96.76 66.458z"/></svg></label></div></header><article><p class=meta>Last updated
Unknown
<a href=/MySQL/%e5%9f%ba%e7%a1%80/%e6%97%a5%e5%bf%97.md rel=noopener>Edit Source</a></p><ul class=tags></ul><aside class=mainTOC><details open><summary>Table of Contents</summary><nav id=TableOfContents><ol><li><a href=#为什么需要undo-log>为什么需要undo log</a></li><li><a href=#undo-log-得个过程><strong>Undo log 得个过程</strong></a></li><li><a href=#undo-log-格式>Undo log 格式</a></li><li><a href=#undo-log-与-mvcc>Undo log 与 MVCC</a></li></ol><ol><li><a href=#redo-log-和undo-log-的区别><strong>Redo log 和undo log 的区别</strong></a></li><li><a href=#redo-log-要写到磁盘数据也要写磁盘为什么要多此一举><strong>redo log 要写到磁盘，数据也要写磁盘，为什么要多此一举？</strong></a></li><li><a href=#redo-log-什么时候刷盘>redo log 什么时候刷盘</a></li></ol><ol><li><a href=#为啥使用binlog>为啥使用binlog？</a></li><li><a href=#rebo-log-和binlog的区别><strong>Rebo log 和binlog的区别：</strong></a></li><li><a href=#执行器和innodb的update流程>执行器和InnoDB的update流程</a></li><li><a href=#主从复制如何实现>主从复制如何实现</a></li><li><a href=#从库是不是越多越好>从库是不是越多越好</a></li><li><a href=#主从复制模型>主从复制模型</a></li><li><a href=#binlog-什么时候刷盘>binlog 什么时候刷盘？</a><ol><li></li></ol></li></ol><ol><li><a href=#为啥要有两阶段提交>为啥要有两阶段提交</a></li><li><a href=#2-个阶段>2 个阶段</a></li><li><a href=#两阶段提交的过程>两阶段提交的过程</a></li><li><a href=#异常重启>异常重启</a><ol><li></li></ol></li><li><a href=#两阶段提交有什么问题>两阶段提交有什么问题？</a><ol><li></li></ol></li></ol><ol><li><a href=#有-binlog-组提交那有-redo-log-组提交吗>有 binlog 组提交，那有 redo log 组提交吗？</a></li><li><a href=#flush-阶段>flush 阶段</a></li><li><a href=#sync-阶段>sync 阶段</a></li><li><a href=#commit-阶段>commit 阶段</a></li></ol></nav></details></aside><p>Update 的执行过程</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-SQL data-lang=SQL><span class=line><span class=cl><span class=k>UPDATE</span><span class=w> </span><span class=n>t_user</span><span class=w> </span><span class=k>SET</span><span class=w> </span><span class=n>name</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=s1>&#39;xiaolin&#39;</span><span class=w> </span><span class=k>WHERE</span><span class=w> </span><span class=n>id</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=mi>1</span><span class=p>;</span><span class=w>
</span></span></span></code></pre></td></tr></table></div></div><ul><li><p>客户端先通过连接器建立连接，连接器自会判断用户身份；</p></li><li><p>因为这是一条 update 语句，所以不需要经过查询缓存，但是表上有更新语句，是会把整个表的查询缓存清空的，所以说查询缓存很鸡肋，在 MySQL 8.0 就被移除这个功能了；</p></li><li><p>解析器会通过词法分析识别出关键字 update，表名等等，构建出语法树，接着还会做语法分析，判断输入的语句是否符合 MySQL 语法；</p></li><li><p>预处理器会判断表和字段是否存在；</p></li><li><p>优化器确定执行计划，因为 where 条件中的 id 是主键索引，所以决定要使用 id 这个索引；</p></li><li><p>执行器负责具体执行，找到这一行，然后更新。</p></li></ul><p>与查询流程不一样的是，更新流程还涉及三个个重要的日志模块，它们正是我们今天要讨论的主角：<strong>redo log（重做日志）和 binlog（归档日志），undo log（回滚日志）</strong></p><table><thead><tr><th>日志</th><th>作用</th></tr></thead><tbody><tr><td>Redo log（重做日志）</td><td>是 Innodb 存储引擎层生成的日志，实现了事务中的原子性，主要用于事务回滚和 MVCC</td></tr><tr><td>binlog（归档日志）</td><td>是 Innodb 存储引擎层生成的日志，实现了事务中的持久性，主要用于掉电等故障恢复；</td></tr><tr><td>undo log（回滚日志)</td><td>- 用于数据备份和主从复制；</td></tr></tbody></table><a href=#undo-log><h1 id=undo-log><span class=hanchor arialabel=Anchor># </span>Undo log</h1></a><a href=#为什么需要undo-log><h2 id=为什么需要undo-log><span class=hanchor arialabel=Anchor># </span>为什么需要undo log</h2></a><p>一个事务在执行过程中，在还没有提交事务之前，如果MySQL 发生了崩溃，要怎么回滚到事务之前的数据呢?</p><p>每次在事务执行过程中，都记录下回滚时需要的信息到一个日志里，那么在事务执行中途发生了 MySQL 崩溃后，就不用担心无法回滚到事务之前的数据,这就是<strong>undo log（回滚日志）</strong>，它保证了事务的
<a href=https://xiaolincoding.com/mysql/transaction/mvcc.html#%E4%BA%8B%E5%8A%A1%E6%9C%89%E5%93%AA%E4%BA%9B%E7%89%B9%E6%80%A7 rel=noopener>ACID 特性 (opens new window)</a>中的原子性（Atomicity）</p><a href=#undo-log-得个过程><h2 id=undo-log-得个过程><span class=hanchor arialabel=Anchor># </span><strong>Undo log 得个过程</strong></h2></a><p><img src=https://googoo-s.github.io//statistic/asynccode-274.png width=auto alt></p><p>nnoDB 引擎对一条记录进行操作（修改、删除、新增）时，要把回滚时需要的信息都记录到 undo log 里，比如：</p><ul><li><p>在插入一条记录时，要把这条记录的<strong>主键值</strong>记下来，这样之后回滚时只需要把这个主键值对应的记录删掉就好了；</p></li><li><p>在删除一条记录时，要把这条记录中的<strong>内容都</strong>记下来，这样之后回滚时再把由这些内容组成的记录插入到表中就好了；</p></li><li><p>在更新一条记录时，要把被更新的列的<strong>旧值</strong>记下来，这样之后回滚时再把这些列更新为旧值就好了。</p></li></ul><a href=#undo-log-格式><h2 id=undo-log-格式><span class=hanchor arialabel=Anchor># </span>Undo log 格式</h2></a><p>条记录的每一次更新操作产生的 undo log 格式都有一个 roll_pointer 指针和一个 trx_id 事务id：</p><ul><li><p>通过 trx_id 可以知道该记录是被哪个事务修改的；</p></li><li><p>通过 roll_pointer 指针可以将这些 undo log 串成一个链表，这个链表就被称为版本链；</p></li></ul><p>版本链如下图：</p><p><img src=https://googoo-s.github.io//statistic/asynccode-276.png width=auto alt></p><a href=#undo-log-与-mvcc><h2 id=undo-log-与-mvcc><span class=hanchor arialabel=Anchor># </span>Undo log 与 MVCC</h2></a><p>undo log 还有一个作用，通过 ReadView + undo log 实现 MVCC（多版本并发控制）。</p><p>对于「读提交」和「可重复读」隔离级别的事务来说，它们的快照读（普通 select 语句）是通过 Read View + undo log 来实现的，它们的区别在于创建 Read View 的时机不同</p><ul><li><p>「读提交」隔离级别是在每个 select 都会生成一个新的 Read View，也意味着，事务期间的多次读取同一条数据，前后两次读的数据可能会出现不一致，因为可能这期间另外一个事务修改了该记录，并提交了事务。</p></li><li><p>「可重复读」隔离级别是启动事务时生成一个 Read View，然后整个事务期间都在用这个 Read View，这样就保证了在事务期间读到的数据都是事务启动前的记录。</p></li></ul><p>这两个隔离级别实现是通过「事务的 Read View 里的字段」和「记录中的两个隐藏列（trx_id 和 roll_pointer）」的比对，如果不满足可见行，就会顺着 <strong>undo log 版本链</strong>里找到满足其可见性的记录，从而控制并发事务访问同一个记录时的行为，这就叫 MVCC（多版本并发控制）。</p><a href=#redo-log---引擎层><h1 id=redo-log---引擎层><span class=hanchor arialabel=Anchor># </span>redo log &ndash;<strong>引擎层</strong></h1></a><p>Buffer Pool() 是提高了读写效率没错，但是问题来了，<strong>Buffer Pool 是基于内存的，而内存总是不可靠，万一断电重启，还没来得及落盘的脏页数据就会丢失。</strong></p><ul><li><p>redo log 是物理日志，<strong>记录了某个数据页做了什么修改</strong>，比如对 XXX 表空间中的 YYY 数据页 ZZZ 偏移量的地方做了AAA 更新，每当执行一个事务就会产生这样的一条或者多条物理日志。</p></li><li><p>在事务提交时，只要先将 redo log 持久化到磁盘即可，可以不需要等到将缓存在 Buffer Pool 里的脏页数据持久化到磁盘。</p></li><li><p>在内存修改该 Undo 页面后，需要记录对应的 redo log</p></li></ul><a href=#redo-log-和undo-log-的区别><h2 id=redo-log-和undo-log-的区别><span class=hanchor arialabel=Anchor># </span><strong>Redo log 和undo log 的区别</strong></h2></a><ul><li><p>redo log 记录了此次事务「完成后」的数据状态，记录的是更新之后的值；</p></li><li><p>undo log 记录了此次事务「开始前」的数据状态，记录的是更新之前的值；</p></li></ul><p>事务提交之前发生了崩溃，重启后会通过 undo log 回滚事务，事务提交之后发生了崩溃，重启后会通过 redo log 恢复事务，如下图：</p><p><img src=https://googoo-s.github.io//statistic/asynccode-287.png width=auto alt></p><a href=#redo-log-要写到磁盘数据也要写磁盘为什么要多此一举><h2 id=redo-log-要写到磁盘数据也要写磁盘为什么要多此一举><span class=hanchor arialabel=Anchor># </span><strong>redo log 要写到磁盘，数据也要写磁盘，为什么要多此一举？</strong></h2></a><ul><li><p>写入 redo log 的方式使用了追加操作， 所以磁盘操作是顺序写，而写入数据需要先找到写入位置，然后才写到磁盘，所以磁盘操作是随机写。</p></li><li><p>实现事务的持久性，让 MySQL 有 crash-safe 的能力，能够保证 MySQL 在任何时间段突然崩溃，重启后之前已提交的记录都不会丢失；</p></li></ul><p><strong>WAL技术（Write-Ahead Logging）它的关键点就是先写日志，再写磁盘</strong></p><ul><li><p>具体来说，当有一条记录需要更新的时候，InnoDB 引擎就<strong>会先把记录写到 redo log（粉板- redo-buffer-log）里面</strong>，并更新内存，这个时候更新就算完成了。</p></li><li><p>同时，InnoDB 引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做</p></li></ul><p>**InnoDB 的 redo log 是固定大小的，工作在引擎层，**从头开始写，写到末尾就又回到开头循环写</p><p><img src=https://googoo-s.github.io//statistic/asynccode-290.png width=auto alt></p><p>过程：</p><ol><li><p>write pos 是当前记录的位置，一边写一边后移，checkpoint 是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件</p></li><li><p>write pos 和 checkpoint 之间的是“粉板”上还空着的部分，可以用来记录新的操作。如果 write pos 追上 checkpoint，表示“粉板”满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把 checkpoint 推进一下</p><ol><li><p>这个时候MySql 会阻塞</p></li><li><p>会停下来将 Buffer Pool 中的脏页刷新到磁盘中，然后标记 redo log 哪些记录可以被擦除，接着对旧的 redo log 记录进行擦除，等擦除完旧记录腾出了空间，checkpoint 就会往后移动（图中顺时针）</p></li></ol></li></ol><p><strong>有了 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为 crash-safe。</strong></p><p><img src=https://googoo-s.github.io//statistic/asynccode.webp width=auto alt></p><p>redo log buffer 默认大小 16 MB，可以通过 <code>innodb_log_Buffer_size</code> 参数动态的调整大小，增大它的大小可以让 MySQL 处理「大事务」是不必写入磁盘，进而提升写 IO 性能。</p><a href=#redo-log-什么时候刷盘><h2 id=redo-log-什么时候刷盘><span class=hanchor arialabel=Anchor># </span>redo log 什么时候刷盘</h2></a><ul><li><p>MySQL 正常关闭时；</p></li><li><p>当 redo log buffer 中记录的写入量大于 redo log buffer 内存空间的一半时，会触发落盘；</p></li><li><p>InnoDB 的后台线程每隔 1 秒，将 redo log buffer 持久化到磁盘。</p></li><li><p>每次事务提交时都将缓存在 redo log buffer 里的 redo log 直接持久化到磁盘（这个策略可由 innodb_flush_log_at_trx_commit 参数控制，下面会说）。</p><ul><li><p><code>innodb_flush_log_at_trx_commit</code></p><ul><li><p>0:每次事务提交时 ,将 redo log 留在 redo log buffer 中 ，该模式下在事务提交时不会主动触发写入磁盘的操作。</p></li><li><p>1:每次事务提交时，都将缓存在 redo log buffer 里的 redo log 直接持久化到磁盘，这样可以保证 MySQL 异常重启之后数据不会丢失。</p></li><li><p>2:表示每次事务提交时，都只是缓存在 redo log buffer 里的 redo log 写到 redo log 文件，注意写入到「 redo log 文件」并不意味着写入到了磁盘，因为操作系统的文件系统中有个 Page Cache（如果你想了解 Page Cache，可以看
<a href=https://xiaolincoding.com/os/6_file_system/pagecache.html rel=noopener>这篇 (opens new window)</a>），Page Cache 是专门用来缓存文件数据的，所以写入「 redo log文件」意味着写入到了操作系统的文件缓存。</p></li></ul></li></ul></li></ul><p><img src=https://googoo-s.github.io//statistic/asynccode-281.png width=auto alt></p><a href=#binlog---server层><h1 id=binlog---server层><span class=hanchor arialabel=Anchor># </span>binlog &ndash;server层</h1></a><a href=#为啥使用binlog><h2 id=为啥使用binlog><span class=hanchor arialabel=Anchor># </span>为啥使用binlog？</h2></a><ul><li><p>开始 MySQL 里并没有 InnoDB 引擎，MySQL 自带的引擎是 MyISAM</p></li><li><p>MyISAM 没有 crash-safe 的能力，binlog 日志只能用于归档</p></li><li><p>而 InnoDB 是另一个公司以插件形式引入 MySQL 的，既然只依靠 binlog 是没有 crash-safe 能力的</p></li></ul><a href=#rebo-log-和binlog的区别><h2 id=rebo-log-和binlog的区别><span class=hanchor arialabel=Anchor># </span><strong>Rebo log 和binlog的区别：</strong></h2></a><ul><li><p>redo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。</p></li><li><p>redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID=2 这一行的 c 字段加 1 ”,Redo log不是记录数据页“更新之后的状态”，而是记录这个页 “做了什么改动”。</p></li><li><p>Binlog有两种模式，</p><ul><li><p>statement 格式的话是记sql语句，</p></li><li><p>row格式会记录行的内容，记两条，更新前和更新后都有</p></li><li><p>MIXED：包含了 STATEMENT 和 ROW 模式，它会根据不同的情况自动使用 ROW 模式和 STATEMENT 模式；</p></li></ul></li><li><p>redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志</p></li><li><p><em>用途不同：</em></p><ul><li><p>binlog 用于备份恢复、主从复制；·</p></li><li><p>redo log 用于掉电等故障恢复。</p></li></ul></li></ul><a href=#执行器和innodb的update流程><h2 id=执行器和innodb的update流程><span class=hanchor arialabel=Anchor># </span>执行器和InnoDB的update流程</h2></a><p>update T set c=c+1 where ID=2;</p><ol><li><p>执行器先找引擎取 ID=2 这一行，如果 ID=2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。</p></li><li><p>执行器拿到引擎给的行数据，把这个值加上 1，再调用引擎接口写入这行新数据</p></li><li><p>引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。</p></li><li><p>执行器生成这个操作的 binlog，并把 binlog 写入磁盘。</p></li><li><p>执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。</p></li></ol><p><img src=https://googoo-s.github.io//statistic/asynccode-277.png width=auto alt></p><a href=#主从复制如何实现><h2 id=主从复制如何实现><span class=hanchor arialabel=Anchor># </span>主从复制如何实现</h2></a><p>MySQL 的主从复制依赖于 binlog ，也就是记录 MySQL 上的所有变化并以二进制形式保存在磁盘上。复<strong>制的过程就是将 binlog 中的数据从主库传输到从库上。</strong></p><p>这个过程一般是异步的，也就是主库上执行事务操作的线程不会等待复制 binlog 的线程同步完成。</p><p><img src=https://googoo-s.github.io//statistic/asynccode-277.png width=auto alt></p><p>MySQL 集群的主从复制过程梳理成 3 个阶段：</p><ul><li><p>写入 Binlog：主库写 binlog 日志，提交事务，并更新本地存储数据。</p></li><li><p>同步 Binlog：把 binlog 复制到所有从库上，每个从库把 binlog 写到暂存日志中。</p></li><li><p>回放 Binlog：回放 binlog，并更新存储引擎中的数据。</p></li></ul><p>具体详细过程如下：</p><ul><li><p>MySQL 主库在收到客户端提交事务的请求之后，会先写入 binlog，再提交事务，更新存储引擎中的数据，事务提交完成后，返回给客户端“操作成功”的响应。</p></li><li><p>从库会创建一个专门的 I/O 线程，连接主库的 log dump 线程，来接收主库的 binlog 日志，再把 binlog 信息写入 relay log 的中继日志里，再返回给主库“复制成功”的响应。</p></li><li><p>从库会创建一个用于回放 binlog 的线程，去读 relay log 中继日志，然后回放 binlog 更新存储引擎中的数据，最终实现主从的数据一致性。</p></li></ul><p>在完成主从复制之后，你就可以在写数据时只写主库，在读数据时只读从库，这样即使写请求会锁表或者锁记录，也不会影响读请求的执行。</p><p><img src=https://googoo-s.github.io//statistic/asynccode-275.png width=auto alt></p><a href=#从库是不是越多越好><h2 id=从库是不是越多越好><span class=hanchor arialabel=Anchor># </span>从库是不是越多越好</h2></a><p>因为从库数量增加，从库连接上来的 I/O 线程也比较多，主库也要创建同样多的 log dump 线程来处理复制的请求，对主库资源消耗比较高，同时还受限于主库的网络带宽。</p><a href=#主从复制模型><h2 id=主从复制模型><span class=hanchor arialabel=Anchor># </span>主从复制模型</h2></a><ul><li><p>同步复制：MySQL 主库提交事务的线程要<strong>等待所有从库的复制成功响应，才返回客户端结果</strong>。这种方式在实际项目中，基本上没法用，</p><ul><li><p>一是性能很差，因为要复制到所有节点才返回响应；</p></li><li><p>二是可用性也很差，主库和所有从库任何一个数据库出问题，都会影响业务。</p></li></ul></li><li><p>异步复制（默认模型）：MySQL <strong>主库提交事务的线程并不会等待 binlog 同步到各从库，就返回客户端结果。这种模式一旦主库宕机，数据就会发生丢失</strong>。</p></li><li><p>半同步复制：介于两者之间，事务线程不用等待所有的从库复制成功响应，只<strong>要一部分复制成功响应回来就行，比如一主二从的集群，只要数据成功复制到任意一个从库上，主库的事务线程就可以返回给客户端</strong>。</p></li></ul><a href=#binlog-什么时候刷盘><h2 id=binlog-什么时候刷盘><span class=hanchor arialabel=Anchor># </span>binlog 什么时候刷盘？</h2></a><p>事务执行过程中，先把日志写到 binlog cache（Server 层的 cache），事务提交的时候，再把 binlog cache 写到 binlog 文件中。</p><p><strong>一个事务的 binlog 是不能被拆开的，因此无论这个事务有多大</strong>（比如有很多条语句），也要保证一次性写入，这样<strong>如果一个事务的 binlog 被拆开的时候，在备库执行就会被当做多个事务分段自行，这样破坏了原子性，是有问题的。</strong></p><p>MySQL 给每个线程分配了一片内存用于缓冲 binlog ，该内存叫 <strong>binlog cache</strong></p><a href=#什么时候-binlog-cache-会写到-binlog-文件><h4 id=什么时候-binlog-cache-会写到-binlog-文件><span class=hanchor arialabel=Anchor># </span>什么时候 binlog cache 会写到 binlog 文件？</h4></a><p>在事务提交的时候，执行器把 binlog cache 里的完整事务写入到 binlog 文件中，并清空 binlog cache。</p><p><img src=https://googoo-s.github.io//statistic/asynccode-282.png width=auto alt></p><p>虽然每个线程有自己 binlog cache，但是最终都写到同一个 binlog 文件：</p><ul><li><p>图中的 write，指的就是指把日志写入到 binlog 文件，但是并没有把数据持久化到磁盘，因为数据还缓存在文件系统的 page cache 里，write 的写入速度还是比较快的，因为不涉及磁盘 I/O。</p></li><li><p>图中的 fsync，才是将数据持久化到磁盘的操作，这里就会涉及磁盘 I/O，所以频繁的 fsync 会导致磁盘的 I/O 升高。</p></li></ul><p>MySQL提供一个 sync_binlog 参数来控制数据库的 binlog 刷到磁盘上的频率：</p><ul><li><p>sync_binlog = 0 的时候，表示每次提交事务都只 write，不 fsync，后续交由操作系统决定何时将数据持久化到磁盘；</p></li><li><p>sync_binlog = 1 的时候，表示每次提交事务都会 write，然后马上执行 fsync；</p></li><li><p>sync_binlog =N(N>1) 的时候，表示每次提交事务都 write，但累积 N 个事务后才 fsync。</p></li></ul><a href=#两阶段提交><h1 id=两阶段提交><span class=hanchor arialabel=Anchor># </span>两阶段提交</h1></a><a href=#为啥要有两阶段提交><h2 id=为啥要有两阶段提交><span class=hanchor arialabel=Anchor># </span>为啥要有两阶段提交</h2></a><p>redo log 和 binlog 都要持久化到磁盘，但是这两个是独立的逻辑，可能出现半成功的状态，这样就造成<strong>两份日志之间的逻辑不一致。</strong></p><p><strong>两阶段提交的必要性&mdash;使用反证法</strong></p><p>假设当前 ID=2 的行，字段 c 的值是 0，再假设执行 update 语句过程中在写完第一个日志后，第二个日志还没有写完期间发生了 crash</p><ul><li><p>先写 redo log 后写 binlog。假设在 redo log 写完，binlog 还没有写完的时候，MySQL 进程异常重启，redo log 写完之后，系统即使崩溃，仍然能够把数据恢复回来，所以恢复后这一行 c 的值是 1。这时候 binlog 里面就没有记录这个语句。因此，之后备份日志的时候，存起来的 binlog 里面就没有这条语句。，如果需要用这个 binlog 来恢复临时库的话，由于这个语句的 binlog 丢失，这个临时库就会少了这一次更新，恢复出来的这一行 c 的值就是 0</p></li><li><p>先写 binlog 后写 redo log。如果在 binlog 写完之后 crash，由于 redo log 还没写，崩溃恢复以后这个事务无效，所以这一行 c 的值是 0。但是 binlog 里面已经记录了“把 c 从 0 改成 1”这个日志。所以，在之后用 binlog 来恢复的时候就多了一个事务出来，恢复出来的这一行 c 的值就是 1，与原库的值不同</p></li></ul><p>保证了cashe-safe</p><a href=#2-个阶段><h2 id=2-个阶段><span class=hanchor arialabel=Anchor># </span>2 个阶段</h2></a><p>分别是「准备（Prepare）阶段」和「提交（Commit）阶段」，每个阶段都由协调者（Coordinator）和参与者（Participant）共同完成。。</p><p>举个拳击比赛的例子，两位拳击手（参与者）开始比赛之前，裁判（协调者）会在中间确认两位拳击手的状态，类似于问你准备好了吗？</p><ul><li><p>准备阶段：裁判（协调者）会依次询问两位拳击手（参与者）是否准备好了，然后拳击手听到后做出应答，如果觉得自己准备好了，就会跟裁判说准备好了；如果没有自己还没有准备好（比如拳套还没有带好），就会跟裁判说还没准备好。</p></li><li><p>提交阶段：如果两位拳击手（参与者）都回答准备好了，裁判（协调者）宣布比赛正式开始，两位拳击手就可以直接开打；如果任何一位拳击手（参与者）回答没有准备好，裁判（协调者）会宣布比赛暂停，对应事务中的回滚操作。</p></li></ul><a href=#两阶段提交的过程><h2 id=两阶段提交的过程><span class=hanchor arialabel=Anchor># </span>两阶段提交的过程</h2></a><p>MySQL 使用了内部 XA 事务（是的，也有外部 XA 事务，跟本文不太相关，我就不介绍了），<strong>内部 XA 事务由 binlog 作为协调者，存储引擎是参与者</strong></p><p>MySQL 内部开启一个 XA 事务，分两阶段来完成 XA 事务的提交，如下图：</p><p><img src=https://googoo-s.github.io//statistic/asynccode-278.png width=auto alt></p><p>从图中可看出，事务的提交过程有两个阶段，就是将 redo log 的写入拆成了两个步骤：prepare 和 commit，中间再穿插写入binlog，具体如下：</p><ul><li><p>prepare 阶段：将 XID（内部 XA 事务的 ID） 写入到 redo log，同时将 redo log 对应的事务状态设置为 prepare，然后将 redo log 持久化到磁盘（innodb_flush_log_at_trx_commit = 1 的作用）；</p></li><li><p>commit 阶段：把 XID 写入到 binlog，然后将 binlog 持久化到磁盘（sync_binlog = 1 的作用），接着调用引擎的提交事务接口，将 redo log 状态设置为 commit，此时该状态并不需要持久化到磁盘，只需要 write 到文件系统的 page cache 中就够了，因为只要 binlog 写磁盘成功，就算 redo log 的状态还是 prepare 也没有关系，一样会被认为事务已经执行成功；</p></li></ul><a href=#异常重启><h2 id=异常重启><span class=hanchor arialabel=Anchor># </span>异常重启</h2></a><p>下图中有时刻 A 和时刻 B 都有可能发生崩溃：</p><p><img src=https://googoo-s.github.io//statistic/asynccode-279.png width=auto alt></p><p>不管是时刻 A（redo log 已经写入磁盘， binlog 还没写入磁盘），还是时刻 B （redo log 和 binlog 都已经写入磁盘，还没写入 commit 标识）崩溃，此时的 redo log 都处于 prepare 状态。</p><p>在 MySQL 重启后会按顺序扫描 redo log 文件，<strong>碰到处于 prepare 状态的 redo log，就拿着 redo log 中的 XID 去 binlog 查看是否存在此 XID：</strong></p><ul><li><p>如果 binlog 中没有当前内部 XA 事务的 XID，说明 redolog 完成刷盘，但是 binlog 还没有刷盘，则回滚事务。对应时刻 A 崩溃恢复的情况。</p></li><li><p>如果 binlog 中有当前内部 XA 事务的 XID，说明 redolog 和 binlog 都已经完成了刷盘，则提交事务。对应时刻 B 崩溃恢复的情况。</p></li></ul><p>所以说，<strong>两阶段提交是以 binlog 写成功为事务提交成功的标识，因为 binlog 写成功了</strong>，就意味着能在 binlog 中查找到与 redo log 相同的 XID。</p><a href=#处于-prepare-阶段的-redo-log-加上完整-binlog重启就提交事务mysql-为什么要这么设计><h4 id=处于-prepare-阶段的-redo-log-加上完整-binlog重启就提交事务mysql-为什么要这么设计><span class=hanchor arialabel=Anchor># </span><strong>处于 prepare 阶段的 redo log 加上完整 binlog，重启就提交事务，MySQL 为什么要这么设计?</strong></h4></a><p>binlog 已经写入了，之后就会被从库（或者用这个 binlog 恢复出来的库）使用。</p><p>所以，在主库上也要提交这个事务。采用这个策略，主库和备库的数据就保证了一致性。</p><a href=#事务没提交的时候redo-log-会被持久化到磁盘吗><h4 id=事务没提交的时候redo-log-会被持久化到磁盘吗><span class=hanchor arialabel=Anchor># </span>事务没提交的时候，redo log 会被持久化到磁盘吗？</h4></a><p>会的。</p><p>事务执行中间过程的 redo log 也是直接写在 redo log buffer 中的，这些缓存在 redo log buffer 里的 redo log 也会被「后台线程」每隔一秒一起持久化到磁盘。</p><p>也就是说，事务没提交的时候，redo log 也是可能被持久化到磁盘的。</p><a href=#两阶段提交有什么问题><h2 id=两阶段提交有什么问题><span class=hanchor arialabel=Anchor># </span>两阶段提交有什么问题？</h2></a><p>两阶段提交虽然保证了两个日志文件的数据一致性，但是性能很差，主要有两个方面的影响：</p><ul><li><p>磁盘 I/O 次数高：对于“双1”配置，每个事务提交都会进行两次 fsync（刷盘），一次是 redo log 刷盘，另一次是 binlog 刷盘。</p></li><li><p>锁竞争激烈：两阶段提交虽然能够</p><ul><li><p>保证「单事务」两个日志的内容一致，</p></li><li><p>但在「多事务」的情况下，却不能保证两者的提交顺序一致，因此，在两阶段提交的流程基础上，<strong>还需要加一个锁来保证提交的原子性</strong>，从而保证多事务的情况下，两个日志的提交顺序一致。</p></li></ul></li></ul><a href=#为什么两阶段提交的磁盘-io-次数会很高><h4 id=为什么两阶段提交的磁盘-io-次数会很高><span class=hanchor arialabel=Anchor># </span>为什么两阶段提交的磁盘 I/O 次数会很高？</h4></a><p>binlog 和 redo log 在内存中都对应的缓存空间，binlog 会缓存在 binlog cache，redo log 会缓存在 redo log buffer，它们持久化到磁盘的时机分别由下面这两个参数控制。一<strong>般我们为了避免日志丢失的风险，会将这两个参数设置为 1：</strong></p><ul><li><p>当 sync_binlog = 1 的时候，表示每次提交事务都会将 binlog cache 里的 binlog 直接持久到磁盘；</p></li><li><p>当 innodb_flush_log_at_trx_commit = 1 时，表示每次事务提交时，都将缓存在 redo log buffer 里的 redo log 直接持久化到磁盘；</p></li></ul><p>可以看到，如果 sync_binlog 和 当 innodb_flush_log_at_trx_commit 都设置为 1，那么在每个事务提交过程中， 都会至少调用 2 次刷盘操作，一次是 redo log 刷盘，一次是 binlog 落盘，所以这会成为性能瓶颈。</p><a href=#为什么锁竞争激烈><h4 id=为什么锁竞争激烈><span class=hanchor arialabel=Anchor># </span>为什么锁竞争激烈？</h4></a><p>在早期的 MySQL 版本中，通过使用 prepare_commit_mutex 锁来保证事务提交的顺序，<strong>在一个事务获取到锁时才能进入 prepare 阶段，一直到 commit 阶段结束才能释放锁</strong>，下个事务才可以继续进行 prepare 操作。</p><a href=#组提交><h1 id=组提交><span class=hanchor arialabel=Anchor># </span>组提交</h1></a><p>MySQL 引入了 binlog 组提交（group commit）机制，当有多个事务提交的时候，会将多个 binlog 刷盘操作合并成一个，从而减少磁盘 I/O 的次数</p><p>引入了组提交机制后，prepare 阶段不变，只针对 commit 阶段，<strong>将 commit 阶段拆分为三个过程</strong>：</p><ul><li><p>flush 阶段：多个事务按进入的顺序将 binlog 从 cache 写入文件（不刷盘）；</p></li><li><p>sync 阶段：对 binlog 文件做 fsync 操作（多个事务的 binlog 合并一次刷盘）；</p></li><li><p>commit 阶段：各个事务按顺序做 InnoDB commit 操作；</p></li></ul><p>上面的每个阶段都有一个队列，<strong>每个阶段有锁进行保护，因此保证了事务写入的顺序</strong>，第一个进入队列的事务会成为 leader，leader领导所在队列的所有事务，全权负责整队的操作，完成后通知队内其他事务操作结束。</p><p><img src=https://googoo-s.github.io//statistic/asynccode-284.png width=auto alt></p><p>对每个阶段引入了队列后，<strong>锁就只针对每个队列进行保护，不再锁住提交事务的整个过程</strong>，可以看的出来，锁粒度减小了，这样就使得多个阶段可以并发执行，从而提升效率。</p><a href=#有-binlog-组提交那有-redo-log-组提交吗><h2 id=有-binlog-组提交那有-redo-log-组提交吗><span class=hanchor arialabel=Anchor># </span>有 binlog 组提交，那有 redo log 组提交吗？</h2></a><p>这个要看 MySQL 版本，MySQL 5.6 没有 redo log 组提交，MySQL 5.7 有 redo log 组提交。</p><p>所以在 MySQL 5.7 版本中，做了个改进**，在 prepare 阶段不再让事务各自执行 redo log 刷盘操作，而是推迟到组提交的 flush 阶段，也就是说 prepare 阶段融合在了 flush 阶段**。</p><p>这个优化是将 <strong>redo log 的刷盘延迟到了 flush 阶段之中</strong>，sync 阶段之前。通过延迟写 redo log 的方式，为 redolog 做了一次组写入，这样 binlog 和 redo log 都进行了优化。</p><p>接下来介绍每个阶段的过程，注意下面的过程针对的是“双 1” 配置（sync_binlog 和 innodb_flush_log_at_trx_commit 都配置为 1）。</p><a href=#flush-阶段><h2 id=flush-阶段><span class=hanchor arialabel=Anchor># </span>flush 阶段</h2></a><p>第一个事务会成为 flush 阶段的 Leader，此时后面到来的事务都是 Follower ：</p><p><img src=https://googoo-s.github.io//statistic/asynccode-284.png width=auto alt></p><p>接着，获取队列中的事务组，由<strong>绿色事务组的 Leader 对 rodo log 做一次 write + fsyn</strong>c，即一次将同组事务的 redolog 刷盘：</p><p><img src=https://googoo-s.github.io//statistic/asynccode-280.png width=auto alt></p><p>完成了 prepare 阶段后，**将绿色这一组事务执行过程中产生的 binlog 写入 binlog 文件（**调用 write，不会调用 fsync，所以不会刷盘，binlog 缓存在操作系统的文件系统中）。</p><p><img src=https://googoo-s.github.io//statistic/asynccode-280.png width=auto alt></p><p>从上面这个过程，可以知道 <strong>flush 阶段队列的作用是用于支撑 redo log 的组提交</strong>。</p><p>如果在这一步完成后数据库崩溃，由于 binlog 中没有该组事务的记录，所以 MySQL 会在重启后回滚该组事务。</p><a href=#sync-阶段><h2 id=sync-阶段><span class=hanchor arialabel=Anchor># </span>sync 阶段</h2></a><p>绿色这一组事务的 binlog 写入到 binlog 文件后，并**不会马上执行刷盘的操作，而是会等待一段时间，**这个等待的时长由 <code>Binlog_group_commit_sync_delay</code> 参数控制，<strong>目的是为了组合更多事务的 binlog，然后再一起刷盘，如下过程：</strong></p><p><img src=https://googoo-s.github.io//statistic/asynccode-285.png width=auto alt></p><p>不过，<strong>在等待的过程中，如果事务的数量提前达到了</strong> <strong><code>Binlog_group_commit_sync_no_delay_count</code></strong> <strong>参数设置的值，就不用继续等待了，就马上将 binlog 刷盘</strong>，如下图：</p><p><img src=https://googoo-s.github.io//statistic/asynccode-283.png width=auto alt></p><p>从上面的过程，可以知道 s<strong>ync 阶段队列的作用是用于支持 binlog 的组提交</strong>。</p><p>如果想提升 binlog 组提交的效果，可以通过设置下面这两个参数来实现：</p><ul><li><p><code>binlog_group_commit_sync_delay= N</code>，表示在等待 N 微妙后，直接调用 fsync，将处于文件系统中 page cache 中的 binlog 刷盘，也就是将「 binlog 文件」持久化到磁盘。</p></li><li><p><code>binlog_group_commit_sync_no_delay_count = N</code>，表示如果队列中的事务数达到 N 个，就忽视binlog_group_commit_sync_delay 的设置，直接调用 fsync，将处于文件系统中 page cache 中的 binlog 刷盘。</p></li></ul><p>如果在这一步完成后数据库崩溃，由于 binlog 中已经有了事务记录，MySQL会在重启后通过 redo log 刷盘的数据继续进行事务的提交。</p><a href=#commit-阶段><h2 id=commit-阶段><span class=hanchor arialabel=Anchor># </span>commit 阶段</h2></a><p>最后进入 commit 阶段，<strong>调用引擎的提交事务接口，将 redo log 状态设置为 commit。</strong></p><p><img src=https://googoo-s.github.io//statistic/asynccode-286.png width=auto alt></p><p>commit 阶段队列的作用是承接 sync 阶段的事务，完成最后的引擎提交，使得 sync 可以尽早的处理下一组事务，最大化组提交的效率。</p><a href=#update-更新流程><h1 id=update-更新流程><span class=hanchor arialabel=Anchor># </span><strong>Update 更新流程</strong></h1></a><p>具体更新一条记录 <code>UPDATE t_user SET name = 'xiaolin' WHERE id = 1;</code> 的流程如下:</p><ol><li><p>执行器负责具体执行，会调用存储引擎的接口，通过主键索引树搜索获取 id = 1 这一行记录：</p><ol><li><p>如果 id=1 这一行所在的数据页本来就在 buffer pool 中，就直接返回给执行器更新；</p></li><li><p>如果记录不在 buffer pool，将数据页从磁盘读入到 buffer pool，返回记录给执行器。</p></li></ol></li><li><p>执行器得到聚簇索引记录后，会看一下更新前的记录和更新后的记录是否一样：</p><ol><li><p>如果一样的话就不进行后续更新流程；</p></li><li><p>如果不一样的话就把更新前的记录和更新后的记录都当作参数传给 InnoDB 层，让 InnoDB 真正的执行更新记录的操作；</p></li></ol></li><li><p>开启事务， InnoDB 层更新记录前，首先要记录相应的 undo log，因为这是更新操作，需要把被更新的列的旧值记下来，也就是要生成一条 undo log，undo log 会写入 Buffer Pool 中的 Undo 页面，不过在内存修改该 Undo 页面后，需要记录对应的 redo log。</p></li><li><p>InnoDB 层开始更新记录，会先更新内存（同时标记为脏页），然后将记录写到 redo log 里面，这个时候更新就算完成了。为了减少磁盘I/O，不会立即将脏页写入磁盘，后续由后台线程选择一个合适的时机将脏页写入到磁盘。这就是 WAL 技术，MySQL 的写操作并不是立刻写到磁盘上，而是先写 redo 日志，然后在合适的时间再将修改的行数据写到磁盘上。</p></li><li><p>至此，一条记录更新完了。</p></li><li><p>在一条更新语句执行完成后，然后开始记录该语句对应的 binlog，此时记录的 binlog 会被保存到 binlog cache，并没有刷新到硬盘上的 binlog 文件，在事务提交时才会统一将该事务运行过程中的所有 binlog 刷新到硬盘。</p></li><li><p>事务提交（为了方便说明，这里不说组提交的过程，只说两阶段提交）：</p><ol><li><p>prepare 阶段：将 redo log 对应的事务状态设置为 prepare，然后将 redo log 刷新到硬盘；</p></li><li><p>commit 阶段：将 binlog 刷新到磁盘，接着调用引擎的提交事务接口，将 redo log 状态设置为 commit（将事务设置为 commit 状态后，刷入到磁盘 redo log 文件）；</p></li></ol></li><li><p>至此，一条更新语句执行完成。</p></li></ol><a href=#备份周期设置><h1 id=备份周期设置><span class=hanchor arialabel=Anchor># </span>备份周期设置</h1></a><p>首先，是恢复数据丢失的时间，既然需要恢复，肯定是数据丢失了。如果一天一备份的话，只要找到这天的全备，加入这天某段时间的binlog来恢复，如果一周一备份，假设是周一，而你要恢复的数据是周日某个时间点，那就，需要全备+周一到周日某个时间点的全部binlog用来恢复，时间相比前者需要增加很多；看业务能忍受的程度</p><p>其次，是数据库丢失，如果一周一备份的话，需要确保整个一周的binlog都完好无损，否则将无法恢复；而一天一备，只要保证这天的binlog都完好无损；当然这个可以通过校验，或者冗余等技术来实现，相比之下，上面那点更重要</p></article><hr><div class=page-end id=footer><div class=backlinks-container><h3>Backlinks</h3><ul class=backlinks><li>No backlinks found</li></ul></div><div><script src=https://cdn.jsdelivr.net/npm/d3@6.7.0/dist/d3.min.js integrity="sha256-+7jaYCp29O1JusNWHaYtgUn6EhuP0VaFuswhNV06MyI=" crossorigin=anonymous></script><h3>Interactive Graph</h3><div id=graph-container></div><style>:root{--g-node:var(--secondary);--g-node-active:var(--primary);--g-node-inactive:var(--visited);--g-link:var(--outlinegray);--g-link-active:#5a7282}</style><script src=https://googoo-s.github.io/js/graph.6579af7b10c818dbd2ca038702db0224.js></script></div></div><div id=contact_buttons><footer><p>Made by googoo-s using <a href=https://github.com/jackyzha0/quartz>Quartz</a>, © 2023</p><ul><li><a href=https://googoo-s.github.io/>Home</a></li><li><a href=https://github.com/googoo-s>GitHub</a></li></ul></footer></div></div></body></html>